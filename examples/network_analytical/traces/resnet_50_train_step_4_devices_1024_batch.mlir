module @pmap__unnamed_wrapped_function_ attributes {mhlo.num_partitions = 1 : i32, mhlo.num_replicas = 4 : i32} {
  func.func public @main(%arg0: tensor<i32> {mhlo.is_same_data_across_replicas = true}, %arg1: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg2: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg3: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg4: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg5: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg6: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg7: tensor<1x1x64x64xf32> {mhlo.is_same_data_across_replicas = true}, %arg8: tensor<3x3x64x64xf32> {mhlo.is_same_data_across_replicas = true}, %arg9: tensor<1x1x64x256xf32> {mhlo.is_same_data_across_replicas = true}, %arg10: tensor<1x1x64x256xf32> {mhlo.is_same_data_across_replicas = true}, %arg11: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg12: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg13: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg14: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg15: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg16: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg17: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg18: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg19: tensor<1x1x256x64xf32> {mhlo.is_same_data_across_replicas = true}, %arg20: tensor<3x3x64x64xf32> {mhlo.is_same_data_across_replicas = true}, %arg21: tensor<1x1x64x256xf32> {mhlo.is_same_data_across_replicas = true}, %arg22: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg23: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg24: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg25: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg26: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg27: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg28: tensor<1x1x1024x256xf32> {mhlo.is_same_data_across_replicas = true}, %arg29: tensor<3x3x256x256xf32> {mhlo.is_same_data_across_replicas = true}, %arg30: tensor<1x1x256x1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg31: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg32: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg33: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg34: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg35: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg36: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg37: tensor<1x1x1024x256xf32> {mhlo.is_same_data_across_replicas = true}, %arg38: tensor<3x3x256x256xf32> {mhlo.is_same_data_across_replicas = true}, %arg39: tensor<1x1x256x1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg40: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg41: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg42: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg43: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg44: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg45: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg46: tensor<1x1x1024x256xf32> {mhlo.is_same_data_across_replicas = true}, %arg47: tensor<3x3x256x256xf32> {mhlo.is_same_data_across_replicas = true}, %arg48: tensor<1x1x256x1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg49: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg50: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg51: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg52: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg53: tensor<2048xf32> {mhlo.is_same_data_across_replicas = true}, %arg54: tensor<2048xf32> {mhlo.is_same_data_across_replicas = true}, %arg55: tensor<1x1x1024x512xf32> {mhlo.is_same_data_across_replicas = true}, %arg56: tensor<3x3x512x512xf32> {mhlo.is_same_data_across_replicas = true}, %arg57: tensor<1x1x512x2048xf32> {mhlo.is_same_data_across_replicas = true}, %arg58: tensor<1x1x1024x2048xf32> {mhlo.is_same_data_across_replicas = true}, %arg59: tensor<2048xf32> {mhlo.is_same_data_across_replicas = true}, %arg60: tensor<2048xf32> {mhlo.is_same_data_across_replicas = true}, %arg61: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg62: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg63: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg64: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg65: tensor<2048xf32> {mhlo.is_same_data_across_replicas = true}, %arg66: tensor<2048xf32> {mhlo.is_same_data_across_replicas = true}, %arg67: tensor<1x1x2048x512xf32> {mhlo.is_same_data_across_replicas = true}, %arg68: tensor<3x3x512x512xf32> {mhlo.is_same_data_across_replicas = true}, %arg69: tensor<1x1x512x2048xf32> {mhlo.is_same_data_across_replicas = true}, %arg70: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg71: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg72: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg73: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg74: tensor<2048xf32> {mhlo.is_same_data_across_replicas = true}, %arg75: tensor<2048xf32> {mhlo.is_same_data_across_replicas = true}, %arg76: tensor<1x1x2048x512xf32> {mhlo.is_same_data_across_replicas = true}, %arg77: tensor<3x3x512x512xf32> {mhlo.is_same_data_across_replicas = true}, %arg78: tensor<1x1x512x2048xf32> {mhlo.is_same_data_across_replicas = true}, %arg79: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg80: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg81: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg82: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg83: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg84: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg85: tensor<1x1x256x64xf32> {mhlo.is_same_data_across_replicas = true}, %arg86: tensor<3x3x64x64xf32> {mhlo.is_same_data_across_replicas = true}, %arg87: tensor<1x1x64x256xf32> {mhlo.is_same_data_across_replicas = true}, %arg88: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg89: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg90: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg91: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg92: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg93: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg94: tensor<1x1x256x128xf32> {mhlo.is_same_data_across_replicas = true}, %arg95: tensor<3x3x128x128xf32> {mhlo.is_same_data_across_replicas = true}, %arg96: tensor<1x1x128x512xf32> {mhlo.is_same_data_across_replicas = true}, %arg97: tensor<1x1x256x512xf32> {mhlo.is_same_data_across_replicas = true}, %arg98: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg99: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg100: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg101: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg102: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg103: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg104: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg105: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg106: tensor<1x1x512x128xf32> {mhlo.is_same_data_across_replicas = true}, %arg107: tensor<3x3x128x128xf32> {mhlo.is_same_data_across_replicas = true}, %arg108: tensor<1x1x128x512xf32> {mhlo.is_same_data_across_replicas = true}, %arg109: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg110: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg111: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg112: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg113: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg114: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg115: tensor<1x1x512x128xf32> {mhlo.is_same_data_across_replicas = true}, %arg116: tensor<3x3x128x128xf32> {mhlo.is_same_data_across_replicas = true}, %arg117: tensor<1x1x128x512xf32> {mhlo.is_same_data_across_replicas = true}, %arg118: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg119: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg120: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg121: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg122: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg123: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg124: tensor<1x1x512x128xf32> {mhlo.is_same_data_across_replicas = true}, %arg125: tensor<3x3x128x128xf32> {mhlo.is_same_data_across_replicas = true}, %arg126: tensor<1x1x128x512xf32> {mhlo.is_same_data_across_replicas = true}, %arg127: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg128: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg129: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg130: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg131: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg132: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg133: tensor<1x1x512x256xf32> {mhlo.is_same_data_across_replicas = true}, %arg134: tensor<3x3x256x256xf32> {mhlo.is_same_data_across_replicas = true}, %arg135: tensor<1x1x256x1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg136: tensor<1x1x512x1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg137: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg138: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg139: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg140: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg141: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg142: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg143: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg144: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg145: tensor<1x1x1024x256xf32> {mhlo.is_same_data_across_replicas = true}, %arg146: tensor<3x3x256x256xf32> {mhlo.is_same_data_across_replicas = true}, %arg147: tensor<1x1x256x1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg148: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg149: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg150: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg151: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg152: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg153: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg154: tensor<1x1x1024x256xf32> {mhlo.is_same_data_across_replicas = true}, %arg155: tensor<3x3x256x256xf32> {mhlo.is_same_data_across_replicas = true}, %arg156: tensor<1x1x256x1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg157: tensor<1000xf32> {mhlo.is_same_data_across_replicas = true}, %arg158: tensor<2048x1000xf32> {mhlo.is_same_data_across_replicas = true}, %arg159: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg160: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg161: tensor<7x7x3x64xf32> {mhlo.is_same_data_across_replicas = true}, %arg162: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg163: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg164: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg165: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg166: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg167: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg168: tensor<1x1x64x64xf32> {mhlo.is_same_data_across_replicas = true}, %arg169: tensor<3x3x64x64xf32> {mhlo.is_same_data_across_replicas = true}, %arg170: tensor<1x1x64x256xf32> {mhlo.is_same_data_across_replicas = true}, %arg171: tensor<1x1x64x256xf32> {mhlo.is_same_data_across_replicas = true}, %arg172: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg173: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg174: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg175: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg176: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg177: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg178: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg179: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg180: tensor<1x1x256x64xf32> {mhlo.is_same_data_across_replicas = true}, %arg181: tensor<3x3x64x64xf32> {mhlo.is_same_data_across_replicas = true}, %arg182: tensor<1x1x64x256xf32> {mhlo.is_same_data_across_replicas = true}, %arg183: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg184: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg185: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg186: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg187: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg188: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg189: tensor<1x1x1024x256xf32> {mhlo.is_same_data_across_replicas = true}, %arg190: tensor<3x3x256x256xf32> {mhlo.is_same_data_across_replicas = true}, %arg191: tensor<1x1x256x1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg192: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg193: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg194: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg195: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg196: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg197: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg198: tensor<1x1x1024x256xf32> {mhlo.is_same_data_across_replicas = true}, %arg199: tensor<3x3x256x256xf32> {mhlo.is_same_data_across_replicas = true}, %arg200: tensor<1x1x256x1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg201: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg202: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg203: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg204: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg205: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg206: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg207: tensor<1x1x1024x256xf32> {mhlo.is_same_data_across_replicas = true}, %arg208: tensor<3x3x256x256xf32> {mhlo.is_same_data_across_replicas = true}, %arg209: tensor<1x1x256x1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg210: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg211: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg212: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg213: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg214: tensor<2048xf32> {mhlo.is_same_data_across_replicas = true}, %arg215: tensor<2048xf32> {mhlo.is_same_data_across_replicas = true}, %arg216: tensor<1x1x1024x512xf32> {mhlo.is_same_data_across_replicas = true}, %arg217: tensor<3x3x512x512xf32> {mhlo.is_same_data_across_replicas = true}, %arg218: tensor<1x1x512x2048xf32> {mhlo.is_same_data_across_replicas = true}, %arg219: tensor<1x1x1024x2048xf32> {mhlo.is_same_data_across_replicas = true}, %arg220: tensor<2048xf32> {mhlo.is_same_data_across_replicas = true}, %arg221: tensor<2048xf32> {mhlo.is_same_data_across_replicas = true}, %arg222: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg223: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg224: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg225: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg226: tensor<2048xf32> {mhlo.is_same_data_across_replicas = true}, %arg227: tensor<2048xf32> {mhlo.is_same_data_across_replicas = true}, %arg228: tensor<1x1x2048x512xf32> {mhlo.is_same_data_across_replicas = true}, %arg229: tensor<3x3x512x512xf32> {mhlo.is_same_data_across_replicas = true}, %arg230: tensor<1x1x512x2048xf32> {mhlo.is_same_data_across_replicas = true}, %arg231: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg232: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg233: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg234: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg235: tensor<2048xf32> {mhlo.is_same_data_across_replicas = true}, %arg236: tensor<2048xf32> {mhlo.is_same_data_across_replicas = true}, %arg237: tensor<1x1x2048x512xf32> {mhlo.is_same_data_across_replicas = true}, %arg238: tensor<3x3x512x512xf32> {mhlo.is_same_data_across_replicas = true}, %arg239: tensor<1x1x512x2048xf32> {mhlo.is_same_data_across_replicas = true}, %arg240: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg241: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg242: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg243: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg244: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg245: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg246: tensor<1x1x256x64xf32> {mhlo.is_same_data_across_replicas = true}, %arg247: tensor<3x3x64x64xf32> {mhlo.is_same_data_across_replicas = true}, %arg248: tensor<1x1x64x256xf32> {mhlo.is_same_data_across_replicas = true}, %arg249: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg250: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg251: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg252: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg253: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg254: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg255: tensor<1x1x256x128xf32> {mhlo.is_same_data_across_replicas = true}, %arg256: tensor<3x3x128x128xf32> {mhlo.is_same_data_across_replicas = true}, %arg257: tensor<1x1x128x512xf32> {mhlo.is_same_data_across_replicas = true}, %arg258: tensor<1x1x256x512xf32> {mhlo.is_same_data_across_replicas = true}, %arg259: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg260: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg261: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg262: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg263: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg264: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg265: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg266: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg267: tensor<1x1x512x128xf32> {mhlo.is_same_data_across_replicas = true}, %arg268: tensor<3x3x128x128xf32> {mhlo.is_same_data_across_replicas = true}, %arg269: tensor<1x1x128x512xf32> {mhlo.is_same_data_across_replicas = true}, %arg270: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg271: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg272: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg273: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg274: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg275: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg276: tensor<1x1x512x128xf32> {mhlo.is_same_data_across_replicas = true}, %arg277: tensor<3x3x128x128xf32> {mhlo.is_same_data_across_replicas = true}, %arg278: tensor<1x1x128x512xf32> {mhlo.is_same_data_across_replicas = true}, %arg279: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg280: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg281: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg282: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg283: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg284: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg285: tensor<1x1x512x128xf32> {mhlo.is_same_data_across_replicas = true}, %arg286: tensor<3x3x128x128xf32> {mhlo.is_same_data_across_replicas = true}, %arg287: tensor<1x1x128x512xf32> {mhlo.is_same_data_across_replicas = true}, %arg288: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg289: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg290: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg291: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg292: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg293: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg294: tensor<1x1x512x256xf32> {mhlo.is_same_data_across_replicas = true}, %arg295: tensor<3x3x256x256xf32> {mhlo.is_same_data_across_replicas = true}, %arg296: tensor<1x1x256x1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg297: tensor<1x1x512x1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg298: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg299: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg300: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg301: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg302: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg303: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg304: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg305: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg306: tensor<1x1x1024x256xf32> {mhlo.is_same_data_across_replicas = true}, %arg307: tensor<3x3x256x256xf32> {mhlo.is_same_data_across_replicas = true}, %arg308: tensor<1x1x256x1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg309: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg310: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg311: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg312: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg313: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg314: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg315: tensor<1x1x1024x256xf32> {mhlo.is_same_data_across_replicas = true}, %arg316: tensor<3x3x256x256xf32> {mhlo.is_same_data_across_replicas = true}, %arg317: tensor<1x1x256x1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg318: tensor<1000xf32> {mhlo.is_same_data_across_replicas = true}, %arg319: tensor<2048x1000xf32> {mhlo.is_same_data_across_replicas = true}, %arg320: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg321: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg322: tensor<7x7x3x64xf32> {mhlo.is_same_data_across_replicas = true}, %arg323: tensor<i32> {mhlo.is_same_data_across_replicas = true}, %arg324: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg325: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg326: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg327: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg328: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg329: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg330: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg331: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg332: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg333: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg334: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg335: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg336: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg337: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg338: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg339: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg340: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg341: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg342: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg343: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg344: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg345: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg346: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg347: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg348: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg349: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg350: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg351: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg352: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg353: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg354: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg355: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg356: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg357: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg358: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg359: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg360: tensor<2048xf32> {mhlo.is_same_data_across_replicas = true}, %arg361: tensor<2048xf32> {mhlo.is_same_data_across_replicas = true}, %arg362: tensor<2048xf32> {mhlo.is_same_data_across_replicas = true}, %arg363: tensor<2048xf32> {mhlo.is_same_data_across_replicas = true}, %arg364: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg365: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg366: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg367: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg368: tensor<2048xf32> {mhlo.is_same_data_across_replicas = true}, %arg369: tensor<2048xf32> {mhlo.is_same_data_across_replicas = true}, %arg370: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg371: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg372: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg373: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg374: tensor<2048xf32> {mhlo.is_same_data_across_replicas = true}, %arg375: tensor<2048xf32> {mhlo.is_same_data_across_replicas = true}, %arg376: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg377: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg378: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg379: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg380: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg381: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg382: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg383: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg384: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg385: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg386: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg387: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg388: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg389: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg390: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg391: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg392: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg393: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg394: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg395: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg396: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg397: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg398: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg399: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg400: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg401: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg402: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg403: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg404: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg405: tensor<128xf32> {mhlo.is_same_data_across_replicas = true}, %arg406: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg407: tensor<512xf32> {mhlo.is_same_data_across_replicas = true}, %arg408: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg409: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg410: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg411: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg412: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg413: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg414: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg415: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg416: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg417: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg418: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg419: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg420: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg421: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg422: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg423: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg424: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg425: tensor<256xf32> {mhlo.is_same_data_across_replicas = true}, %arg426: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg427: tensor<1024xf32> {mhlo.is_same_data_across_replicas = true}, %arg428: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg429: tensor<64xf32> {mhlo.is_same_data_across_replicas = true}, %arg430: tensor<1x256x224x224x3xf16>, %arg431: tensor<1x256xi32>) -> (tensor<i32> {jax.result_info = "[0].step"}, tensor<64xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_0']['BatchNorm_0']['bias']"}, tensor<64xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_0']['BatchNorm_0']['scale']"}, tensor<64xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_0']['BatchNorm_1']['bias']"}, tensor<64xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_0']['BatchNorm_1']['scale']"}, tensor<256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_0']['BatchNorm_2']['bias']"}, tensor<256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_0']['BatchNorm_2']['scale']"}, tensor<1x1x64x64xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_0']['Conv_0']['kernel']"}, tensor<3x3x64x64xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_0']['Conv_1']['kernel']"}, tensor<1x1x64x256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_0']['Conv_2']['kernel']"}, tensor<1x1x64x256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_0']['conv_proj']['kernel']"}, tensor<256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_0']['norm_proj']['bias']"}, tensor<256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_0']['norm_proj']['scale']"}, tensor<64xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_1']['BatchNorm_0']['bias']"}, tensor<64xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_1']['BatchNorm_0']['scale']"}, tensor<64xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_1']['BatchNorm_1']['bias']"}, tensor<64xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_1']['BatchNorm_1']['scale']"}, tensor<256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_1']['BatchNorm_2']['bias']"}, tensor<256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_1']['BatchNorm_2']['scale']"}, tensor<1x1x256x64xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_1']['Conv_0']['kernel']"}, tensor<3x3x64x64xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_1']['Conv_1']['kernel']"}, tensor<1x1x64x256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_1']['Conv_2']['kernel']"}, tensor<256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_10']['BatchNorm_0']['bias']"}, tensor<256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_10']['BatchNorm_0']['scale']"}, tensor<256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_10']['BatchNorm_1']['bias']"}, tensor<256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_10']['BatchNorm_1']['scale']"}, tensor<1024xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_10']['BatchNorm_2']['bias']"}, tensor<1024xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_10']['BatchNorm_2']['scale']"}, tensor<1x1x1024x256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_10']['Conv_0']['kernel']"}, tensor<3x3x256x256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_10']['Conv_1']['kernel']"}, tensor<1x1x256x1024xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_10']['Conv_2']['kernel']"}, tensor<256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_11']['BatchNorm_0']['bias']"}, tensor<256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_11']['BatchNorm_0']['scale']"}, tensor<256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_11']['BatchNorm_1']['bias']"}, tensor<256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_11']['BatchNorm_1']['scale']"}, tensor<1024xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_11']['BatchNorm_2']['bias']"}, tensor<1024xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_11']['BatchNorm_2']['scale']"}, tensor<1x1x1024x256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_11']['Conv_0']['kernel']"}, tensor<3x3x256x256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_11']['Conv_1']['kernel']"}, tensor<1x1x256x1024xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_11']['Conv_2']['kernel']"}, tensor<256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_12']['BatchNorm_0']['bias']"}, tensor<256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_12']['BatchNorm_0']['scale']"}, tensor<256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_12']['BatchNorm_1']['bias']"}, tensor<256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_12']['BatchNorm_1']['scale']"}, tensor<1024xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_12']['BatchNorm_2']['bias']"}, tensor<1024xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_12']['BatchNorm_2']['scale']"}, tensor<1x1x1024x256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_12']['Conv_0']['kernel']"}, tensor<3x3x256x256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_12']['Conv_1']['kernel']"}, tensor<1x1x256x1024xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_12']['Conv_2']['kernel']"}, tensor<512xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_13']['BatchNorm_0']['bias']"}, tensor<512xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_13']['BatchNorm_0']['scale']"}, tensor<512xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_13']['BatchNorm_1']['bias']"}, tensor<512xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_13']['BatchNorm_1']['scale']"}, tensor<2048xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_13']['BatchNorm_2']['bias']"}, tensor<2048xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_13']['BatchNorm_2']['scale']"}, tensor<1x1x1024x512xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_13']['Conv_0']['kernel']"}, tensor<3x3x512x512xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_13']['Conv_1']['kernel']"}, tensor<1x1x512x2048xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_13']['Conv_2']['kernel']"}, tensor<1x1x1024x2048xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_13']['conv_proj']['kernel']"}, tensor<2048xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_13']['norm_proj']['bias']"}, tensor<2048xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_13']['norm_proj']['scale']"}, tensor<512xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_14']['BatchNorm_0']['bias']"}, tensor<512xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_14']['BatchNorm_0']['scale']"}, tensor<512xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_14']['BatchNorm_1']['bias']"}, tensor<512xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_14']['BatchNorm_1']['scale']"}, tensor<2048xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_14']['BatchNorm_2']['bias']"}, tensor<2048xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_14']['BatchNorm_2']['scale']"}, tensor<1x1x2048x512xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_14']['Conv_0']['kernel']"}, tensor<3x3x512x512xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_14']['Conv_1']['kernel']"}, tensor<1x1x512x2048xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_14']['Conv_2']['kernel']"}, tensor<512xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_15']['BatchNorm_0']['bias']"}, tensor<512xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_15']['BatchNorm_0']['scale']"}, tensor<512xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_15']['BatchNorm_1']['bias']"}, tensor<512xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_15']['BatchNorm_1']['scale']"}, tensor<2048xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_15']['BatchNorm_2']['bias']"}, tensor<2048xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_15']['BatchNorm_2']['scale']"}, tensor<1x1x2048x512xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_15']['Conv_0']['kernel']"}, tensor<3x3x512x512xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_15']['Conv_1']['kernel']"}, tensor<1x1x512x2048xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_15']['Conv_2']['kernel']"}, tensor<64xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_2']['BatchNorm_0']['bias']"}, tensor<64xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_2']['BatchNorm_0']['scale']"}, tensor<64xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_2']['BatchNorm_1']['bias']"}, tensor<64xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_2']['BatchNorm_1']['scale']"}, tensor<256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_2']['BatchNorm_2']['bias']"}, tensor<256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_2']['BatchNorm_2']['scale']"}, tensor<1x1x256x64xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_2']['Conv_0']['kernel']"}, tensor<3x3x64x64xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_2']['Conv_1']['kernel']"}, tensor<1x1x64x256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_2']['Conv_2']['kernel']"}, tensor<128xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_3']['BatchNorm_0']['bias']"}, tensor<128xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_3']['BatchNorm_0']['scale']"}, tensor<128xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_3']['BatchNorm_1']['bias']"}, tensor<128xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_3']['BatchNorm_1']['scale']"}, tensor<512xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_3']['BatchNorm_2']['bias']"}, tensor<512xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_3']['BatchNorm_2']['scale']"}, tensor<1x1x256x128xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_3']['Conv_0']['kernel']"}, tensor<3x3x128x128xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_3']['Conv_1']['kernel']"}, tensor<1x1x128x512xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_3']['Conv_2']['kernel']"}, tensor<1x1x256x512xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_3']['conv_proj']['kernel']"}, tensor<512xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_3']['norm_proj']['bias']"}, tensor<512xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_3']['norm_proj']['scale']"}, tensor<128xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_4']['BatchNorm_0']['bias']"}, tensor<128xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_4']['BatchNorm_0']['scale']"}, tensor<128xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_4']['BatchNorm_1']['bias']"}, tensor<128xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_4']['BatchNorm_1']['scale']"}, tensor<512xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_4']['BatchNorm_2']['bias']"}, tensor<512xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_4']['BatchNorm_2']['scale']"}, tensor<1x1x512x128xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_4']['Conv_0']['kernel']"}, tensor<3x3x128x128xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_4']['Conv_1']['kernel']"}, tensor<1x1x128x512xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_4']['Conv_2']['kernel']"}, tensor<128xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_5']['BatchNorm_0']['bias']"}, tensor<128xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_5']['BatchNorm_0']['scale']"}, tensor<128xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_5']['BatchNorm_1']['bias']"}, tensor<128xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_5']['BatchNorm_1']['scale']"}, tensor<512xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_5']['BatchNorm_2']['bias']"}, tensor<512xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_5']['BatchNorm_2']['scale']"}, tensor<1x1x512x128xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_5']['Conv_0']['kernel']"}, tensor<3x3x128x128xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_5']['Conv_1']['kernel']"}, tensor<1x1x128x512xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_5']['Conv_2']['kernel']"}, tensor<128xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_6']['BatchNorm_0']['bias']"}, tensor<128xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_6']['BatchNorm_0']['scale']"}, tensor<128xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_6']['BatchNorm_1']['bias']"}, tensor<128xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_6']['BatchNorm_1']['scale']"}, tensor<512xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_6']['BatchNorm_2']['bias']"}, tensor<512xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_6']['BatchNorm_2']['scale']"}, tensor<1x1x512x128xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_6']['Conv_0']['kernel']"}, tensor<3x3x128x128xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_6']['Conv_1']['kernel']"}, tensor<1x1x128x512xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_6']['Conv_2']['kernel']"}, tensor<256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_7']['BatchNorm_0']['bias']"}, tensor<256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_7']['BatchNorm_0']['scale']"}, tensor<256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_7']['BatchNorm_1']['bias']"}, tensor<256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_7']['BatchNorm_1']['scale']"}, tensor<1024xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_7']['BatchNorm_2']['bias']"}, tensor<1024xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_7']['BatchNorm_2']['scale']"}, tensor<1x1x512x256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_7']['Conv_0']['kernel']"}, tensor<3x3x256x256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_7']['Conv_1']['kernel']"}, tensor<1x1x256x1024xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_7']['Conv_2']['kernel']"}, tensor<1x1x512x1024xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_7']['conv_proj']['kernel']"}, tensor<1024xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_7']['norm_proj']['bias']"}, tensor<1024xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_7']['norm_proj']['scale']"}, tensor<256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_8']['BatchNorm_0']['bias']"}, tensor<256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_8']['BatchNorm_0']['scale']"}, tensor<256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_8']['BatchNorm_1']['bias']"}, tensor<256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_8']['BatchNorm_1']['scale']"}, tensor<1024xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_8']['BatchNorm_2']['bias']"}, tensor<1024xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_8']['BatchNorm_2']['scale']"}, tensor<1x1x1024x256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_8']['Conv_0']['kernel']"}, tensor<3x3x256x256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_8']['Conv_1']['kernel']"}, tensor<1x1x256x1024xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_8']['Conv_2']['kernel']"}, tensor<256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_9']['BatchNorm_0']['bias']"}, tensor<256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_9']['BatchNorm_0']['scale']"}, tensor<256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_9']['BatchNorm_1']['bias']"}, tensor<256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_9']['BatchNorm_1']['scale']"}, tensor<1024xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_9']['BatchNorm_2']['bias']"}, tensor<1024xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_9']['BatchNorm_2']['scale']"}, tensor<1x1x1024x256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_9']['Conv_0']['kernel']"}, tensor<3x3x256x256xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_9']['Conv_1']['kernel']"}, tensor<1x1x256x1024xf32> {jax.result_info = "[0].params['BottleneckResNetBlock_9']['Conv_2']['kernel']"}, tensor<1000xf32> {jax.result_info = "[0].params['Dense_0']['bias']"}, tensor<2048x1000xf32> {jax.result_info = "[0].params['Dense_0']['kernel']"}, tensor<64xf32> {jax.result_info = "[0].params['bn_init']['bias']"}, tensor<64xf32> {jax.result_info = "[0].params['bn_init']['scale']"}, tensor<7x7x3x64xf32> {jax.result_info = "[0].params['conv_init']['kernel']"}, tensor<64xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_0']['BatchNorm_0']['bias']"}, tensor<64xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_0']['BatchNorm_0']['scale']"}, tensor<64xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_0']['BatchNorm_1']['bias']"}, tensor<64xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_0']['BatchNorm_1']['scale']"}, tensor<256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_0']['BatchNorm_2']['bias']"}, tensor<256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_0']['BatchNorm_2']['scale']"}, tensor<1x1x64x64xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_0']['Conv_0']['kernel']"}, tensor<3x3x64x64xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_0']['Conv_1']['kernel']"}, tensor<1x1x64x256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_0']['Conv_2']['kernel']"}, tensor<1x1x64x256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_0']['conv_proj']['kernel']"}, tensor<256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_0']['norm_proj']['bias']"}, tensor<256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_0']['norm_proj']['scale']"}, tensor<64xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_1']['BatchNorm_0']['bias']"}, tensor<64xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_1']['BatchNorm_0']['scale']"}, tensor<64xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_1']['BatchNorm_1']['bias']"}, tensor<64xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_1']['BatchNorm_1']['scale']"}, tensor<256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_1']['BatchNorm_2']['bias']"}, tensor<256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_1']['BatchNorm_2']['scale']"}, tensor<1x1x256x64xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_1']['Conv_0']['kernel']"}, tensor<3x3x64x64xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_1']['Conv_1']['kernel']"}, tensor<1x1x64x256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_1']['Conv_2']['kernel']"}, tensor<256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_10']['BatchNorm_0']['bias']"}, tensor<256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_10']['BatchNorm_0']['scale']"}, tensor<256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_10']['BatchNorm_1']['bias']"}, tensor<256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_10']['BatchNorm_1']['scale']"}, tensor<1024xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_10']['BatchNorm_2']['bias']"}, tensor<1024xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_10']['BatchNorm_2']['scale']"}, tensor<1x1x1024x256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_10']['Conv_0']['kernel']"}, tensor<3x3x256x256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_10']['Conv_1']['kernel']"}, tensor<1x1x256x1024xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_10']['Conv_2']['kernel']"}, tensor<256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_11']['BatchNorm_0']['bias']"}, tensor<256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_11']['BatchNorm_0']['scale']"}, tensor<256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_11']['BatchNorm_1']['bias']"}, tensor<256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_11']['BatchNorm_1']['scale']"}, tensor<1024xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_11']['BatchNorm_2']['bias']"}, tensor<1024xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_11']['BatchNorm_2']['scale']"}, tensor<1x1x1024x256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_11']['Conv_0']['kernel']"}, tensor<3x3x256x256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_11']['Conv_1']['kernel']"}, tensor<1x1x256x1024xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_11']['Conv_2']['kernel']"}, tensor<256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_12']['BatchNorm_0']['bias']"}, tensor<256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_12']['BatchNorm_0']['scale']"}, tensor<256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_12']['BatchNorm_1']['bias']"}, tensor<256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_12']['BatchNorm_1']['scale']"}, tensor<1024xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_12']['BatchNorm_2']['bias']"}, tensor<1024xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_12']['BatchNorm_2']['scale']"}, tensor<1x1x1024x256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_12']['Conv_0']['kernel']"}, tensor<3x3x256x256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_12']['Conv_1']['kernel']"}, tensor<1x1x256x1024xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_12']['Conv_2']['kernel']"}, tensor<512xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_13']['BatchNorm_0']['bias']"}, tensor<512xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_13']['BatchNorm_0']['scale']"}, tensor<512xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_13']['BatchNorm_1']['bias']"}, tensor<512xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_13']['BatchNorm_1']['scale']"}, tensor<2048xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_13']['BatchNorm_2']['bias']"}, tensor<2048xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_13']['BatchNorm_2']['scale']"}, tensor<1x1x1024x512xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_13']['Conv_0']['kernel']"}, tensor<3x3x512x512xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_13']['Conv_1']['kernel']"}, tensor<1x1x512x2048xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_13']['Conv_2']['kernel']"}, tensor<1x1x1024x2048xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_13']['conv_proj']['kernel']"}, tensor<2048xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_13']['norm_proj']['bias']"}, tensor<2048xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_13']['norm_proj']['scale']"}, tensor<512xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_14']['BatchNorm_0']['bias']"}, tensor<512xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_14']['BatchNorm_0']['scale']"}, tensor<512xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_14']['BatchNorm_1']['bias']"}, tensor<512xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_14']['BatchNorm_1']['scale']"}, tensor<2048xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_14']['BatchNorm_2']['bias']"}, tensor<2048xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_14']['BatchNorm_2']['scale']"}, tensor<1x1x2048x512xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_14']['Conv_0']['kernel']"}, tensor<3x3x512x512xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_14']['Conv_1']['kernel']"}, tensor<1x1x512x2048xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_14']['Conv_2']['kernel']"}, tensor<512xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_15']['BatchNorm_0']['bias']"}, tensor<512xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_15']['BatchNorm_0']['scale']"}, tensor<512xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_15']['BatchNorm_1']['bias']"}, tensor<512xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_15']['BatchNorm_1']['scale']"}, tensor<2048xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_15']['BatchNorm_2']['bias']"}, tensor<2048xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_15']['BatchNorm_2']['scale']"}, tensor<1x1x2048x512xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_15']['Conv_0']['kernel']"}, tensor<3x3x512x512xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_15']['Conv_1']['kernel']"}, tensor<1x1x512x2048xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_15']['Conv_2']['kernel']"}, tensor<64xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_2']['BatchNorm_0']['bias']"}, tensor<64xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_2']['BatchNorm_0']['scale']"}, tensor<64xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_2']['BatchNorm_1']['bias']"}, tensor<64xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_2']['BatchNorm_1']['scale']"}, tensor<256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_2']['BatchNorm_2']['bias']"}, tensor<256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_2']['BatchNorm_2']['scale']"}, tensor<1x1x256x64xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_2']['Conv_0']['kernel']"}, tensor<3x3x64x64xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_2']['Conv_1']['kernel']"}, tensor<1x1x64x256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_2']['Conv_2']['kernel']"}, tensor<128xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_3']['BatchNorm_0']['bias']"}, tensor<128xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_3']['BatchNorm_0']['scale']"}, tensor<128xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_3']['BatchNorm_1']['bias']"}, tensor<128xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_3']['BatchNorm_1']['scale']"}, tensor<512xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_3']['BatchNorm_2']['bias']"}, tensor<512xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_3']['BatchNorm_2']['scale']"}, tensor<1x1x256x128xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_3']['Conv_0']['kernel']"}, tensor<3x3x128x128xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_3']['Conv_1']['kernel']"}, tensor<1x1x128x512xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_3']['Conv_2']['kernel']"}, tensor<1x1x256x512xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_3']['conv_proj']['kernel']"}, tensor<512xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_3']['norm_proj']['bias']"}, tensor<512xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_3']['norm_proj']['scale']"}, tensor<128xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_4']['BatchNorm_0']['bias']"}, tensor<128xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_4']['BatchNorm_0']['scale']"}, tensor<128xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_4']['BatchNorm_1']['bias']"}, tensor<128xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_4']['BatchNorm_1']['scale']"}, tensor<512xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_4']['BatchNorm_2']['bias']"}, tensor<512xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_4']['BatchNorm_2']['scale']"}, tensor<1x1x512x128xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_4']['Conv_0']['kernel']"}, tensor<3x3x128x128xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_4']['Conv_1']['kernel']"}, tensor<1x1x128x512xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_4']['Conv_2']['kernel']"}, tensor<128xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_5']['BatchNorm_0']['bias']"}, tensor<128xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_5']['BatchNorm_0']['scale']"}, tensor<128xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_5']['BatchNorm_1']['bias']"}, tensor<128xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_5']['BatchNorm_1']['scale']"}, tensor<512xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_5']['BatchNorm_2']['bias']"}, tensor<512xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_5']['BatchNorm_2']['scale']"}, tensor<1x1x512x128xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_5']['Conv_0']['kernel']"}, tensor<3x3x128x128xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_5']['Conv_1']['kernel']"}, tensor<1x1x128x512xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_5']['Conv_2']['kernel']"}, tensor<128xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_6']['BatchNorm_0']['bias']"}, tensor<128xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_6']['BatchNorm_0']['scale']"}, tensor<128xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_6']['BatchNorm_1']['bias']"}, tensor<128xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_6']['BatchNorm_1']['scale']"}, tensor<512xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_6']['BatchNorm_2']['bias']"}, tensor<512xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_6']['BatchNorm_2']['scale']"}, tensor<1x1x512x128xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_6']['Conv_0']['kernel']"}, tensor<3x3x128x128xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_6']['Conv_1']['kernel']"}, tensor<1x1x128x512xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_6']['Conv_2']['kernel']"}, tensor<256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_7']['BatchNorm_0']['bias']"}, tensor<256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_7']['BatchNorm_0']['scale']"}, tensor<256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_7']['BatchNorm_1']['bias']"}, tensor<256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_7']['BatchNorm_1']['scale']"}, tensor<1024xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_7']['BatchNorm_2']['bias']"}, tensor<1024xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_7']['BatchNorm_2']['scale']"}, tensor<1x1x512x256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_7']['Conv_0']['kernel']"}, tensor<3x3x256x256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_7']['Conv_1']['kernel']"}, tensor<1x1x256x1024xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_7']['Conv_2']['kernel']"}, tensor<1x1x512x1024xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_7']['conv_proj']['kernel']"}, tensor<1024xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_7']['norm_proj']['bias']"}, tensor<1024xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_7']['norm_proj']['scale']"}, tensor<256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_8']['BatchNorm_0']['bias']"}, tensor<256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_8']['BatchNorm_0']['scale']"}, tensor<256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_8']['BatchNorm_1']['bias']"}, tensor<256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_8']['BatchNorm_1']['scale']"}, tensor<1024xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_8']['BatchNorm_2']['bias']"}, tensor<1024xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_8']['BatchNorm_2']['scale']"}, tensor<1x1x1024x256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_8']['Conv_0']['kernel']"}, tensor<3x3x256x256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_8']['Conv_1']['kernel']"}, tensor<1x1x256x1024xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_8']['Conv_2']['kernel']"}, tensor<256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_9']['BatchNorm_0']['bias']"}, tensor<256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_9']['BatchNorm_0']['scale']"}, tensor<256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_9']['BatchNorm_1']['bias']"}, tensor<256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_9']['BatchNorm_1']['scale']"}, tensor<1024xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_9']['BatchNorm_2']['bias']"}, tensor<1024xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_9']['BatchNorm_2']['scale']"}, tensor<1x1x1024x256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_9']['Conv_0']['kernel']"}, tensor<3x3x256x256xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_9']['Conv_1']['kernel']"}, tensor<1x1x256x1024xf32> {jax.result_info = "[0].opt_state[0].trace['BottleneckResNetBlock_9']['Conv_2']['kernel']"}, tensor<1000xf32> {jax.result_info = "[0].opt_state[0].trace['Dense_0']['bias']"}, tensor<2048x1000xf32> {jax.result_info = "[0].opt_state[0].trace['Dense_0']['kernel']"}, tensor<64xf32> {jax.result_info = "[0].opt_state[0].trace['bn_init']['bias']"}, tensor<64xf32> {jax.result_info = "[0].opt_state[0].trace['bn_init']['scale']"}, tensor<7x7x3x64xf32> {jax.result_info = "[0].opt_state[0].trace['conv_init']['kernel']"}, tensor<i32> {jax.result_info = "[0].opt_state[1].count"}, tensor<64xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_0']['BatchNorm_0']['mean']"}, tensor<64xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_0']['BatchNorm_0']['var']"}, tensor<64xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_0']['BatchNorm_1']['mean']"}, tensor<64xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_0']['BatchNorm_1']['var']"}, tensor<256xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_0']['BatchNorm_2']['mean']"}, tensor<256xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_0']['BatchNorm_2']['var']"}, tensor<256xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_0']['norm_proj']['mean']"}, tensor<256xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_0']['norm_proj']['var']"}, tensor<64xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_1']['BatchNorm_0']['mean']"}, tensor<64xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_1']['BatchNorm_0']['var']"}, tensor<64xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_1']['BatchNorm_1']['mean']"}, tensor<64xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_1']['BatchNorm_1']['var']"}, tensor<256xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_1']['BatchNorm_2']['mean']"}, tensor<256xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_1']['BatchNorm_2']['var']"}, tensor<256xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_10']['BatchNorm_0']['mean']"}, tensor<256xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_10']['BatchNorm_0']['var']"}, tensor<256xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_10']['BatchNorm_1']['mean']"}, tensor<256xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_10']['BatchNorm_1']['var']"}, tensor<1024xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_10']['BatchNorm_2']['mean']"}, tensor<1024xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_10']['BatchNorm_2']['var']"}, tensor<256xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_11']['BatchNorm_0']['mean']"}, tensor<256xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_11']['BatchNorm_0']['var']"}, tensor<256xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_11']['BatchNorm_1']['mean']"}, tensor<256xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_11']['BatchNorm_1']['var']"}, tensor<1024xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_11']['BatchNorm_2']['mean']"}, tensor<1024xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_11']['BatchNorm_2']['var']"}, tensor<256xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_12']['BatchNorm_0']['mean']"}, tensor<256xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_12']['BatchNorm_0']['var']"}, tensor<256xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_12']['BatchNorm_1']['mean']"}, tensor<256xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_12']['BatchNorm_1']['var']"}, tensor<1024xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_12']['BatchNorm_2']['mean']"}, tensor<1024xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_12']['BatchNorm_2']['var']"}, tensor<512xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_13']['BatchNorm_0']['mean']"}, tensor<512xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_13']['BatchNorm_0']['var']"}, tensor<512xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_13']['BatchNorm_1']['mean']"}, tensor<512xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_13']['BatchNorm_1']['var']"}, tensor<2048xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_13']['BatchNorm_2']['mean']"}, tensor<2048xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_13']['BatchNorm_2']['var']"}, tensor<2048xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_13']['norm_proj']['mean']"}, tensor<2048xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_13']['norm_proj']['var']"}, tensor<512xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_14']['BatchNorm_0']['mean']"}, tensor<512xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_14']['BatchNorm_0']['var']"}, tensor<512xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_14']['BatchNorm_1']['mean']"}, tensor<512xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_14']['BatchNorm_1']['var']"}, tensor<2048xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_14']['BatchNorm_2']['mean']"}, tensor<2048xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_14']['BatchNorm_2']['var']"}, tensor<512xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_15']['BatchNorm_0']['mean']"}, tensor<512xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_15']['BatchNorm_0']['var']"}, tensor<512xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_15']['BatchNorm_1']['mean']"}, tensor<512xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_15']['BatchNorm_1']['var']"}, tensor<2048xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_15']['BatchNorm_2']['mean']"}, tensor<2048xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_15']['BatchNorm_2']['var']"}, tensor<64xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_2']['BatchNorm_0']['mean']"}, tensor<64xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_2']['BatchNorm_0']['var']"}, tensor<64xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_2']['BatchNorm_1']['mean']"}, tensor<64xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_2']['BatchNorm_1']['var']"}, tensor<256xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_2']['BatchNorm_2']['mean']"}, tensor<256xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_2']['BatchNorm_2']['var']"}, tensor<128xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_3']['BatchNorm_0']['mean']"}, tensor<128xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_3']['BatchNorm_0']['var']"}, tensor<128xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_3']['BatchNorm_1']['mean']"}, tensor<128xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_3']['BatchNorm_1']['var']"}, tensor<512xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_3']['BatchNorm_2']['mean']"}, tensor<512xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_3']['BatchNorm_2']['var']"}, tensor<512xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_3']['norm_proj']['mean']"}, tensor<512xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_3']['norm_proj']['var']"}, tensor<128xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_4']['BatchNorm_0']['mean']"}, tensor<128xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_4']['BatchNorm_0']['var']"}, tensor<128xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_4']['BatchNorm_1']['mean']"}, tensor<128xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_4']['BatchNorm_1']['var']"}, tensor<512xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_4']['BatchNorm_2']['mean']"}, tensor<512xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_4']['BatchNorm_2']['var']"}, tensor<128xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_5']['BatchNorm_0']['mean']"}, tensor<128xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_5']['BatchNorm_0']['var']"}, tensor<128xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_5']['BatchNorm_1']['mean']"}, tensor<128xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_5']['BatchNorm_1']['var']"}, tensor<512xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_5']['BatchNorm_2']['mean']"}, tensor<512xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_5']['BatchNorm_2']['var']"}, tensor<128xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_6']['BatchNorm_0']['mean']"}, tensor<128xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_6']['BatchNorm_0']['var']"}, tensor<128xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_6']['BatchNorm_1']['mean']"}, tensor<128xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_6']['BatchNorm_1']['var']"}, tensor<512xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_6']['BatchNorm_2']['mean']"}, tensor<512xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_6']['BatchNorm_2']['var']"}, tensor<256xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_7']['BatchNorm_0']['mean']"}, tensor<256xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_7']['BatchNorm_0']['var']"}, tensor<256xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_7']['BatchNorm_1']['mean']"}, tensor<256xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_7']['BatchNorm_1']['var']"}, tensor<1024xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_7']['BatchNorm_2']['mean']"}, tensor<1024xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_7']['BatchNorm_2']['var']"}, tensor<1024xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_7']['norm_proj']['mean']"}, tensor<1024xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_7']['norm_proj']['var']"}, tensor<256xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_8']['BatchNorm_0']['mean']"}, tensor<256xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_8']['BatchNorm_0']['var']"}, tensor<256xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_8']['BatchNorm_1']['mean']"}, tensor<256xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_8']['BatchNorm_1']['var']"}, tensor<1024xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_8']['BatchNorm_2']['mean']"}, tensor<1024xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_8']['BatchNorm_2']['var']"}, tensor<256xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_9']['BatchNorm_0']['mean']"}, tensor<256xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_9']['BatchNorm_0']['var']"}, tensor<256xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_9']['BatchNorm_1']['mean']"}, tensor<256xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_9']['BatchNorm_1']['var']"}, tensor<1024xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_9']['BatchNorm_2']['mean']"}, tensor<1024xf32> {jax.result_info = "[0].batch_stats['BottleneckResNetBlock_9']['BatchNorm_2']['var']"}, tensor<64xf32> {jax.result_info = "[0].batch_stats['bn_init']['mean']"}, tensor<64xf32> {jax.result_info = "[0].batch_stats['bn_init']['var']"}, tensor<1xf32> {jax.result_info = "[1]['accuracy']"}, tensor<1xf32> {jax.result_info = "[1]['learning_rate']"}, tensor<1xf32> {jax.result_info = "[1]['loss']"}) {
    %0 = stablehlo.reshape %arg430 : (tensor<1x256x224x224x3xf16>) -> tensor<256x224x224x3xf16>
    %1 = stablehlo.reshape %arg431 : (tensor<1x256xi32>) -> tensor<256xi32>
    %c = stablehlo.constant dense<0> : tensor<i32>
    %2 = stablehlo.subtract %arg0, %c : tensor<i32>
    %cst = stablehlo.constant dense<5.000000e+02> : tensor<f32>
    %3 = call @clip(%2, %c, %cst) : (tensor<i32>, tensor<i32>, tensor<f32>) -> tensor<f32>
    %4 = stablehlo.divide %3, %cst : tensor<f32>
    %cst_0 = stablehlo.constant dense<1.000000e+00> : tensor<f32>
    %5 = stablehlo.subtract %cst_0, %4 : tensor<f32>
    %cst_1 = stablehlo.constant dense<-4.000000e-01> : tensor<f32>
    %6 = stablehlo.multiply %cst_1, %5 : tensor<f32>
    %cst_2 = stablehlo.constant dense<4.000000e-01> : tensor<f32>
    %7 = stablehlo.add %6, %cst_2 : tensor<f32>
    %8 = stablehlo.convert %arg0 : (tensor<i32>) -> tensor<f32>
    %9 = stablehlo.compare  LT, %8, %cst,  FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
    %10 = stablehlo.convert %arg0 : (tensor<i32>) -> tensor<f32>
    %11 = stablehlo.subtract %10, %cst : tensor<f32>
    %cst_3 = stablehlo.constant dense<1.000000e+02> : tensor<f32>
    %12 = stablehlo.minimum %11, %cst_3 : tensor<f32>
    %cst_4 = stablehlo.constant dense<3.14159274> : tensor<f32>
    %13 = stablehlo.multiply %cst_4, %12 : tensor<f32>
    %14 = stablehlo.divide %13, %cst_3 : tensor<f32>
    %15 = stablehlo.cosine %14 : tensor<f32>
    %16 = stablehlo.add %cst_0, %15 : tensor<f32>
    %cst_5 = stablehlo.constant dense<5.000000e-01> : tensor<f32>
    %17 = stablehlo.multiply %cst_5, %16 : tensor<f32>
    %18 = stablehlo.power %17, %cst_0 : tensor<f32>
    %19 = stablehlo.multiply %cst_0, %18 : tensor<f32>
    %cst_6 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %20 = stablehlo.add %19, %cst_6 : tensor<f32>
    %21 = stablehlo.multiply %cst_2, %20 : tensor<f32>
    %22 = call @_where(%9, %7, %21) : (tensor<i1>, tensor<f32>, tensor<f32>) -> tensor<f32>
    %23 = stablehlo.convert %arg161 : (tensor<7x7x3x64xf32>) -> tensor<7x7x3x64xf16>
    %24 = stablehlo.convolution(%0, %23) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [2, 2], pad = [[3, 3], [3, 3]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x224x224x3xf16>, tensor<7x7x3x64xf16>) -> tensor<256x112x112x64xf16>
    %25 = stablehlo.convert %24 : (tensor<256x112x112x64xf16>) -> tensor<256x112x112x64xf32>
    %26 = stablehlo.multiply %25, %25 : tensor<256x112x112x64xf32>
    %cst_7 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %27 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x112x112x64xf32>
    %28 = stablehlo.multiply %27, %25 : tensor<256x112x112x64xf32>
    %cst_8 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %29 = stablehlo.reduce(%25 init: %cst_8) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x112x112x64xf32>, tensor<f32>) -> tensor<64xf32>
    %cst_9 = stablehlo.constant dense<0x4A440000> : tensor<f32>
    %30 = stablehlo.broadcast_in_dim %cst_9, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %31 = stablehlo.divide %29, %30 : tensor<64xf32>
    %cst_10 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %32 = stablehlo.reduce(%26 init: %cst_10) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x112x112x64xf32>, tensor<f32>) -> tensor<64xf32>
    %33 = stablehlo.broadcast_in_dim %cst_9, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %34 = stablehlo.divide %32, %33 : tensor<64xf32>
    %35 = stablehlo.broadcast_in_dim %31, dims = [1] : (tensor<64xf32>) -> tensor<1x64xf32>
    %36 = stablehlo.broadcast_in_dim %34, dims = [1] : (tensor<64xf32>) -> tensor<1x64xf32>
    %37 = stablehlo.concatenate %35, %36, dim = 0 : (tensor<1x64xf32>, tensor<1x64xf32>) -> tensor<2x64xf32>
    %38 = "stablehlo.all_reduce"(%37) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x64xf32>) -> tensor<2x64xf32>
    %cst_11 = stablehlo.constant dense<4.000000e+00> : tensor<f32>
    %39 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x64xf32>
    %40 = stablehlo.divide %38, %39 : tensor<2x64xf32>
    %41 = stablehlo.slice %40 [0:1, 0:64] : (tensor<2x64xf32>) -> tensor<1x64xf32>
    %42 = stablehlo.reshape %41 : (tensor<1x64xf32>) -> tensor<64xf32>
    %43 = stablehlo.slice %40 [1:2, 0:64] : (tensor<2x64xf32>) -> tensor<1x64xf32>
    %44 = stablehlo.reshape %43 : (tensor<1x64xf32>) -> tensor<64xf32>
    %45 = stablehlo.multiply %42, %42 : tensor<64xf32>
    %46 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %47 = stablehlo.multiply %46, %42 : tensor<64xf32>
    %48 = stablehlo.subtract %44, %45 : tensor<64xf32>
    %cst_12 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %49 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %50 = stablehlo.maximum %49, %48 : tensor<64xf32>
    %51 = stablehlo.compare  EQ, %48, %50,  FLOAT : (tensor<64xf32>, tensor<64xf32>) -> tensor<64xi1>
    %cst_13 = stablehlo.constant dense<1.000000e+00> : tensor<f32>
    %52 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %53 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %54 = stablehlo.select %51, %52, %53 : tensor<64xi1>, tensor<64xf32>
    %55 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %56 = stablehlo.compare  EQ, %55, %50,  FLOAT : (tensor<64xf32>, tensor<64xf32>) -> tensor<64xi1>
    %57 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %58 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %59 = stablehlo.select %56, %57, %58 : tensor<64xi1>, tensor<64xf32>
    %60 = stablehlo.divide %54, %59 : tensor<64xf32>
    %cst_14 = stablehlo.constant dense<0.899999976> : tensor<f32>
    %61 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %62 = stablehlo.multiply %61, %arg428 : tensor<64xf32>
    %cst_15 = stablehlo.constant dense<1.000000e-01> : tensor<f32>
    %63 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %64 = stablehlo.multiply %63, %42 : tensor<64xf32>
    %65 = stablehlo.add %62, %64 : tensor<64xf32>
    %66 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %67 = stablehlo.multiply %66, %arg429 : tensor<64xf32>
    %68 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %69 = stablehlo.multiply %68, %50 : tensor<64xf32>
    %70 = stablehlo.add %67, %69 : tensor<64xf32>
    %71 = stablehlo.broadcast_in_dim %42, dims = [3] : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %72 = stablehlo.broadcast_in_dim %50, dims = [3] : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %73 = stablehlo.convert %24 : (tensor<256x112x112x64xf16>) -> tensor<256x112x112x64xf32>
    %74 = stablehlo.broadcast_in_dim %71, dims = [0, 1, 2, 3] : (tensor<1x1x1x64xf32>) -> tensor<256x112x112x64xf32>
    %75 = stablehlo.subtract %73, %74 : tensor<256x112x112x64xf32>
    %cst_16 = stablehlo.constant dense<9.99999974E-6> : tensor<f32>
    %76 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x64xf32>
    %77 = stablehlo.add %72, %76 : tensor<1x1x1x64xf32>
    %78 = stablehlo.rsqrt %77 : tensor<1x1x1x64xf32>
    %79 = stablehlo.divide %78, %77 : tensor<1x1x1x64xf32>
    %cst_17 = stablehlo.constant dense<-5.000000e-01> : tensor<f32>
    %80 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x64xf32>
    %81 = stablehlo.multiply %80, %79 : tensor<1x1x1x64xf32>
    %82 = stablehlo.reshape %arg160 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %83 = stablehlo.multiply %78, %82 : tensor<1x1x1x64xf32>
    %84 = stablehlo.broadcast_in_dim %83, dims = [0, 1, 2, 3] : (tensor<1x1x1x64xf32>) -> tensor<256x112x112x64xf32>
    %85 = stablehlo.multiply %75, %84 : tensor<256x112x112x64xf32>
    %86 = stablehlo.reshape %arg159 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %87 = stablehlo.broadcast_in_dim %86, dims = [0, 1, 2, 3] : (tensor<1x1x1x64xf32>) -> tensor<256x112x112x64xf32>
    %88 = stablehlo.add %85, %87 : tensor<256x112x112x64xf32>
    %89 = stablehlo.convert %88 : (tensor<256x112x112x64xf32>) -> tensor<256x112x112x64xf16>
    %90 = call @relu(%89) : (tensor<256x112x112x64xf16>) -> tensor<256x112x112x64xf16>
    %cst_18 = stablehlo.constant dense<0.000000e+00> : tensor<f16>
    %91 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x112x112x64xf16>
    %92 = stablehlo.compare  GT, %89, %91,  FLOAT : (tensor<256x112x112x64xf16>, tensor<256x112x112x64xf16>) -> tensor<256x112x112x64xi1>
    %93 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x112x112x64xf16>
    %cst_19 = stablehlo.constant dense<0xFC00> : tensor<f16>
    %94 = stablehlo.broadcast_in_dim %cst_19, dims = [] : (tensor<f16>) -> tensor<f16>
    %95 = "stablehlo.reduce_window"(%90, %94) <{base_dilations = array<i64: 1, 1, 1, 1>, padding = dense<[[0, 0], [0, 1], [0, 1], [0, 0]]> : tensor<4x2xi64>, window_dilations = array<i64: 1, 1, 1, 1>, window_dimensions = array<i64: 1, 3, 3, 1>, window_strides = array<i64: 1, 2, 2, 1>}> ({
    ^bb0(%arg432: tensor<f16>, %arg433: tensor<f16>):
      %9450 = stablehlo.maximum %arg432, %arg433 : tensor<f16>
      stablehlo.return %9450 : tensor<f16>
    }) : (tensor<256x112x112x64xf16>, tensor<f16>) -> tensor<256x56x56x64xf16>
    %96 = stablehlo.convert %arg7 : (tensor<1x1x64x64xf32>) -> tensor<1x1x64x64xf16>
    %97 = stablehlo.convolution(%95, %96) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x64xf16>, tensor<1x1x64x64xf16>) -> tensor<256x56x56x64xf16>
    %98 = stablehlo.convert %97 : (tensor<256x56x56x64xf16>) -> tensor<256x56x56x64xf32>
    %99 = stablehlo.multiply %98, %98 : tensor<256x56x56x64xf32>
    %100 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x56x56x64xf32>
    %101 = stablehlo.multiply %100, %98 : tensor<256x56x56x64xf32>
    %cst_20 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %102 = stablehlo.reduce(%98 init: %cst_20) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x64xf32>, tensor<f32>) -> tensor<64xf32>
    %cst_21 = stablehlo.constant dense<8.028160e+05> : tensor<f32>
    %103 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %104 = stablehlo.divide %102, %103 : tensor<64xf32>
    %cst_22 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %105 = stablehlo.reduce(%99 init: %cst_22) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x64xf32>, tensor<f32>) -> tensor<64xf32>
    %106 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %107 = stablehlo.divide %105, %106 : tensor<64xf32>
    %108 = stablehlo.broadcast_in_dim %104, dims = [1] : (tensor<64xf32>) -> tensor<1x64xf32>
    %109 = stablehlo.broadcast_in_dim %107, dims = [1] : (tensor<64xf32>) -> tensor<1x64xf32>
    %110 = stablehlo.concatenate %108, %109, dim = 0 : (tensor<1x64xf32>, tensor<1x64xf32>) -> tensor<2x64xf32>
    %111 = "stablehlo.all_reduce"(%110) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x64xf32>) -> tensor<2x64xf32>
    %112 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x64xf32>
    %113 = stablehlo.divide %111, %112 : tensor<2x64xf32>
    %114 = stablehlo.slice %113 [0:1, 0:64] : (tensor<2x64xf32>) -> tensor<1x64xf32>
    %115 = stablehlo.reshape %114 : (tensor<1x64xf32>) -> tensor<64xf32>
    %116 = stablehlo.slice %113 [1:2, 0:64] : (tensor<2x64xf32>) -> tensor<1x64xf32>
    %117 = stablehlo.reshape %116 : (tensor<1x64xf32>) -> tensor<64xf32>
    %118 = stablehlo.multiply %115, %115 : tensor<64xf32>
    %119 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %120 = stablehlo.multiply %119, %115 : tensor<64xf32>
    %121 = stablehlo.subtract %117, %118 : tensor<64xf32>
    %122 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %123 = stablehlo.maximum %122, %121 : tensor<64xf32>
    %124 = stablehlo.compare  EQ, %121, %123,  FLOAT : (tensor<64xf32>, tensor<64xf32>) -> tensor<64xi1>
    %125 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %126 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %127 = stablehlo.select %124, %125, %126 : tensor<64xi1>, tensor<64xf32>
    %128 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %129 = stablehlo.compare  EQ, %128, %123,  FLOAT : (tensor<64xf32>, tensor<64xf32>) -> tensor<64xi1>
    %130 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %131 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %132 = stablehlo.select %129, %130, %131 : tensor<64xi1>, tensor<64xf32>
    %133 = stablehlo.divide %127, %132 : tensor<64xf32>
    %134 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %135 = stablehlo.multiply %134, %arg324 : tensor<64xf32>
    %136 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %137 = stablehlo.multiply %136, %115 : tensor<64xf32>
    %138 = stablehlo.add %135, %137 : tensor<64xf32>
    %139 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %140 = stablehlo.multiply %139, %arg325 : tensor<64xf32>
    %141 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %142 = stablehlo.multiply %141, %123 : tensor<64xf32>
    %143 = stablehlo.add %140, %142 : tensor<64xf32>
    %144 = stablehlo.broadcast_in_dim %115, dims = [3] : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %145 = stablehlo.broadcast_in_dim %123, dims = [3] : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %146 = stablehlo.convert %97 : (tensor<256x56x56x64xf16>) -> tensor<256x56x56x64xf32>
    %147 = stablehlo.broadcast_in_dim %144, dims = [0, 1, 2, 3] : (tensor<1x1x1x64xf32>) -> tensor<256x56x56x64xf32>
    %148 = stablehlo.subtract %146, %147 : tensor<256x56x56x64xf32>
    %149 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x64xf32>
    %150 = stablehlo.add %145, %149 : tensor<1x1x1x64xf32>
    %151 = stablehlo.rsqrt %150 : tensor<1x1x1x64xf32>
    %152 = stablehlo.divide %151, %150 : tensor<1x1x1x64xf32>
    %153 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x64xf32>
    %154 = stablehlo.multiply %153, %152 : tensor<1x1x1x64xf32>
    %155 = stablehlo.reshape %arg2 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %156 = stablehlo.multiply %151, %155 : tensor<1x1x1x64xf32>
    %157 = stablehlo.broadcast_in_dim %156, dims = [0, 1, 2, 3] : (tensor<1x1x1x64xf32>) -> tensor<256x56x56x64xf32>
    %158 = stablehlo.multiply %148, %157 : tensor<256x56x56x64xf32>
    %159 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %160 = stablehlo.broadcast_in_dim %159, dims = [0, 1, 2, 3] : (tensor<1x1x1x64xf32>) -> tensor<256x56x56x64xf32>
    %161 = stablehlo.add %158, %160 : tensor<256x56x56x64xf32>
    %162 = stablehlo.convert %161 : (tensor<256x56x56x64xf32>) -> tensor<256x56x56x64xf16>
    %163 = call @relu_0(%162) : (tensor<256x56x56x64xf16>) -> tensor<256x56x56x64xf16>
    %164 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x56x56x64xf16>
    %165 = stablehlo.compare  GT, %162, %164,  FLOAT : (tensor<256x56x56x64xf16>, tensor<256x56x56x64xf16>) -> tensor<256x56x56x64xi1>
    %166 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x56x56x64xf16>
    %167 = stablehlo.convert %arg8 : (tensor<3x3x64x64xf32>) -> tensor<3x3x64x64xf16>
    %168 = stablehlo.convolution(%163, %167) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x64xf16>, tensor<3x3x64x64xf16>) -> tensor<256x56x56x64xf16>
    %169 = stablehlo.convert %168 : (tensor<256x56x56x64xf16>) -> tensor<256x56x56x64xf32>
    %170 = stablehlo.multiply %169, %169 : tensor<256x56x56x64xf32>
    %171 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x56x56x64xf32>
    %172 = stablehlo.multiply %171, %169 : tensor<256x56x56x64xf32>
    %cst_23 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %173 = stablehlo.reduce(%169 init: %cst_23) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x64xf32>, tensor<f32>) -> tensor<64xf32>
    %174 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %175 = stablehlo.divide %173, %174 : tensor<64xf32>
    %cst_24 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %176 = stablehlo.reduce(%170 init: %cst_24) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x64xf32>, tensor<f32>) -> tensor<64xf32>
    %177 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %178 = stablehlo.divide %176, %177 : tensor<64xf32>
    %179 = stablehlo.broadcast_in_dim %175, dims = [1] : (tensor<64xf32>) -> tensor<1x64xf32>
    %180 = stablehlo.broadcast_in_dim %178, dims = [1] : (tensor<64xf32>) -> tensor<1x64xf32>
    %181 = stablehlo.concatenate %179, %180, dim = 0 : (tensor<1x64xf32>, tensor<1x64xf32>) -> tensor<2x64xf32>
    %182 = "stablehlo.all_reduce"(%181) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x64xf32>) -> tensor<2x64xf32>
    %183 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x64xf32>
    %184 = stablehlo.divide %182, %183 : tensor<2x64xf32>
    %185 = stablehlo.slice %184 [0:1, 0:64] : (tensor<2x64xf32>) -> tensor<1x64xf32>
    %186 = stablehlo.reshape %185 : (tensor<1x64xf32>) -> tensor<64xf32>
    %187 = stablehlo.slice %184 [1:2, 0:64] : (tensor<2x64xf32>) -> tensor<1x64xf32>
    %188 = stablehlo.reshape %187 : (tensor<1x64xf32>) -> tensor<64xf32>
    %189 = stablehlo.multiply %186, %186 : tensor<64xf32>
    %190 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %191 = stablehlo.multiply %190, %186 : tensor<64xf32>
    %192 = stablehlo.subtract %188, %189 : tensor<64xf32>
    %193 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %194 = stablehlo.maximum %193, %192 : tensor<64xf32>
    %195 = stablehlo.compare  EQ, %192, %194,  FLOAT : (tensor<64xf32>, tensor<64xf32>) -> tensor<64xi1>
    %196 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %197 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %198 = stablehlo.select %195, %196, %197 : tensor<64xi1>, tensor<64xf32>
    %199 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %200 = stablehlo.compare  EQ, %199, %194,  FLOAT : (tensor<64xf32>, tensor<64xf32>) -> tensor<64xi1>
    %201 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %202 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %203 = stablehlo.select %200, %201, %202 : tensor<64xi1>, tensor<64xf32>
    %204 = stablehlo.divide %198, %203 : tensor<64xf32>
    %205 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %206 = stablehlo.multiply %205, %arg326 : tensor<64xf32>
    %207 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %208 = stablehlo.multiply %207, %186 : tensor<64xf32>
    %209 = stablehlo.add %206, %208 : tensor<64xf32>
    %210 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %211 = stablehlo.multiply %210, %arg327 : tensor<64xf32>
    %212 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %213 = stablehlo.multiply %212, %194 : tensor<64xf32>
    %214 = stablehlo.add %211, %213 : tensor<64xf32>
    %215 = stablehlo.broadcast_in_dim %186, dims = [3] : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %216 = stablehlo.broadcast_in_dim %194, dims = [3] : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %217 = stablehlo.convert %168 : (tensor<256x56x56x64xf16>) -> tensor<256x56x56x64xf32>
    %218 = stablehlo.broadcast_in_dim %215, dims = [0, 1, 2, 3] : (tensor<1x1x1x64xf32>) -> tensor<256x56x56x64xf32>
    %219 = stablehlo.subtract %217, %218 : tensor<256x56x56x64xf32>
    %220 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x64xf32>
    %221 = stablehlo.add %216, %220 : tensor<1x1x1x64xf32>
    %222 = stablehlo.rsqrt %221 : tensor<1x1x1x64xf32>
    %223 = stablehlo.divide %222, %221 : tensor<1x1x1x64xf32>
    %224 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x64xf32>
    %225 = stablehlo.multiply %224, %223 : tensor<1x1x1x64xf32>
    %226 = stablehlo.reshape %arg4 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %227 = stablehlo.multiply %222, %226 : tensor<1x1x1x64xf32>
    %228 = stablehlo.broadcast_in_dim %227, dims = [0, 1, 2, 3] : (tensor<1x1x1x64xf32>) -> tensor<256x56x56x64xf32>
    %229 = stablehlo.multiply %219, %228 : tensor<256x56x56x64xf32>
    %230 = stablehlo.reshape %arg3 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %231 = stablehlo.broadcast_in_dim %230, dims = [0, 1, 2, 3] : (tensor<1x1x1x64xf32>) -> tensor<256x56x56x64xf32>
    %232 = stablehlo.add %229, %231 : tensor<256x56x56x64xf32>
    %233 = stablehlo.convert %232 : (tensor<256x56x56x64xf32>) -> tensor<256x56x56x64xf16>
    %234 = call @relu_0(%233) : (tensor<256x56x56x64xf16>) -> tensor<256x56x56x64xf16>
    %235 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x56x56x64xf16>
    %236 = stablehlo.compare  GT, %233, %235,  FLOAT : (tensor<256x56x56x64xf16>, tensor<256x56x56x64xf16>) -> tensor<256x56x56x64xi1>
    %237 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x56x56x64xf16>
    %238 = stablehlo.convert %arg9 : (tensor<1x1x64x256xf32>) -> tensor<1x1x64x256xf16>
    %239 = stablehlo.convolution(%234, %238) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x64xf16>, tensor<1x1x64x256xf16>) -> tensor<256x56x56x256xf16>
    %240 = stablehlo.convert %239 : (tensor<256x56x56x256xf16>) -> tensor<256x56x56x256xf32>
    %241 = stablehlo.multiply %240, %240 : tensor<256x56x56x256xf32>
    %242 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x56x56x256xf32>
    %243 = stablehlo.multiply %242, %240 : tensor<256x56x56x256xf32>
    %cst_25 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %244 = stablehlo.reduce(%240 init: %cst_25) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x256xf32>, tensor<f32>) -> tensor<256xf32>
    %245 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %246 = stablehlo.divide %244, %245 : tensor<256xf32>
    %cst_26 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %247 = stablehlo.reduce(%241 init: %cst_26) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x256xf32>, tensor<f32>) -> tensor<256xf32>
    %248 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %249 = stablehlo.divide %247, %248 : tensor<256xf32>
    %250 = stablehlo.broadcast_in_dim %246, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %251 = stablehlo.broadcast_in_dim %249, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %252 = stablehlo.concatenate %250, %251, dim = 0 : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<2x256xf32>
    %253 = "stablehlo.all_reduce"(%252) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x256xf32>) -> tensor<2x256xf32>
    %254 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x256xf32>
    %255 = stablehlo.divide %253, %254 : tensor<2x256xf32>
    %256 = stablehlo.slice %255 [0:1, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %257 = stablehlo.reshape %256 : (tensor<1x256xf32>) -> tensor<256xf32>
    %258 = stablehlo.slice %255 [1:2, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %259 = stablehlo.reshape %258 : (tensor<1x256xf32>) -> tensor<256xf32>
    %260 = stablehlo.multiply %257, %257 : tensor<256xf32>
    %261 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %262 = stablehlo.multiply %261, %257 : tensor<256xf32>
    %263 = stablehlo.subtract %259, %260 : tensor<256xf32>
    %264 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %265 = stablehlo.maximum %264, %263 : tensor<256xf32>
    %266 = stablehlo.compare  EQ, %263, %265,  FLOAT : (tensor<256xf32>, tensor<256xf32>) -> tensor<256xi1>
    %267 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %268 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %269 = stablehlo.select %266, %267, %268 : tensor<256xi1>, tensor<256xf32>
    %270 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %271 = stablehlo.compare  EQ, %270, %265,  FLOAT : (tensor<256xf32>, tensor<256xf32>) -> tensor<256xi1>
    %272 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %273 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %274 = stablehlo.select %271, %272, %273 : tensor<256xi1>, tensor<256xf32>
    %275 = stablehlo.divide %269, %274 : tensor<256xf32>
    %276 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %277 = stablehlo.multiply %276, %arg328 : tensor<256xf32>
    %278 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %279 = stablehlo.multiply %278, %257 : tensor<256xf32>
    %280 = stablehlo.add %277, %279 : tensor<256xf32>
    %281 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %282 = stablehlo.multiply %281, %arg329 : tensor<256xf32>
    %283 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %284 = stablehlo.multiply %283, %265 : tensor<256xf32>
    %285 = stablehlo.add %282, %284 : tensor<256xf32>
    %286 = stablehlo.broadcast_in_dim %257, dims = [3] : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %287 = stablehlo.broadcast_in_dim %265, dims = [3] : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %288 = stablehlo.convert %239 : (tensor<256x56x56x256xf16>) -> tensor<256x56x56x256xf32>
    %289 = stablehlo.broadcast_in_dim %286, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x56x56x256xf32>
    %290 = stablehlo.subtract %288, %289 : tensor<256x56x56x256xf32>
    %291 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x256xf32>
    %292 = stablehlo.add %287, %291 : tensor<1x1x1x256xf32>
    %293 = stablehlo.rsqrt %292 : tensor<1x1x1x256xf32>
    %294 = stablehlo.divide %293, %292 : tensor<1x1x1x256xf32>
    %295 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x256xf32>
    %296 = stablehlo.multiply %295, %294 : tensor<1x1x1x256xf32>
    %297 = stablehlo.reshape %arg6 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %298 = stablehlo.multiply %293, %297 : tensor<1x1x1x256xf32>
    %299 = stablehlo.broadcast_in_dim %298, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x56x56x256xf32>
    %300 = stablehlo.multiply %290, %299 : tensor<256x56x56x256xf32>
    %301 = stablehlo.reshape %arg5 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %302 = stablehlo.broadcast_in_dim %301, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x56x56x256xf32>
    %303 = stablehlo.add %300, %302 : tensor<256x56x56x256xf32>
    %304 = stablehlo.convert %303 : (tensor<256x56x56x256xf32>) -> tensor<256x56x56x256xf16>
    %305 = stablehlo.convert %arg10 : (tensor<1x1x64x256xf32>) -> tensor<1x1x64x256xf16>
    %306 = stablehlo.convolution(%95, %305) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x64xf16>, tensor<1x1x64x256xf16>) -> tensor<256x56x56x256xf16>
    %307 = stablehlo.convert %306 : (tensor<256x56x56x256xf16>) -> tensor<256x56x56x256xf32>
    %308 = stablehlo.multiply %307, %307 : tensor<256x56x56x256xf32>
    %309 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x56x56x256xf32>
    %310 = stablehlo.multiply %309, %307 : tensor<256x56x56x256xf32>
    %cst_27 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %311 = stablehlo.reduce(%307 init: %cst_27) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x256xf32>, tensor<f32>) -> tensor<256xf32>
    %312 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %313 = stablehlo.divide %311, %312 : tensor<256xf32>
    %cst_28 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %314 = stablehlo.reduce(%308 init: %cst_28) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x256xf32>, tensor<f32>) -> tensor<256xf32>
    %315 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %316 = stablehlo.divide %314, %315 : tensor<256xf32>
    %317 = stablehlo.broadcast_in_dim %313, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %318 = stablehlo.broadcast_in_dim %316, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %319 = stablehlo.concatenate %317, %318, dim = 0 : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<2x256xf32>
    %320 = "stablehlo.all_reduce"(%319) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x256xf32>) -> tensor<2x256xf32>
    %321 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x256xf32>
    %322 = stablehlo.divide %320, %321 : tensor<2x256xf32>
    %323 = stablehlo.slice %322 [0:1, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %324 = stablehlo.reshape %323 : (tensor<1x256xf32>) -> tensor<256xf32>
    %325 = stablehlo.slice %322 [1:2, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %326 = stablehlo.reshape %325 : (tensor<1x256xf32>) -> tensor<256xf32>
    %327 = stablehlo.multiply %324, %324 : tensor<256xf32>
    %328 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %329 = stablehlo.multiply %328, %324 : tensor<256xf32>
    %330 = stablehlo.subtract %326, %327 : tensor<256xf32>
    %331 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %332 = stablehlo.maximum %331, %330 : tensor<256xf32>
    %333 = stablehlo.compare  EQ, %330, %332,  FLOAT : (tensor<256xf32>, tensor<256xf32>) -> tensor<256xi1>
    %334 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %335 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %336 = stablehlo.select %333, %334, %335 : tensor<256xi1>, tensor<256xf32>
    %337 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %338 = stablehlo.compare  EQ, %337, %332,  FLOAT : (tensor<256xf32>, tensor<256xf32>) -> tensor<256xi1>
    %339 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %340 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %341 = stablehlo.select %338, %339, %340 : tensor<256xi1>, tensor<256xf32>
    %342 = stablehlo.divide %336, %341 : tensor<256xf32>
    %343 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %344 = stablehlo.multiply %343, %arg330 : tensor<256xf32>
    %345 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %346 = stablehlo.multiply %345, %324 : tensor<256xf32>
    %347 = stablehlo.add %344, %346 : tensor<256xf32>
    %348 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %349 = stablehlo.multiply %348, %arg331 : tensor<256xf32>
    %350 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %351 = stablehlo.multiply %350, %332 : tensor<256xf32>
    %352 = stablehlo.add %349, %351 : tensor<256xf32>
    %353 = stablehlo.broadcast_in_dim %324, dims = [3] : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %354 = stablehlo.broadcast_in_dim %332, dims = [3] : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %355 = stablehlo.convert %306 : (tensor<256x56x56x256xf16>) -> tensor<256x56x56x256xf32>
    %356 = stablehlo.broadcast_in_dim %353, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x56x56x256xf32>
    %357 = stablehlo.subtract %355, %356 : tensor<256x56x56x256xf32>
    %358 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x256xf32>
    %359 = stablehlo.add %354, %358 : tensor<1x1x1x256xf32>
    %360 = stablehlo.rsqrt %359 : tensor<1x1x1x256xf32>
    %361 = stablehlo.divide %360, %359 : tensor<1x1x1x256xf32>
    %362 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x256xf32>
    %363 = stablehlo.multiply %362, %361 : tensor<1x1x1x256xf32>
    %364 = stablehlo.reshape %arg12 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %365 = stablehlo.multiply %360, %364 : tensor<1x1x1x256xf32>
    %366 = stablehlo.broadcast_in_dim %365, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x56x56x256xf32>
    %367 = stablehlo.multiply %357, %366 : tensor<256x56x56x256xf32>
    %368 = stablehlo.reshape %arg11 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %369 = stablehlo.broadcast_in_dim %368, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x56x56x256xf32>
    %370 = stablehlo.add %367, %369 : tensor<256x56x56x256xf32>
    %371 = stablehlo.convert %370 : (tensor<256x56x56x256xf32>) -> tensor<256x56x56x256xf16>
    %372 = stablehlo.add %371, %304 : tensor<256x56x56x256xf16>
    %373 = call @relu_1(%372) : (tensor<256x56x56x256xf16>) -> tensor<256x56x56x256xf16>
    %374 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x56x56x256xf16>
    %375 = stablehlo.compare  GT, %372, %374,  FLOAT : (tensor<256x56x56x256xf16>, tensor<256x56x56x256xf16>) -> tensor<256x56x56x256xi1>
    %376 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x56x56x256xf16>
    %377 = stablehlo.convert %arg19 : (tensor<1x1x256x64xf32>) -> tensor<1x1x256x64xf16>
    %378 = stablehlo.convolution(%373, %377) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x256xf16>, tensor<1x1x256x64xf16>) -> tensor<256x56x56x64xf16>
    %379 = stablehlo.convert %378 : (tensor<256x56x56x64xf16>) -> tensor<256x56x56x64xf32>
    %380 = stablehlo.multiply %379, %379 : tensor<256x56x56x64xf32>
    %381 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x56x56x64xf32>
    %382 = stablehlo.multiply %381, %379 : tensor<256x56x56x64xf32>
    %cst_29 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %383 = stablehlo.reduce(%379 init: %cst_29) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x64xf32>, tensor<f32>) -> tensor<64xf32>
    %384 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %385 = stablehlo.divide %383, %384 : tensor<64xf32>
    %cst_30 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %386 = stablehlo.reduce(%380 init: %cst_30) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x64xf32>, tensor<f32>) -> tensor<64xf32>
    %387 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %388 = stablehlo.divide %386, %387 : tensor<64xf32>
    %389 = stablehlo.broadcast_in_dim %385, dims = [1] : (tensor<64xf32>) -> tensor<1x64xf32>
    %390 = stablehlo.broadcast_in_dim %388, dims = [1] : (tensor<64xf32>) -> tensor<1x64xf32>
    %391 = stablehlo.concatenate %389, %390, dim = 0 : (tensor<1x64xf32>, tensor<1x64xf32>) -> tensor<2x64xf32>
    %392 = "stablehlo.all_reduce"(%391) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x64xf32>) -> tensor<2x64xf32>
    %393 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x64xf32>
    %394 = stablehlo.divide %392, %393 : tensor<2x64xf32>
    %395 = stablehlo.slice %394 [0:1, 0:64] : (tensor<2x64xf32>) -> tensor<1x64xf32>
    %396 = stablehlo.reshape %395 : (tensor<1x64xf32>) -> tensor<64xf32>
    %397 = stablehlo.slice %394 [1:2, 0:64] : (tensor<2x64xf32>) -> tensor<1x64xf32>
    %398 = stablehlo.reshape %397 : (tensor<1x64xf32>) -> tensor<64xf32>
    %399 = stablehlo.multiply %396, %396 : tensor<64xf32>
    %400 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %401 = stablehlo.multiply %400, %396 : tensor<64xf32>
    %402 = stablehlo.subtract %398, %399 : tensor<64xf32>
    %403 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %404 = stablehlo.maximum %403, %402 : tensor<64xf32>
    %405 = stablehlo.compare  EQ, %402, %404,  FLOAT : (tensor<64xf32>, tensor<64xf32>) -> tensor<64xi1>
    %406 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %407 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %408 = stablehlo.select %405, %406, %407 : tensor<64xi1>, tensor<64xf32>
    %409 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %410 = stablehlo.compare  EQ, %409, %404,  FLOAT : (tensor<64xf32>, tensor<64xf32>) -> tensor<64xi1>
    %411 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %412 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %413 = stablehlo.select %410, %411, %412 : tensor<64xi1>, tensor<64xf32>
    %414 = stablehlo.divide %408, %413 : tensor<64xf32>
    %415 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %416 = stablehlo.multiply %415, %arg332 : tensor<64xf32>
    %417 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %418 = stablehlo.multiply %417, %396 : tensor<64xf32>
    %419 = stablehlo.add %416, %418 : tensor<64xf32>
    %420 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %421 = stablehlo.multiply %420, %arg333 : tensor<64xf32>
    %422 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %423 = stablehlo.multiply %422, %404 : tensor<64xf32>
    %424 = stablehlo.add %421, %423 : tensor<64xf32>
    %425 = stablehlo.broadcast_in_dim %396, dims = [3] : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %426 = stablehlo.broadcast_in_dim %404, dims = [3] : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %427 = stablehlo.convert %378 : (tensor<256x56x56x64xf16>) -> tensor<256x56x56x64xf32>
    %428 = stablehlo.broadcast_in_dim %425, dims = [0, 1, 2, 3] : (tensor<1x1x1x64xf32>) -> tensor<256x56x56x64xf32>
    %429 = stablehlo.subtract %427, %428 : tensor<256x56x56x64xf32>
    %430 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x64xf32>
    %431 = stablehlo.add %426, %430 : tensor<1x1x1x64xf32>
    %432 = stablehlo.rsqrt %431 : tensor<1x1x1x64xf32>
    %433 = stablehlo.divide %432, %431 : tensor<1x1x1x64xf32>
    %434 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x64xf32>
    %435 = stablehlo.multiply %434, %433 : tensor<1x1x1x64xf32>
    %436 = stablehlo.reshape %arg14 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %437 = stablehlo.multiply %432, %436 : tensor<1x1x1x64xf32>
    %438 = stablehlo.broadcast_in_dim %437, dims = [0, 1, 2, 3] : (tensor<1x1x1x64xf32>) -> tensor<256x56x56x64xf32>
    %439 = stablehlo.multiply %429, %438 : tensor<256x56x56x64xf32>
    %440 = stablehlo.reshape %arg13 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %441 = stablehlo.broadcast_in_dim %440, dims = [0, 1, 2, 3] : (tensor<1x1x1x64xf32>) -> tensor<256x56x56x64xf32>
    %442 = stablehlo.add %439, %441 : tensor<256x56x56x64xf32>
    %443 = stablehlo.convert %442 : (tensor<256x56x56x64xf32>) -> tensor<256x56x56x64xf16>
    %444 = call @relu_0(%443) : (tensor<256x56x56x64xf16>) -> tensor<256x56x56x64xf16>
    %445 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x56x56x64xf16>
    %446 = stablehlo.compare  GT, %443, %445,  FLOAT : (tensor<256x56x56x64xf16>, tensor<256x56x56x64xf16>) -> tensor<256x56x56x64xi1>
    %447 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x56x56x64xf16>
    %448 = stablehlo.convert %arg20 : (tensor<3x3x64x64xf32>) -> tensor<3x3x64x64xf16>
    %449 = stablehlo.convolution(%444, %448) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x64xf16>, tensor<3x3x64x64xf16>) -> tensor<256x56x56x64xf16>
    %450 = stablehlo.convert %449 : (tensor<256x56x56x64xf16>) -> tensor<256x56x56x64xf32>
    %451 = stablehlo.multiply %450, %450 : tensor<256x56x56x64xf32>
    %452 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x56x56x64xf32>
    %453 = stablehlo.multiply %452, %450 : tensor<256x56x56x64xf32>
    %cst_31 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %454 = stablehlo.reduce(%450 init: %cst_31) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x64xf32>, tensor<f32>) -> tensor<64xf32>
    %455 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %456 = stablehlo.divide %454, %455 : tensor<64xf32>
    %cst_32 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %457 = stablehlo.reduce(%451 init: %cst_32) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x64xf32>, tensor<f32>) -> tensor<64xf32>
    %458 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %459 = stablehlo.divide %457, %458 : tensor<64xf32>
    %460 = stablehlo.broadcast_in_dim %456, dims = [1] : (tensor<64xf32>) -> tensor<1x64xf32>
    %461 = stablehlo.broadcast_in_dim %459, dims = [1] : (tensor<64xf32>) -> tensor<1x64xf32>
    %462 = stablehlo.concatenate %460, %461, dim = 0 : (tensor<1x64xf32>, tensor<1x64xf32>) -> tensor<2x64xf32>
    %463 = "stablehlo.all_reduce"(%462) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x64xf32>) -> tensor<2x64xf32>
    %464 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x64xf32>
    %465 = stablehlo.divide %463, %464 : tensor<2x64xf32>
    %466 = stablehlo.slice %465 [0:1, 0:64] : (tensor<2x64xf32>) -> tensor<1x64xf32>
    %467 = stablehlo.reshape %466 : (tensor<1x64xf32>) -> tensor<64xf32>
    %468 = stablehlo.slice %465 [1:2, 0:64] : (tensor<2x64xf32>) -> tensor<1x64xf32>
    %469 = stablehlo.reshape %468 : (tensor<1x64xf32>) -> tensor<64xf32>
    %470 = stablehlo.multiply %467, %467 : tensor<64xf32>
    %471 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %472 = stablehlo.multiply %471, %467 : tensor<64xf32>
    %473 = stablehlo.subtract %469, %470 : tensor<64xf32>
    %474 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %475 = stablehlo.maximum %474, %473 : tensor<64xf32>
    %476 = stablehlo.compare  EQ, %473, %475,  FLOAT : (tensor<64xf32>, tensor<64xf32>) -> tensor<64xi1>
    %477 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %478 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %479 = stablehlo.select %476, %477, %478 : tensor<64xi1>, tensor<64xf32>
    %480 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %481 = stablehlo.compare  EQ, %480, %475,  FLOAT : (tensor<64xf32>, tensor<64xf32>) -> tensor<64xi1>
    %482 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %483 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %484 = stablehlo.select %481, %482, %483 : tensor<64xi1>, tensor<64xf32>
    %485 = stablehlo.divide %479, %484 : tensor<64xf32>
    %486 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %487 = stablehlo.multiply %486, %arg334 : tensor<64xf32>
    %488 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %489 = stablehlo.multiply %488, %467 : tensor<64xf32>
    %490 = stablehlo.add %487, %489 : tensor<64xf32>
    %491 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %492 = stablehlo.multiply %491, %arg335 : tensor<64xf32>
    %493 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %494 = stablehlo.multiply %493, %475 : tensor<64xf32>
    %495 = stablehlo.add %492, %494 : tensor<64xf32>
    %496 = stablehlo.broadcast_in_dim %467, dims = [3] : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %497 = stablehlo.broadcast_in_dim %475, dims = [3] : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %498 = stablehlo.convert %449 : (tensor<256x56x56x64xf16>) -> tensor<256x56x56x64xf32>
    %499 = stablehlo.broadcast_in_dim %496, dims = [0, 1, 2, 3] : (tensor<1x1x1x64xf32>) -> tensor<256x56x56x64xf32>
    %500 = stablehlo.subtract %498, %499 : tensor<256x56x56x64xf32>
    %501 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x64xf32>
    %502 = stablehlo.add %497, %501 : tensor<1x1x1x64xf32>
    %503 = stablehlo.rsqrt %502 : tensor<1x1x1x64xf32>
    %504 = stablehlo.divide %503, %502 : tensor<1x1x1x64xf32>
    %505 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x64xf32>
    %506 = stablehlo.multiply %505, %504 : tensor<1x1x1x64xf32>
    %507 = stablehlo.reshape %arg16 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %508 = stablehlo.multiply %503, %507 : tensor<1x1x1x64xf32>
    %509 = stablehlo.broadcast_in_dim %508, dims = [0, 1, 2, 3] : (tensor<1x1x1x64xf32>) -> tensor<256x56x56x64xf32>
    %510 = stablehlo.multiply %500, %509 : tensor<256x56x56x64xf32>
    %511 = stablehlo.reshape %arg15 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %512 = stablehlo.broadcast_in_dim %511, dims = [0, 1, 2, 3] : (tensor<1x1x1x64xf32>) -> tensor<256x56x56x64xf32>
    %513 = stablehlo.add %510, %512 : tensor<256x56x56x64xf32>
    %514 = stablehlo.convert %513 : (tensor<256x56x56x64xf32>) -> tensor<256x56x56x64xf16>
    %515 = call @relu_0(%514) : (tensor<256x56x56x64xf16>) -> tensor<256x56x56x64xf16>
    %516 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x56x56x64xf16>
    %517 = stablehlo.compare  GT, %514, %516,  FLOAT : (tensor<256x56x56x64xf16>, tensor<256x56x56x64xf16>) -> tensor<256x56x56x64xi1>
    %518 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x56x56x64xf16>
    %519 = stablehlo.convert %arg21 : (tensor<1x1x64x256xf32>) -> tensor<1x1x64x256xf16>
    %520 = stablehlo.convolution(%515, %519) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x64xf16>, tensor<1x1x64x256xf16>) -> tensor<256x56x56x256xf16>
    %521 = stablehlo.convert %520 : (tensor<256x56x56x256xf16>) -> tensor<256x56x56x256xf32>
    %522 = stablehlo.multiply %521, %521 : tensor<256x56x56x256xf32>
    %523 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x56x56x256xf32>
    %524 = stablehlo.multiply %523, %521 : tensor<256x56x56x256xf32>
    %cst_33 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %525 = stablehlo.reduce(%521 init: %cst_33) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x256xf32>, tensor<f32>) -> tensor<256xf32>
    %526 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %527 = stablehlo.divide %525, %526 : tensor<256xf32>
    %cst_34 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %528 = stablehlo.reduce(%522 init: %cst_34) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x256xf32>, tensor<f32>) -> tensor<256xf32>
    %529 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %530 = stablehlo.divide %528, %529 : tensor<256xf32>
    %531 = stablehlo.broadcast_in_dim %527, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %532 = stablehlo.broadcast_in_dim %530, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %533 = stablehlo.concatenate %531, %532, dim = 0 : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<2x256xf32>
    %534 = "stablehlo.all_reduce"(%533) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x256xf32>) -> tensor<2x256xf32>
    %535 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x256xf32>
    %536 = stablehlo.divide %534, %535 : tensor<2x256xf32>
    %537 = stablehlo.slice %536 [0:1, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %538 = stablehlo.reshape %537 : (tensor<1x256xf32>) -> tensor<256xf32>
    %539 = stablehlo.slice %536 [1:2, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %540 = stablehlo.reshape %539 : (tensor<1x256xf32>) -> tensor<256xf32>
    %541 = stablehlo.multiply %538, %538 : tensor<256xf32>
    %542 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %543 = stablehlo.multiply %542, %538 : tensor<256xf32>
    %544 = stablehlo.subtract %540, %541 : tensor<256xf32>
    %545 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %546 = stablehlo.maximum %545, %544 : tensor<256xf32>
    %547 = stablehlo.compare  EQ, %544, %546,  FLOAT : (tensor<256xf32>, tensor<256xf32>) -> tensor<256xi1>
    %548 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %549 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %550 = stablehlo.select %547, %548, %549 : tensor<256xi1>, tensor<256xf32>
    %551 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %552 = stablehlo.compare  EQ, %551, %546,  FLOAT : (tensor<256xf32>, tensor<256xf32>) -> tensor<256xi1>
    %553 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %554 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %555 = stablehlo.select %552, %553, %554 : tensor<256xi1>, tensor<256xf32>
    %556 = stablehlo.divide %550, %555 : tensor<256xf32>
    %557 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %558 = stablehlo.multiply %557, %arg336 : tensor<256xf32>
    %559 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %560 = stablehlo.multiply %559, %538 : tensor<256xf32>
    %561 = stablehlo.add %558, %560 : tensor<256xf32>
    %562 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %563 = stablehlo.multiply %562, %arg337 : tensor<256xf32>
    %564 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %565 = stablehlo.multiply %564, %546 : tensor<256xf32>
    %566 = stablehlo.add %563, %565 : tensor<256xf32>
    %567 = stablehlo.broadcast_in_dim %538, dims = [3] : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %568 = stablehlo.broadcast_in_dim %546, dims = [3] : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %569 = stablehlo.convert %520 : (tensor<256x56x56x256xf16>) -> tensor<256x56x56x256xf32>
    %570 = stablehlo.broadcast_in_dim %567, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x56x56x256xf32>
    %571 = stablehlo.subtract %569, %570 : tensor<256x56x56x256xf32>
    %572 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x256xf32>
    %573 = stablehlo.add %568, %572 : tensor<1x1x1x256xf32>
    %574 = stablehlo.rsqrt %573 : tensor<1x1x1x256xf32>
    %575 = stablehlo.divide %574, %573 : tensor<1x1x1x256xf32>
    %576 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x256xf32>
    %577 = stablehlo.multiply %576, %575 : tensor<1x1x1x256xf32>
    %578 = stablehlo.reshape %arg18 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %579 = stablehlo.multiply %574, %578 : tensor<1x1x1x256xf32>
    %580 = stablehlo.broadcast_in_dim %579, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x56x56x256xf32>
    %581 = stablehlo.multiply %571, %580 : tensor<256x56x56x256xf32>
    %582 = stablehlo.reshape %arg17 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %583 = stablehlo.broadcast_in_dim %582, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x56x56x256xf32>
    %584 = stablehlo.add %581, %583 : tensor<256x56x56x256xf32>
    %585 = stablehlo.convert %584 : (tensor<256x56x56x256xf32>) -> tensor<256x56x56x256xf16>
    %586 = stablehlo.add %373, %585 : tensor<256x56x56x256xf16>
    %587 = call @relu_1(%586) : (tensor<256x56x56x256xf16>) -> tensor<256x56x56x256xf16>
    %588 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x56x56x256xf16>
    %589 = stablehlo.compare  GT, %586, %588,  FLOAT : (tensor<256x56x56x256xf16>, tensor<256x56x56x256xf16>) -> tensor<256x56x56x256xi1>
    %590 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x56x56x256xf16>
    %591 = stablehlo.convert %arg85 : (tensor<1x1x256x64xf32>) -> tensor<1x1x256x64xf16>
    %592 = stablehlo.convolution(%587, %591) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x256xf16>, tensor<1x1x256x64xf16>) -> tensor<256x56x56x64xf16>
    %593 = stablehlo.convert %592 : (tensor<256x56x56x64xf16>) -> tensor<256x56x56x64xf32>
    %594 = stablehlo.multiply %593, %593 : tensor<256x56x56x64xf32>
    %595 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x56x56x64xf32>
    %596 = stablehlo.multiply %595, %593 : tensor<256x56x56x64xf32>
    %cst_35 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %597 = stablehlo.reduce(%593 init: %cst_35) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x64xf32>, tensor<f32>) -> tensor<64xf32>
    %598 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %599 = stablehlo.divide %597, %598 : tensor<64xf32>
    %cst_36 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %600 = stablehlo.reduce(%594 init: %cst_36) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x64xf32>, tensor<f32>) -> tensor<64xf32>
    %601 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %602 = stablehlo.divide %600, %601 : tensor<64xf32>
    %603 = stablehlo.broadcast_in_dim %599, dims = [1] : (tensor<64xf32>) -> tensor<1x64xf32>
    %604 = stablehlo.broadcast_in_dim %602, dims = [1] : (tensor<64xf32>) -> tensor<1x64xf32>
    %605 = stablehlo.concatenate %603, %604, dim = 0 : (tensor<1x64xf32>, tensor<1x64xf32>) -> tensor<2x64xf32>
    %606 = "stablehlo.all_reduce"(%605) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x64xf32>) -> tensor<2x64xf32>
    %607 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x64xf32>
    %608 = stablehlo.divide %606, %607 : tensor<2x64xf32>
    %609 = stablehlo.slice %608 [0:1, 0:64] : (tensor<2x64xf32>) -> tensor<1x64xf32>
    %610 = stablehlo.reshape %609 : (tensor<1x64xf32>) -> tensor<64xf32>
    %611 = stablehlo.slice %608 [1:2, 0:64] : (tensor<2x64xf32>) -> tensor<1x64xf32>
    %612 = stablehlo.reshape %611 : (tensor<1x64xf32>) -> tensor<64xf32>
    %613 = stablehlo.multiply %610, %610 : tensor<64xf32>
    %614 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %615 = stablehlo.multiply %614, %610 : tensor<64xf32>
    %616 = stablehlo.subtract %612, %613 : tensor<64xf32>
    %617 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %618 = stablehlo.maximum %617, %616 : tensor<64xf32>
    %619 = stablehlo.compare  EQ, %616, %618,  FLOAT : (tensor<64xf32>, tensor<64xf32>) -> tensor<64xi1>
    %620 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %621 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %622 = stablehlo.select %619, %620, %621 : tensor<64xi1>, tensor<64xf32>
    %623 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %624 = stablehlo.compare  EQ, %623, %618,  FLOAT : (tensor<64xf32>, tensor<64xf32>) -> tensor<64xi1>
    %625 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %626 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %627 = stablehlo.select %624, %625, %626 : tensor<64xi1>, tensor<64xf32>
    %628 = stablehlo.divide %622, %627 : tensor<64xf32>
    %629 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %630 = stablehlo.multiply %629, %arg376 : tensor<64xf32>
    %631 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %632 = stablehlo.multiply %631, %610 : tensor<64xf32>
    %633 = stablehlo.add %630, %632 : tensor<64xf32>
    %634 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %635 = stablehlo.multiply %634, %arg377 : tensor<64xf32>
    %636 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %637 = stablehlo.multiply %636, %618 : tensor<64xf32>
    %638 = stablehlo.add %635, %637 : tensor<64xf32>
    %639 = stablehlo.broadcast_in_dim %610, dims = [3] : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %640 = stablehlo.broadcast_in_dim %618, dims = [3] : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %641 = stablehlo.convert %592 : (tensor<256x56x56x64xf16>) -> tensor<256x56x56x64xf32>
    %642 = stablehlo.broadcast_in_dim %639, dims = [0, 1, 2, 3] : (tensor<1x1x1x64xf32>) -> tensor<256x56x56x64xf32>
    %643 = stablehlo.subtract %641, %642 : tensor<256x56x56x64xf32>
    %644 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x64xf32>
    %645 = stablehlo.add %640, %644 : tensor<1x1x1x64xf32>
    %646 = stablehlo.rsqrt %645 : tensor<1x1x1x64xf32>
    %647 = stablehlo.divide %646, %645 : tensor<1x1x1x64xf32>
    %648 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x64xf32>
    %649 = stablehlo.multiply %648, %647 : tensor<1x1x1x64xf32>
    %650 = stablehlo.reshape %arg80 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %651 = stablehlo.multiply %646, %650 : tensor<1x1x1x64xf32>
    %652 = stablehlo.broadcast_in_dim %651, dims = [0, 1, 2, 3] : (tensor<1x1x1x64xf32>) -> tensor<256x56x56x64xf32>
    %653 = stablehlo.multiply %643, %652 : tensor<256x56x56x64xf32>
    %654 = stablehlo.reshape %arg79 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %655 = stablehlo.broadcast_in_dim %654, dims = [0, 1, 2, 3] : (tensor<1x1x1x64xf32>) -> tensor<256x56x56x64xf32>
    %656 = stablehlo.add %653, %655 : tensor<256x56x56x64xf32>
    %657 = stablehlo.convert %656 : (tensor<256x56x56x64xf32>) -> tensor<256x56x56x64xf16>
    %658 = call @relu_0(%657) : (tensor<256x56x56x64xf16>) -> tensor<256x56x56x64xf16>
    %659 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x56x56x64xf16>
    %660 = stablehlo.compare  GT, %657, %659,  FLOAT : (tensor<256x56x56x64xf16>, tensor<256x56x56x64xf16>) -> tensor<256x56x56x64xi1>
    %661 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x56x56x64xf16>
    %662 = stablehlo.convert %arg86 : (tensor<3x3x64x64xf32>) -> tensor<3x3x64x64xf16>
    %663 = stablehlo.convolution(%658, %662) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x64xf16>, tensor<3x3x64x64xf16>) -> tensor<256x56x56x64xf16>
    %664 = stablehlo.convert %663 : (tensor<256x56x56x64xf16>) -> tensor<256x56x56x64xf32>
    %665 = stablehlo.multiply %664, %664 : tensor<256x56x56x64xf32>
    %666 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x56x56x64xf32>
    %667 = stablehlo.multiply %666, %664 : tensor<256x56x56x64xf32>
    %cst_37 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %668 = stablehlo.reduce(%664 init: %cst_37) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x64xf32>, tensor<f32>) -> tensor<64xf32>
    %669 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %670 = stablehlo.divide %668, %669 : tensor<64xf32>
    %cst_38 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %671 = stablehlo.reduce(%665 init: %cst_38) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x64xf32>, tensor<f32>) -> tensor<64xf32>
    %672 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %673 = stablehlo.divide %671, %672 : tensor<64xf32>
    %674 = stablehlo.broadcast_in_dim %670, dims = [1] : (tensor<64xf32>) -> tensor<1x64xf32>
    %675 = stablehlo.broadcast_in_dim %673, dims = [1] : (tensor<64xf32>) -> tensor<1x64xf32>
    %676 = stablehlo.concatenate %674, %675, dim = 0 : (tensor<1x64xf32>, tensor<1x64xf32>) -> tensor<2x64xf32>
    %677 = "stablehlo.all_reduce"(%676) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x64xf32>) -> tensor<2x64xf32>
    %678 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x64xf32>
    %679 = stablehlo.divide %677, %678 : tensor<2x64xf32>
    %680 = stablehlo.slice %679 [0:1, 0:64] : (tensor<2x64xf32>) -> tensor<1x64xf32>
    %681 = stablehlo.reshape %680 : (tensor<1x64xf32>) -> tensor<64xf32>
    %682 = stablehlo.slice %679 [1:2, 0:64] : (tensor<2x64xf32>) -> tensor<1x64xf32>
    %683 = stablehlo.reshape %682 : (tensor<1x64xf32>) -> tensor<64xf32>
    %684 = stablehlo.multiply %681, %681 : tensor<64xf32>
    %685 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %686 = stablehlo.multiply %685, %681 : tensor<64xf32>
    %687 = stablehlo.subtract %683, %684 : tensor<64xf32>
    %688 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %689 = stablehlo.maximum %688, %687 : tensor<64xf32>
    %690 = stablehlo.compare  EQ, %687, %689,  FLOAT : (tensor<64xf32>, tensor<64xf32>) -> tensor<64xi1>
    %691 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %692 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %693 = stablehlo.select %690, %691, %692 : tensor<64xi1>, tensor<64xf32>
    %694 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %695 = stablehlo.compare  EQ, %694, %689,  FLOAT : (tensor<64xf32>, tensor<64xf32>) -> tensor<64xi1>
    %696 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %697 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %698 = stablehlo.select %695, %696, %697 : tensor<64xi1>, tensor<64xf32>
    %699 = stablehlo.divide %693, %698 : tensor<64xf32>
    %700 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %701 = stablehlo.multiply %700, %arg378 : tensor<64xf32>
    %702 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %703 = stablehlo.multiply %702, %681 : tensor<64xf32>
    %704 = stablehlo.add %701, %703 : tensor<64xf32>
    %705 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %706 = stablehlo.multiply %705, %arg379 : tensor<64xf32>
    %707 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %708 = stablehlo.multiply %707, %689 : tensor<64xf32>
    %709 = stablehlo.add %706, %708 : tensor<64xf32>
    %710 = stablehlo.broadcast_in_dim %681, dims = [3] : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %711 = stablehlo.broadcast_in_dim %689, dims = [3] : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %712 = stablehlo.convert %663 : (tensor<256x56x56x64xf16>) -> tensor<256x56x56x64xf32>
    %713 = stablehlo.broadcast_in_dim %710, dims = [0, 1, 2, 3] : (tensor<1x1x1x64xf32>) -> tensor<256x56x56x64xf32>
    %714 = stablehlo.subtract %712, %713 : tensor<256x56x56x64xf32>
    %715 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x64xf32>
    %716 = stablehlo.add %711, %715 : tensor<1x1x1x64xf32>
    %717 = stablehlo.rsqrt %716 : tensor<1x1x1x64xf32>
    %718 = stablehlo.divide %717, %716 : tensor<1x1x1x64xf32>
    %719 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x64xf32>
    %720 = stablehlo.multiply %719, %718 : tensor<1x1x1x64xf32>
    %721 = stablehlo.reshape %arg82 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %722 = stablehlo.multiply %717, %721 : tensor<1x1x1x64xf32>
    %723 = stablehlo.broadcast_in_dim %722, dims = [0, 1, 2, 3] : (tensor<1x1x1x64xf32>) -> tensor<256x56x56x64xf32>
    %724 = stablehlo.multiply %714, %723 : tensor<256x56x56x64xf32>
    %725 = stablehlo.reshape %arg81 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %726 = stablehlo.broadcast_in_dim %725, dims = [0, 1, 2, 3] : (tensor<1x1x1x64xf32>) -> tensor<256x56x56x64xf32>
    %727 = stablehlo.add %724, %726 : tensor<256x56x56x64xf32>
    %728 = stablehlo.convert %727 : (tensor<256x56x56x64xf32>) -> tensor<256x56x56x64xf16>
    %729 = call @relu_0(%728) : (tensor<256x56x56x64xf16>) -> tensor<256x56x56x64xf16>
    %730 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x56x56x64xf16>
    %731 = stablehlo.compare  GT, %728, %730,  FLOAT : (tensor<256x56x56x64xf16>, tensor<256x56x56x64xf16>) -> tensor<256x56x56x64xi1>
    %732 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x56x56x64xf16>
    %733 = stablehlo.convert %arg87 : (tensor<1x1x64x256xf32>) -> tensor<1x1x64x256xf16>
    %734 = stablehlo.convolution(%729, %733) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x64xf16>, tensor<1x1x64x256xf16>) -> tensor<256x56x56x256xf16>
    %735 = stablehlo.convert %734 : (tensor<256x56x56x256xf16>) -> tensor<256x56x56x256xf32>
    %736 = stablehlo.multiply %735, %735 : tensor<256x56x56x256xf32>
    %737 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x56x56x256xf32>
    %738 = stablehlo.multiply %737, %735 : tensor<256x56x56x256xf32>
    %cst_39 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %739 = stablehlo.reduce(%735 init: %cst_39) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x256xf32>, tensor<f32>) -> tensor<256xf32>
    %740 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %741 = stablehlo.divide %739, %740 : tensor<256xf32>
    %cst_40 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %742 = stablehlo.reduce(%736 init: %cst_40) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x256xf32>, tensor<f32>) -> tensor<256xf32>
    %743 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %744 = stablehlo.divide %742, %743 : tensor<256xf32>
    %745 = stablehlo.broadcast_in_dim %741, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %746 = stablehlo.broadcast_in_dim %744, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %747 = stablehlo.concatenate %745, %746, dim = 0 : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<2x256xf32>
    %748 = "stablehlo.all_reduce"(%747) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x256xf32>) -> tensor<2x256xf32>
    %749 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x256xf32>
    %750 = stablehlo.divide %748, %749 : tensor<2x256xf32>
    %751 = stablehlo.slice %750 [0:1, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %752 = stablehlo.reshape %751 : (tensor<1x256xf32>) -> tensor<256xf32>
    %753 = stablehlo.slice %750 [1:2, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %754 = stablehlo.reshape %753 : (tensor<1x256xf32>) -> tensor<256xf32>
    %755 = stablehlo.multiply %752, %752 : tensor<256xf32>
    %756 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %757 = stablehlo.multiply %756, %752 : tensor<256xf32>
    %758 = stablehlo.subtract %754, %755 : tensor<256xf32>
    %759 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %760 = stablehlo.maximum %759, %758 : tensor<256xf32>
    %761 = stablehlo.compare  EQ, %758, %760,  FLOAT : (tensor<256xf32>, tensor<256xf32>) -> tensor<256xi1>
    %762 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %763 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %764 = stablehlo.select %761, %762, %763 : tensor<256xi1>, tensor<256xf32>
    %765 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %766 = stablehlo.compare  EQ, %765, %760,  FLOAT : (tensor<256xf32>, tensor<256xf32>) -> tensor<256xi1>
    %767 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %768 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %769 = stablehlo.select %766, %767, %768 : tensor<256xi1>, tensor<256xf32>
    %770 = stablehlo.divide %764, %769 : tensor<256xf32>
    %771 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %772 = stablehlo.multiply %771, %arg380 : tensor<256xf32>
    %773 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %774 = stablehlo.multiply %773, %752 : tensor<256xf32>
    %775 = stablehlo.add %772, %774 : tensor<256xf32>
    %776 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %777 = stablehlo.multiply %776, %arg381 : tensor<256xf32>
    %778 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %779 = stablehlo.multiply %778, %760 : tensor<256xf32>
    %780 = stablehlo.add %777, %779 : tensor<256xf32>
    %781 = stablehlo.broadcast_in_dim %752, dims = [3] : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %782 = stablehlo.broadcast_in_dim %760, dims = [3] : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %783 = stablehlo.convert %734 : (tensor<256x56x56x256xf16>) -> tensor<256x56x56x256xf32>
    %784 = stablehlo.broadcast_in_dim %781, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x56x56x256xf32>
    %785 = stablehlo.subtract %783, %784 : tensor<256x56x56x256xf32>
    %786 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x256xf32>
    %787 = stablehlo.add %782, %786 : tensor<1x1x1x256xf32>
    %788 = stablehlo.rsqrt %787 : tensor<1x1x1x256xf32>
    %789 = stablehlo.divide %788, %787 : tensor<1x1x1x256xf32>
    %790 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x256xf32>
    %791 = stablehlo.multiply %790, %789 : tensor<1x1x1x256xf32>
    %792 = stablehlo.reshape %arg84 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %793 = stablehlo.multiply %788, %792 : tensor<1x1x1x256xf32>
    %794 = stablehlo.broadcast_in_dim %793, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x56x56x256xf32>
    %795 = stablehlo.multiply %785, %794 : tensor<256x56x56x256xf32>
    %796 = stablehlo.reshape %arg83 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %797 = stablehlo.broadcast_in_dim %796, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x56x56x256xf32>
    %798 = stablehlo.add %795, %797 : tensor<256x56x56x256xf32>
    %799 = stablehlo.convert %798 : (tensor<256x56x56x256xf32>) -> tensor<256x56x56x256xf16>
    %800 = stablehlo.add %587, %799 : tensor<256x56x56x256xf16>
    %801 = call @relu_1(%800) : (tensor<256x56x56x256xf16>) -> tensor<256x56x56x256xf16>
    %802 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x56x56x256xf16>
    %803 = stablehlo.compare  GT, %800, %802,  FLOAT : (tensor<256x56x56x256xf16>, tensor<256x56x56x256xf16>) -> tensor<256x56x56x256xi1>
    %804 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x56x56x256xf16>
    %805 = stablehlo.convert %arg94 : (tensor<1x1x256x128xf32>) -> tensor<1x1x256x128xf16>
    %806 = stablehlo.convolution(%801, %805) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x256xf16>, tensor<1x1x256x128xf16>) -> tensor<256x56x56x128xf16>
    %807 = stablehlo.convert %806 : (tensor<256x56x56x128xf16>) -> tensor<256x56x56x128xf32>
    %808 = stablehlo.multiply %807, %807 : tensor<256x56x56x128xf32>
    %809 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x56x56x128xf32>
    %810 = stablehlo.multiply %809, %807 : tensor<256x56x56x128xf32>
    %cst_41 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %811 = stablehlo.reduce(%807 init: %cst_41) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x128xf32>, tensor<f32>) -> tensor<128xf32>
    %812 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %813 = stablehlo.divide %811, %812 : tensor<128xf32>
    %cst_42 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %814 = stablehlo.reduce(%808 init: %cst_42) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x128xf32>, tensor<f32>) -> tensor<128xf32>
    %815 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %816 = stablehlo.divide %814, %815 : tensor<128xf32>
    %817 = stablehlo.broadcast_in_dim %813, dims = [1] : (tensor<128xf32>) -> tensor<1x128xf32>
    %818 = stablehlo.broadcast_in_dim %816, dims = [1] : (tensor<128xf32>) -> tensor<1x128xf32>
    %819 = stablehlo.concatenate %817, %818, dim = 0 : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<2x128xf32>
    %820 = "stablehlo.all_reduce"(%819) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x128xf32>) -> tensor<2x128xf32>
    %821 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x128xf32>
    %822 = stablehlo.divide %820, %821 : tensor<2x128xf32>
    %823 = stablehlo.slice %822 [0:1, 0:128] : (tensor<2x128xf32>) -> tensor<1x128xf32>
    %824 = stablehlo.reshape %823 : (tensor<1x128xf32>) -> tensor<128xf32>
    %825 = stablehlo.slice %822 [1:2, 0:128] : (tensor<2x128xf32>) -> tensor<1x128xf32>
    %826 = stablehlo.reshape %825 : (tensor<1x128xf32>) -> tensor<128xf32>
    %827 = stablehlo.multiply %824, %824 : tensor<128xf32>
    %828 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %829 = stablehlo.multiply %828, %824 : tensor<128xf32>
    %830 = stablehlo.subtract %826, %827 : tensor<128xf32>
    %831 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %832 = stablehlo.maximum %831, %830 : tensor<128xf32>
    %833 = stablehlo.compare  EQ, %830, %832,  FLOAT : (tensor<128xf32>, tensor<128xf32>) -> tensor<128xi1>
    %834 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %835 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %836 = stablehlo.select %833, %834, %835 : tensor<128xi1>, tensor<128xf32>
    %837 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %838 = stablehlo.compare  EQ, %837, %832,  FLOAT : (tensor<128xf32>, tensor<128xf32>) -> tensor<128xi1>
    %839 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %840 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %841 = stablehlo.select %838, %839, %840 : tensor<128xi1>, tensor<128xf32>
    %842 = stablehlo.divide %836, %841 : tensor<128xf32>
    %843 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %844 = stablehlo.multiply %843, %arg382 : tensor<128xf32>
    %845 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %846 = stablehlo.multiply %845, %824 : tensor<128xf32>
    %847 = stablehlo.add %844, %846 : tensor<128xf32>
    %848 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %849 = stablehlo.multiply %848, %arg383 : tensor<128xf32>
    %850 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %851 = stablehlo.multiply %850, %832 : tensor<128xf32>
    %852 = stablehlo.add %849, %851 : tensor<128xf32>
    %853 = stablehlo.broadcast_in_dim %824, dims = [3] : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %854 = stablehlo.broadcast_in_dim %832, dims = [3] : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %855 = stablehlo.convert %806 : (tensor<256x56x56x128xf16>) -> tensor<256x56x56x128xf32>
    %856 = stablehlo.broadcast_in_dim %853, dims = [0, 1, 2, 3] : (tensor<1x1x1x128xf32>) -> tensor<256x56x56x128xf32>
    %857 = stablehlo.subtract %855, %856 : tensor<256x56x56x128xf32>
    %858 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x128xf32>
    %859 = stablehlo.add %854, %858 : tensor<1x1x1x128xf32>
    %860 = stablehlo.rsqrt %859 : tensor<1x1x1x128xf32>
    %861 = stablehlo.divide %860, %859 : tensor<1x1x1x128xf32>
    %862 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x128xf32>
    %863 = stablehlo.multiply %862, %861 : tensor<1x1x1x128xf32>
    %864 = stablehlo.reshape %arg89 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %865 = stablehlo.multiply %860, %864 : tensor<1x1x1x128xf32>
    %866 = stablehlo.broadcast_in_dim %865, dims = [0, 1, 2, 3] : (tensor<1x1x1x128xf32>) -> tensor<256x56x56x128xf32>
    %867 = stablehlo.multiply %857, %866 : tensor<256x56x56x128xf32>
    %868 = stablehlo.reshape %arg88 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %869 = stablehlo.broadcast_in_dim %868, dims = [0, 1, 2, 3] : (tensor<1x1x1x128xf32>) -> tensor<256x56x56x128xf32>
    %870 = stablehlo.add %867, %869 : tensor<256x56x56x128xf32>
    %871 = stablehlo.convert %870 : (tensor<256x56x56x128xf32>) -> tensor<256x56x56x128xf16>
    %872 = call @relu_2(%871) : (tensor<256x56x56x128xf16>) -> tensor<256x56x56x128xf16>
    %873 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x56x56x128xf16>
    %874 = stablehlo.compare  GT, %871, %873,  FLOAT : (tensor<256x56x56x128xf16>, tensor<256x56x56x128xf16>) -> tensor<256x56x56x128xi1>
    %875 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x56x56x128xf16>
    %876 = stablehlo.convert %arg95 : (tensor<3x3x128x128xf32>) -> tensor<3x3x128x128xf16>
    %877 = stablehlo.convolution(%872, %876) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [2, 2], pad = [[0, 1], [0, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x128xf16>, tensor<3x3x128x128xf16>) -> tensor<256x28x28x128xf16>
    %878 = stablehlo.convert %877 : (tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xf32>
    %879 = stablehlo.multiply %878, %878 : tensor<256x28x28x128xf32>
    %880 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x28x28x128xf32>
    %881 = stablehlo.multiply %880, %878 : tensor<256x28x28x128xf32>
    %cst_43 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %882 = stablehlo.reduce(%878 init: %cst_43) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %cst_44 = stablehlo.constant dense<2.007040e+05> : tensor<f32>
    %883 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %884 = stablehlo.divide %882, %883 : tensor<128xf32>
    %cst_45 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %885 = stablehlo.reduce(%879 init: %cst_45) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %886 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %887 = stablehlo.divide %885, %886 : tensor<128xf32>
    %888 = stablehlo.broadcast_in_dim %884, dims = [1] : (tensor<128xf32>) -> tensor<1x128xf32>
    %889 = stablehlo.broadcast_in_dim %887, dims = [1] : (tensor<128xf32>) -> tensor<1x128xf32>
    %890 = stablehlo.concatenate %888, %889, dim = 0 : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<2x128xf32>
    %891 = "stablehlo.all_reduce"(%890) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x128xf32>) -> tensor<2x128xf32>
    %892 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x128xf32>
    %893 = stablehlo.divide %891, %892 : tensor<2x128xf32>
    %894 = stablehlo.slice %893 [0:1, 0:128] : (tensor<2x128xf32>) -> tensor<1x128xf32>
    %895 = stablehlo.reshape %894 : (tensor<1x128xf32>) -> tensor<128xf32>
    %896 = stablehlo.slice %893 [1:2, 0:128] : (tensor<2x128xf32>) -> tensor<1x128xf32>
    %897 = stablehlo.reshape %896 : (tensor<1x128xf32>) -> tensor<128xf32>
    %898 = stablehlo.multiply %895, %895 : tensor<128xf32>
    %899 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %900 = stablehlo.multiply %899, %895 : tensor<128xf32>
    %901 = stablehlo.subtract %897, %898 : tensor<128xf32>
    %902 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %903 = stablehlo.maximum %902, %901 : tensor<128xf32>
    %904 = stablehlo.compare  EQ, %901, %903,  FLOAT : (tensor<128xf32>, tensor<128xf32>) -> tensor<128xi1>
    %905 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %906 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %907 = stablehlo.select %904, %905, %906 : tensor<128xi1>, tensor<128xf32>
    %908 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %909 = stablehlo.compare  EQ, %908, %903,  FLOAT : (tensor<128xf32>, tensor<128xf32>) -> tensor<128xi1>
    %910 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %911 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %912 = stablehlo.select %909, %910, %911 : tensor<128xi1>, tensor<128xf32>
    %913 = stablehlo.divide %907, %912 : tensor<128xf32>
    %914 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %915 = stablehlo.multiply %914, %arg384 : tensor<128xf32>
    %916 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %917 = stablehlo.multiply %916, %895 : tensor<128xf32>
    %918 = stablehlo.add %915, %917 : tensor<128xf32>
    %919 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %920 = stablehlo.multiply %919, %arg385 : tensor<128xf32>
    %921 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %922 = stablehlo.multiply %921, %903 : tensor<128xf32>
    %923 = stablehlo.add %920, %922 : tensor<128xf32>
    %924 = stablehlo.broadcast_in_dim %895, dims = [3] : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %925 = stablehlo.broadcast_in_dim %903, dims = [3] : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %926 = stablehlo.convert %877 : (tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xf32>
    %927 = stablehlo.broadcast_in_dim %924, dims = [0, 1, 2, 3] : (tensor<1x1x1x128xf32>) -> tensor<256x28x28x128xf32>
    %928 = stablehlo.subtract %926, %927 : tensor<256x28x28x128xf32>
    %929 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x128xf32>
    %930 = stablehlo.add %925, %929 : tensor<1x1x1x128xf32>
    %931 = stablehlo.rsqrt %930 : tensor<1x1x1x128xf32>
    %932 = stablehlo.divide %931, %930 : tensor<1x1x1x128xf32>
    %933 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x128xf32>
    %934 = stablehlo.multiply %933, %932 : tensor<1x1x1x128xf32>
    %935 = stablehlo.reshape %arg91 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %936 = stablehlo.multiply %931, %935 : tensor<1x1x1x128xf32>
    %937 = stablehlo.broadcast_in_dim %936, dims = [0, 1, 2, 3] : (tensor<1x1x1x128xf32>) -> tensor<256x28x28x128xf32>
    %938 = stablehlo.multiply %928, %937 : tensor<256x28x28x128xf32>
    %939 = stablehlo.reshape %arg90 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %940 = stablehlo.broadcast_in_dim %939, dims = [0, 1, 2, 3] : (tensor<1x1x1x128xf32>) -> tensor<256x28x28x128xf32>
    %941 = stablehlo.add %938, %940 : tensor<256x28x28x128xf32>
    %942 = stablehlo.convert %941 : (tensor<256x28x28x128xf32>) -> tensor<256x28x28x128xf16>
    %943 = call @relu_3(%942) : (tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xf16>
    %944 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x128xf16>
    %945 = stablehlo.compare  GT, %942, %944,  FLOAT : (tensor<256x28x28x128xf16>, tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xi1>
    %946 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x128xf16>
    %947 = stablehlo.convert %arg96 : (tensor<1x1x128x512xf32>) -> tensor<1x1x128x512xf16>
    %948 = stablehlo.convolution(%943, %947) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x128xf16>, tensor<1x1x128x512xf16>) -> tensor<256x28x28x512xf16>
    %949 = stablehlo.convert %948 : (tensor<256x28x28x512xf16>) -> tensor<256x28x28x512xf32>
    %950 = stablehlo.multiply %949, %949 : tensor<256x28x28x512xf32>
    %951 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x28x28x512xf32>
    %952 = stablehlo.multiply %951, %949 : tensor<256x28x28x512xf32>
    %cst_46 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %953 = stablehlo.reduce(%949 init: %cst_46) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x512xf32>, tensor<f32>) -> tensor<512xf32>
    %954 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %955 = stablehlo.divide %953, %954 : tensor<512xf32>
    %cst_47 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %956 = stablehlo.reduce(%950 init: %cst_47) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x512xf32>, tensor<f32>) -> tensor<512xf32>
    %957 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %958 = stablehlo.divide %956, %957 : tensor<512xf32>
    %959 = stablehlo.broadcast_in_dim %955, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %960 = stablehlo.broadcast_in_dim %958, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %961 = stablehlo.concatenate %959, %960, dim = 0 : (tensor<1x512xf32>, tensor<1x512xf32>) -> tensor<2x512xf32>
    %962 = "stablehlo.all_reduce"(%961) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x512xf32>) -> tensor<2x512xf32>
    %963 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x512xf32>
    %964 = stablehlo.divide %962, %963 : tensor<2x512xf32>
    %965 = stablehlo.slice %964 [0:1, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %966 = stablehlo.reshape %965 : (tensor<1x512xf32>) -> tensor<512xf32>
    %967 = stablehlo.slice %964 [1:2, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %968 = stablehlo.reshape %967 : (tensor<1x512xf32>) -> tensor<512xf32>
    %969 = stablehlo.multiply %966, %966 : tensor<512xf32>
    %970 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %971 = stablehlo.multiply %970, %966 : tensor<512xf32>
    %972 = stablehlo.subtract %968, %969 : tensor<512xf32>
    %973 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %974 = stablehlo.maximum %973, %972 : tensor<512xf32>
    %975 = stablehlo.compare  EQ, %972, %974,  FLOAT : (tensor<512xf32>, tensor<512xf32>) -> tensor<512xi1>
    %976 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %977 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %978 = stablehlo.select %975, %976, %977 : tensor<512xi1>, tensor<512xf32>
    %979 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %980 = stablehlo.compare  EQ, %979, %974,  FLOAT : (tensor<512xf32>, tensor<512xf32>) -> tensor<512xi1>
    %981 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %982 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %983 = stablehlo.select %980, %981, %982 : tensor<512xi1>, tensor<512xf32>
    %984 = stablehlo.divide %978, %983 : tensor<512xf32>
    %985 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %986 = stablehlo.multiply %985, %arg386 : tensor<512xf32>
    %987 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %988 = stablehlo.multiply %987, %966 : tensor<512xf32>
    %989 = stablehlo.add %986, %988 : tensor<512xf32>
    %990 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %991 = stablehlo.multiply %990, %arg387 : tensor<512xf32>
    %992 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %993 = stablehlo.multiply %992, %974 : tensor<512xf32>
    %994 = stablehlo.add %991, %993 : tensor<512xf32>
    %995 = stablehlo.broadcast_in_dim %966, dims = [3] : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %996 = stablehlo.broadcast_in_dim %974, dims = [3] : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %997 = stablehlo.convert %948 : (tensor<256x28x28x512xf16>) -> tensor<256x28x28x512xf32>
    %998 = stablehlo.broadcast_in_dim %995, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x28x28x512xf32>
    %999 = stablehlo.subtract %997, %998 : tensor<256x28x28x512xf32>
    %1000 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x512xf32>
    %1001 = stablehlo.add %996, %1000 : tensor<1x1x1x512xf32>
    %1002 = stablehlo.rsqrt %1001 : tensor<1x1x1x512xf32>
    %1003 = stablehlo.divide %1002, %1001 : tensor<1x1x1x512xf32>
    %1004 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x512xf32>
    %1005 = stablehlo.multiply %1004, %1003 : tensor<1x1x1x512xf32>
    %1006 = stablehlo.reshape %arg93 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %1007 = stablehlo.multiply %1002, %1006 : tensor<1x1x1x512xf32>
    %1008 = stablehlo.broadcast_in_dim %1007, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x28x28x512xf32>
    %1009 = stablehlo.multiply %999, %1008 : tensor<256x28x28x512xf32>
    %1010 = stablehlo.reshape %arg92 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %1011 = stablehlo.broadcast_in_dim %1010, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x28x28x512xf32>
    %1012 = stablehlo.add %1009, %1011 : tensor<256x28x28x512xf32>
    %1013 = stablehlo.convert %1012 : (tensor<256x28x28x512xf32>) -> tensor<256x28x28x512xf16>
    %1014 = stablehlo.convert %arg97 : (tensor<1x1x256x512xf32>) -> tensor<1x1x256x512xf16>
    %1015 = stablehlo.convolution(%801, %1014) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [2, 2], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x256xf16>, tensor<1x1x256x512xf16>) -> tensor<256x28x28x512xf16>
    %1016 = stablehlo.convert %1015 : (tensor<256x28x28x512xf16>) -> tensor<256x28x28x512xf32>
    %1017 = stablehlo.multiply %1016, %1016 : tensor<256x28x28x512xf32>
    %1018 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x28x28x512xf32>
    %1019 = stablehlo.multiply %1018, %1016 : tensor<256x28x28x512xf32>
    %cst_48 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1020 = stablehlo.reduce(%1016 init: %cst_48) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x512xf32>, tensor<f32>) -> tensor<512xf32>
    %1021 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1022 = stablehlo.divide %1020, %1021 : tensor<512xf32>
    %cst_49 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1023 = stablehlo.reduce(%1017 init: %cst_49) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x512xf32>, tensor<f32>) -> tensor<512xf32>
    %1024 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1025 = stablehlo.divide %1023, %1024 : tensor<512xf32>
    %1026 = stablehlo.broadcast_in_dim %1022, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %1027 = stablehlo.broadcast_in_dim %1025, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %1028 = stablehlo.concatenate %1026, %1027, dim = 0 : (tensor<1x512xf32>, tensor<1x512xf32>) -> tensor<2x512xf32>
    %1029 = "stablehlo.all_reduce"(%1028) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x512xf32>) -> tensor<2x512xf32>
    %1030 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x512xf32>
    %1031 = stablehlo.divide %1029, %1030 : tensor<2x512xf32>
    %1032 = stablehlo.slice %1031 [0:1, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %1033 = stablehlo.reshape %1032 : (tensor<1x512xf32>) -> tensor<512xf32>
    %1034 = stablehlo.slice %1031 [1:2, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %1035 = stablehlo.reshape %1034 : (tensor<1x512xf32>) -> tensor<512xf32>
    %1036 = stablehlo.multiply %1033, %1033 : tensor<512xf32>
    %1037 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1038 = stablehlo.multiply %1037, %1033 : tensor<512xf32>
    %1039 = stablehlo.subtract %1035, %1036 : tensor<512xf32>
    %1040 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1041 = stablehlo.maximum %1040, %1039 : tensor<512xf32>
    %1042 = stablehlo.compare  EQ, %1039, %1041,  FLOAT : (tensor<512xf32>, tensor<512xf32>) -> tensor<512xi1>
    %1043 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1044 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1045 = stablehlo.select %1042, %1043, %1044 : tensor<512xi1>, tensor<512xf32>
    %1046 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1047 = stablehlo.compare  EQ, %1046, %1041,  FLOAT : (tensor<512xf32>, tensor<512xf32>) -> tensor<512xi1>
    %1048 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1049 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1050 = stablehlo.select %1047, %1048, %1049 : tensor<512xi1>, tensor<512xf32>
    %1051 = stablehlo.divide %1045, %1050 : tensor<512xf32>
    %1052 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1053 = stablehlo.multiply %1052, %arg388 : tensor<512xf32>
    %1054 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1055 = stablehlo.multiply %1054, %1033 : tensor<512xf32>
    %1056 = stablehlo.add %1053, %1055 : tensor<512xf32>
    %1057 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1058 = stablehlo.multiply %1057, %arg389 : tensor<512xf32>
    %1059 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1060 = stablehlo.multiply %1059, %1041 : tensor<512xf32>
    %1061 = stablehlo.add %1058, %1060 : tensor<512xf32>
    %1062 = stablehlo.broadcast_in_dim %1033, dims = [3] : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %1063 = stablehlo.broadcast_in_dim %1041, dims = [3] : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %1064 = stablehlo.convert %1015 : (tensor<256x28x28x512xf16>) -> tensor<256x28x28x512xf32>
    %1065 = stablehlo.broadcast_in_dim %1062, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x28x28x512xf32>
    %1066 = stablehlo.subtract %1064, %1065 : tensor<256x28x28x512xf32>
    %1067 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x512xf32>
    %1068 = stablehlo.add %1063, %1067 : tensor<1x1x1x512xf32>
    %1069 = stablehlo.rsqrt %1068 : tensor<1x1x1x512xf32>
    %1070 = stablehlo.divide %1069, %1068 : tensor<1x1x1x512xf32>
    %1071 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x512xf32>
    %1072 = stablehlo.multiply %1071, %1070 : tensor<1x1x1x512xf32>
    %1073 = stablehlo.reshape %arg99 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %1074 = stablehlo.multiply %1069, %1073 : tensor<1x1x1x512xf32>
    %1075 = stablehlo.broadcast_in_dim %1074, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x28x28x512xf32>
    %1076 = stablehlo.multiply %1066, %1075 : tensor<256x28x28x512xf32>
    %1077 = stablehlo.reshape %arg98 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %1078 = stablehlo.broadcast_in_dim %1077, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x28x28x512xf32>
    %1079 = stablehlo.add %1076, %1078 : tensor<256x28x28x512xf32>
    %1080 = stablehlo.convert %1079 : (tensor<256x28x28x512xf32>) -> tensor<256x28x28x512xf16>
    %1081 = stablehlo.add %1080, %1013 : tensor<256x28x28x512xf16>
    %1082 = call @relu_4(%1081) : (tensor<256x28x28x512xf16>) -> tensor<256x28x28x512xf16>
    %1083 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x512xf16>
    %1084 = stablehlo.compare  GT, %1081, %1083,  FLOAT : (tensor<256x28x28x512xf16>, tensor<256x28x28x512xf16>) -> tensor<256x28x28x512xi1>
    %1085 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x512xf16>
    %1086 = stablehlo.convert %arg106 : (tensor<1x1x512x128xf32>) -> tensor<1x1x512x128xf16>
    %1087 = stablehlo.convolution(%1082, %1086) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x512xf16>, tensor<1x1x512x128xf16>) -> tensor<256x28x28x128xf16>
    %1088 = stablehlo.convert %1087 : (tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xf32>
    %1089 = stablehlo.multiply %1088, %1088 : tensor<256x28x28x128xf32>
    %1090 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x28x28x128xf32>
    %1091 = stablehlo.multiply %1090, %1088 : tensor<256x28x28x128xf32>
    %cst_50 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1092 = stablehlo.reduce(%1088 init: %cst_50) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %1093 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1094 = stablehlo.divide %1092, %1093 : tensor<128xf32>
    %cst_51 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1095 = stablehlo.reduce(%1089 init: %cst_51) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %1096 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1097 = stablehlo.divide %1095, %1096 : tensor<128xf32>
    %1098 = stablehlo.broadcast_in_dim %1094, dims = [1] : (tensor<128xf32>) -> tensor<1x128xf32>
    %1099 = stablehlo.broadcast_in_dim %1097, dims = [1] : (tensor<128xf32>) -> tensor<1x128xf32>
    %1100 = stablehlo.concatenate %1098, %1099, dim = 0 : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<2x128xf32>
    %1101 = "stablehlo.all_reduce"(%1100) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x128xf32>) -> tensor<2x128xf32>
    %1102 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x128xf32>
    %1103 = stablehlo.divide %1101, %1102 : tensor<2x128xf32>
    %1104 = stablehlo.slice %1103 [0:1, 0:128] : (tensor<2x128xf32>) -> tensor<1x128xf32>
    %1105 = stablehlo.reshape %1104 : (tensor<1x128xf32>) -> tensor<128xf32>
    %1106 = stablehlo.slice %1103 [1:2, 0:128] : (tensor<2x128xf32>) -> tensor<1x128xf32>
    %1107 = stablehlo.reshape %1106 : (tensor<1x128xf32>) -> tensor<128xf32>
    %1108 = stablehlo.multiply %1105, %1105 : tensor<128xf32>
    %1109 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1110 = stablehlo.multiply %1109, %1105 : tensor<128xf32>
    %1111 = stablehlo.subtract %1107, %1108 : tensor<128xf32>
    %1112 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1113 = stablehlo.maximum %1112, %1111 : tensor<128xf32>
    %1114 = stablehlo.compare  EQ, %1111, %1113,  FLOAT : (tensor<128xf32>, tensor<128xf32>) -> tensor<128xi1>
    %1115 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1116 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1117 = stablehlo.select %1114, %1115, %1116 : tensor<128xi1>, tensor<128xf32>
    %1118 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1119 = stablehlo.compare  EQ, %1118, %1113,  FLOAT : (tensor<128xf32>, tensor<128xf32>) -> tensor<128xi1>
    %1120 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1121 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1122 = stablehlo.select %1119, %1120, %1121 : tensor<128xi1>, tensor<128xf32>
    %1123 = stablehlo.divide %1117, %1122 : tensor<128xf32>
    %1124 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1125 = stablehlo.multiply %1124, %arg390 : tensor<128xf32>
    %1126 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1127 = stablehlo.multiply %1126, %1105 : tensor<128xf32>
    %1128 = stablehlo.add %1125, %1127 : tensor<128xf32>
    %1129 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1130 = stablehlo.multiply %1129, %arg391 : tensor<128xf32>
    %1131 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1132 = stablehlo.multiply %1131, %1113 : tensor<128xf32>
    %1133 = stablehlo.add %1130, %1132 : tensor<128xf32>
    %1134 = stablehlo.broadcast_in_dim %1105, dims = [3] : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %1135 = stablehlo.broadcast_in_dim %1113, dims = [3] : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %1136 = stablehlo.convert %1087 : (tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xf32>
    %1137 = stablehlo.broadcast_in_dim %1134, dims = [0, 1, 2, 3] : (tensor<1x1x1x128xf32>) -> tensor<256x28x28x128xf32>
    %1138 = stablehlo.subtract %1136, %1137 : tensor<256x28x28x128xf32>
    %1139 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x128xf32>
    %1140 = stablehlo.add %1135, %1139 : tensor<1x1x1x128xf32>
    %1141 = stablehlo.rsqrt %1140 : tensor<1x1x1x128xf32>
    %1142 = stablehlo.divide %1141, %1140 : tensor<1x1x1x128xf32>
    %1143 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x128xf32>
    %1144 = stablehlo.multiply %1143, %1142 : tensor<1x1x1x128xf32>
    %1145 = stablehlo.reshape %arg101 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %1146 = stablehlo.multiply %1141, %1145 : tensor<1x1x1x128xf32>
    %1147 = stablehlo.broadcast_in_dim %1146, dims = [0, 1, 2, 3] : (tensor<1x1x1x128xf32>) -> tensor<256x28x28x128xf32>
    %1148 = stablehlo.multiply %1138, %1147 : tensor<256x28x28x128xf32>
    %1149 = stablehlo.reshape %arg100 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %1150 = stablehlo.broadcast_in_dim %1149, dims = [0, 1, 2, 3] : (tensor<1x1x1x128xf32>) -> tensor<256x28x28x128xf32>
    %1151 = stablehlo.add %1148, %1150 : tensor<256x28x28x128xf32>
    %1152 = stablehlo.convert %1151 : (tensor<256x28x28x128xf32>) -> tensor<256x28x28x128xf16>
    %1153 = call @relu_3(%1152) : (tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xf16>
    %1154 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x128xf16>
    %1155 = stablehlo.compare  GT, %1152, %1154,  FLOAT : (tensor<256x28x28x128xf16>, tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xi1>
    %1156 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x128xf16>
    %1157 = stablehlo.convert %arg107 : (tensor<3x3x128x128xf32>) -> tensor<3x3x128x128xf16>
    %1158 = stablehlo.convolution(%1153, %1157) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x128xf16>, tensor<3x3x128x128xf16>) -> tensor<256x28x28x128xf16>
    %1159 = stablehlo.convert %1158 : (tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xf32>
    %1160 = stablehlo.multiply %1159, %1159 : tensor<256x28x28x128xf32>
    %1161 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x28x28x128xf32>
    %1162 = stablehlo.multiply %1161, %1159 : tensor<256x28x28x128xf32>
    %cst_52 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1163 = stablehlo.reduce(%1159 init: %cst_52) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %1164 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1165 = stablehlo.divide %1163, %1164 : tensor<128xf32>
    %cst_53 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1166 = stablehlo.reduce(%1160 init: %cst_53) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %1167 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1168 = stablehlo.divide %1166, %1167 : tensor<128xf32>
    %1169 = stablehlo.broadcast_in_dim %1165, dims = [1] : (tensor<128xf32>) -> tensor<1x128xf32>
    %1170 = stablehlo.broadcast_in_dim %1168, dims = [1] : (tensor<128xf32>) -> tensor<1x128xf32>
    %1171 = stablehlo.concatenate %1169, %1170, dim = 0 : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<2x128xf32>
    %1172 = "stablehlo.all_reduce"(%1171) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x128xf32>) -> tensor<2x128xf32>
    %1173 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x128xf32>
    %1174 = stablehlo.divide %1172, %1173 : tensor<2x128xf32>
    %1175 = stablehlo.slice %1174 [0:1, 0:128] : (tensor<2x128xf32>) -> tensor<1x128xf32>
    %1176 = stablehlo.reshape %1175 : (tensor<1x128xf32>) -> tensor<128xf32>
    %1177 = stablehlo.slice %1174 [1:2, 0:128] : (tensor<2x128xf32>) -> tensor<1x128xf32>
    %1178 = stablehlo.reshape %1177 : (tensor<1x128xf32>) -> tensor<128xf32>
    %1179 = stablehlo.multiply %1176, %1176 : tensor<128xf32>
    %1180 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1181 = stablehlo.multiply %1180, %1176 : tensor<128xf32>
    %1182 = stablehlo.subtract %1178, %1179 : tensor<128xf32>
    %1183 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1184 = stablehlo.maximum %1183, %1182 : tensor<128xf32>
    %1185 = stablehlo.compare  EQ, %1182, %1184,  FLOAT : (tensor<128xf32>, tensor<128xf32>) -> tensor<128xi1>
    %1186 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1187 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1188 = stablehlo.select %1185, %1186, %1187 : tensor<128xi1>, tensor<128xf32>
    %1189 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1190 = stablehlo.compare  EQ, %1189, %1184,  FLOAT : (tensor<128xf32>, tensor<128xf32>) -> tensor<128xi1>
    %1191 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1192 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1193 = stablehlo.select %1190, %1191, %1192 : tensor<128xi1>, tensor<128xf32>
    %1194 = stablehlo.divide %1188, %1193 : tensor<128xf32>
    %1195 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1196 = stablehlo.multiply %1195, %arg392 : tensor<128xf32>
    %1197 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1198 = stablehlo.multiply %1197, %1176 : tensor<128xf32>
    %1199 = stablehlo.add %1196, %1198 : tensor<128xf32>
    %1200 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1201 = stablehlo.multiply %1200, %arg393 : tensor<128xf32>
    %1202 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1203 = stablehlo.multiply %1202, %1184 : tensor<128xf32>
    %1204 = stablehlo.add %1201, %1203 : tensor<128xf32>
    %1205 = stablehlo.broadcast_in_dim %1176, dims = [3] : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %1206 = stablehlo.broadcast_in_dim %1184, dims = [3] : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %1207 = stablehlo.convert %1158 : (tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xf32>
    %1208 = stablehlo.broadcast_in_dim %1205, dims = [0, 1, 2, 3] : (tensor<1x1x1x128xf32>) -> tensor<256x28x28x128xf32>
    %1209 = stablehlo.subtract %1207, %1208 : tensor<256x28x28x128xf32>
    %1210 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x128xf32>
    %1211 = stablehlo.add %1206, %1210 : tensor<1x1x1x128xf32>
    %1212 = stablehlo.rsqrt %1211 : tensor<1x1x1x128xf32>
    %1213 = stablehlo.divide %1212, %1211 : tensor<1x1x1x128xf32>
    %1214 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x128xf32>
    %1215 = stablehlo.multiply %1214, %1213 : tensor<1x1x1x128xf32>
    %1216 = stablehlo.reshape %arg103 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %1217 = stablehlo.multiply %1212, %1216 : tensor<1x1x1x128xf32>
    %1218 = stablehlo.broadcast_in_dim %1217, dims = [0, 1, 2, 3] : (tensor<1x1x1x128xf32>) -> tensor<256x28x28x128xf32>
    %1219 = stablehlo.multiply %1209, %1218 : tensor<256x28x28x128xf32>
    %1220 = stablehlo.reshape %arg102 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %1221 = stablehlo.broadcast_in_dim %1220, dims = [0, 1, 2, 3] : (tensor<1x1x1x128xf32>) -> tensor<256x28x28x128xf32>
    %1222 = stablehlo.add %1219, %1221 : tensor<256x28x28x128xf32>
    %1223 = stablehlo.convert %1222 : (tensor<256x28x28x128xf32>) -> tensor<256x28x28x128xf16>
    %1224 = call @relu_3(%1223) : (tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xf16>
    %1225 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x128xf16>
    %1226 = stablehlo.compare  GT, %1223, %1225,  FLOAT : (tensor<256x28x28x128xf16>, tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xi1>
    %1227 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x128xf16>
    %1228 = stablehlo.convert %arg108 : (tensor<1x1x128x512xf32>) -> tensor<1x1x128x512xf16>
    %1229 = stablehlo.convolution(%1224, %1228) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x128xf16>, tensor<1x1x128x512xf16>) -> tensor<256x28x28x512xf16>
    %1230 = stablehlo.convert %1229 : (tensor<256x28x28x512xf16>) -> tensor<256x28x28x512xf32>
    %1231 = stablehlo.multiply %1230, %1230 : tensor<256x28x28x512xf32>
    %1232 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x28x28x512xf32>
    %1233 = stablehlo.multiply %1232, %1230 : tensor<256x28x28x512xf32>
    %cst_54 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1234 = stablehlo.reduce(%1230 init: %cst_54) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x512xf32>, tensor<f32>) -> tensor<512xf32>
    %1235 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1236 = stablehlo.divide %1234, %1235 : tensor<512xf32>
    %cst_55 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1237 = stablehlo.reduce(%1231 init: %cst_55) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x512xf32>, tensor<f32>) -> tensor<512xf32>
    %1238 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1239 = stablehlo.divide %1237, %1238 : tensor<512xf32>
    %1240 = stablehlo.broadcast_in_dim %1236, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %1241 = stablehlo.broadcast_in_dim %1239, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %1242 = stablehlo.concatenate %1240, %1241, dim = 0 : (tensor<1x512xf32>, tensor<1x512xf32>) -> tensor<2x512xf32>
    %1243 = "stablehlo.all_reduce"(%1242) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x512xf32>) -> tensor<2x512xf32>
    %1244 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x512xf32>
    %1245 = stablehlo.divide %1243, %1244 : tensor<2x512xf32>
    %1246 = stablehlo.slice %1245 [0:1, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %1247 = stablehlo.reshape %1246 : (tensor<1x512xf32>) -> tensor<512xf32>
    %1248 = stablehlo.slice %1245 [1:2, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %1249 = stablehlo.reshape %1248 : (tensor<1x512xf32>) -> tensor<512xf32>
    %1250 = stablehlo.multiply %1247, %1247 : tensor<512xf32>
    %1251 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1252 = stablehlo.multiply %1251, %1247 : tensor<512xf32>
    %1253 = stablehlo.subtract %1249, %1250 : tensor<512xf32>
    %1254 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1255 = stablehlo.maximum %1254, %1253 : tensor<512xf32>
    %1256 = stablehlo.compare  EQ, %1253, %1255,  FLOAT : (tensor<512xf32>, tensor<512xf32>) -> tensor<512xi1>
    %1257 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1258 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1259 = stablehlo.select %1256, %1257, %1258 : tensor<512xi1>, tensor<512xf32>
    %1260 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1261 = stablehlo.compare  EQ, %1260, %1255,  FLOAT : (tensor<512xf32>, tensor<512xf32>) -> tensor<512xi1>
    %1262 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1263 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1264 = stablehlo.select %1261, %1262, %1263 : tensor<512xi1>, tensor<512xf32>
    %1265 = stablehlo.divide %1259, %1264 : tensor<512xf32>
    %1266 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1267 = stablehlo.multiply %1266, %arg394 : tensor<512xf32>
    %1268 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1269 = stablehlo.multiply %1268, %1247 : tensor<512xf32>
    %1270 = stablehlo.add %1267, %1269 : tensor<512xf32>
    %1271 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1272 = stablehlo.multiply %1271, %arg395 : tensor<512xf32>
    %1273 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1274 = stablehlo.multiply %1273, %1255 : tensor<512xf32>
    %1275 = stablehlo.add %1272, %1274 : tensor<512xf32>
    %1276 = stablehlo.broadcast_in_dim %1247, dims = [3] : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %1277 = stablehlo.broadcast_in_dim %1255, dims = [3] : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %1278 = stablehlo.convert %1229 : (tensor<256x28x28x512xf16>) -> tensor<256x28x28x512xf32>
    %1279 = stablehlo.broadcast_in_dim %1276, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x28x28x512xf32>
    %1280 = stablehlo.subtract %1278, %1279 : tensor<256x28x28x512xf32>
    %1281 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x512xf32>
    %1282 = stablehlo.add %1277, %1281 : tensor<1x1x1x512xf32>
    %1283 = stablehlo.rsqrt %1282 : tensor<1x1x1x512xf32>
    %1284 = stablehlo.divide %1283, %1282 : tensor<1x1x1x512xf32>
    %1285 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x512xf32>
    %1286 = stablehlo.multiply %1285, %1284 : tensor<1x1x1x512xf32>
    %1287 = stablehlo.reshape %arg105 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %1288 = stablehlo.multiply %1283, %1287 : tensor<1x1x1x512xf32>
    %1289 = stablehlo.broadcast_in_dim %1288, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x28x28x512xf32>
    %1290 = stablehlo.multiply %1280, %1289 : tensor<256x28x28x512xf32>
    %1291 = stablehlo.reshape %arg104 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %1292 = stablehlo.broadcast_in_dim %1291, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x28x28x512xf32>
    %1293 = stablehlo.add %1290, %1292 : tensor<256x28x28x512xf32>
    %1294 = stablehlo.convert %1293 : (tensor<256x28x28x512xf32>) -> tensor<256x28x28x512xf16>
    %1295 = stablehlo.add %1082, %1294 : tensor<256x28x28x512xf16>
    %1296 = call @relu_4(%1295) : (tensor<256x28x28x512xf16>) -> tensor<256x28x28x512xf16>
    %1297 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x512xf16>
    %1298 = stablehlo.compare  GT, %1295, %1297,  FLOAT : (tensor<256x28x28x512xf16>, tensor<256x28x28x512xf16>) -> tensor<256x28x28x512xi1>
    %1299 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x512xf16>
    %1300 = stablehlo.convert %arg115 : (tensor<1x1x512x128xf32>) -> tensor<1x1x512x128xf16>
    %1301 = stablehlo.convolution(%1296, %1300) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x512xf16>, tensor<1x1x512x128xf16>) -> tensor<256x28x28x128xf16>
    %1302 = stablehlo.convert %1301 : (tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xf32>
    %1303 = stablehlo.multiply %1302, %1302 : tensor<256x28x28x128xf32>
    %1304 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x28x28x128xf32>
    %1305 = stablehlo.multiply %1304, %1302 : tensor<256x28x28x128xf32>
    %cst_56 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1306 = stablehlo.reduce(%1302 init: %cst_56) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %1307 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1308 = stablehlo.divide %1306, %1307 : tensor<128xf32>
    %cst_57 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1309 = stablehlo.reduce(%1303 init: %cst_57) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %1310 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1311 = stablehlo.divide %1309, %1310 : tensor<128xf32>
    %1312 = stablehlo.broadcast_in_dim %1308, dims = [1] : (tensor<128xf32>) -> tensor<1x128xf32>
    %1313 = stablehlo.broadcast_in_dim %1311, dims = [1] : (tensor<128xf32>) -> tensor<1x128xf32>
    %1314 = stablehlo.concatenate %1312, %1313, dim = 0 : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<2x128xf32>
    %1315 = "stablehlo.all_reduce"(%1314) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x128xf32>) -> tensor<2x128xf32>
    %1316 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x128xf32>
    %1317 = stablehlo.divide %1315, %1316 : tensor<2x128xf32>
    %1318 = stablehlo.slice %1317 [0:1, 0:128] : (tensor<2x128xf32>) -> tensor<1x128xf32>
    %1319 = stablehlo.reshape %1318 : (tensor<1x128xf32>) -> tensor<128xf32>
    %1320 = stablehlo.slice %1317 [1:2, 0:128] : (tensor<2x128xf32>) -> tensor<1x128xf32>
    %1321 = stablehlo.reshape %1320 : (tensor<1x128xf32>) -> tensor<128xf32>
    %1322 = stablehlo.multiply %1319, %1319 : tensor<128xf32>
    %1323 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1324 = stablehlo.multiply %1323, %1319 : tensor<128xf32>
    %1325 = stablehlo.subtract %1321, %1322 : tensor<128xf32>
    %1326 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1327 = stablehlo.maximum %1326, %1325 : tensor<128xf32>
    %1328 = stablehlo.compare  EQ, %1325, %1327,  FLOAT : (tensor<128xf32>, tensor<128xf32>) -> tensor<128xi1>
    %1329 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1330 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1331 = stablehlo.select %1328, %1329, %1330 : tensor<128xi1>, tensor<128xf32>
    %1332 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1333 = stablehlo.compare  EQ, %1332, %1327,  FLOAT : (tensor<128xf32>, tensor<128xf32>) -> tensor<128xi1>
    %1334 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1335 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1336 = stablehlo.select %1333, %1334, %1335 : tensor<128xi1>, tensor<128xf32>
    %1337 = stablehlo.divide %1331, %1336 : tensor<128xf32>
    %1338 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1339 = stablehlo.multiply %1338, %arg396 : tensor<128xf32>
    %1340 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1341 = stablehlo.multiply %1340, %1319 : tensor<128xf32>
    %1342 = stablehlo.add %1339, %1341 : tensor<128xf32>
    %1343 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1344 = stablehlo.multiply %1343, %arg397 : tensor<128xf32>
    %1345 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1346 = stablehlo.multiply %1345, %1327 : tensor<128xf32>
    %1347 = stablehlo.add %1344, %1346 : tensor<128xf32>
    %1348 = stablehlo.broadcast_in_dim %1319, dims = [3] : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %1349 = stablehlo.broadcast_in_dim %1327, dims = [3] : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %1350 = stablehlo.convert %1301 : (tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xf32>
    %1351 = stablehlo.broadcast_in_dim %1348, dims = [0, 1, 2, 3] : (tensor<1x1x1x128xf32>) -> tensor<256x28x28x128xf32>
    %1352 = stablehlo.subtract %1350, %1351 : tensor<256x28x28x128xf32>
    %1353 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x128xf32>
    %1354 = stablehlo.add %1349, %1353 : tensor<1x1x1x128xf32>
    %1355 = stablehlo.rsqrt %1354 : tensor<1x1x1x128xf32>
    %1356 = stablehlo.divide %1355, %1354 : tensor<1x1x1x128xf32>
    %1357 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x128xf32>
    %1358 = stablehlo.multiply %1357, %1356 : tensor<1x1x1x128xf32>
    %1359 = stablehlo.reshape %arg110 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %1360 = stablehlo.multiply %1355, %1359 : tensor<1x1x1x128xf32>
    %1361 = stablehlo.broadcast_in_dim %1360, dims = [0, 1, 2, 3] : (tensor<1x1x1x128xf32>) -> tensor<256x28x28x128xf32>
    %1362 = stablehlo.multiply %1352, %1361 : tensor<256x28x28x128xf32>
    %1363 = stablehlo.reshape %arg109 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %1364 = stablehlo.broadcast_in_dim %1363, dims = [0, 1, 2, 3] : (tensor<1x1x1x128xf32>) -> tensor<256x28x28x128xf32>
    %1365 = stablehlo.add %1362, %1364 : tensor<256x28x28x128xf32>
    %1366 = stablehlo.convert %1365 : (tensor<256x28x28x128xf32>) -> tensor<256x28x28x128xf16>
    %1367 = call @relu_3(%1366) : (tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xf16>
    %1368 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x128xf16>
    %1369 = stablehlo.compare  GT, %1366, %1368,  FLOAT : (tensor<256x28x28x128xf16>, tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xi1>
    %1370 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x128xf16>
    %1371 = stablehlo.convert %arg116 : (tensor<3x3x128x128xf32>) -> tensor<3x3x128x128xf16>
    %1372 = stablehlo.convolution(%1367, %1371) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x128xf16>, tensor<3x3x128x128xf16>) -> tensor<256x28x28x128xf16>
    %1373 = stablehlo.convert %1372 : (tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xf32>
    %1374 = stablehlo.multiply %1373, %1373 : tensor<256x28x28x128xf32>
    %1375 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x28x28x128xf32>
    %1376 = stablehlo.multiply %1375, %1373 : tensor<256x28x28x128xf32>
    %cst_58 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1377 = stablehlo.reduce(%1373 init: %cst_58) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %1378 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1379 = stablehlo.divide %1377, %1378 : tensor<128xf32>
    %cst_59 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1380 = stablehlo.reduce(%1374 init: %cst_59) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %1381 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1382 = stablehlo.divide %1380, %1381 : tensor<128xf32>
    %1383 = stablehlo.broadcast_in_dim %1379, dims = [1] : (tensor<128xf32>) -> tensor<1x128xf32>
    %1384 = stablehlo.broadcast_in_dim %1382, dims = [1] : (tensor<128xf32>) -> tensor<1x128xf32>
    %1385 = stablehlo.concatenate %1383, %1384, dim = 0 : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<2x128xf32>
    %1386 = "stablehlo.all_reduce"(%1385) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x128xf32>) -> tensor<2x128xf32>
    %1387 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x128xf32>
    %1388 = stablehlo.divide %1386, %1387 : tensor<2x128xf32>
    %1389 = stablehlo.slice %1388 [0:1, 0:128] : (tensor<2x128xf32>) -> tensor<1x128xf32>
    %1390 = stablehlo.reshape %1389 : (tensor<1x128xf32>) -> tensor<128xf32>
    %1391 = stablehlo.slice %1388 [1:2, 0:128] : (tensor<2x128xf32>) -> tensor<1x128xf32>
    %1392 = stablehlo.reshape %1391 : (tensor<1x128xf32>) -> tensor<128xf32>
    %1393 = stablehlo.multiply %1390, %1390 : tensor<128xf32>
    %1394 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1395 = stablehlo.multiply %1394, %1390 : tensor<128xf32>
    %1396 = stablehlo.subtract %1392, %1393 : tensor<128xf32>
    %1397 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1398 = stablehlo.maximum %1397, %1396 : tensor<128xf32>
    %1399 = stablehlo.compare  EQ, %1396, %1398,  FLOAT : (tensor<128xf32>, tensor<128xf32>) -> tensor<128xi1>
    %1400 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1401 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1402 = stablehlo.select %1399, %1400, %1401 : tensor<128xi1>, tensor<128xf32>
    %1403 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1404 = stablehlo.compare  EQ, %1403, %1398,  FLOAT : (tensor<128xf32>, tensor<128xf32>) -> tensor<128xi1>
    %1405 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1406 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1407 = stablehlo.select %1404, %1405, %1406 : tensor<128xi1>, tensor<128xf32>
    %1408 = stablehlo.divide %1402, %1407 : tensor<128xf32>
    %1409 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1410 = stablehlo.multiply %1409, %arg398 : tensor<128xf32>
    %1411 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1412 = stablehlo.multiply %1411, %1390 : tensor<128xf32>
    %1413 = stablehlo.add %1410, %1412 : tensor<128xf32>
    %1414 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1415 = stablehlo.multiply %1414, %arg399 : tensor<128xf32>
    %1416 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1417 = stablehlo.multiply %1416, %1398 : tensor<128xf32>
    %1418 = stablehlo.add %1415, %1417 : tensor<128xf32>
    %1419 = stablehlo.broadcast_in_dim %1390, dims = [3] : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %1420 = stablehlo.broadcast_in_dim %1398, dims = [3] : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %1421 = stablehlo.convert %1372 : (tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xf32>
    %1422 = stablehlo.broadcast_in_dim %1419, dims = [0, 1, 2, 3] : (tensor<1x1x1x128xf32>) -> tensor<256x28x28x128xf32>
    %1423 = stablehlo.subtract %1421, %1422 : tensor<256x28x28x128xf32>
    %1424 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x128xf32>
    %1425 = stablehlo.add %1420, %1424 : tensor<1x1x1x128xf32>
    %1426 = stablehlo.rsqrt %1425 : tensor<1x1x1x128xf32>
    %1427 = stablehlo.divide %1426, %1425 : tensor<1x1x1x128xf32>
    %1428 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x128xf32>
    %1429 = stablehlo.multiply %1428, %1427 : tensor<1x1x1x128xf32>
    %1430 = stablehlo.reshape %arg112 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %1431 = stablehlo.multiply %1426, %1430 : tensor<1x1x1x128xf32>
    %1432 = stablehlo.broadcast_in_dim %1431, dims = [0, 1, 2, 3] : (tensor<1x1x1x128xf32>) -> tensor<256x28x28x128xf32>
    %1433 = stablehlo.multiply %1423, %1432 : tensor<256x28x28x128xf32>
    %1434 = stablehlo.reshape %arg111 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %1435 = stablehlo.broadcast_in_dim %1434, dims = [0, 1, 2, 3] : (tensor<1x1x1x128xf32>) -> tensor<256x28x28x128xf32>
    %1436 = stablehlo.add %1433, %1435 : tensor<256x28x28x128xf32>
    %1437 = stablehlo.convert %1436 : (tensor<256x28x28x128xf32>) -> tensor<256x28x28x128xf16>
    %1438 = call @relu_3(%1437) : (tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xf16>
    %1439 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x128xf16>
    %1440 = stablehlo.compare  GT, %1437, %1439,  FLOAT : (tensor<256x28x28x128xf16>, tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xi1>
    %1441 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x128xf16>
    %1442 = stablehlo.convert %arg117 : (tensor<1x1x128x512xf32>) -> tensor<1x1x128x512xf16>
    %1443 = stablehlo.convolution(%1438, %1442) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x128xf16>, tensor<1x1x128x512xf16>) -> tensor<256x28x28x512xf16>
    %1444 = stablehlo.convert %1443 : (tensor<256x28x28x512xf16>) -> tensor<256x28x28x512xf32>
    %1445 = stablehlo.multiply %1444, %1444 : tensor<256x28x28x512xf32>
    %1446 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x28x28x512xf32>
    %1447 = stablehlo.multiply %1446, %1444 : tensor<256x28x28x512xf32>
    %cst_60 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1448 = stablehlo.reduce(%1444 init: %cst_60) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x512xf32>, tensor<f32>) -> tensor<512xf32>
    %1449 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1450 = stablehlo.divide %1448, %1449 : tensor<512xf32>
    %cst_61 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1451 = stablehlo.reduce(%1445 init: %cst_61) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x512xf32>, tensor<f32>) -> tensor<512xf32>
    %1452 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1453 = stablehlo.divide %1451, %1452 : tensor<512xf32>
    %1454 = stablehlo.broadcast_in_dim %1450, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %1455 = stablehlo.broadcast_in_dim %1453, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %1456 = stablehlo.concatenate %1454, %1455, dim = 0 : (tensor<1x512xf32>, tensor<1x512xf32>) -> tensor<2x512xf32>
    %1457 = "stablehlo.all_reduce"(%1456) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x512xf32>) -> tensor<2x512xf32>
    %1458 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x512xf32>
    %1459 = stablehlo.divide %1457, %1458 : tensor<2x512xf32>
    %1460 = stablehlo.slice %1459 [0:1, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %1461 = stablehlo.reshape %1460 : (tensor<1x512xf32>) -> tensor<512xf32>
    %1462 = stablehlo.slice %1459 [1:2, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %1463 = stablehlo.reshape %1462 : (tensor<1x512xf32>) -> tensor<512xf32>
    %1464 = stablehlo.multiply %1461, %1461 : tensor<512xf32>
    %1465 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1466 = stablehlo.multiply %1465, %1461 : tensor<512xf32>
    %1467 = stablehlo.subtract %1463, %1464 : tensor<512xf32>
    %1468 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1469 = stablehlo.maximum %1468, %1467 : tensor<512xf32>
    %1470 = stablehlo.compare  EQ, %1467, %1469,  FLOAT : (tensor<512xf32>, tensor<512xf32>) -> tensor<512xi1>
    %1471 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1472 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1473 = stablehlo.select %1470, %1471, %1472 : tensor<512xi1>, tensor<512xf32>
    %1474 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1475 = stablehlo.compare  EQ, %1474, %1469,  FLOAT : (tensor<512xf32>, tensor<512xf32>) -> tensor<512xi1>
    %1476 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1477 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1478 = stablehlo.select %1475, %1476, %1477 : tensor<512xi1>, tensor<512xf32>
    %1479 = stablehlo.divide %1473, %1478 : tensor<512xf32>
    %1480 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1481 = stablehlo.multiply %1480, %arg400 : tensor<512xf32>
    %1482 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1483 = stablehlo.multiply %1482, %1461 : tensor<512xf32>
    %1484 = stablehlo.add %1481, %1483 : tensor<512xf32>
    %1485 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1486 = stablehlo.multiply %1485, %arg401 : tensor<512xf32>
    %1487 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1488 = stablehlo.multiply %1487, %1469 : tensor<512xf32>
    %1489 = stablehlo.add %1486, %1488 : tensor<512xf32>
    %1490 = stablehlo.broadcast_in_dim %1461, dims = [3] : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %1491 = stablehlo.broadcast_in_dim %1469, dims = [3] : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %1492 = stablehlo.convert %1443 : (tensor<256x28x28x512xf16>) -> tensor<256x28x28x512xf32>
    %1493 = stablehlo.broadcast_in_dim %1490, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x28x28x512xf32>
    %1494 = stablehlo.subtract %1492, %1493 : tensor<256x28x28x512xf32>
    %1495 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x512xf32>
    %1496 = stablehlo.add %1491, %1495 : tensor<1x1x1x512xf32>
    %1497 = stablehlo.rsqrt %1496 : tensor<1x1x1x512xf32>
    %1498 = stablehlo.divide %1497, %1496 : tensor<1x1x1x512xf32>
    %1499 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x512xf32>
    %1500 = stablehlo.multiply %1499, %1498 : tensor<1x1x1x512xf32>
    %1501 = stablehlo.reshape %arg114 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %1502 = stablehlo.multiply %1497, %1501 : tensor<1x1x1x512xf32>
    %1503 = stablehlo.broadcast_in_dim %1502, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x28x28x512xf32>
    %1504 = stablehlo.multiply %1494, %1503 : tensor<256x28x28x512xf32>
    %1505 = stablehlo.reshape %arg113 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %1506 = stablehlo.broadcast_in_dim %1505, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x28x28x512xf32>
    %1507 = stablehlo.add %1504, %1506 : tensor<256x28x28x512xf32>
    %1508 = stablehlo.convert %1507 : (tensor<256x28x28x512xf32>) -> tensor<256x28x28x512xf16>
    %1509 = stablehlo.add %1296, %1508 : tensor<256x28x28x512xf16>
    %1510 = call @relu_4(%1509) : (tensor<256x28x28x512xf16>) -> tensor<256x28x28x512xf16>
    %1511 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x512xf16>
    %1512 = stablehlo.compare  GT, %1509, %1511,  FLOAT : (tensor<256x28x28x512xf16>, tensor<256x28x28x512xf16>) -> tensor<256x28x28x512xi1>
    %1513 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x512xf16>
    %1514 = stablehlo.convert %arg124 : (tensor<1x1x512x128xf32>) -> tensor<1x1x512x128xf16>
    %1515 = stablehlo.convolution(%1510, %1514) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x512xf16>, tensor<1x1x512x128xf16>) -> tensor<256x28x28x128xf16>
    %1516 = stablehlo.convert %1515 : (tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xf32>
    %1517 = stablehlo.multiply %1516, %1516 : tensor<256x28x28x128xf32>
    %1518 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x28x28x128xf32>
    %1519 = stablehlo.multiply %1518, %1516 : tensor<256x28x28x128xf32>
    %cst_62 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1520 = stablehlo.reduce(%1516 init: %cst_62) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %1521 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1522 = stablehlo.divide %1520, %1521 : tensor<128xf32>
    %cst_63 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1523 = stablehlo.reduce(%1517 init: %cst_63) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %1524 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1525 = stablehlo.divide %1523, %1524 : tensor<128xf32>
    %1526 = stablehlo.broadcast_in_dim %1522, dims = [1] : (tensor<128xf32>) -> tensor<1x128xf32>
    %1527 = stablehlo.broadcast_in_dim %1525, dims = [1] : (tensor<128xf32>) -> tensor<1x128xf32>
    %1528 = stablehlo.concatenate %1526, %1527, dim = 0 : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<2x128xf32>
    %1529 = "stablehlo.all_reduce"(%1528) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x128xf32>) -> tensor<2x128xf32>
    %1530 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x128xf32>
    %1531 = stablehlo.divide %1529, %1530 : tensor<2x128xf32>
    %1532 = stablehlo.slice %1531 [0:1, 0:128] : (tensor<2x128xf32>) -> tensor<1x128xf32>
    %1533 = stablehlo.reshape %1532 : (tensor<1x128xf32>) -> tensor<128xf32>
    %1534 = stablehlo.slice %1531 [1:2, 0:128] : (tensor<2x128xf32>) -> tensor<1x128xf32>
    %1535 = stablehlo.reshape %1534 : (tensor<1x128xf32>) -> tensor<128xf32>
    %1536 = stablehlo.multiply %1533, %1533 : tensor<128xf32>
    %1537 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1538 = stablehlo.multiply %1537, %1533 : tensor<128xf32>
    %1539 = stablehlo.subtract %1535, %1536 : tensor<128xf32>
    %1540 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1541 = stablehlo.maximum %1540, %1539 : tensor<128xf32>
    %1542 = stablehlo.compare  EQ, %1539, %1541,  FLOAT : (tensor<128xf32>, tensor<128xf32>) -> tensor<128xi1>
    %1543 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1544 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1545 = stablehlo.select %1542, %1543, %1544 : tensor<128xi1>, tensor<128xf32>
    %1546 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1547 = stablehlo.compare  EQ, %1546, %1541,  FLOAT : (tensor<128xf32>, tensor<128xf32>) -> tensor<128xi1>
    %1548 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1549 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1550 = stablehlo.select %1547, %1548, %1549 : tensor<128xi1>, tensor<128xf32>
    %1551 = stablehlo.divide %1545, %1550 : tensor<128xf32>
    %1552 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1553 = stablehlo.multiply %1552, %arg402 : tensor<128xf32>
    %1554 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1555 = stablehlo.multiply %1554, %1533 : tensor<128xf32>
    %1556 = stablehlo.add %1553, %1555 : tensor<128xf32>
    %1557 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1558 = stablehlo.multiply %1557, %arg403 : tensor<128xf32>
    %1559 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1560 = stablehlo.multiply %1559, %1541 : tensor<128xf32>
    %1561 = stablehlo.add %1558, %1560 : tensor<128xf32>
    %1562 = stablehlo.broadcast_in_dim %1533, dims = [3] : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %1563 = stablehlo.broadcast_in_dim %1541, dims = [3] : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %1564 = stablehlo.convert %1515 : (tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xf32>
    %1565 = stablehlo.broadcast_in_dim %1562, dims = [0, 1, 2, 3] : (tensor<1x1x1x128xf32>) -> tensor<256x28x28x128xf32>
    %1566 = stablehlo.subtract %1564, %1565 : tensor<256x28x28x128xf32>
    %1567 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x128xf32>
    %1568 = stablehlo.add %1563, %1567 : tensor<1x1x1x128xf32>
    %1569 = stablehlo.rsqrt %1568 : tensor<1x1x1x128xf32>
    %1570 = stablehlo.divide %1569, %1568 : tensor<1x1x1x128xf32>
    %1571 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x128xf32>
    %1572 = stablehlo.multiply %1571, %1570 : tensor<1x1x1x128xf32>
    %1573 = stablehlo.reshape %arg119 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %1574 = stablehlo.multiply %1569, %1573 : tensor<1x1x1x128xf32>
    %1575 = stablehlo.broadcast_in_dim %1574, dims = [0, 1, 2, 3] : (tensor<1x1x1x128xf32>) -> tensor<256x28x28x128xf32>
    %1576 = stablehlo.multiply %1566, %1575 : tensor<256x28x28x128xf32>
    %1577 = stablehlo.reshape %arg118 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %1578 = stablehlo.broadcast_in_dim %1577, dims = [0, 1, 2, 3] : (tensor<1x1x1x128xf32>) -> tensor<256x28x28x128xf32>
    %1579 = stablehlo.add %1576, %1578 : tensor<256x28x28x128xf32>
    %1580 = stablehlo.convert %1579 : (tensor<256x28x28x128xf32>) -> tensor<256x28x28x128xf16>
    %1581 = call @relu_3(%1580) : (tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xf16>
    %1582 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x128xf16>
    %1583 = stablehlo.compare  GT, %1580, %1582,  FLOAT : (tensor<256x28x28x128xf16>, tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xi1>
    %1584 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x128xf16>
    %1585 = stablehlo.convert %arg125 : (tensor<3x3x128x128xf32>) -> tensor<3x3x128x128xf16>
    %1586 = stablehlo.convolution(%1581, %1585) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x128xf16>, tensor<3x3x128x128xf16>) -> tensor<256x28x28x128xf16>
    %1587 = stablehlo.convert %1586 : (tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xf32>
    %1588 = stablehlo.multiply %1587, %1587 : tensor<256x28x28x128xf32>
    %1589 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x28x28x128xf32>
    %1590 = stablehlo.multiply %1589, %1587 : tensor<256x28x28x128xf32>
    %cst_64 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1591 = stablehlo.reduce(%1587 init: %cst_64) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %1592 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1593 = stablehlo.divide %1591, %1592 : tensor<128xf32>
    %cst_65 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1594 = stablehlo.reduce(%1588 init: %cst_65) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %1595 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1596 = stablehlo.divide %1594, %1595 : tensor<128xf32>
    %1597 = stablehlo.broadcast_in_dim %1593, dims = [1] : (tensor<128xf32>) -> tensor<1x128xf32>
    %1598 = stablehlo.broadcast_in_dim %1596, dims = [1] : (tensor<128xf32>) -> tensor<1x128xf32>
    %1599 = stablehlo.concatenate %1597, %1598, dim = 0 : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<2x128xf32>
    %1600 = "stablehlo.all_reduce"(%1599) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x128xf32>) -> tensor<2x128xf32>
    %1601 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x128xf32>
    %1602 = stablehlo.divide %1600, %1601 : tensor<2x128xf32>
    %1603 = stablehlo.slice %1602 [0:1, 0:128] : (tensor<2x128xf32>) -> tensor<1x128xf32>
    %1604 = stablehlo.reshape %1603 : (tensor<1x128xf32>) -> tensor<128xf32>
    %1605 = stablehlo.slice %1602 [1:2, 0:128] : (tensor<2x128xf32>) -> tensor<1x128xf32>
    %1606 = stablehlo.reshape %1605 : (tensor<1x128xf32>) -> tensor<128xf32>
    %1607 = stablehlo.multiply %1604, %1604 : tensor<128xf32>
    %1608 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1609 = stablehlo.multiply %1608, %1604 : tensor<128xf32>
    %1610 = stablehlo.subtract %1606, %1607 : tensor<128xf32>
    %1611 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1612 = stablehlo.maximum %1611, %1610 : tensor<128xf32>
    %1613 = stablehlo.compare  EQ, %1610, %1612,  FLOAT : (tensor<128xf32>, tensor<128xf32>) -> tensor<128xi1>
    %1614 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1615 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1616 = stablehlo.select %1613, %1614, %1615 : tensor<128xi1>, tensor<128xf32>
    %1617 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1618 = stablehlo.compare  EQ, %1617, %1612,  FLOAT : (tensor<128xf32>, tensor<128xf32>) -> tensor<128xi1>
    %1619 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1620 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1621 = stablehlo.select %1618, %1619, %1620 : tensor<128xi1>, tensor<128xf32>
    %1622 = stablehlo.divide %1616, %1621 : tensor<128xf32>
    %1623 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1624 = stablehlo.multiply %1623, %arg404 : tensor<128xf32>
    %1625 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1626 = stablehlo.multiply %1625, %1604 : tensor<128xf32>
    %1627 = stablehlo.add %1624, %1626 : tensor<128xf32>
    %1628 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1629 = stablehlo.multiply %1628, %arg405 : tensor<128xf32>
    %1630 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %1631 = stablehlo.multiply %1630, %1612 : tensor<128xf32>
    %1632 = stablehlo.add %1629, %1631 : tensor<128xf32>
    %1633 = stablehlo.broadcast_in_dim %1604, dims = [3] : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %1634 = stablehlo.broadcast_in_dim %1612, dims = [3] : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %1635 = stablehlo.convert %1586 : (tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xf32>
    %1636 = stablehlo.broadcast_in_dim %1633, dims = [0, 1, 2, 3] : (tensor<1x1x1x128xf32>) -> tensor<256x28x28x128xf32>
    %1637 = stablehlo.subtract %1635, %1636 : tensor<256x28x28x128xf32>
    %1638 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x128xf32>
    %1639 = stablehlo.add %1634, %1638 : tensor<1x1x1x128xf32>
    %1640 = stablehlo.rsqrt %1639 : tensor<1x1x1x128xf32>
    %1641 = stablehlo.divide %1640, %1639 : tensor<1x1x1x128xf32>
    %1642 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x128xf32>
    %1643 = stablehlo.multiply %1642, %1641 : tensor<1x1x1x128xf32>
    %1644 = stablehlo.reshape %arg121 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %1645 = stablehlo.multiply %1640, %1644 : tensor<1x1x1x128xf32>
    %1646 = stablehlo.broadcast_in_dim %1645, dims = [0, 1, 2, 3] : (tensor<1x1x1x128xf32>) -> tensor<256x28x28x128xf32>
    %1647 = stablehlo.multiply %1637, %1646 : tensor<256x28x28x128xf32>
    %1648 = stablehlo.reshape %arg120 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %1649 = stablehlo.broadcast_in_dim %1648, dims = [0, 1, 2, 3] : (tensor<1x1x1x128xf32>) -> tensor<256x28x28x128xf32>
    %1650 = stablehlo.add %1647, %1649 : tensor<256x28x28x128xf32>
    %1651 = stablehlo.convert %1650 : (tensor<256x28x28x128xf32>) -> tensor<256x28x28x128xf16>
    %1652 = call @relu_3(%1651) : (tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xf16>
    %1653 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x128xf16>
    %1654 = stablehlo.compare  GT, %1651, %1653,  FLOAT : (tensor<256x28x28x128xf16>, tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xi1>
    %1655 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x128xf16>
    %1656 = stablehlo.convert %arg126 : (tensor<1x1x128x512xf32>) -> tensor<1x1x128x512xf16>
    %1657 = stablehlo.convolution(%1652, %1656) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x128xf16>, tensor<1x1x128x512xf16>) -> tensor<256x28x28x512xf16>
    %1658 = stablehlo.convert %1657 : (tensor<256x28x28x512xf16>) -> tensor<256x28x28x512xf32>
    %1659 = stablehlo.multiply %1658, %1658 : tensor<256x28x28x512xf32>
    %1660 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x28x28x512xf32>
    %1661 = stablehlo.multiply %1660, %1658 : tensor<256x28x28x512xf32>
    %cst_66 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1662 = stablehlo.reduce(%1658 init: %cst_66) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x512xf32>, tensor<f32>) -> tensor<512xf32>
    %1663 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1664 = stablehlo.divide %1662, %1663 : tensor<512xf32>
    %cst_67 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1665 = stablehlo.reduce(%1659 init: %cst_67) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x512xf32>, tensor<f32>) -> tensor<512xf32>
    %1666 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1667 = stablehlo.divide %1665, %1666 : tensor<512xf32>
    %1668 = stablehlo.broadcast_in_dim %1664, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %1669 = stablehlo.broadcast_in_dim %1667, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %1670 = stablehlo.concatenate %1668, %1669, dim = 0 : (tensor<1x512xf32>, tensor<1x512xf32>) -> tensor<2x512xf32>
    %1671 = "stablehlo.all_reduce"(%1670) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x512xf32>) -> tensor<2x512xf32>
    %1672 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x512xf32>
    %1673 = stablehlo.divide %1671, %1672 : tensor<2x512xf32>
    %1674 = stablehlo.slice %1673 [0:1, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %1675 = stablehlo.reshape %1674 : (tensor<1x512xf32>) -> tensor<512xf32>
    %1676 = stablehlo.slice %1673 [1:2, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %1677 = stablehlo.reshape %1676 : (tensor<1x512xf32>) -> tensor<512xf32>
    %1678 = stablehlo.multiply %1675, %1675 : tensor<512xf32>
    %1679 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1680 = stablehlo.multiply %1679, %1675 : tensor<512xf32>
    %1681 = stablehlo.subtract %1677, %1678 : tensor<512xf32>
    %1682 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1683 = stablehlo.maximum %1682, %1681 : tensor<512xf32>
    %1684 = stablehlo.compare  EQ, %1681, %1683,  FLOAT : (tensor<512xf32>, tensor<512xf32>) -> tensor<512xi1>
    %1685 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1686 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1687 = stablehlo.select %1684, %1685, %1686 : tensor<512xi1>, tensor<512xf32>
    %1688 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1689 = stablehlo.compare  EQ, %1688, %1683,  FLOAT : (tensor<512xf32>, tensor<512xf32>) -> tensor<512xi1>
    %1690 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1691 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1692 = stablehlo.select %1689, %1690, %1691 : tensor<512xi1>, tensor<512xf32>
    %1693 = stablehlo.divide %1687, %1692 : tensor<512xf32>
    %1694 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1695 = stablehlo.multiply %1694, %arg406 : tensor<512xf32>
    %1696 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1697 = stablehlo.multiply %1696, %1675 : tensor<512xf32>
    %1698 = stablehlo.add %1695, %1697 : tensor<512xf32>
    %1699 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1700 = stablehlo.multiply %1699, %arg407 : tensor<512xf32>
    %1701 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %1702 = stablehlo.multiply %1701, %1683 : tensor<512xf32>
    %1703 = stablehlo.add %1700, %1702 : tensor<512xf32>
    %1704 = stablehlo.broadcast_in_dim %1675, dims = [3] : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %1705 = stablehlo.broadcast_in_dim %1683, dims = [3] : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %1706 = stablehlo.convert %1657 : (tensor<256x28x28x512xf16>) -> tensor<256x28x28x512xf32>
    %1707 = stablehlo.broadcast_in_dim %1704, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x28x28x512xf32>
    %1708 = stablehlo.subtract %1706, %1707 : tensor<256x28x28x512xf32>
    %1709 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x512xf32>
    %1710 = stablehlo.add %1705, %1709 : tensor<1x1x1x512xf32>
    %1711 = stablehlo.rsqrt %1710 : tensor<1x1x1x512xf32>
    %1712 = stablehlo.divide %1711, %1710 : tensor<1x1x1x512xf32>
    %1713 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x512xf32>
    %1714 = stablehlo.multiply %1713, %1712 : tensor<1x1x1x512xf32>
    %1715 = stablehlo.reshape %arg123 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %1716 = stablehlo.multiply %1711, %1715 : tensor<1x1x1x512xf32>
    %1717 = stablehlo.broadcast_in_dim %1716, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x28x28x512xf32>
    %1718 = stablehlo.multiply %1708, %1717 : tensor<256x28x28x512xf32>
    %1719 = stablehlo.reshape %arg122 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %1720 = stablehlo.broadcast_in_dim %1719, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x28x28x512xf32>
    %1721 = stablehlo.add %1718, %1720 : tensor<256x28x28x512xf32>
    %1722 = stablehlo.convert %1721 : (tensor<256x28x28x512xf32>) -> tensor<256x28x28x512xf16>
    %1723 = stablehlo.add %1510, %1722 : tensor<256x28x28x512xf16>
    %1724 = call @relu_4(%1723) : (tensor<256x28x28x512xf16>) -> tensor<256x28x28x512xf16>
    %1725 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x512xf16>
    %1726 = stablehlo.compare  GT, %1723, %1725,  FLOAT : (tensor<256x28x28x512xf16>, tensor<256x28x28x512xf16>) -> tensor<256x28x28x512xi1>
    %1727 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x512xf16>
    %1728 = stablehlo.convert %arg133 : (tensor<1x1x512x256xf32>) -> tensor<1x1x512x256xf16>
    %1729 = stablehlo.convolution(%1724, %1728) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x512xf16>, tensor<1x1x512x256xf16>) -> tensor<256x28x28x256xf16>
    %1730 = stablehlo.convert %1729 : (tensor<256x28x28x256xf16>) -> tensor<256x28x28x256xf32>
    %1731 = stablehlo.multiply %1730, %1730 : tensor<256x28x28x256xf32>
    %1732 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x28x28x256xf32>
    %1733 = stablehlo.multiply %1732, %1730 : tensor<256x28x28x256xf32>
    %cst_68 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1734 = stablehlo.reduce(%1730 init: %cst_68) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x256xf32>, tensor<f32>) -> tensor<256xf32>
    %1735 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %1736 = stablehlo.divide %1734, %1735 : tensor<256xf32>
    %cst_69 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1737 = stablehlo.reduce(%1731 init: %cst_69) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x256xf32>, tensor<f32>) -> tensor<256xf32>
    %1738 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %1739 = stablehlo.divide %1737, %1738 : tensor<256xf32>
    %1740 = stablehlo.broadcast_in_dim %1736, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %1741 = stablehlo.broadcast_in_dim %1739, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %1742 = stablehlo.concatenate %1740, %1741, dim = 0 : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<2x256xf32>
    %1743 = "stablehlo.all_reduce"(%1742) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x256xf32>) -> tensor<2x256xf32>
    %1744 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x256xf32>
    %1745 = stablehlo.divide %1743, %1744 : tensor<2x256xf32>
    %1746 = stablehlo.slice %1745 [0:1, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %1747 = stablehlo.reshape %1746 : (tensor<1x256xf32>) -> tensor<256xf32>
    %1748 = stablehlo.slice %1745 [1:2, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %1749 = stablehlo.reshape %1748 : (tensor<1x256xf32>) -> tensor<256xf32>
    %1750 = stablehlo.multiply %1747, %1747 : tensor<256xf32>
    %1751 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %1752 = stablehlo.multiply %1751, %1747 : tensor<256xf32>
    %1753 = stablehlo.subtract %1749, %1750 : tensor<256xf32>
    %1754 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %1755 = stablehlo.maximum %1754, %1753 : tensor<256xf32>
    %1756 = stablehlo.compare  EQ, %1753, %1755,  FLOAT : (tensor<256xf32>, tensor<256xf32>) -> tensor<256xi1>
    %1757 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %1758 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %1759 = stablehlo.select %1756, %1757, %1758 : tensor<256xi1>, tensor<256xf32>
    %1760 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %1761 = stablehlo.compare  EQ, %1760, %1755,  FLOAT : (tensor<256xf32>, tensor<256xf32>) -> tensor<256xi1>
    %1762 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %1763 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %1764 = stablehlo.select %1761, %1762, %1763 : tensor<256xi1>, tensor<256xf32>
    %1765 = stablehlo.divide %1759, %1764 : tensor<256xf32>
    %1766 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %1767 = stablehlo.multiply %1766, %arg408 : tensor<256xf32>
    %1768 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %1769 = stablehlo.multiply %1768, %1747 : tensor<256xf32>
    %1770 = stablehlo.add %1767, %1769 : tensor<256xf32>
    %1771 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %1772 = stablehlo.multiply %1771, %arg409 : tensor<256xf32>
    %1773 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %1774 = stablehlo.multiply %1773, %1755 : tensor<256xf32>
    %1775 = stablehlo.add %1772, %1774 : tensor<256xf32>
    %1776 = stablehlo.broadcast_in_dim %1747, dims = [3] : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %1777 = stablehlo.broadcast_in_dim %1755, dims = [3] : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %1778 = stablehlo.convert %1729 : (tensor<256x28x28x256xf16>) -> tensor<256x28x28x256xf32>
    %1779 = stablehlo.broadcast_in_dim %1776, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x28x28x256xf32>
    %1780 = stablehlo.subtract %1778, %1779 : tensor<256x28x28x256xf32>
    %1781 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x256xf32>
    %1782 = stablehlo.add %1777, %1781 : tensor<1x1x1x256xf32>
    %1783 = stablehlo.rsqrt %1782 : tensor<1x1x1x256xf32>
    %1784 = stablehlo.divide %1783, %1782 : tensor<1x1x1x256xf32>
    %1785 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x256xf32>
    %1786 = stablehlo.multiply %1785, %1784 : tensor<1x1x1x256xf32>
    %1787 = stablehlo.reshape %arg128 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %1788 = stablehlo.multiply %1783, %1787 : tensor<1x1x1x256xf32>
    %1789 = stablehlo.broadcast_in_dim %1788, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x28x28x256xf32>
    %1790 = stablehlo.multiply %1780, %1789 : tensor<256x28x28x256xf32>
    %1791 = stablehlo.reshape %arg127 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %1792 = stablehlo.broadcast_in_dim %1791, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x28x28x256xf32>
    %1793 = stablehlo.add %1790, %1792 : tensor<256x28x28x256xf32>
    %1794 = stablehlo.convert %1793 : (tensor<256x28x28x256xf32>) -> tensor<256x28x28x256xf16>
    %1795 = call @relu_5(%1794) : (tensor<256x28x28x256xf16>) -> tensor<256x28x28x256xf16>
    %1796 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x256xf16>
    %1797 = stablehlo.compare  GT, %1794, %1796,  FLOAT : (tensor<256x28x28x256xf16>, tensor<256x28x28x256xf16>) -> tensor<256x28x28x256xi1>
    %1798 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x256xf16>
    %1799 = stablehlo.convert %arg134 : (tensor<3x3x256x256xf32>) -> tensor<3x3x256x256xf16>
    %1800 = stablehlo.convolution(%1795, %1799) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [2, 2], pad = [[0, 1], [0, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x256xf16>, tensor<3x3x256x256xf16>) -> tensor<256x14x14x256xf16>
    %1801 = stablehlo.convert %1800 : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf32>
    %1802 = stablehlo.multiply %1801, %1801 : tensor<256x14x14x256xf32>
    %1803 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x14x14x256xf32>
    %1804 = stablehlo.multiply %1803, %1801 : tensor<256x14x14x256xf32>
    %cst_70 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1805 = stablehlo.reduce(%1801 init: %cst_70) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %cst_71 = stablehlo.constant dense<5.017600e+04> : tensor<f32>
    %1806 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %1807 = stablehlo.divide %1805, %1806 : tensor<256xf32>
    %cst_72 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1808 = stablehlo.reduce(%1802 init: %cst_72) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %1809 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %1810 = stablehlo.divide %1808, %1809 : tensor<256xf32>
    %1811 = stablehlo.broadcast_in_dim %1807, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %1812 = stablehlo.broadcast_in_dim %1810, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %1813 = stablehlo.concatenate %1811, %1812, dim = 0 : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<2x256xf32>
    %1814 = "stablehlo.all_reduce"(%1813) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x256xf32>) -> tensor<2x256xf32>
    %1815 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x256xf32>
    %1816 = stablehlo.divide %1814, %1815 : tensor<2x256xf32>
    %1817 = stablehlo.slice %1816 [0:1, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %1818 = stablehlo.reshape %1817 : (tensor<1x256xf32>) -> tensor<256xf32>
    %1819 = stablehlo.slice %1816 [1:2, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %1820 = stablehlo.reshape %1819 : (tensor<1x256xf32>) -> tensor<256xf32>
    %1821 = stablehlo.multiply %1818, %1818 : tensor<256xf32>
    %1822 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %1823 = stablehlo.multiply %1822, %1818 : tensor<256xf32>
    %1824 = stablehlo.subtract %1820, %1821 : tensor<256xf32>
    %1825 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %1826 = stablehlo.maximum %1825, %1824 : tensor<256xf32>
    %1827 = stablehlo.compare  EQ, %1824, %1826,  FLOAT : (tensor<256xf32>, tensor<256xf32>) -> tensor<256xi1>
    %1828 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %1829 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %1830 = stablehlo.select %1827, %1828, %1829 : tensor<256xi1>, tensor<256xf32>
    %1831 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %1832 = stablehlo.compare  EQ, %1831, %1826,  FLOAT : (tensor<256xf32>, tensor<256xf32>) -> tensor<256xi1>
    %1833 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %1834 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %1835 = stablehlo.select %1832, %1833, %1834 : tensor<256xi1>, tensor<256xf32>
    %1836 = stablehlo.divide %1830, %1835 : tensor<256xf32>
    %1837 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %1838 = stablehlo.multiply %1837, %arg410 : tensor<256xf32>
    %1839 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %1840 = stablehlo.multiply %1839, %1818 : tensor<256xf32>
    %1841 = stablehlo.add %1838, %1840 : tensor<256xf32>
    %1842 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %1843 = stablehlo.multiply %1842, %arg411 : tensor<256xf32>
    %1844 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %1845 = stablehlo.multiply %1844, %1826 : tensor<256xf32>
    %1846 = stablehlo.add %1843, %1845 : tensor<256xf32>
    %1847 = stablehlo.broadcast_in_dim %1818, dims = [3] : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %1848 = stablehlo.broadcast_in_dim %1826, dims = [3] : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %1849 = stablehlo.convert %1800 : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf32>
    %1850 = stablehlo.broadcast_in_dim %1847, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %1851 = stablehlo.subtract %1849, %1850 : tensor<256x14x14x256xf32>
    %1852 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x256xf32>
    %1853 = stablehlo.add %1848, %1852 : tensor<1x1x1x256xf32>
    %1854 = stablehlo.rsqrt %1853 : tensor<1x1x1x256xf32>
    %1855 = stablehlo.divide %1854, %1853 : tensor<1x1x1x256xf32>
    %1856 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x256xf32>
    %1857 = stablehlo.multiply %1856, %1855 : tensor<1x1x1x256xf32>
    %1858 = stablehlo.reshape %arg130 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %1859 = stablehlo.multiply %1854, %1858 : tensor<1x1x1x256xf32>
    %1860 = stablehlo.broadcast_in_dim %1859, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %1861 = stablehlo.multiply %1851, %1860 : tensor<256x14x14x256xf32>
    %1862 = stablehlo.reshape %arg129 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %1863 = stablehlo.broadcast_in_dim %1862, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %1864 = stablehlo.add %1861, %1863 : tensor<256x14x14x256xf32>
    %1865 = stablehlo.convert %1864 : (tensor<256x14x14x256xf32>) -> tensor<256x14x14x256xf16>
    %1866 = call @relu_6(%1865) : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf16>
    %1867 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %1868 = stablehlo.compare  GT, %1865, %1867,  FLOAT : (tensor<256x14x14x256xf16>, tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xi1>
    %1869 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %1870 = stablehlo.convert %arg135 : (tensor<1x1x256x1024xf32>) -> tensor<1x1x256x1024xf16>
    %1871 = stablehlo.convolution(%1866, %1870) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x256xf16>, tensor<1x1x256x1024xf16>) -> tensor<256x14x14x1024xf16>
    %1872 = stablehlo.convert %1871 : (tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xf32>
    %1873 = stablehlo.multiply %1872, %1872 : tensor<256x14x14x1024xf32>
    %1874 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x14x14x1024xf32>
    %1875 = stablehlo.multiply %1874, %1872 : tensor<256x14x14x1024xf32>
    %cst_73 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1876 = stablehlo.reduce(%1872 init: %cst_73) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %1877 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %1878 = stablehlo.divide %1876, %1877 : tensor<1024xf32>
    %cst_74 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1879 = stablehlo.reduce(%1873 init: %cst_74) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %1880 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %1881 = stablehlo.divide %1879, %1880 : tensor<1024xf32>
    %1882 = stablehlo.broadcast_in_dim %1878, dims = [1] : (tensor<1024xf32>) -> tensor<1x1024xf32>
    %1883 = stablehlo.broadcast_in_dim %1881, dims = [1] : (tensor<1024xf32>) -> tensor<1x1024xf32>
    %1884 = stablehlo.concatenate %1882, %1883, dim = 0 : (tensor<1x1024xf32>, tensor<1x1024xf32>) -> tensor<2x1024xf32>
    %1885 = "stablehlo.all_reduce"(%1884) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x1024xf32>) -> tensor<2x1024xf32>
    %1886 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x1024xf32>
    %1887 = stablehlo.divide %1885, %1886 : tensor<2x1024xf32>
    %1888 = stablehlo.slice %1887 [0:1, 0:1024] : (tensor<2x1024xf32>) -> tensor<1x1024xf32>
    %1889 = stablehlo.reshape %1888 : (tensor<1x1024xf32>) -> tensor<1024xf32>
    %1890 = stablehlo.slice %1887 [1:2, 0:1024] : (tensor<2x1024xf32>) -> tensor<1x1024xf32>
    %1891 = stablehlo.reshape %1890 : (tensor<1x1024xf32>) -> tensor<1024xf32>
    %1892 = stablehlo.multiply %1889, %1889 : tensor<1024xf32>
    %1893 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %1894 = stablehlo.multiply %1893, %1889 : tensor<1024xf32>
    %1895 = stablehlo.subtract %1891, %1892 : tensor<1024xf32>
    %1896 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %1897 = stablehlo.maximum %1896, %1895 : tensor<1024xf32>
    %1898 = stablehlo.compare  EQ, %1895, %1897,  FLOAT : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xi1>
    %1899 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %1900 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %1901 = stablehlo.select %1898, %1899, %1900 : tensor<1024xi1>, tensor<1024xf32>
    %1902 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %1903 = stablehlo.compare  EQ, %1902, %1897,  FLOAT : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xi1>
    %1904 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %1905 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %1906 = stablehlo.select %1903, %1904, %1905 : tensor<1024xi1>, tensor<1024xf32>
    %1907 = stablehlo.divide %1901, %1906 : tensor<1024xf32>
    %1908 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %1909 = stablehlo.multiply %1908, %arg412 : tensor<1024xf32>
    %1910 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %1911 = stablehlo.multiply %1910, %1889 : tensor<1024xf32>
    %1912 = stablehlo.add %1909, %1911 : tensor<1024xf32>
    %1913 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %1914 = stablehlo.multiply %1913, %arg413 : tensor<1024xf32>
    %1915 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %1916 = stablehlo.multiply %1915, %1897 : tensor<1024xf32>
    %1917 = stablehlo.add %1914, %1916 : tensor<1024xf32>
    %1918 = stablehlo.broadcast_in_dim %1889, dims = [3] : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %1919 = stablehlo.broadcast_in_dim %1897, dims = [3] : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %1920 = stablehlo.convert %1871 : (tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xf32>
    %1921 = stablehlo.broadcast_in_dim %1918, dims = [0, 1, 2, 3] : (tensor<1x1x1x1024xf32>) -> tensor<256x14x14x1024xf32>
    %1922 = stablehlo.subtract %1920, %1921 : tensor<256x14x14x1024xf32>
    %1923 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x1024xf32>
    %1924 = stablehlo.add %1919, %1923 : tensor<1x1x1x1024xf32>
    %1925 = stablehlo.rsqrt %1924 : tensor<1x1x1x1024xf32>
    %1926 = stablehlo.divide %1925, %1924 : tensor<1x1x1x1024xf32>
    %1927 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x1024xf32>
    %1928 = stablehlo.multiply %1927, %1926 : tensor<1x1x1x1024xf32>
    %1929 = stablehlo.reshape %arg132 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %1930 = stablehlo.multiply %1925, %1929 : tensor<1x1x1x1024xf32>
    %1931 = stablehlo.broadcast_in_dim %1930, dims = [0, 1, 2, 3] : (tensor<1x1x1x1024xf32>) -> tensor<256x14x14x1024xf32>
    %1932 = stablehlo.multiply %1922, %1931 : tensor<256x14x14x1024xf32>
    %1933 = stablehlo.reshape %arg131 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %1934 = stablehlo.broadcast_in_dim %1933, dims = [0, 1, 2, 3] : (tensor<1x1x1x1024xf32>) -> tensor<256x14x14x1024xf32>
    %1935 = stablehlo.add %1932, %1934 : tensor<256x14x14x1024xf32>
    %1936 = stablehlo.convert %1935 : (tensor<256x14x14x1024xf32>) -> tensor<256x14x14x1024xf16>
    %1937 = stablehlo.convert %arg136 : (tensor<1x1x512x1024xf32>) -> tensor<1x1x512x1024xf16>
    %1938 = stablehlo.convolution(%1724, %1937) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [2, 2], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x512xf16>, tensor<1x1x512x1024xf16>) -> tensor<256x14x14x1024xf16>
    %1939 = stablehlo.convert %1938 : (tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xf32>
    %1940 = stablehlo.multiply %1939, %1939 : tensor<256x14x14x1024xf32>
    %1941 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x14x14x1024xf32>
    %1942 = stablehlo.multiply %1941, %1939 : tensor<256x14x14x1024xf32>
    %cst_75 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1943 = stablehlo.reduce(%1939 init: %cst_75) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %1944 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %1945 = stablehlo.divide %1943, %1944 : tensor<1024xf32>
    %cst_76 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1946 = stablehlo.reduce(%1940 init: %cst_76) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %1947 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %1948 = stablehlo.divide %1946, %1947 : tensor<1024xf32>
    %1949 = stablehlo.broadcast_in_dim %1945, dims = [1] : (tensor<1024xf32>) -> tensor<1x1024xf32>
    %1950 = stablehlo.broadcast_in_dim %1948, dims = [1] : (tensor<1024xf32>) -> tensor<1x1024xf32>
    %1951 = stablehlo.concatenate %1949, %1950, dim = 0 : (tensor<1x1024xf32>, tensor<1x1024xf32>) -> tensor<2x1024xf32>
    %1952 = "stablehlo.all_reduce"(%1951) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x1024xf32>) -> tensor<2x1024xf32>
    %1953 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x1024xf32>
    %1954 = stablehlo.divide %1952, %1953 : tensor<2x1024xf32>
    %1955 = stablehlo.slice %1954 [0:1, 0:1024] : (tensor<2x1024xf32>) -> tensor<1x1024xf32>
    %1956 = stablehlo.reshape %1955 : (tensor<1x1024xf32>) -> tensor<1024xf32>
    %1957 = stablehlo.slice %1954 [1:2, 0:1024] : (tensor<2x1024xf32>) -> tensor<1x1024xf32>
    %1958 = stablehlo.reshape %1957 : (tensor<1x1024xf32>) -> tensor<1024xf32>
    %1959 = stablehlo.multiply %1956, %1956 : tensor<1024xf32>
    %1960 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %1961 = stablehlo.multiply %1960, %1956 : tensor<1024xf32>
    %1962 = stablehlo.subtract %1958, %1959 : tensor<1024xf32>
    %1963 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %1964 = stablehlo.maximum %1963, %1962 : tensor<1024xf32>
    %1965 = stablehlo.compare  EQ, %1962, %1964,  FLOAT : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xi1>
    %1966 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %1967 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %1968 = stablehlo.select %1965, %1966, %1967 : tensor<1024xi1>, tensor<1024xf32>
    %1969 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %1970 = stablehlo.compare  EQ, %1969, %1964,  FLOAT : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xi1>
    %1971 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %1972 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %1973 = stablehlo.select %1970, %1971, %1972 : tensor<1024xi1>, tensor<1024xf32>
    %1974 = stablehlo.divide %1968, %1973 : tensor<1024xf32>
    %1975 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %1976 = stablehlo.multiply %1975, %arg414 : tensor<1024xf32>
    %1977 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %1978 = stablehlo.multiply %1977, %1956 : tensor<1024xf32>
    %1979 = stablehlo.add %1976, %1978 : tensor<1024xf32>
    %1980 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %1981 = stablehlo.multiply %1980, %arg415 : tensor<1024xf32>
    %1982 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %1983 = stablehlo.multiply %1982, %1964 : tensor<1024xf32>
    %1984 = stablehlo.add %1981, %1983 : tensor<1024xf32>
    %1985 = stablehlo.broadcast_in_dim %1956, dims = [3] : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %1986 = stablehlo.broadcast_in_dim %1964, dims = [3] : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %1987 = stablehlo.convert %1938 : (tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xf32>
    %1988 = stablehlo.broadcast_in_dim %1985, dims = [0, 1, 2, 3] : (tensor<1x1x1x1024xf32>) -> tensor<256x14x14x1024xf32>
    %1989 = stablehlo.subtract %1987, %1988 : tensor<256x14x14x1024xf32>
    %1990 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x1024xf32>
    %1991 = stablehlo.add %1986, %1990 : tensor<1x1x1x1024xf32>
    %1992 = stablehlo.rsqrt %1991 : tensor<1x1x1x1024xf32>
    %1993 = stablehlo.divide %1992, %1991 : tensor<1x1x1x1024xf32>
    %1994 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x1024xf32>
    %1995 = stablehlo.multiply %1994, %1993 : tensor<1x1x1x1024xf32>
    %1996 = stablehlo.reshape %arg138 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %1997 = stablehlo.multiply %1992, %1996 : tensor<1x1x1x1024xf32>
    %1998 = stablehlo.broadcast_in_dim %1997, dims = [0, 1, 2, 3] : (tensor<1x1x1x1024xf32>) -> tensor<256x14x14x1024xf32>
    %1999 = stablehlo.multiply %1989, %1998 : tensor<256x14x14x1024xf32>
    %2000 = stablehlo.reshape %arg137 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %2001 = stablehlo.broadcast_in_dim %2000, dims = [0, 1, 2, 3] : (tensor<1x1x1x1024xf32>) -> tensor<256x14x14x1024xf32>
    %2002 = stablehlo.add %1999, %2001 : tensor<256x14x14x1024xf32>
    %2003 = stablehlo.convert %2002 : (tensor<256x14x14x1024xf32>) -> tensor<256x14x14x1024xf16>
    %2004 = stablehlo.add %2003, %1936 : tensor<256x14x14x1024xf16>
    %2005 = call @relu_7(%2004) : (tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xf16>
    %2006 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x1024xf16>
    %2007 = stablehlo.compare  GT, %2004, %2006,  FLOAT : (tensor<256x14x14x1024xf16>, tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xi1>
    %2008 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x1024xf16>
    %2009 = stablehlo.convert %arg145 : (tensor<1x1x1024x256xf32>) -> tensor<1x1x1024x256xf16>
    %2010 = stablehlo.convolution(%2005, %2009) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x1024xf16>, tensor<1x1x1024x256xf16>) -> tensor<256x14x14x256xf16>
    %2011 = stablehlo.convert %2010 : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf32>
    %2012 = stablehlo.multiply %2011, %2011 : tensor<256x14x14x256xf32>
    %2013 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x14x14x256xf32>
    %2014 = stablehlo.multiply %2013, %2011 : tensor<256x14x14x256xf32>
    %cst_77 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %2015 = stablehlo.reduce(%2011 init: %cst_77) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %2016 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2017 = stablehlo.divide %2015, %2016 : tensor<256xf32>
    %cst_78 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %2018 = stablehlo.reduce(%2012 init: %cst_78) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %2019 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2020 = stablehlo.divide %2018, %2019 : tensor<256xf32>
    %2021 = stablehlo.broadcast_in_dim %2017, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %2022 = stablehlo.broadcast_in_dim %2020, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %2023 = stablehlo.concatenate %2021, %2022, dim = 0 : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<2x256xf32>
    %2024 = "stablehlo.all_reduce"(%2023) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x256xf32>) -> tensor<2x256xf32>
    %2025 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x256xf32>
    %2026 = stablehlo.divide %2024, %2025 : tensor<2x256xf32>
    %2027 = stablehlo.slice %2026 [0:1, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %2028 = stablehlo.reshape %2027 : (tensor<1x256xf32>) -> tensor<256xf32>
    %2029 = stablehlo.slice %2026 [1:2, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %2030 = stablehlo.reshape %2029 : (tensor<1x256xf32>) -> tensor<256xf32>
    %2031 = stablehlo.multiply %2028, %2028 : tensor<256xf32>
    %2032 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2033 = stablehlo.multiply %2032, %2028 : tensor<256xf32>
    %2034 = stablehlo.subtract %2030, %2031 : tensor<256xf32>
    %2035 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2036 = stablehlo.maximum %2035, %2034 : tensor<256xf32>
    %2037 = stablehlo.compare  EQ, %2034, %2036,  FLOAT : (tensor<256xf32>, tensor<256xf32>) -> tensor<256xi1>
    %2038 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2039 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2040 = stablehlo.select %2037, %2038, %2039 : tensor<256xi1>, tensor<256xf32>
    %2041 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2042 = stablehlo.compare  EQ, %2041, %2036,  FLOAT : (tensor<256xf32>, tensor<256xf32>) -> tensor<256xi1>
    %2043 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2044 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2045 = stablehlo.select %2042, %2043, %2044 : tensor<256xi1>, tensor<256xf32>
    %2046 = stablehlo.divide %2040, %2045 : tensor<256xf32>
    %2047 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2048 = stablehlo.multiply %2047, %arg416 : tensor<256xf32>
    %2049 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2050 = stablehlo.multiply %2049, %2028 : tensor<256xf32>
    %2051 = stablehlo.add %2048, %2050 : tensor<256xf32>
    %2052 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2053 = stablehlo.multiply %2052, %arg417 : tensor<256xf32>
    %2054 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2055 = stablehlo.multiply %2054, %2036 : tensor<256xf32>
    %2056 = stablehlo.add %2053, %2055 : tensor<256xf32>
    %2057 = stablehlo.broadcast_in_dim %2028, dims = [3] : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2058 = stablehlo.broadcast_in_dim %2036, dims = [3] : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2059 = stablehlo.convert %2010 : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf32>
    %2060 = stablehlo.broadcast_in_dim %2057, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %2061 = stablehlo.subtract %2059, %2060 : tensor<256x14x14x256xf32>
    %2062 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x256xf32>
    %2063 = stablehlo.add %2058, %2062 : tensor<1x1x1x256xf32>
    %2064 = stablehlo.rsqrt %2063 : tensor<1x1x1x256xf32>
    %2065 = stablehlo.divide %2064, %2063 : tensor<1x1x1x256xf32>
    %2066 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x256xf32>
    %2067 = stablehlo.multiply %2066, %2065 : tensor<1x1x1x256xf32>
    %2068 = stablehlo.reshape %arg140 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2069 = stablehlo.multiply %2064, %2068 : tensor<1x1x1x256xf32>
    %2070 = stablehlo.broadcast_in_dim %2069, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %2071 = stablehlo.multiply %2061, %2070 : tensor<256x14x14x256xf32>
    %2072 = stablehlo.reshape %arg139 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2073 = stablehlo.broadcast_in_dim %2072, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %2074 = stablehlo.add %2071, %2073 : tensor<256x14x14x256xf32>
    %2075 = stablehlo.convert %2074 : (tensor<256x14x14x256xf32>) -> tensor<256x14x14x256xf16>
    %2076 = call @relu_6(%2075) : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf16>
    %2077 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %2078 = stablehlo.compare  GT, %2075, %2077,  FLOAT : (tensor<256x14x14x256xf16>, tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xi1>
    %2079 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %2080 = stablehlo.convert %arg146 : (tensor<3x3x256x256xf32>) -> tensor<3x3x256x256xf16>
    %2081 = stablehlo.convolution(%2076, %2080) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x256xf16>, tensor<3x3x256x256xf16>) -> tensor<256x14x14x256xf16>
    %2082 = stablehlo.convert %2081 : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf32>
    %2083 = stablehlo.multiply %2082, %2082 : tensor<256x14x14x256xf32>
    %2084 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x14x14x256xf32>
    %2085 = stablehlo.multiply %2084, %2082 : tensor<256x14x14x256xf32>
    %cst_79 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %2086 = stablehlo.reduce(%2082 init: %cst_79) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %2087 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2088 = stablehlo.divide %2086, %2087 : tensor<256xf32>
    %cst_80 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %2089 = stablehlo.reduce(%2083 init: %cst_80) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %2090 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2091 = stablehlo.divide %2089, %2090 : tensor<256xf32>
    %2092 = stablehlo.broadcast_in_dim %2088, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %2093 = stablehlo.broadcast_in_dim %2091, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %2094 = stablehlo.concatenate %2092, %2093, dim = 0 : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<2x256xf32>
    %2095 = "stablehlo.all_reduce"(%2094) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x256xf32>) -> tensor<2x256xf32>
    %2096 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x256xf32>
    %2097 = stablehlo.divide %2095, %2096 : tensor<2x256xf32>
    %2098 = stablehlo.slice %2097 [0:1, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %2099 = stablehlo.reshape %2098 : (tensor<1x256xf32>) -> tensor<256xf32>
    %2100 = stablehlo.slice %2097 [1:2, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %2101 = stablehlo.reshape %2100 : (tensor<1x256xf32>) -> tensor<256xf32>
    %2102 = stablehlo.multiply %2099, %2099 : tensor<256xf32>
    %2103 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2104 = stablehlo.multiply %2103, %2099 : tensor<256xf32>
    %2105 = stablehlo.subtract %2101, %2102 : tensor<256xf32>
    %2106 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2107 = stablehlo.maximum %2106, %2105 : tensor<256xf32>
    %2108 = stablehlo.compare  EQ, %2105, %2107,  FLOAT : (tensor<256xf32>, tensor<256xf32>) -> tensor<256xi1>
    %2109 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2110 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2111 = stablehlo.select %2108, %2109, %2110 : tensor<256xi1>, tensor<256xf32>
    %2112 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2113 = stablehlo.compare  EQ, %2112, %2107,  FLOAT : (tensor<256xf32>, tensor<256xf32>) -> tensor<256xi1>
    %2114 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2115 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2116 = stablehlo.select %2113, %2114, %2115 : tensor<256xi1>, tensor<256xf32>
    %2117 = stablehlo.divide %2111, %2116 : tensor<256xf32>
    %2118 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2119 = stablehlo.multiply %2118, %arg418 : tensor<256xf32>
    %2120 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2121 = stablehlo.multiply %2120, %2099 : tensor<256xf32>
    %2122 = stablehlo.add %2119, %2121 : tensor<256xf32>
    %2123 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2124 = stablehlo.multiply %2123, %arg419 : tensor<256xf32>
    %2125 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2126 = stablehlo.multiply %2125, %2107 : tensor<256xf32>
    %2127 = stablehlo.add %2124, %2126 : tensor<256xf32>
    %2128 = stablehlo.broadcast_in_dim %2099, dims = [3] : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2129 = stablehlo.broadcast_in_dim %2107, dims = [3] : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2130 = stablehlo.convert %2081 : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf32>
    %2131 = stablehlo.broadcast_in_dim %2128, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %2132 = stablehlo.subtract %2130, %2131 : tensor<256x14x14x256xf32>
    %2133 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x256xf32>
    %2134 = stablehlo.add %2129, %2133 : tensor<1x1x1x256xf32>
    %2135 = stablehlo.rsqrt %2134 : tensor<1x1x1x256xf32>
    %2136 = stablehlo.divide %2135, %2134 : tensor<1x1x1x256xf32>
    %2137 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x256xf32>
    %2138 = stablehlo.multiply %2137, %2136 : tensor<1x1x1x256xf32>
    %2139 = stablehlo.reshape %arg142 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2140 = stablehlo.multiply %2135, %2139 : tensor<1x1x1x256xf32>
    %2141 = stablehlo.broadcast_in_dim %2140, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %2142 = stablehlo.multiply %2132, %2141 : tensor<256x14x14x256xf32>
    %2143 = stablehlo.reshape %arg141 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2144 = stablehlo.broadcast_in_dim %2143, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %2145 = stablehlo.add %2142, %2144 : tensor<256x14x14x256xf32>
    %2146 = stablehlo.convert %2145 : (tensor<256x14x14x256xf32>) -> tensor<256x14x14x256xf16>
    %2147 = call @relu_6(%2146) : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf16>
    %2148 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %2149 = stablehlo.compare  GT, %2146, %2148,  FLOAT : (tensor<256x14x14x256xf16>, tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xi1>
    %2150 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %2151 = stablehlo.convert %arg147 : (tensor<1x1x256x1024xf32>) -> tensor<1x1x256x1024xf16>
    %2152 = stablehlo.convolution(%2147, %2151) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x256xf16>, tensor<1x1x256x1024xf16>) -> tensor<256x14x14x1024xf16>
    %2153 = stablehlo.convert %2152 : (tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xf32>
    %2154 = stablehlo.multiply %2153, %2153 : tensor<256x14x14x1024xf32>
    %2155 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x14x14x1024xf32>
    %2156 = stablehlo.multiply %2155, %2153 : tensor<256x14x14x1024xf32>
    %cst_81 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %2157 = stablehlo.reduce(%2153 init: %cst_81) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %2158 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2159 = stablehlo.divide %2157, %2158 : tensor<1024xf32>
    %cst_82 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %2160 = stablehlo.reduce(%2154 init: %cst_82) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %2161 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2162 = stablehlo.divide %2160, %2161 : tensor<1024xf32>
    %2163 = stablehlo.broadcast_in_dim %2159, dims = [1] : (tensor<1024xf32>) -> tensor<1x1024xf32>
    %2164 = stablehlo.broadcast_in_dim %2162, dims = [1] : (tensor<1024xf32>) -> tensor<1x1024xf32>
    %2165 = stablehlo.concatenate %2163, %2164, dim = 0 : (tensor<1x1024xf32>, tensor<1x1024xf32>) -> tensor<2x1024xf32>
    %2166 = "stablehlo.all_reduce"(%2165) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x1024xf32>) -> tensor<2x1024xf32>
    %2167 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x1024xf32>
    %2168 = stablehlo.divide %2166, %2167 : tensor<2x1024xf32>
    %2169 = stablehlo.slice %2168 [0:1, 0:1024] : (tensor<2x1024xf32>) -> tensor<1x1024xf32>
    %2170 = stablehlo.reshape %2169 : (tensor<1x1024xf32>) -> tensor<1024xf32>
    %2171 = stablehlo.slice %2168 [1:2, 0:1024] : (tensor<2x1024xf32>) -> tensor<1x1024xf32>
    %2172 = stablehlo.reshape %2171 : (tensor<1x1024xf32>) -> tensor<1024xf32>
    %2173 = stablehlo.multiply %2170, %2170 : tensor<1024xf32>
    %2174 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2175 = stablehlo.multiply %2174, %2170 : tensor<1024xf32>
    %2176 = stablehlo.subtract %2172, %2173 : tensor<1024xf32>
    %2177 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2178 = stablehlo.maximum %2177, %2176 : tensor<1024xf32>
    %2179 = stablehlo.compare  EQ, %2176, %2178,  FLOAT : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xi1>
    %2180 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2181 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2182 = stablehlo.select %2179, %2180, %2181 : tensor<1024xi1>, tensor<1024xf32>
    %2183 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2184 = stablehlo.compare  EQ, %2183, %2178,  FLOAT : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xi1>
    %2185 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2186 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2187 = stablehlo.select %2184, %2185, %2186 : tensor<1024xi1>, tensor<1024xf32>
    %2188 = stablehlo.divide %2182, %2187 : tensor<1024xf32>
    %2189 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2190 = stablehlo.multiply %2189, %arg420 : tensor<1024xf32>
    %2191 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2192 = stablehlo.multiply %2191, %2170 : tensor<1024xf32>
    %2193 = stablehlo.add %2190, %2192 : tensor<1024xf32>
    %2194 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2195 = stablehlo.multiply %2194, %arg421 : tensor<1024xf32>
    %2196 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2197 = stablehlo.multiply %2196, %2178 : tensor<1024xf32>
    %2198 = stablehlo.add %2195, %2197 : tensor<1024xf32>
    %2199 = stablehlo.broadcast_in_dim %2170, dims = [3] : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %2200 = stablehlo.broadcast_in_dim %2178, dims = [3] : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %2201 = stablehlo.convert %2152 : (tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xf32>
    %2202 = stablehlo.broadcast_in_dim %2199, dims = [0, 1, 2, 3] : (tensor<1x1x1x1024xf32>) -> tensor<256x14x14x1024xf32>
    %2203 = stablehlo.subtract %2201, %2202 : tensor<256x14x14x1024xf32>
    %2204 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x1024xf32>
    %2205 = stablehlo.add %2200, %2204 : tensor<1x1x1x1024xf32>
    %2206 = stablehlo.rsqrt %2205 : tensor<1x1x1x1024xf32>
    %2207 = stablehlo.divide %2206, %2205 : tensor<1x1x1x1024xf32>
    %2208 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x1024xf32>
    %2209 = stablehlo.multiply %2208, %2207 : tensor<1x1x1x1024xf32>
    %2210 = stablehlo.reshape %arg144 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %2211 = stablehlo.multiply %2206, %2210 : tensor<1x1x1x1024xf32>
    %2212 = stablehlo.broadcast_in_dim %2211, dims = [0, 1, 2, 3] : (tensor<1x1x1x1024xf32>) -> tensor<256x14x14x1024xf32>
    %2213 = stablehlo.multiply %2203, %2212 : tensor<256x14x14x1024xf32>
    %2214 = stablehlo.reshape %arg143 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %2215 = stablehlo.broadcast_in_dim %2214, dims = [0, 1, 2, 3] : (tensor<1x1x1x1024xf32>) -> tensor<256x14x14x1024xf32>
    %2216 = stablehlo.add %2213, %2215 : tensor<256x14x14x1024xf32>
    %2217 = stablehlo.convert %2216 : (tensor<256x14x14x1024xf32>) -> tensor<256x14x14x1024xf16>
    %2218 = stablehlo.add %2005, %2217 : tensor<256x14x14x1024xf16>
    %2219 = call @relu_7(%2218) : (tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xf16>
    %2220 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x1024xf16>
    %2221 = stablehlo.compare  GT, %2218, %2220,  FLOAT : (tensor<256x14x14x1024xf16>, tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xi1>
    %2222 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x1024xf16>
    %2223 = stablehlo.convert %arg154 : (tensor<1x1x1024x256xf32>) -> tensor<1x1x1024x256xf16>
    %2224 = stablehlo.convolution(%2219, %2223) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x1024xf16>, tensor<1x1x1024x256xf16>) -> tensor<256x14x14x256xf16>
    %2225 = stablehlo.convert %2224 : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf32>
    %2226 = stablehlo.multiply %2225, %2225 : tensor<256x14x14x256xf32>
    %2227 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x14x14x256xf32>
    %2228 = stablehlo.multiply %2227, %2225 : tensor<256x14x14x256xf32>
    %cst_83 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %2229 = stablehlo.reduce(%2225 init: %cst_83) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %2230 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2231 = stablehlo.divide %2229, %2230 : tensor<256xf32>
    %cst_84 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %2232 = stablehlo.reduce(%2226 init: %cst_84) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %2233 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2234 = stablehlo.divide %2232, %2233 : tensor<256xf32>
    %2235 = stablehlo.broadcast_in_dim %2231, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %2236 = stablehlo.broadcast_in_dim %2234, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %2237 = stablehlo.concatenate %2235, %2236, dim = 0 : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<2x256xf32>
    %2238 = "stablehlo.all_reduce"(%2237) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x256xf32>) -> tensor<2x256xf32>
    %2239 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x256xf32>
    %2240 = stablehlo.divide %2238, %2239 : tensor<2x256xf32>
    %2241 = stablehlo.slice %2240 [0:1, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %2242 = stablehlo.reshape %2241 : (tensor<1x256xf32>) -> tensor<256xf32>
    %2243 = stablehlo.slice %2240 [1:2, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %2244 = stablehlo.reshape %2243 : (tensor<1x256xf32>) -> tensor<256xf32>
    %2245 = stablehlo.multiply %2242, %2242 : tensor<256xf32>
    %2246 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2247 = stablehlo.multiply %2246, %2242 : tensor<256xf32>
    %2248 = stablehlo.subtract %2244, %2245 : tensor<256xf32>
    %2249 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2250 = stablehlo.maximum %2249, %2248 : tensor<256xf32>
    %2251 = stablehlo.compare  EQ, %2248, %2250,  FLOAT : (tensor<256xf32>, tensor<256xf32>) -> tensor<256xi1>
    %2252 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2253 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2254 = stablehlo.select %2251, %2252, %2253 : tensor<256xi1>, tensor<256xf32>
    %2255 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2256 = stablehlo.compare  EQ, %2255, %2250,  FLOAT : (tensor<256xf32>, tensor<256xf32>) -> tensor<256xi1>
    %2257 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2258 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2259 = stablehlo.select %2256, %2257, %2258 : tensor<256xi1>, tensor<256xf32>
    %2260 = stablehlo.divide %2254, %2259 : tensor<256xf32>
    %2261 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2262 = stablehlo.multiply %2261, %arg422 : tensor<256xf32>
    %2263 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2264 = stablehlo.multiply %2263, %2242 : tensor<256xf32>
    %2265 = stablehlo.add %2262, %2264 : tensor<256xf32>
    %2266 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2267 = stablehlo.multiply %2266, %arg423 : tensor<256xf32>
    %2268 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2269 = stablehlo.multiply %2268, %2250 : tensor<256xf32>
    %2270 = stablehlo.add %2267, %2269 : tensor<256xf32>
    %2271 = stablehlo.broadcast_in_dim %2242, dims = [3] : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2272 = stablehlo.broadcast_in_dim %2250, dims = [3] : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2273 = stablehlo.convert %2224 : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf32>
    %2274 = stablehlo.broadcast_in_dim %2271, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %2275 = stablehlo.subtract %2273, %2274 : tensor<256x14x14x256xf32>
    %2276 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x256xf32>
    %2277 = stablehlo.add %2272, %2276 : tensor<1x1x1x256xf32>
    %2278 = stablehlo.rsqrt %2277 : tensor<1x1x1x256xf32>
    %2279 = stablehlo.divide %2278, %2277 : tensor<1x1x1x256xf32>
    %2280 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x256xf32>
    %2281 = stablehlo.multiply %2280, %2279 : tensor<1x1x1x256xf32>
    %2282 = stablehlo.reshape %arg149 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2283 = stablehlo.multiply %2278, %2282 : tensor<1x1x1x256xf32>
    %2284 = stablehlo.broadcast_in_dim %2283, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %2285 = stablehlo.multiply %2275, %2284 : tensor<256x14x14x256xf32>
    %2286 = stablehlo.reshape %arg148 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2287 = stablehlo.broadcast_in_dim %2286, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %2288 = stablehlo.add %2285, %2287 : tensor<256x14x14x256xf32>
    %2289 = stablehlo.convert %2288 : (tensor<256x14x14x256xf32>) -> tensor<256x14x14x256xf16>
    %2290 = call @relu_6(%2289) : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf16>
    %2291 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %2292 = stablehlo.compare  GT, %2289, %2291,  FLOAT : (tensor<256x14x14x256xf16>, tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xi1>
    %2293 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %2294 = stablehlo.convert %arg155 : (tensor<3x3x256x256xf32>) -> tensor<3x3x256x256xf16>
    %2295 = stablehlo.convolution(%2290, %2294) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x256xf16>, tensor<3x3x256x256xf16>) -> tensor<256x14x14x256xf16>
    %2296 = stablehlo.convert %2295 : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf32>
    %2297 = stablehlo.multiply %2296, %2296 : tensor<256x14x14x256xf32>
    %2298 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x14x14x256xf32>
    %2299 = stablehlo.multiply %2298, %2296 : tensor<256x14x14x256xf32>
    %cst_85 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %2300 = stablehlo.reduce(%2296 init: %cst_85) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %2301 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2302 = stablehlo.divide %2300, %2301 : tensor<256xf32>
    %cst_86 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %2303 = stablehlo.reduce(%2297 init: %cst_86) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %2304 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2305 = stablehlo.divide %2303, %2304 : tensor<256xf32>
    %2306 = stablehlo.broadcast_in_dim %2302, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %2307 = stablehlo.broadcast_in_dim %2305, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %2308 = stablehlo.concatenate %2306, %2307, dim = 0 : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<2x256xf32>
    %2309 = "stablehlo.all_reduce"(%2308) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x256xf32>) -> tensor<2x256xf32>
    %2310 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x256xf32>
    %2311 = stablehlo.divide %2309, %2310 : tensor<2x256xf32>
    %2312 = stablehlo.slice %2311 [0:1, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %2313 = stablehlo.reshape %2312 : (tensor<1x256xf32>) -> tensor<256xf32>
    %2314 = stablehlo.slice %2311 [1:2, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %2315 = stablehlo.reshape %2314 : (tensor<1x256xf32>) -> tensor<256xf32>
    %2316 = stablehlo.multiply %2313, %2313 : tensor<256xf32>
    %2317 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2318 = stablehlo.multiply %2317, %2313 : tensor<256xf32>
    %2319 = stablehlo.subtract %2315, %2316 : tensor<256xf32>
    %2320 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2321 = stablehlo.maximum %2320, %2319 : tensor<256xf32>
    %2322 = stablehlo.compare  EQ, %2319, %2321,  FLOAT : (tensor<256xf32>, tensor<256xf32>) -> tensor<256xi1>
    %2323 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2324 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2325 = stablehlo.select %2322, %2323, %2324 : tensor<256xi1>, tensor<256xf32>
    %2326 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2327 = stablehlo.compare  EQ, %2326, %2321,  FLOAT : (tensor<256xf32>, tensor<256xf32>) -> tensor<256xi1>
    %2328 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2329 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2330 = stablehlo.select %2327, %2328, %2329 : tensor<256xi1>, tensor<256xf32>
    %2331 = stablehlo.divide %2325, %2330 : tensor<256xf32>
    %2332 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2333 = stablehlo.multiply %2332, %arg424 : tensor<256xf32>
    %2334 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2335 = stablehlo.multiply %2334, %2313 : tensor<256xf32>
    %2336 = stablehlo.add %2333, %2335 : tensor<256xf32>
    %2337 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2338 = stablehlo.multiply %2337, %arg425 : tensor<256xf32>
    %2339 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2340 = stablehlo.multiply %2339, %2321 : tensor<256xf32>
    %2341 = stablehlo.add %2338, %2340 : tensor<256xf32>
    %2342 = stablehlo.broadcast_in_dim %2313, dims = [3] : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2343 = stablehlo.broadcast_in_dim %2321, dims = [3] : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2344 = stablehlo.convert %2295 : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf32>
    %2345 = stablehlo.broadcast_in_dim %2342, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %2346 = stablehlo.subtract %2344, %2345 : tensor<256x14x14x256xf32>
    %2347 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x256xf32>
    %2348 = stablehlo.add %2343, %2347 : tensor<1x1x1x256xf32>
    %2349 = stablehlo.rsqrt %2348 : tensor<1x1x1x256xf32>
    %2350 = stablehlo.divide %2349, %2348 : tensor<1x1x1x256xf32>
    %2351 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x256xf32>
    %2352 = stablehlo.multiply %2351, %2350 : tensor<1x1x1x256xf32>
    %2353 = stablehlo.reshape %arg151 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2354 = stablehlo.multiply %2349, %2353 : tensor<1x1x1x256xf32>
    %2355 = stablehlo.broadcast_in_dim %2354, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %2356 = stablehlo.multiply %2346, %2355 : tensor<256x14x14x256xf32>
    %2357 = stablehlo.reshape %arg150 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2358 = stablehlo.broadcast_in_dim %2357, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %2359 = stablehlo.add %2356, %2358 : tensor<256x14x14x256xf32>
    %2360 = stablehlo.convert %2359 : (tensor<256x14x14x256xf32>) -> tensor<256x14x14x256xf16>
    %2361 = call @relu_6(%2360) : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf16>
    %2362 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %2363 = stablehlo.compare  GT, %2360, %2362,  FLOAT : (tensor<256x14x14x256xf16>, tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xi1>
    %2364 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %2365 = stablehlo.convert %arg156 : (tensor<1x1x256x1024xf32>) -> tensor<1x1x256x1024xf16>
    %2366 = stablehlo.convolution(%2361, %2365) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x256xf16>, tensor<1x1x256x1024xf16>) -> tensor<256x14x14x1024xf16>
    %2367 = stablehlo.convert %2366 : (tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xf32>
    %2368 = stablehlo.multiply %2367, %2367 : tensor<256x14x14x1024xf32>
    %2369 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x14x14x1024xf32>
    %2370 = stablehlo.multiply %2369, %2367 : tensor<256x14x14x1024xf32>
    %cst_87 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %2371 = stablehlo.reduce(%2367 init: %cst_87) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %2372 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2373 = stablehlo.divide %2371, %2372 : tensor<1024xf32>
    %cst_88 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %2374 = stablehlo.reduce(%2368 init: %cst_88) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %2375 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2376 = stablehlo.divide %2374, %2375 : tensor<1024xf32>
    %2377 = stablehlo.broadcast_in_dim %2373, dims = [1] : (tensor<1024xf32>) -> tensor<1x1024xf32>
    %2378 = stablehlo.broadcast_in_dim %2376, dims = [1] : (tensor<1024xf32>) -> tensor<1x1024xf32>
    %2379 = stablehlo.concatenate %2377, %2378, dim = 0 : (tensor<1x1024xf32>, tensor<1x1024xf32>) -> tensor<2x1024xf32>
    %2380 = "stablehlo.all_reduce"(%2379) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x1024xf32>) -> tensor<2x1024xf32>
    %2381 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x1024xf32>
    %2382 = stablehlo.divide %2380, %2381 : tensor<2x1024xf32>
    %2383 = stablehlo.slice %2382 [0:1, 0:1024] : (tensor<2x1024xf32>) -> tensor<1x1024xf32>
    %2384 = stablehlo.reshape %2383 : (tensor<1x1024xf32>) -> tensor<1024xf32>
    %2385 = stablehlo.slice %2382 [1:2, 0:1024] : (tensor<2x1024xf32>) -> tensor<1x1024xf32>
    %2386 = stablehlo.reshape %2385 : (tensor<1x1024xf32>) -> tensor<1024xf32>
    %2387 = stablehlo.multiply %2384, %2384 : tensor<1024xf32>
    %2388 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2389 = stablehlo.multiply %2388, %2384 : tensor<1024xf32>
    %2390 = stablehlo.subtract %2386, %2387 : tensor<1024xf32>
    %2391 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2392 = stablehlo.maximum %2391, %2390 : tensor<1024xf32>
    %2393 = stablehlo.compare  EQ, %2390, %2392,  FLOAT : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xi1>
    %2394 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2395 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2396 = stablehlo.select %2393, %2394, %2395 : tensor<1024xi1>, tensor<1024xf32>
    %2397 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2398 = stablehlo.compare  EQ, %2397, %2392,  FLOAT : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xi1>
    %2399 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2400 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2401 = stablehlo.select %2398, %2399, %2400 : tensor<1024xi1>, tensor<1024xf32>
    %2402 = stablehlo.divide %2396, %2401 : tensor<1024xf32>
    %2403 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2404 = stablehlo.multiply %2403, %arg426 : tensor<1024xf32>
    %2405 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2406 = stablehlo.multiply %2405, %2384 : tensor<1024xf32>
    %2407 = stablehlo.add %2404, %2406 : tensor<1024xf32>
    %2408 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2409 = stablehlo.multiply %2408, %arg427 : tensor<1024xf32>
    %2410 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2411 = stablehlo.multiply %2410, %2392 : tensor<1024xf32>
    %2412 = stablehlo.add %2409, %2411 : tensor<1024xf32>
    %2413 = stablehlo.broadcast_in_dim %2384, dims = [3] : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %2414 = stablehlo.broadcast_in_dim %2392, dims = [3] : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %2415 = stablehlo.convert %2366 : (tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xf32>
    %2416 = stablehlo.broadcast_in_dim %2413, dims = [0, 1, 2, 3] : (tensor<1x1x1x1024xf32>) -> tensor<256x14x14x1024xf32>
    %2417 = stablehlo.subtract %2415, %2416 : tensor<256x14x14x1024xf32>
    %2418 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x1024xf32>
    %2419 = stablehlo.add %2414, %2418 : tensor<1x1x1x1024xf32>
    %2420 = stablehlo.rsqrt %2419 : tensor<1x1x1x1024xf32>
    %2421 = stablehlo.divide %2420, %2419 : tensor<1x1x1x1024xf32>
    %2422 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x1024xf32>
    %2423 = stablehlo.multiply %2422, %2421 : tensor<1x1x1x1024xf32>
    %2424 = stablehlo.reshape %arg153 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %2425 = stablehlo.multiply %2420, %2424 : tensor<1x1x1x1024xf32>
    %2426 = stablehlo.broadcast_in_dim %2425, dims = [0, 1, 2, 3] : (tensor<1x1x1x1024xf32>) -> tensor<256x14x14x1024xf32>
    %2427 = stablehlo.multiply %2417, %2426 : tensor<256x14x14x1024xf32>
    %2428 = stablehlo.reshape %arg152 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %2429 = stablehlo.broadcast_in_dim %2428, dims = [0, 1, 2, 3] : (tensor<1x1x1x1024xf32>) -> tensor<256x14x14x1024xf32>
    %2430 = stablehlo.add %2427, %2429 : tensor<256x14x14x1024xf32>
    %2431 = stablehlo.convert %2430 : (tensor<256x14x14x1024xf32>) -> tensor<256x14x14x1024xf16>
    %2432 = stablehlo.add %2219, %2431 : tensor<256x14x14x1024xf16>
    %2433 = call @relu_7(%2432) : (tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xf16>
    %2434 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x1024xf16>
    %2435 = stablehlo.compare  GT, %2432, %2434,  FLOAT : (tensor<256x14x14x1024xf16>, tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xi1>
    %2436 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x1024xf16>
    %2437 = stablehlo.convert %arg28 : (tensor<1x1x1024x256xf32>) -> tensor<1x1x1024x256xf16>
    %2438 = stablehlo.convolution(%2433, %2437) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x1024xf16>, tensor<1x1x1024x256xf16>) -> tensor<256x14x14x256xf16>
    %2439 = stablehlo.convert %2438 : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf32>
    %2440 = stablehlo.multiply %2439, %2439 : tensor<256x14x14x256xf32>
    %2441 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x14x14x256xf32>
    %2442 = stablehlo.multiply %2441, %2439 : tensor<256x14x14x256xf32>
    %cst_89 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %2443 = stablehlo.reduce(%2439 init: %cst_89) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %2444 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2445 = stablehlo.divide %2443, %2444 : tensor<256xf32>
    %cst_90 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %2446 = stablehlo.reduce(%2440 init: %cst_90) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %2447 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2448 = stablehlo.divide %2446, %2447 : tensor<256xf32>
    %2449 = stablehlo.broadcast_in_dim %2445, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %2450 = stablehlo.broadcast_in_dim %2448, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %2451 = stablehlo.concatenate %2449, %2450, dim = 0 : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<2x256xf32>
    %2452 = "stablehlo.all_reduce"(%2451) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x256xf32>) -> tensor<2x256xf32>
    %2453 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x256xf32>
    %2454 = stablehlo.divide %2452, %2453 : tensor<2x256xf32>
    %2455 = stablehlo.slice %2454 [0:1, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %2456 = stablehlo.reshape %2455 : (tensor<1x256xf32>) -> tensor<256xf32>
    %2457 = stablehlo.slice %2454 [1:2, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %2458 = stablehlo.reshape %2457 : (tensor<1x256xf32>) -> tensor<256xf32>
    %2459 = stablehlo.multiply %2456, %2456 : tensor<256xf32>
    %2460 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2461 = stablehlo.multiply %2460, %2456 : tensor<256xf32>
    %2462 = stablehlo.subtract %2458, %2459 : tensor<256xf32>
    %2463 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2464 = stablehlo.maximum %2463, %2462 : tensor<256xf32>
    %2465 = stablehlo.compare  EQ, %2462, %2464,  FLOAT : (tensor<256xf32>, tensor<256xf32>) -> tensor<256xi1>
    %2466 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2467 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2468 = stablehlo.select %2465, %2466, %2467 : tensor<256xi1>, tensor<256xf32>
    %2469 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2470 = stablehlo.compare  EQ, %2469, %2464,  FLOAT : (tensor<256xf32>, tensor<256xf32>) -> tensor<256xi1>
    %2471 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2472 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2473 = stablehlo.select %2470, %2471, %2472 : tensor<256xi1>, tensor<256xf32>
    %2474 = stablehlo.divide %2468, %2473 : tensor<256xf32>
    %2475 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2476 = stablehlo.multiply %2475, %arg338 : tensor<256xf32>
    %2477 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2478 = stablehlo.multiply %2477, %2456 : tensor<256xf32>
    %2479 = stablehlo.add %2476, %2478 : tensor<256xf32>
    %2480 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2481 = stablehlo.multiply %2480, %arg339 : tensor<256xf32>
    %2482 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2483 = stablehlo.multiply %2482, %2464 : tensor<256xf32>
    %2484 = stablehlo.add %2481, %2483 : tensor<256xf32>
    %2485 = stablehlo.broadcast_in_dim %2456, dims = [3] : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2486 = stablehlo.broadcast_in_dim %2464, dims = [3] : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2487 = stablehlo.convert %2438 : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf32>
    %2488 = stablehlo.broadcast_in_dim %2485, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %2489 = stablehlo.subtract %2487, %2488 : tensor<256x14x14x256xf32>
    %2490 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x256xf32>
    %2491 = stablehlo.add %2486, %2490 : tensor<1x1x1x256xf32>
    %2492 = stablehlo.rsqrt %2491 : tensor<1x1x1x256xf32>
    %2493 = stablehlo.divide %2492, %2491 : tensor<1x1x1x256xf32>
    %2494 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x256xf32>
    %2495 = stablehlo.multiply %2494, %2493 : tensor<1x1x1x256xf32>
    %2496 = stablehlo.reshape %arg23 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2497 = stablehlo.multiply %2492, %2496 : tensor<1x1x1x256xf32>
    %2498 = stablehlo.broadcast_in_dim %2497, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %2499 = stablehlo.multiply %2489, %2498 : tensor<256x14x14x256xf32>
    %2500 = stablehlo.reshape %arg22 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2501 = stablehlo.broadcast_in_dim %2500, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %2502 = stablehlo.add %2499, %2501 : tensor<256x14x14x256xf32>
    %2503 = stablehlo.convert %2502 : (tensor<256x14x14x256xf32>) -> tensor<256x14x14x256xf16>
    %2504 = call @relu_6(%2503) : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf16>
    %2505 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %2506 = stablehlo.compare  GT, %2503, %2505,  FLOAT : (tensor<256x14x14x256xf16>, tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xi1>
    %2507 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %2508 = stablehlo.convert %arg29 : (tensor<3x3x256x256xf32>) -> tensor<3x3x256x256xf16>
    %2509 = stablehlo.convolution(%2504, %2508) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x256xf16>, tensor<3x3x256x256xf16>) -> tensor<256x14x14x256xf16>
    %2510 = stablehlo.convert %2509 : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf32>
    %2511 = stablehlo.multiply %2510, %2510 : tensor<256x14x14x256xf32>
    %2512 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x14x14x256xf32>
    %2513 = stablehlo.multiply %2512, %2510 : tensor<256x14x14x256xf32>
    %cst_91 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %2514 = stablehlo.reduce(%2510 init: %cst_91) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %2515 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2516 = stablehlo.divide %2514, %2515 : tensor<256xf32>
    %cst_92 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %2517 = stablehlo.reduce(%2511 init: %cst_92) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %2518 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2519 = stablehlo.divide %2517, %2518 : tensor<256xf32>
    %2520 = stablehlo.broadcast_in_dim %2516, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %2521 = stablehlo.broadcast_in_dim %2519, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %2522 = stablehlo.concatenate %2520, %2521, dim = 0 : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<2x256xf32>
    %2523 = "stablehlo.all_reduce"(%2522) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x256xf32>) -> tensor<2x256xf32>
    %2524 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x256xf32>
    %2525 = stablehlo.divide %2523, %2524 : tensor<2x256xf32>
    %2526 = stablehlo.slice %2525 [0:1, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %2527 = stablehlo.reshape %2526 : (tensor<1x256xf32>) -> tensor<256xf32>
    %2528 = stablehlo.slice %2525 [1:2, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %2529 = stablehlo.reshape %2528 : (tensor<1x256xf32>) -> tensor<256xf32>
    %2530 = stablehlo.multiply %2527, %2527 : tensor<256xf32>
    %2531 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2532 = stablehlo.multiply %2531, %2527 : tensor<256xf32>
    %2533 = stablehlo.subtract %2529, %2530 : tensor<256xf32>
    %2534 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2535 = stablehlo.maximum %2534, %2533 : tensor<256xf32>
    %2536 = stablehlo.compare  EQ, %2533, %2535,  FLOAT : (tensor<256xf32>, tensor<256xf32>) -> tensor<256xi1>
    %2537 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2538 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2539 = stablehlo.select %2536, %2537, %2538 : tensor<256xi1>, tensor<256xf32>
    %2540 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2541 = stablehlo.compare  EQ, %2540, %2535,  FLOAT : (tensor<256xf32>, tensor<256xf32>) -> tensor<256xi1>
    %2542 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2543 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2544 = stablehlo.select %2541, %2542, %2543 : tensor<256xi1>, tensor<256xf32>
    %2545 = stablehlo.divide %2539, %2544 : tensor<256xf32>
    %2546 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2547 = stablehlo.multiply %2546, %arg340 : tensor<256xf32>
    %2548 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2549 = stablehlo.multiply %2548, %2527 : tensor<256xf32>
    %2550 = stablehlo.add %2547, %2549 : tensor<256xf32>
    %2551 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2552 = stablehlo.multiply %2551, %arg341 : tensor<256xf32>
    %2553 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2554 = stablehlo.multiply %2553, %2535 : tensor<256xf32>
    %2555 = stablehlo.add %2552, %2554 : tensor<256xf32>
    %2556 = stablehlo.broadcast_in_dim %2527, dims = [3] : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2557 = stablehlo.broadcast_in_dim %2535, dims = [3] : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2558 = stablehlo.convert %2509 : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf32>
    %2559 = stablehlo.broadcast_in_dim %2556, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %2560 = stablehlo.subtract %2558, %2559 : tensor<256x14x14x256xf32>
    %2561 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x256xf32>
    %2562 = stablehlo.add %2557, %2561 : tensor<1x1x1x256xf32>
    %2563 = stablehlo.rsqrt %2562 : tensor<1x1x1x256xf32>
    %2564 = stablehlo.divide %2563, %2562 : tensor<1x1x1x256xf32>
    %2565 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x256xf32>
    %2566 = stablehlo.multiply %2565, %2564 : tensor<1x1x1x256xf32>
    %2567 = stablehlo.reshape %arg25 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2568 = stablehlo.multiply %2563, %2567 : tensor<1x1x1x256xf32>
    %2569 = stablehlo.broadcast_in_dim %2568, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %2570 = stablehlo.multiply %2560, %2569 : tensor<256x14x14x256xf32>
    %2571 = stablehlo.reshape %arg24 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2572 = stablehlo.broadcast_in_dim %2571, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %2573 = stablehlo.add %2570, %2572 : tensor<256x14x14x256xf32>
    %2574 = stablehlo.convert %2573 : (tensor<256x14x14x256xf32>) -> tensor<256x14x14x256xf16>
    %2575 = call @relu_6(%2574) : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf16>
    %2576 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %2577 = stablehlo.compare  GT, %2574, %2576,  FLOAT : (tensor<256x14x14x256xf16>, tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xi1>
    %2578 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %2579 = stablehlo.convert %arg30 : (tensor<1x1x256x1024xf32>) -> tensor<1x1x256x1024xf16>
    %2580 = stablehlo.convolution(%2575, %2579) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x256xf16>, tensor<1x1x256x1024xf16>) -> tensor<256x14x14x1024xf16>
    %2581 = stablehlo.convert %2580 : (tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xf32>
    %2582 = stablehlo.multiply %2581, %2581 : tensor<256x14x14x1024xf32>
    %2583 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x14x14x1024xf32>
    %2584 = stablehlo.multiply %2583, %2581 : tensor<256x14x14x1024xf32>
    %cst_93 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %2585 = stablehlo.reduce(%2581 init: %cst_93) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %2586 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2587 = stablehlo.divide %2585, %2586 : tensor<1024xf32>
    %cst_94 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %2588 = stablehlo.reduce(%2582 init: %cst_94) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %2589 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2590 = stablehlo.divide %2588, %2589 : tensor<1024xf32>
    %2591 = stablehlo.broadcast_in_dim %2587, dims = [1] : (tensor<1024xf32>) -> tensor<1x1024xf32>
    %2592 = stablehlo.broadcast_in_dim %2590, dims = [1] : (tensor<1024xf32>) -> tensor<1x1024xf32>
    %2593 = stablehlo.concatenate %2591, %2592, dim = 0 : (tensor<1x1024xf32>, tensor<1x1024xf32>) -> tensor<2x1024xf32>
    %2594 = "stablehlo.all_reduce"(%2593) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x1024xf32>) -> tensor<2x1024xf32>
    %2595 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x1024xf32>
    %2596 = stablehlo.divide %2594, %2595 : tensor<2x1024xf32>
    %2597 = stablehlo.slice %2596 [0:1, 0:1024] : (tensor<2x1024xf32>) -> tensor<1x1024xf32>
    %2598 = stablehlo.reshape %2597 : (tensor<1x1024xf32>) -> tensor<1024xf32>
    %2599 = stablehlo.slice %2596 [1:2, 0:1024] : (tensor<2x1024xf32>) -> tensor<1x1024xf32>
    %2600 = stablehlo.reshape %2599 : (tensor<1x1024xf32>) -> tensor<1024xf32>
    %2601 = stablehlo.multiply %2598, %2598 : tensor<1024xf32>
    %2602 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2603 = stablehlo.multiply %2602, %2598 : tensor<1024xf32>
    %2604 = stablehlo.subtract %2600, %2601 : tensor<1024xf32>
    %2605 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2606 = stablehlo.maximum %2605, %2604 : tensor<1024xf32>
    %2607 = stablehlo.compare  EQ, %2604, %2606,  FLOAT : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xi1>
    %2608 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2609 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2610 = stablehlo.select %2607, %2608, %2609 : tensor<1024xi1>, tensor<1024xf32>
    %2611 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2612 = stablehlo.compare  EQ, %2611, %2606,  FLOAT : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xi1>
    %2613 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2614 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2615 = stablehlo.select %2612, %2613, %2614 : tensor<1024xi1>, tensor<1024xf32>
    %2616 = stablehlo.divide %2610, %2615 : tensor<1024xf32>
    %2617 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2618 = stablehlo.multiply %2617, %arg342 : tensor<1024xf32>
    %2619 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2620 = stablehlo.multiply %2619, %2598 : tensor<1024xf32>
    %2621 = stablehlo.add %2618, %2620 : tensor<1024xf32>
    %2622 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2623 = stablehlo.multiply %2622, %arg343 : tensor<1024xf32>
    %2624 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2625 = stablehlo.multiply %2624, %2606 : tensor<1024xf32>
    %2626 = stablehlo.add %2623, %2625 : tensor<1024xf32>
    %2627 = stablehlo.broadcast_in_dim %2598, dims = [3] : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %2628 = stablehlo.broadcast_in_dim %2606, dims = [3] : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %2629 = stablehlo.convert %2580 : (tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xf32>
    %2630 = stablehlo.broadcast_in_dim %2627, dims = [0, 1, 2, 3] : (tensor<1x1x1x1024xf32>) -> tensor<256x14x14x1024xf32>
    %2631 = stablehlo.subtract %2629, %2630 : tensor<256x14x14x1024xf32>
    %2632 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x1024xf32>
    %2633 = stablehlo.add %2628, %2632 : tensor<1x1x1x1024xf32>
    %2634 = stablehlo.rsqrt %2633 : tensor<1x1x1x1024xf32>
    %2635 = stablehlo.divide %2634, %2633 : tensor<1x1x1x1024xf32>
    %2636 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x1024xf32>
    %2637 = stablehlo.multiply %2636, %2635 : tensor<1x1x1x1024xf32>
    %2638 = stablehlo.reshape %arg27 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %2639 = stablehlo.multiply %2634, %2638 : tensor<1x1x1x1024xf32>
    %2640 = stablehlo.broadcast_in_dim %2639, dims = [0, 1, 2, 3] : (tensor<1x1x1x1024xf32>) -> tensor<256x14x14x1024xf32>
    %2641 = stablehlo.multiply %2631, %2640 : tensor<256x14x14x1024xf32>
    %2642 = stablehlo.reshape %arg26 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %2643 = stablehlo.broadcast_in_dim %2642, dims = [0, 1, 2, 3] : (tensor<1x1x1x1024xf32>) -> tensor<256x14x14x1024xf32>
    %2644 = stablehlo.add %2641, %2643 : tensor<256x14x14x1024xf32>
    %2645 = stablehlo.convert %2644 : (tensor<256x14x14x1024xf32>) -> tensor<256x14x14x1024xf16>
    %2646 = stablehlo.add %2433, %2645 : tensor<256x14x14x1024xf16>
    %2647 = call @relu_7(%2646) : (tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xf16>
    %2648 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x1024xf16>
    %2649 = stablehlo.compare  GT, %2646, %2648,  FLOAT : (tensor<256x14x14x1024xf16>, tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xi1>
    %2650 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x1024xf16>
    %2651 = stablehlo.convert %arg37 : (tensor<1x1x1024x256xf32>) -> tensor<1x1x1024x256xf16>
    %2652 = stablehlo.convolution(%2647, %2651) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x1024xf16>, tensor<1x1x1024x256xf16>) -> tensor<256x14x14x256xf16>
    %2653 = stablehlo.convert %2652 : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf32>
    %2654 = stablehlo.multiply %2653, %2653 : tensor<256x14x14x256xf32>
    %2655 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x14x14x256xf32>
    %2656 = stablehlo.multiply %2655, %2653 : tensor<256x14x14x256xf32>
    %cst_95 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %2657 = stablehlo.reduce(%2653 init: %cst_95) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %2658 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2659 = stablehlo.divide %2657, %2658 : tensor<256xf32>
    %cst_96 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %2660 = stablehlo.reduce(%2654 init: %cst_96) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %2661 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2662 = stablehlo.divide %2660, %2661 : tensor<256xf32>
    %2663 = stablehlo.broadcast_in_dim %2659, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %2664 = stablehlo.broadcast_in_dim %2662, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %2665 = stablehlo.concatenate %2663, %2664, dim = 0 : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<2x256xf32>
    %2666 = "stablehlo.all_reduce"(%2665) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x256xf32>) -> tensor<2x256xf32>
    %2667 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x256xf32>
    %2668 = stablehlo.divide %2666, %2667 : tensor<2x256xf32>
    %2669 = stablehlo.slice %2668 [0:1, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %2670 = stablehlo.reshape %2669 : (tensor<1x256xf32>) -> tensor<256xf32>
    %2671 = stablehlo.slice %2668 [1:2, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %2672 = stablehlo.reshape %2671 : (tensor<1x256xf32>) -> tensor<256xf32>
    %2673 = stablehlo.multiply %2670, %2670 : tensor<256xf32>
    %2674 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2675 = stablehlo.multiply %2674, %2670 : tensor<256xf32>
    %2676 = stablehlo.subtract %2672, %2673 : tensor<256xf32>
    %2677 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2678 = stablehlo.maximum %2677, %2676 : tensor<256xf32>
    %2679 = stablehlo.compare  EQ, %2676, %2678,  FLOAT : (tensor<256xf32>, tensor<256xf32>) -> tensor<256xi1>
    %2680 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2681 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2682 = stablehlo.select %2679, %2680, %2681 : tensor<256xi1>, tensor<256xf32>
    %2683 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2684 = stablehlo.compare  EQ, %2683, %2678,  FLOAT : (tensor<256xf32>, tensor<256xf32>) -> tensor<256xi1>
    %2685 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2686 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2687 = stablehlo.select %2684, %2685, %2686 : tensor<256xi1>, tensor<256xf32>
    %2688 = stablehlo.divide %2682, %2687 : tensor<256xf32>
    %2689 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2690 = stablehlo.multiply %2689, %arg344 : tensor<256xf32>
    %2691 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2692 = stablehlo.multiply %2691, %2670 : tensor<256xf32>
    %2693 = stablehlo.add %2690, %2692 : tensor<256xf32>
    %2694 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2695 = stablehlo.multiply %2694, %arg345 : tensor<256xf32>
    %2696 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2697 = stablehlo.multiply %2696, %2678 : tensor<256xf32>
    %2698 = stablehlo.add %2695, %2697 : tensor<256xf32>
    %2699 = stablehlo.broadcast_in_dim %2670, dims = [3] : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2700 = stablehlo.broadcast_in_dim %2678, dims = [3] : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2701 = stablehlo.convert %2652 : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf32>
    %2702 = stablehlo.broadcast_in_dim %2699, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %2703 = stablehlo.subtract %2701, %2702 : tensor<256x14x14x256xf32>
    %2704 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x256xf32>
    %2705 = stablehlo.add %2700, %2704 : tensor<1x1x1x256xf32>
    %2706 = stablehlo.rsqrt %2705 : tensor<1x1x1x256xf32>
    %2707 = stablehlo.divide %2706, %2705 : tensor<1x1x1x256xf32>
    %2708 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x256xf32>
    %2709 = stablehlo.multiply %2708, %2707 : tensor<1x1x1x256xf32>
    %2710 = stablehlo.reshape %arg32 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2711 = stablehlo.multiply %2706, %2710 : tensor<1x1x1x256xf32>
    %2712 = stablehlo.broadcast_in_dim %2711, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %2713 = stablehlo.multiply %2703, %2712 : tensor<256x14x14x256xf32>
    %2714 = stablehlo.reshape %arg31 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2715 = stablehlo.broadcast_in_dim %2714, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %2716 = stablehlo.add %2713, %2715 : tensor<256x14x14x256xf32>
    %2717 = stablehlo.convert %2716 : (tensor<256x14x14x256xf32>) -> tensor<256x14x14x256xf16>
    %2718 = call @relu_6(%2717) : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf16>
    %2719 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %2720 = stablehlo.compare  GT, %2717, %2719,  FLOAT : (tensor<256x14x14x256xf16>, tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xi1>
    %2721 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %2722 = stablehlo.convert %arg38 : (tensor<3x3x256x256xf32>) -> tensor<3x3x256x256xf16>
    %2723 = stablehlo.convolution(%2718, %2722) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x256xf16>, tensor<3x3x256x256xf16>) -> tensor<256x14x14x256xf16>
    %2724 = stablehlo.convert %2723 : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf32>
    %2725 = stablehlo.multiply %2724, %2724 : tensor<256x14x14x256xf32>
    %2726 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x14x14x256xf32>
    %2727 = stablehlo.multiply %2726, %2724 : tensor<256x14x14x256xf32>
    %cst_97 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %2728 = stablehlo.reduce(%2724 init: %cst_97) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %2729 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2730 = stablehlo.divide %2728, %2729 : tensor<256xf32>
    %cst_98 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %2731 = stablehlo.reduce(%2725 init: %cst_98) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %2732 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2733 = stablehlo.divide %2731, %2732 : tensor<256xf32>
    %2734 = stablehlo.broadcast_in_dim %2730, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %2735 = stablehlo.broadcast_in_dim %2733, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %2736 = stablehlo.concatenate %2734, %2735, dim = 0 : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<2x256xf32>
    %2737 = "stablehlo.all_reduce"(%2736) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x256xf32>) -> tensor<2x256xf32>
    %2738 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x256xf32>
    %2739 = stablehlo.divide %2737, %2738 : tensor<2x256xf32>
    %2740 = stablehlo.slice %2739 [0:1, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %2741 = stablehlo.reshape %2740 : (tensor<1x256xf32>) -> tensor<256xf32>
    %2742 = stablehlo.slice %2739 [1:2, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %2743 = stablehlo.reshape %2742 : (tensor<1x256xf32>) -> tensor<256xf32>
    %2744 = stablehlo.multiply %2741, %2741 : tensor<256xf32>
    %2745 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2746 = stablehlo.multiply %2745, %2741 : tensor<256xf32>
    %2747 = stablehlo.subtract %2743, %2744 : tensor<256xf32>
    %2748 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2749 = stablehlo.maximum %2748, %2747 : tensor<256xf32>
    %2750 = stablehlo.compare  EQ, %2747, %2749,  FLOAT : (tensor<256xf32>, tensor<256xf32>) -> tensor<256xi1>
    %2751 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2752 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2753 = stablehlo.select %2750, %2751, %2752 : tensor<256xi1>, tensor<256xf32>
    %2754 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2755 = stablehlo.compare  EQ, %2754, %2749,  FLOAT : (tensor<256xf32>, tensor<256xf32>) -> tensor<256xi1>
    %2756 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2757 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2758 = stablehlo.select %2755, %2756, %2757 : tensor<256xi1>, tensor<256xf32>
    %2759 = stablehlo.divide %2753, %2758 : tensor<256xf32>
    %2760 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2761 = stablehlo.multiply %2760, %arg346 : tensor<256xf32>
    %2762 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2763 = stablehlo.multiply %2762, %2741 : tensor<256xf32>
    %2764 = stablehlo.add %2761, %2763 : tensor<256xf32>
    %2765 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2766 = stablehlo.multiply %2765, %arg347 : tensor<256xf32>
    %2767 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2768 = stablehlo.multiply %2767, %2749 : tensor<256xf32>
    %2769 = stablehlo.add %2766, %2768 : tensor<256xf32>
    %2770 = stablehlo.broadcast_in_dim %2741, dims = [3] : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2771 = stablehlo.broadcast_in_dim %2749, dims = [3] : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2772 = stablehlo.convert %2723 : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf32>
    %2773 = stablehlo.broadcast_in_dim %2770, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %2774 = stablehlo.subtract %2772, %2773 : tensor<256x14x14x256xf32>
    %2775 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x256xf32>
    %2776 = stablehlo.add %2771, %2775 : tensor<1x1x1x256xf32>
    %2777 = stablehlo.rsqrt %2776 : tensor<1x1x1x256xf32>
    %2778 = stablehlo.divide %2777, %2776 : tensor<1x1x1x256xf32>
    %2779 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x256xf32>
    %2780 = stablehlo.multiply %2779, %2778 : tensor<1x1x1x256xf32>
    %2781 = stablehlo.reshape %arg34 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2782 = stablehlo.multiply %2777, %2781 : tensor<1x1x1x256xf32>
    %2783 = stablehlo.broadcast_in_dim %2782, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %2784 = stablehlo.multiply %2774, %2783 : tensor<256x14x14x256xf32>
    %2785 = stablehlo.reshape %arg33 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2786 = stablehlo.broadcast_in_dim %2785, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %2787 = stablehlo.add %2784, %2786 : tensor<256x14x14x256xf32>
    %2788 = stablehlo.convert %2787 : (tensor<256x14x14x256xf32>) -> tensor<256x14x14x256xf16>
    %2789 = call @relu_6(%2788) : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf16>
    %2790 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %2791 = stablehlo.compare  GT, %2788, %2790,  FLOAT : (tensor<256x14x14x256xf16>, tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xi1>
    %2792 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %2793 = stablehlo.convert %arg39 : (tensor<1x1x256x1024xf32>) -> tensor<1x1x256x1024xf16>
    %2794 = stablehlo.convolution(%2789, %2793) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x256xf16>, tensor<1x1x256x1024xf16>) -> tensor<256x14x14x1024xf16>
    %2795 = stablehlo.convert %2794 : (tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xf32>
    %2796 = stablehlo.multiply %2795, %2795 : tensor<256x14x14x1024xf32>
    %2797 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x14x14x1024xf32>
    %2798 = stablehlo.multiply %2797, %2795 : tensor<256x14x14x1024xf32>
    %cst_99 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %2799 = stablehlo.reduce(%2795 init: %cst_99) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %2800 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2801 = stablehlo.divide %2799, %2800 : tensor<1024xf32>
    %cst_100 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %2802 = stablehlo.reduce(%2796 init: %cst_100) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %2803 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2804 = stablehlo.divide %2802, %2803 : tensor<1024xf32>
    %2805 = stablehlo.broadcast_in_dim %2801, dims = [1] : (tensor<1024xf32>) -> tensor<1x1024xf32>
    %2806 = stablehlo.broadcast_in_dim %2804, dims = [1] : (tensor<1024xf32>) -> tensor<1x1024xf32>
    %2807 = stablehlo.concatenate %2805, %2806, dim = 0 : (tensor<1x1024xf32>, tensor<1x1024xf32>) -> tensor<2x1024xf32>
    %2808 = "stablehlo.all_reduce"(%2807) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x1024xf32>) -> tensor<2x1024xf32>
    %2809 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x1024xf32>
    %2810 = stablehlo.divide %2808, %2809 : tensor<2x1024xf32>
    %2811 = stablehlo.slice %2810 [0:1, 0:1024] : (tensor<2x1024xf32>) -> tensor<1x1024xf32>
    %2812 = stablehlo.reshape %2811 : (tensor<1x1024xf32>) -> tensor<1024xf32>
    %2813 = stablehlo.slice %2810 [1:2, 0:1024] : (tensor<2x1024xf32>) -> tensor<1x1024xf32>
    %2814 = stablehlo.reshape %2813 : (tensor<1x1024xf32>) -> tensor<1024xf32>
    %2815 = stablehlo.multiply %2812, %2812 : tensor<1024xf32>
    %2816 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2817 = stablehlo.multiply %2816, %2812 : tensor<1024xf32>
    %2818 = stablehlo.subtract %2814, %2815 : tensor<1024xf32>
    %2819 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2820 = stablehlo.maximum %2819, %2818 : tensor<1024xf32>
    %2821 = stablehlo.compare  EQ, %2818, %2820,  FLOAT : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xi1>
    %2822 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2823 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2824 = stablehlo.select %2821, %2822, %2823 : tensor<1024xi1>, tensor<1024xf32>
    %2825 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2826 = stablehlo.compare  EQ, %2825, %2820,  FLOAT : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xi1>
    %2827 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2828 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2829 = stablehlo.select %2826, %2827, %2828 : tensor<1024xi1>, tensor<1024xf32>
    %2830 = stablehlo.divide %2824, %2829 : tensor<1024xf32>
    %2831 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2832 = stablehlo.multiply %2831, %arg348 : tensor<1024xf32>
    %2833 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2834 = stablehlo.multiply %2833, %2812 : tensor<1024xf32>
    %2835 = stablehlo.add %2832, %2834 : tensor<1024xf32>
    %2836 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2837 = stablehlo.multiply %2836, %arg349 : tensor<1024xf32>
    %2838 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %2839 = stablehlo.multiply %2838, %2820 : tensor<1024xf32>
    %2840 = stablehlo.add %2837, %2839 : tensor<1024xf32>
    %2841 = stablehlo.broadcast_in_dim %2812, dims = [3] : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %2842 = stablehlo.broadcast_in_dim %2820, dims = [3] : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %2843 = stablehlo.convert %2794 : (tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xf32>
    %2844 = stablehlo.broadcast_in_dim %2841, dims = [0, 1, 2, 3] : (tensor<1x1x1x1024xf32>) -> tensor<256x14x14x1024xf32>
    %2845 = stablehlo.subtract %2843, %2844 : tensor<256x14x14x1024xf32>
    %2846 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x1024xf32>
    %2847 = stablehlo.add %2842, %2846 : tensor<1x1x1x1024xf32>
    %2848 = stablehlo.rsqrt %2847 : tensor<1x1x1x1024xf32>
    %2849 = stablehlo.divide %2848, %2847 : tensor<1x1x1x1024xf32>
    %2850 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x1024xf32>
    %2851 = stablehlo.multiply %2850, %2849 : tensor<1x1x1x1024xf32>
    %2852 = stablehlo.reshape %arg36 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %2853 = stablehlo.multiply %2848, %2852 : tensor<1x1x1x1024xf32>
    %2854 = stablehlo.broadcast_in_dim %2853, dims = [0, 1, 2, 3] : (tensor<1x1x1x1024xf32>) -> tensor<256x14x14x1024xf32>
    %2855 = stablehlo.multiply %2845, %2854 : tensor<256x14x14x1024xf32>
    %2856 = stablehlo.reshape %arg35 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %2857 = stablehlo.broadcast_in_dim %2856, dims = [0, 1, 2, 3] : (tensor<1x1x1x1024xf32>) -> tensor<256x14x14x1024xf32>
    %2858 = stablehlo.add %2855, %2857 : tensor<256x14x14x1024xf32>
    %2859 = stablehlo.convert %2858 : (tensor<256x14x14x1024xf32>) -> tensor<256x14x14x1024xf16>
    %2860 = stablehlo.add %2647, %2859 : tensor<256x14x14x1024xf16>
    %2861 = call @relu_7(%2860) : (tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xf16>
    %2862 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x1024xf16>
    %2863 = stablehlo.compare  GT, %2860, %2862,  FLOAT : (tensor<256x14x14x1024xf16>, tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xi1>
    %2864 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x1024xf16>
    %2865 = stablehlo.convert %arg46 : (tensor<1x1x1024x256xf32>) -> tensor<1x1x1024x256xf16>
    %2866 = stablehlo.convolution(%2861, %2865) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x1024xf16>, tensor<1x1x1024x256xf16>) -> tensor<256x14x14x256xf16>
    %2867 = stablehlo.convert %2866 : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf32>
    %2868 = stablehlo.multiply %2867, %2867 : tensor<256x14x14x256xf32>
    %2869 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x14x14x256xf32>
    %2870 = stablehlo.multiply %2869, %2867 : tensor<256x14x14x256xf32>
    %cst_101 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %2871 = stablehlo.reduce(%2867 init: %cst_101) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %2872 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2873 = stablehlo.divide %2871, %2872 : tensor<256xf32>
    %cst_102 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %2874 = stablehlo.reduce(%2868 init: %cst_102) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %2875 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2876 = stablehlo.divide %2874, %2875 : tensor<256xf32>
    %2877 = stablehlo.broadcast_in_dim %2873, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %2878 = stablehlo.broadcast_in_dim %2876, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %2879 = stablehlo.concatenate %2877, %2878, dim = 0 : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<2x256xf32>
    %2880 = "stablehlo.all_reduce"(%2879) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x256xf32>) -> tensor<2x256xf32>
    %2881 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x256xf32>
    %2882 = stablehlo.divide %2880, %2881 : tensor<2x256xf32>
    %2883 = stablehlo.slice %2882 [0:1, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %2884 = stablehlo.reshape %2883 : (tensor<1x256xf32>) -> tensor<256xf32>
    %2885 = stablehlo.slice %2882 [1:2, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %2886 = stablehlo.reshape %2885 : (tensor<1x256xf32>) -> tensor<256xf32>
    %2887 = stablehlo.multiply %2884, %2884 : tensor<256xf32>
    %2888 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2889 = stablehlo.multiply %2888, %2884 : tensor<256xf32>
    %2890 = stablehlo.subtract %2886, %2887 : tensor<256xf32>
    %2891 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2892 = stablehlo.maximum %2891, %2890 : tensor<256xf32>
    %2893 = stablehlo.compare  EQ, %2890, %2892,  FLOAT : (tensor<256xf32>, tensor<256xf32>) -> tensor<256xi1>
    %2894 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2895 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2896 = stablehlo.select %2893, %2894, %2895 : tensor<256xi1>, tensor<256xf32>
    %2897 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2898 = stablehlo.compare  EQ, %2897, %2892,  FLOAT : (tensor<256xf32>, tensor<256xf32>) -> tensor<256xi1>
    %2899 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2900 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2901 = stablehlo.select %2898, %2899, %2900 : tensor<256xi1>, tensor<256xf32>
    %2902 = stablehlo.divide %2896, %2901 : tensor<256xf32>
    %2903 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2904 = stablehlo.multiply %2903, %arg350 : tensor<256xf32>
    %2905 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2906 = stablehlo.multiply %2905, %2884 : tensor<256xf32>
    %2907 = stablehlo.add %2904, %2906 : tensor<256xf32>
    %2908 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2909 = stablehlo.multiply %2908, %arg351 : tensor<256xf32>
    %2910 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2911 = stablehlo.multiply %2910, %2892 : tensor<256xf32>
    %2912 = stablehlo.add %2909, %2911 : tensor<256xf32>
    %2913 = stablehlo.broadcast_in_dim %2884, dims = [3] : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2914 = stablehlo.broadcast_in_dim %2892, dims = [3] : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2915 = stablehlo.convert %2866 : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf32>
    %2916 = stablehlo.broadcast_in_dim %2913, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %2917 = stablehlo.subtract %2915, %2916 : tensor<256x14x14x256xf32>
    %2918 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x256xf32>
    %2919 = stablehlo.add %2914, %2918 : tensor<1x1x1x256xf32>
    %2920 = stablehlo.rsqrt %2919 : tensor<1x1x1x256xf32>
    %2921 = stablehlo.divide %2920, %2919 : tensor<1x1x1x256xf32>
    %2922 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x256xf32>
    %2923 = stablehlo.multiply %2922, %2921 : tensor<1x1x1x256xf32>
    %2924 = stablehlo.reshape %arg41 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2925 = stablehlo.multiply %2920, %2924 : tensor<1x1x1x256xf32>
    %2926 = stablehlo.broadcast_in_dim %2925, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %2927 = stablehlo.multiply %2917, %2926 : tensor<256x14x14x256xf32>
    %2928 = stablehlo.reshape %arg40 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2929 = stablehlo.broadcast_in_dim %2928, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %2930 = stablehlo.add %2927, %2929 : tensor<256x14x14x256xf32>
    %2931 = stablehlo.convert %2930 : (tensor<256x14x14x256xf32>) -> tensor<256x14x14x256xf16>
    %2932 = call @relu_6(%2931) : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf16>
    %2933 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %2934 = stablehlo.compare  GT, %2931, %2933,  FLOAT : (tensor<256x14x14x256xf16>, tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xi1>
    %2935 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %2936 = stablehlo.convert %arg47 : (tensor<3x3x256x256xf32>) -> tensor<3x3x256x256xf16>
    %2937 = stablehlo.convolution(%2932, %2936) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x256xf16>, tensor<3x3x256x256xf16>) -> tensor<256x14x14x256xf16>
    %2938 = stablehlo.convert %2937 : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf32>
    %2939 = stablehlo.multiply %2938, %2938 : tensor<256x14x14x256xf32>
    %2940 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x14x14x256xf32>
    %2941 = stablehlo.multiply %2940, %2938 : tensor<256x14x14x256xf32>
    %cst_103 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %2942 = stablehlo.reduce(%2938 init: %cst_103) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %2943 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2944 = stablehlo.divide %2942, %2943 : tensor<256xf32>
    %cst_104 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %2945 = stablehlo.reduce(%2939 init: %cst_104) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %2946 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2947 = stablehlo.divide %2945, %2946 : tensor<256xf32>
    %2948 = stablehlo.broadcast_in_dim %2944, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %2949 = stablehlo.broadcast_in_dim %2947, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %2950 = stablehlo.concatenate %2948, %2949, dim = 0 : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<2x256xf32>
    %2951 = "stablehlo.all_reduce"(%2950) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x256xf32>) -> tensor<2x256xf32>
    %2952 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x256xf32>
    %2953 = stablehlo.divide %2951, %2952 : tensor<2x256xf32>
    %2954 = stablehlo.slice %2953 [0:1, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %2955 = stablehlo.reshape %2954 : (tensor<1x256xf32>) -> tensor<256xf32>
    %2956 = stablehlo.slice %2953 [1:2, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %2957 = stablehlo.reshape %2956 : (tensor<1x256xf32>) -> tensor<256xf32>
    %2958 = stablehlo.multiply %2955, %2955 : tensor<256xf32>
    %2959 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2960 = stablehlo.multiply %2959, %2955 : tensor<256xf32>
    %2961 = stablehlo.subtract %2957, %2958 : tensor<256xf32>
    %2962 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2963 = stablehlo.maximum %2962, %2961 : tensor<256xf32>
    %2964 = stablehlo.compare  EQ, %2961, %2963,  FLOAT : (tensor<256xf32>, tensor<256xf32>) -> tensor<256xi1>
    %2965 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2966 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2967 = stablehlo.select %2964, %2965, %2966 : tensor<256xi1>, tensor<256xf32>
    %2968 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2969 = stablehlo.compare  EQ, %2968, %2963,  FLOAT : (tensor<256xf32>, tensor<256xf32>) -> tensor<256xi1>
    %2970 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2971 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2972 = stablehlo.select %2969, %2970, %2971 : tensor<256xi1>, tensor<256xf32>
    %2973 = stablehlo.divide %2967, %2972 : tensor<256xf32>
    %2974 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2975 = stablehlo.multiply %2974, %arg352 : tensor<256xf32>
    %2976 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2977 = stablehlo.multiply %2976, %2955 : tensor<256xf32>
    %2978 = stablehlo.add %2975, %2977 : tensor<256xf32>
    %2979 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2980 = stablehlo.multiply %2979, %arg353 : tensor<256xf32>
    %2981 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %2982 = stablehlo.multiply %2981, %2963 : tensor<256xf32>
    %2983 = stablehlo.add %2980, %2982 : tensor<256xf32>
    %2984 = stablehlo.broadcast_in_dim %2955, dims = [3] : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2985 = stablehlo.broadcast_in_dim %2963, dims = [3] : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2986 = stablehlo.convert %2937 : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf32>
    %2987 = stablehlo.broadcast_in_dim %2984, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %2988 = stablehlo.subtract %2986, %2987 : tensor<256x14x14x256xf32>
    %2989 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x256xf32>
    %2990 = stablehlo.add %2985, %2989 : tensor<1x1x1x256xf32>
    %2991 = stablehlo.rsqrt %2990 : tensor<1x1x1x256xf32>
    %2992 = stablehlo.divide %2991, %2990 : tensor<1x1x1x256xf32>
    %2993 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x256xf32>
    %2994 = stablehlo.multiply %2993, %2992 : tensor<1x1x1x256xf32>
    %2995 = stablehlo.reshape %arg43 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %2996 = stablehlo.multiply %2991, %2995 : tensor<1x1x1x256xf32>
    %2997 = stablehlo.broadcast_in_dim %2996, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %2998 = stablehlo.multiply %2988, %2997 : tensor<256x14x14x256xf32>
    %2999 = stablehlo.reshape %arg42 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %3000 = stablehlo.broadcast_in_dim %2999, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %3001 = stablehlo.add %2998, %3000 : tensor<256x14x14x256xf32>
    %3002 = stablehlo.convert %3001 : (tensor<256x14x14x256xf32>) -> tensor<256x14x14x256xf16>
    %3003 = call @relu_6(%3002) : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf16>
    %3004 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %3005 = stablehlo.compare  GT, %3002, %3004,  FLOAT : (tensor<256x14x14x256xf16>, tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xi1>
    %3006 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %3007 = stablehlo.convert %arg48 : (tensor<1x1x256x1024xf32>) -> tensor<1x1x256x1024xf16>
    %3008 = stablehlo.convolution(%3003, %3007) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x256xf16>, tensor<1x1x256x1024xf16>) -> tensor<256x14x14x1024xf16>
    %3009 = stablehlo.convert %3008 : (tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xf32>
    %3010 = stablehlo.multiply %3009, %3009 : tensor<256x14x14x1024xf32>
    %3011 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x14x14x1024xf32>
    %3012 = stablehlo.multiply %3011, %3009 : tensor<256x14x14x1024xf32>
    %cst_105 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3013 = stablehlo.reduce(%3009 init: %cst_105) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %3014 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %3015 = stablehlo.divide %3013, %3014 : tensor<1024xf32>
    %cst_106 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3016 = stablehlo.reduce(%3010 init: %cst_106) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %3017 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %3018 = stablehlo.divide %3016, %3017 : tensor<1024xf32>
    %3019 = stablehlo.broadcast_in_dim %3015, dims = [1] : (tensor<1024xf32>) -> tensor<1x1024xf32>
    %3020 = stablehlo.broadcast_in_dim %3018, dims = [1] : (tensor<1024xf32>) -> tensor<1x1024xf32>
    %3021 = stablehlo.concatenate %3019, %3020, dim = 0 : (tensor<1x1024xf32>, tensor<1x1024xf32>) -> tensor<2x1024xf32>
    %3022 = "stablehlo.all_reduce"(%3021) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x1024xf32>) -> tensor<2x1024xf32>
    %3023 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x1024xf32>
    %3024 = stablehlo.divide %3022, %3023 : tensor<2x1024xf32>
    %3025 = stablehlo.slice %3024 [0:1, 0:1024] : (tensor<2x1024xf32>) -> tensor<1x1024xf32>
    %3026 = stablehlo.reshape %3025 : (tensor<1x1024xf32>) -> tensor<1024xf32>
    %3027 = stablehlo.slice %3024 [1:2, 0:1024] : (tensor<2x1024xf32>) -> tensor<1x1024xf32>
    %3028 = stablehlo.reshape %3027 : (tensor<1x1024xf32>) -> tensor<1024xf32>
    %3029 = stablehlo.multiply %3026, %3026 : tensor<1024xf32>
    %3030 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %3031 = stablehlo.multiply %3030, %3026 : tensor<1024xf32>
    %3032 = stablehlo.subtract %3028, %3029 : tensor<1024xf32>
    %3033 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %3034 = stablehlo.maximum %3033, %3032 : tensor<1024xf32>
    %3035 = stablehlo.compare  EQ, %3032, %3034,  FLOAT : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xi1>
    %3036 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %3037 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %3038 = stablehlo.select %3035, %3036, %3037 : tensor<1024xi1>, tensor<1024xf32>
    %3039 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %3040 = stablehlo.compare  EQ, %3039, %3034,  FLOAT : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xi1>
    %3041 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %3042 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %3043 = stablehlo.select %3040, %3041, %3042 : tensor<1024xi1>, tensor<1024xf32>
    %3044 = stablehlo.divide %3038, %3043 : tensor<1024xf32>
    %3045 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %3046 = stablehlo.multiply %3045, %arg354 : tensor<1024xf32>
    %3047 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %3048 = stablehlo.multiply %3047, %3026 : tensor<1024xf32>
    %3049 = stablehlo.add %3046, %3048 : tensor<1024xf32>
    %3050 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %3051 = stablehlo.multiply %3050, %arg355 : tensor<1024xf32>
    %3052 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %3053 = stablehlo.multiply %3052, %3034 : tensor<1024xf32>
    %3054 = stablehlo.add %3051, %3053 : tensor<1024xf32>
    %3055 = stablehlo.broadcast_in_dim %3026, dims = [3] : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %3056 = stablehlo.broadcast_in_dim %3034, dims = [3] : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %3057 = stablehlo.convert %3008 : (tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xf32>
    %3058 = stablehlo.broadcast_in_dim %3055, dims = [0, 1, 2, 3] : (tensor<1x1x1x1024xf32>) -> tensor<256x14x14x1024xf32>
    %3059 = stablehlo.subtract %3057, %3058 : tensor<256x14x14x1024xf32>
    %3060 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x1024xf32>
    %3061 = stablehlo.add %3056, %3060 : tensor<1x1x1x1024xf32>
    %3062 = stablehlo.rsqrt %3061 : tensor<1x1x1x1024xf32>
    %3063 = stablehlo.divide %3062, %3061 : tensor<1x1x1x1024xf32>
    %3064 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x1024xf32>
    %3065 = stablehlo.multiply %3064, %3063 : tensor<1x1x1x1024xf32>
    %3066 = stablehlo.reshape %arg45 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %3067 = stablehlo.multiply %3062, %3066 : tensor<1x1x1x1024xf32>
    %3068 = stablehlo.broadcast_in_dim %3067, dims = [0, 1, 2, 3] : (tensor<1x1x1x1024xf32>) -> tensor<256x14x14x1024xf32>
    %3069 = stablehlo.multiply %3059, %3068 : tensor<256x14x14x1024xf32>
    %3070 = stablehlo.reshape %arg44 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %3071 = stablehlo.broadcast_in_dim %3070, dims = [0, 1, 2, 3] : (tensor<1x1x1x1024xf32>) -> tensor<256x14x14x1024xf32>
    %3072 = stablehlo.add %3069, %3071 : tensor<256x14x14x1024xf32>
    %3073 = stablehlo.convert %3072 : (tensor<256x14x14x1024xf32>) -> tensor<256x14x14x1024xf16>
    %3074 = stablehlo.add %2861, %3073 : tensor<256x14x14x1024xf16>
    %3075 = call @relu_7(%3074) : (tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xf16>
    %3076 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x1024xf16>
    %3077 = stablehlo.compare  GT, %3074, %3076,  FLOAT : (tensor<256x14x14x1024xf16>, tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xi1>
    %3078 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x1024xf16>
    %3079 = stablehlo.convert %arg55 : (tensor<1x1x1024x512xf32>) -> tensor<1x1x1024x512xf16>
    %3080 = stablehlo.convolution(%3075, %3079) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x1024xf16>, tensor<1x1x1024x512xf16>) -> tensor<256x14x14x512xf16>
    %3081 = stablehlo.convert %3080 : (tensor<256x14x14x512xf16>) -> tensor<256x14x14x512xf32>
    %3082 = stablehlo.multiply %3081, %3081 : tensor<256x14x14x512xf32>
    %3083 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x14x14x512xf32>
    %3084 = stablehlo.multiply %3083, %3081 : tensor<256x14x14x512xf32>
    %cst_107 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3085 = stablehlo.reduce(%3081 init: %cst_107) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x512xf32>, tensor<f32>) -> tensor<512xf32>
    %3086 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3087 = stablehlo.divide %3085, %3086 : tensor<512xf32>
    %cst_108 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3088 = stablehlo.reduce(%3082 init: %cst_108) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x512xf32>, tensor<f32>) -> tensor<512xf32>
    %3089 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3090 = stablehlo.divide %3088, %3089 : tensor<512xf32>
    %3091 = stablehlo.broadcast_in_dim %3087, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %3092 = stablehlo.broadcast_in_dim %3090, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %3093 = stablehlo.concatenate %3091, %3092, dim = 0 : (tensor<1x512xf32>, tensor<1x512xf32>) -> tensor<2x512xf32>
    %3094 = "stablehlo.all_reduce"(%3093) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x512xf32>) -> tensor<2x512xf32>
    %3095 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x512xf32>
    %3096 = stablehlo.divide %3094, %3095 : tensor<2x512xf32>
    %3097 = stablehlo.slice %3096 [0:1, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %3098 = stablehlo.reshape %3097 : (tensor<1x512xf32>) -> tensor<512xf32>
    %3099 = stablehlo.slice %3096 [1:2, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %3100 = stablehlo.reshape %3099 : (tensor<1x512xf32>) -> tensor<512xf32>
    %3101 = stablehlo.multiply %3098, %3098 : tensor<512xf32>
    %3102 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3103 = stablehlo.multiply %3102, %3098 : tensor<512xf32>
    %3104 = stablehlo.subtract %3100, %3101 : tensor<512xf32>
    %3105 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3106 = stablehlo.maximum %3105, %3104 : tensor<512xf32>
    %3107 = stablehlo.compare  EQ, %3104, %3106,  FLOAT : (tensor<512xf32>, tensor<512xf32>) -> tensor<512xi1>
    %3108 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3109 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3110 = stablehlo.select %3107, %3108, %3109 : tensor<512xi1>, tensor<512xf32>
    %3111 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3112 = stablehlo.compare  EQ, %3111, %3106,  FLOAT : (tensor<512xf32>, tensor<512xf32>) -> tensor<512xi1>
    %3113 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3114 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3115 = stablehlo.select %3112, %3113, %3114 : tensor<512xi1>, tensor<512xf32>
    %3116 = stablehlo.divide %3110, %3115 : tensor<512xf32>
    %3117 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3118 = stablehlo.multiply %3117, %arg356 : tensor<512xf32>
    %3119 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3120 = stablehlo.multiply %3119, %3098 : tensor<512xf32>
    %3121 = stablehlo.add %3118, %3120 : tensor<512xf32>
    %3122 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3123 = stablehlo.multiply %3122, %arg357 : tensor<512xf32>
    %3124 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3125 = stablehlo.multiply %3124, %3106 : tensor<512xf32>
    %3126 = stablehlo.add %3123, %3125 : tensor<512xf32>
    %3127 = stablehlo.broadcast_in_dim %3098, dims = [3] : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %3128 = stablehlo.broadcast_in_dim %3106, dims = [3] : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %3129 = stablehlo.convert %3080 : (tensor<256x14x14x512xf16>) -> tensor<256x14x14x512xf32>
    %3130 = stablehlo.broadcast_in_dim %3127, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x14x14x512xf32>
    %3131 = stablehlo.subtract %3129, %3130 : tensor<256x14x14x512xf32>
    %3132 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x512xf32>
    %3133 = stablehlo.add %3128, %3132 : tensor<1x1x1x512xf32>
    %3134 = stablehlo.rsqrt %3133 : tensor<1x1x1x512xf32>
    %3135 = stablehlo.divide %3134, %3133 : tensor<1x1x1x512xf32>
    %3136 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x512xf32>
    %3137 = stablehlo.multiply %3136, %3135 : tensor<1x1x1x512xf32>
    %3138 = stablehlo.reshape %arg50 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %3139 = stablehlo.multiply %3134, %3138 : tensor<1x1x1x512xf32>
    %3140 = stablehlo.broadcast_in_dim %3139, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x14x14x512xf32>
    %3141 = stablehlo.multiply %3131, %3140 : tensor<256x14x14x512xf32>
    %3142 = stablehlo.reshape %arg49 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %3143 = stablehlo.broadcast_in_dim %3142, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x14x14x512xf32>
    %3144 = stablehlo.add %3141, %3143 : tensor<256x14x14x512xf32>
    %3145 = stablehlo.convert %3144 : (tensor<256x14x14x512xf32>) -> tensor<256x14x14x512xf16>
    %3146 = call @relu_8(%3145) : (tensor<256x14x14x512xf16>) -> tensor<256x14x14x512xf16>
    %3147 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x512xf16>
    %3148 = stablehlo.compare  GT, %3145, %3147,  FLOAT : (tensor<256x14x14x512xf16>, tensor<256x14x14x512xf16>) -> tensor<256x14x14x512xi1>
    %3149 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x512xf16>
    %3150 = stablehlo.convert %arg56 : (tensor<3x3x512x512xf32>) -> tensor<3x3x512x512xf16>
    %3151 = stablehlo.convolution(%3146, %3150) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [2, 2], pad = [[0, 1], [0, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x512xf16>, tensor<3x3x512x512xf16>) -> tensor<256x7x7x512xf16>
    %3152 = stablehlo.convert %3151 : (tensor<256x7x7x512xf16>) -> tensor<256x7x7x512xf32>
    %3153 = stablehlo.multiply %3152, %3152 : tensor<256x7x7x512xf32>
    %3154 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x7x7x512xf32>
    %3155 = stablehlo.multiply %3154, %3152 : tensor<256x7x7x512xf32>
    %cst_109 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3156 = stablehlo.reduce(%3152 init: %cst_109) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x512xf32>, tensor<f32>) -> tensor<512xf32>
    %cst_110 = stablehlo.constant dense<1.254400e+04> : tensor<f32>
    %3157 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3158 = stablehlo.divide %3156, %3157 : tensor<512xf32>
    %cst_111 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3159 = stablehlo.reduce(%3153 init: %cst_111) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x512xf32>, tensor<f32>) -> tensor<512xf32>
    %3160 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3161 = stablehlo.divide %3159, %3160 : tensor<512xf32>
    %3162 = stablehlo.broadcast_in_dim %3158, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %3163 = stablehlo.broadcast_in_dim %3161, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %3164 = stablehlo.concatenate %3162, %3163, dim = 0 : (tensor<1x512xf32>, tensor<1x512xf32>) -> tensor<2x512xf32>
    %3165 = "stablehlo.all_reduce"(%3164) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x512xf32>) -> tensor<2x512xf32>
    %3166 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x512xf32>
    %3167 = stablehlo.divide %3165, %3166 : tensor<2x512xf32>
    %3168 = stablehlo.slice %3167 [0:1, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %3169 = stablehlo.reshape %3168 : (tensor<1x512xf32>) -> tensor<512xf32>
    %3170 = stablehlo.slice %3167 [1:2, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %3171 = stablehlo.reshape %3170 : (tensor<1x512xf32>) -> tensor<512xf32>
    %3172 = stablehlo.multiply %3169, %3169 : tensor<512xf32>
    %3173 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3174 = stablehlo.multiply %3173, %3169 : tensor<512xf32>
    %3175 = stablehlo.subtract %3171, %3172 : tensor<512xf32>
    %3176 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3177 = stablehlo.maximum %3176, %3175 : tensor<512xf32>
    %3178 = stablehlo.compare  EQ, %3175, %3177,  FLOAT : (tensor<512xf32>, tensor<512xf32>) -> tensor<512xi1>
    %3179 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3180 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3181 = stablehlo.select %3178, %3179, %3180 : tensor<512xi1>, tensor<512xf32>
    %3182 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3183 = stablehlo.compare  EQ, %3182, %3177,  FLOAT : (tensor<512xf32>, tensor<512xf32>) -> tensor<512xi1>
    %3184 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3185 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3186 = stablehlo.select %3183, %3184, %3185 : tensor<512xi1>, tensor<512xf32>
    %3187 = stablehlo.divide %3181, %3186 : tensor<512xf32>
    %3188 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3189 = stablehlo.multiply %3188, %arg358 : tensor<512xf32>
    %3190 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3191 = stablehlo.multiply %3190, %3169 : tensor<512xf32>
    %3192 = stablehlo.add %3189, %3191 : tensor<512xf32>
    %3193 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3194 = stablehlo.multiply %3193, %arg359 : tensor<512xf32>
    %3195 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3196 = stablehlo.multiply %3195, %3177 : tensor<512xf32>
    %3197 = stablehlo.add %3194, %3196 : tensor<512xf32>
    %3198 = stablehlo.broadcast_in_dim %3169, dims = [3] : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %3199 = stablehlo.broadcast_in_dim %3177, dims = [3] : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %3200 = stablehlo.convert %3151 : (tensor<256x7x7x512xf16>) -> tensor<256x7x7x512xf32>
    %3201 = stablehlo.broadcast_in_dim %3198, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x7x7x512xf32>
    %3202 = stablehlo.subtract %3200, %3201 : tensor<256x7x7x512xf32>
    %3203 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x512xf32>
    %3204 = stablehlo.add %3199, %3203 : tensor<1x1x1x512xf32>
    %3205 = stablehlo.rsqrt %3204 : tensor<1x1x1x512xf32>
    %3206 = stablehlo.divide %3205, %3204 : tensor<1x1x1x512xf32>
    %3207 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x512xf32>
    %3208 = stablehlo.multiply %3207, %3206 : tensor<1x1x1x512xf32>
    %3209 = stablehlo.reshape %arg52 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %3210 = stablehlo.multiply %3205, %3209 : tensor<1x1x1x512xf32>
    %3211 = stablehlo.broadcast_in_dim %3210, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x7x7x512xf32>
    %3212 = stablehlo.multiply %3202, %3211 : tensor<256x7x7x512xf32>
    %3213 = stablehlo.reshape %arg51 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %3214 = stablehlo.broadcast_in_dim %3213, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x7x7x512xf32>
    %3215 = stablehlo.add %3212, %3214 : tensor<256x7x7x512xf32>
    %3216 = stablehlo.convert %3215 : (tensor<256x7x7x512xf32>) -> tensor<256x7x7x512xf16>
    %3217 = call @relu_9(%3216) : (tensor<256x7x7x512xf16>) -> tensor<256x7x7x512xf16>
    %3218 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x7x7x512xf16>
    %3219 = stablehlo.compare  GT, %3216, %3218,  FLOAT : (tensor<256x7x7x512xf16>, tensor<256x7x7x512xf16>) -> tensor<256x7x7x512xi1>
    %3220 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x7x7x512xf16>
    %3221 = stablehlo.convert %arg57 : (tensor<1x1x512x2048xf32>) -> tensor<1x1x512x2048xf16>
    %3222 = stablehlo.convolution(%3217, %3221) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x7x7x512xf16>, tensor<1x1x512x2048xf16>) -> tensor<256x7x7x2048xf16>
    %3223 = stablehlo.convert %3222 : (tensor<256x7x7x2048xf16>) -> tensor<256x7x7x2048xf32>
    %3224 = stablehlo.multiply %3223, %3223 : tensor<256x7x7x2048xf32>
    %3225 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x7x7x2048xf32>
    %3226 = stablehlo.multiply %3225, %3223 : tensor<256x7x7x2048xf32>
    %cst_112 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3227 = stablehlo.reduce(%3223 init: %cst_112) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %3228 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3229 = stablehlo.divide %3227, %3228 : tensor<2048xf32>
    %cst_113 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3230 = stablehlo.reduce(%3224 init: %cst_113) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %3231 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3232 = stablehlo.divide %3230, %3231 : tensor<2048xf32>
    %3233 = stablehlo.broadcast_in_dim %3229, dims = [1] : (tensor<2048xf32>) -> tensor<1x2048xf32>
    %3234 = stablehlo.broadcast_in_dim %3232, dims = [1] : (tensor<2048xf32>) -> tensor<1x2048xf32>
    %3235 = stablehlo.concatenate %3233, %3234, dim = 0 : (tensor<1x2048xf32>, tensor<1x2048xf32>) -> tensor<2x2048xf32>
    %3236 = "stablehlo.all_reduce"(%3235) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x2048xf32>) -> tensor<2x2048xf32>
    %3237 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x2048xf32>
    %3238 = stablehlo.divide %3236, %3237 : tensor<2x2048xf32>
    %3239 = stablehlo.slice %3238 [0:1, 0:2048] : (tensor<2x2048xf32>) -> tensor<1x2048xf32>
    %3240 = stablehlo.reshape %3239 : (tensor<1x2048xf32>) -> tensor<2048xf32>
    %3241 = stablehlo.slice %3238 [1:2, 0:2048] : (tensor<2x2048xf32>) -> tensor<1x2048xf32>
    %3242 = stablehlo.reshape %3241 : (tensor<1x2048xf32>) -> tensor<2048xf32>
    %3243 = stablehlo.multiply %3240, %3240 : tensor<2048xf32>
    %3244 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3245 = stablehlo.multiply %3244, %3240 : tensor<2048xf32>
    %3246 = stablehlo.subtract %3242, %3243 : tensor<2048xf32>
    %3247 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3248 = stablehlo.maximum %3247, %3246 : tensor<2048xf32>
    %3249 = stablehlo.compare  EQ, %3246, %3248,  FLOAT : (tensor<2048xf32>, tensor<2048xf32>) -> tensor<2048xi1>
    %3250 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3251 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3252 = stablehlo.select %3249, %3250, %3251 : tensor<2048xi1>, tensor<2048xf32>
    %3253 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3254 = stablehlo.compare  EQ, %3253, %3248,  FLOAT : (tensor<2048xf32>, tensor<2048xf32>) -> tensor<2048xi1>
    %3255 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3256 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3257 = stablehlo.select %3254, %3255, %3256 : tensor<2048xi1>, tensor<2048xf32>
    %3258 = stablehlo.divide %3252, %3257 : tensor<2048xf32>
    %3259 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3260 = stablehlo.multiply %3259, %arg360 : tensor<2048xf32>
    %3261 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3262 = stablehlo.multiply %3261, %3240 : tensor<2048xf32>
    %3263 = stablehlo.add %3260, %3262 : tensor<2048xf32>
    %3264 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3265 = stablehlo.multiply %3264, %arg361 : tensor<2048xf32>
    %3266 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3267 = stablehlo.multiply %3266, %3248 : tensor<2048xf32>
    %3268 = stablehlo.add %3265, %3267 : tensor<2048xf32>
    %3269 = stablehlo.broadcast_in_dim %3240, dims = [3] : (tensor<2048xf32>) -> tensor<1x1x1x2048xf32>
    %3270 = stablehlo.broadcast_in_dim %3248, dims = [3] : (tensor<2048xf32>) -> tensor<1x1x1x2048xf32>
    %3271 = stablehlo.convert %3222 : (tensor<256x7x7x2048xf16>) -> tensor<256x7x7x2048xf32>
    %3272 = stablehlo.broadcast_in_dim %3269, dims = [0, 1, 2, 3] : (tensor<1x1x1x2048xf32>) -> tensor<256x7x7x2048xf32>
    %3273 = stablehlo.subtract %3271, %3272 : tensor<256x7x7x2048xf32>
    %3274 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x2048xf32>
    %3275 = stablehlo.add %3270, %3274 : tensor<1x1x1x2048xf32>
    %3276 = stablehlo.rsqrt %3275 : tensor<1x1x1x2048xf32>
    %3277 = stablehlo.divide %3276, %3275 : tensor<1x1x1x2048xf32>
    %3278 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x2048xf32>
    %3279 = stablehlo.multiply %3278, %3277 : tensor<1x1x1x2048xf32>
    %3280 = stablehlo.reshape %arg54 : (tensor<2048xf32>) -> tensor<1x1x1x2048xf32>
    %3281 = stablehlo.multiply %3276, %3280 : tensor<1x1x1x2048xf32>
    %3282 = stablehlo.broadcast_in_dim %3281, dims = [0, 1, 2, 3] : (tensor<1x1x1x2048xf32>) -> tensor<256x7x7x2048xf32>
    %3283 = stablehlo.multiply %3273, %3282 : tensor<256x7x7x2048xf32>
    %3284 = stablehlo.reshape %arg53 : (tensor<2048xf32>) -> tensor<1x1x1x2048xf32>
    %3285 = stablehlo.broadcast_in_dim %3284, dims = [0, 1, 2, 3] : (tensor<1x1x1x2048xf32>) -> tensor<256x7x7x2048xf32>
    %3286 = stablehlo.add %3283, %3285 : tensor<256x7x7x2048xf32>
    %3287 = stablehlo.convert %3286 : (tensor<256x7x7x2048xf32>) -> tensor<256x7x7x2048xf16>
    %3288 = stablehlo.convert %arg58 : (tensor<1x1x1024x2048xf32>) -> tensor<1x1x1024x2048xf16>
    %3289 = stablehlo.convolution(%3075, %3288) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [2, 2], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x1024xf16>, tensor<1x1x1024x2048xf16>) -> tensor<256x7x7x2048xf16>
    %3290 = stablehlo.convert %3289 : (tensor<256x7x7x2048xf16>) -> tensor<256x7x7x2048xf32>
    %3291 = stablehlo.multiply %3290, %3290 : tensor<256x7x7x2048xf32>
    %3292 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x7x7x2048xf32>
    %3293 = stablehlo.multiply %3292, %3290 : tensor<256x7x7x2048xf32>
    %cst_114 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3294 = stablehlo.reduce(%3290 init: %cst_114) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %3295 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3296 = stablehlo.divide %3294, %3295 : tensor<2048xf32>
    %cst_115 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3297 = stablehlo.reduce(%3291 init: %cst_115) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %3298 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3299 = stablehlo.divide %3297, %3298 : tensor<2048xf32>
    %3300 = stablehlo.broadcast_in_dim %3296, dims = [1] : (tensor<2048xf32>) -> tensor<1x2048xf32>
    %3301 = stablehlo.broadcast_in_dim %3299, dims = [1] : (tensor<2048xf32>) -> tensor<1x2048xf32>
    %3302 = stablehlo.concatenate %3300, %3301, dim = 0 : (tensor<1x2048xf32>, tensor<1x2048xf32>) -> tensor<2x2048xf32>
    %3303 = "stablehlo.all_reduce"(%3302) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x2048xf32>) -> tensor<2x2048xf32>
    %3304 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x2048xf32>
    %3305 = stablehlo.divide %3303, %3304 : tensor<2x2048xf32>
    %3306 = stablehlo.slice %3305 [0:1, 0:2048] : (tensor<2x2048xf32>) -> tensor<1x2048xf32>
    %3307 = stablehlo.reshape %3306 : (tensor<1x2048xf32>) -> tensor<2048xf32>
    %3308 = stablehlo.slice %3305 [1:2, 0:2048] : (tensor<2x2048xf32>) -> tensor<1x2048xf32>
    %3309 = stablehlo.reshape %3308 : (tensor<1x2048xf32>) -> tensor<2048xf32>
    %3310 = stablehlo.multiply %3307, %3307 : tensor<2048xf32>
    %3311 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3312 = stablehlo.multiply %3311, %3307 : tensor<2048xf32>
    %3313 = stablehlo.subtract %3309, %3310 : tensor<2048xf32>
    %3314 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3315 = stablehlo.maximum %3314, %3313 : tensor<2048xf32>
    %3316 = stablehlo.compare  EQ, %3313, %3315,  FLOAT : (tensor<2048xf32>, tensor<2048xf32>) -> tensor<2048xi1>
    %3317 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3318 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3319 = stablehlo.select %3316, %3317, %3318 : tensor<2048xi1>, tensor<2048xf32>
    %3320 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3321 = stablehlo.compare  EQ, %3320, %3315,  FLOAT : (tensor<2048xf32>, tensor<2048xf32>) -> tensor<2048xi1>
    %3322 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3323 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3324 = stablehlo.select %3321, %3322, %3323 : tensor<2048xi1>, tensor<2048xf32>
    %3325 = stablehlo.divide %3319, %3324 : tensor<2048xf32>
    %3326 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3327 = stablehlo.multiply %3326, %arg362 : tensor<2048xf32>
    %3328 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3329 = stablehlo.multiply %3328, %3307 : tensor<2048xf32>
    %3330 = stablehlo.add %3327, %3329 : tensor<2048xf32>
    %3331 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3332 = stablehlo.multiply %3331, %arg363 : tensor<2048xf32>
    %3333 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3334 = stablehlo.multiply %3333, %3315 : tensor<2048xf32>
    %3335 = stablehlo.add %3332, %3334 : tensor<2048xf32>
    %3336 = stablehlo.broadcast_in_dim %3307, dims = [3] : (tensor<2048xf32>) -> tensor<1x1x1x2048xf32>
    %3337 = stablehlo.broadcast_in_dim %3315, dims = [3] : (tensor<2048xf32>) -> tensor<1x1x1x2048xf32>
    %3338 = stablehlo.convert %3289 : (tensor<256x7x7x2048xf16>) -> tensor<256x7x7x2048xf32>
    %3339 = stablehlo.broadcast_in_dim %3336, dims = [0, 1, 2, 3] : (tensor<1x1x1x2048xf32>) -> tensor<256x7x7x2048xf32>
    %3340 = stablehlo.subtract %3338, %3339 : tensor<256x7x7x2048xf32>
    %3341 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x2048xf32>
    %3342 = stablehlo.add %3337, %3341 : tensor<1x1x1x2048xf32>
    %3343 = stablehlo.rsqrt %3342 : tensor<1x1x1x2048xf32>
    %3344 = stablehlo.divide %3343, %3342 : tensor<1x1x1x2048xf32>
    %3345 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x2048xf32>
    %3346 = stablehlo.multiply %3345, %3344 : tensor<1x1x1x2048xf32>
    %3347 = stablehlo.reshape %arg60 : (tensor<2048xf32>) -> tensor<1x1x1x2048xf32>
    %3348 = stablehlo.multiply %3343, %3347 : tensor<1x1x1x2048xf32>
    %3349 = stablehlo.broadcast_in_dim %3348, dims = [0, 1, 2, 3] : (tensor<1x1x1x2048xf32>) -> tensor<256x7x7x2048xf32>
    %3350 = stablehlo.multiply %3340, %3349 : tensor<256x7x7x2048xf32>
    %3351 = stablehlo.reshape %arg59 : (tensor<2048xf32>) -> tensor<1x1x1x2048xf32>
    %3352 = stablehlo.broadcast_in_dim %3351, dims = [0, 1, 2, 3] : (tensor<1x1x1x2048xf32>) -> tensor<256x7x7x2048xf32>
    %3353 = stablehlo.add %3350, %3352 : tensor<256x7x7x2048xf32>
    %3354 = stablehlo.convert %3353 : (tensor<256x7x7x2048xf32>) -> tensor<256x7x7x2048xf16>
    %3355 = stablehlo.add %3354, %3287 : tensor<256x7x7x2048xf16>
    %3356 = call @relu_10(%3355) : (tensor<256x7x7x2048xf16>) -> tensor<256x7x7x2048xf16>
    %3357 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x7x7x2048xf16>
    %3358 = stablehlo.compare  GT, %3355, %3357,  FLOAT : (tensor<256x7x7x2048xf16>, tensor<256x7x7x2048xf16>) -> tensor<256x7x7x2048xi1>
    %3359 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x7x7x2048xf16>
    %3360 = stablehlo.convert %arg67 : (tensor<1x1x2048x512xf32>) -> tensor<1x1x2048x512xf16>
    %3361 = stablehlo.convolution(%3356, %3360) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x7x7x2048xf16>, tensor<1x1x2048x512xf16>) -> tensor<256x7x7x512xf16>
    %3362 = stablehlo.convert %3361 : (tensor<256x7x7x512xf16>) -> tensor<256x7x7x512xf32>
    %3363 = stablehlo.multiply %3362, %3362 : tensor<256x7x7x512xf32>
    %3364 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x7x7x512xf32>
    %3365 = stablehlo.multiply %3364, %3362 : tensor<256x7x7x512xf32>
    %cst_116 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3366 = stablehlo.reduce(%3362 init: %cst_116) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x512xf32>, tensor<f32>) -> tensor<512xf32>
    %3367 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3368 = stablehlo.divide %3366, %3367 : tensor<512xf32>
    %cst_117 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3369 = stablehlo.reduce(%3363 init: %cst_117) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x512xf32>, tensor<f32>) -> tensor<512xf32>
    %3370 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3371 = stablehlo.divide %3369, %3370 : tensor<512xf32>
    %3372 = stablehlo.broadcast_in_dim %3368, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %3373 = stablehlo.broadcast_in_dim %3371, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %3374 = stablehlo.concatenate %3372, %3373, dim = 0 : (tensor<1x512xf32>, tensor<1x512xf32>) -> tensor<2x512xf32>
    %3375 = "stablehlo.all_reduce"(%3374) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x512xf32>) -> tensor<2x512xf32>
    %3376 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x512xf32>
    %3377 = stablehlo.divide %3375, %3376 : tensor<2x512xf32>
    %3378 = stablehlo.slice %3377 [0:1, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %3379 = stablehlo.reshape %3378 : (tensor<1x512xf32>) -> tensor<512xf32>
    %3380 = stablehlo.slice %3377 [1:2, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %3381 = stablehlo.reshape %3380 : (tensor<1x512xf32>) -> tensor<512xf32>
    %3382 = stablehlo.multiply %3379, %3379 : tensor<512xf32>
    %3383 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3384 = stablehlo.multiply %3383, %3379 : tensor<512xf32>
    %3385 = stablehlo.subtract %3381, %3382 : tensor<512xf32>
    %3386 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3387 = stablehlo.maximum %3386, %3385 : tensor<512xf32>
    %3388 = stablehlo.compare  EQ, %3385, %3387,  FLOAT : (tensor<512xf32>, tensor<512xf32>) -> tensor<512xi1>
    %3389 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3390 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3391 = stablehlo.select %3388, %3389, %3390 : tensor<512xi1>, tensor<512xf32>
    %3392 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3393 = stablehlo.compare  EQ, %3392, %3387,  FLOAT : (tensor<512xf32>, tensor<512xf32>) -> tensor<512xi1>
    %3394 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3395 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3396 = stablehlo.select %3393, %3394, %3395 : tensor<512xi1>, tensor<512xf32>
    %3397 = stablehlo.divide %3391, %3396 : tensor<512xf32>
    %3398 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3399 = stablehlo.multiply %3398, %arg364 : tensor<512xf32>
    %3400 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3401 = stablehlo.multiply %3400, %3379 : tensor<512xf32>
    %3402 = stablehlo.add %3399, %3401 : tensor<512xf32>
    %3403 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3404 = stablehlo.multiply %3403, %arg365 : tensor<512xf32>
    %3405 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3406 = stablehlo.multiply %3405, %3387 : tensor<512xf32>
    %3407 = stablehlo.add %3404, %3406 : tensor<512xf32>
    %3408 = stablehlo.broadcast_in_dim %3379, dims = [3] : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %3409 = stablehlo.broadcast_in_dim %3387, dims = [3] : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %3410 = stablehlo.convert %3361 : (tensor<256x7x7x512xf16>) -> tensor<256x7x7x512xf32>
    %3411 = stablehlo.broadcast_in_dim %3408, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x7x7x512xf32>
    %3412 = stablehlo.subtract %3410, %3411 : tensor<256x7x7x512xf32>
    %3413 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x512xf32>
    %3414 = stablehlo.add %3409, %3413 : tensor<1x1x1x512xf32>
    %3415 = stablehlo.rsqrt %3414 : tensor<1x1x1x512xf32>
    %3416 = stablehlo.divide %3415, %3414 : tensor<1x1x1x512xf32>
    %3417 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x512xf32>
    %3418 = stablehlo.multiply %3417, %3416 : tensor<1x1x1x512xf32>
    %3419 = stablehlo.reshape %arg62 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %3420 = stablehlo.multiply %3415, %3419 : tensor<1x1x1x512xf32>
    %3421 = stablehlo.broadcast_in_dim %3420, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x7x7x512xf32>
    %3422 = stablehlo.multiply %3412, %3421 : tensor<256x7x7x512xf32>
    %3423 = stablehlo.reshape %arg61 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %3424 = stablehlo.broadcast_in_dim %3423, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x7x7x512xf32>
    %3425 = stablehlo.add %3422, %3424 : tensor<256x7x7x512xf32>
    %3426 = stablehlo.convert %3425 : (tensor<256x7x7x512xf32>) -> tensor<256x7x7x512xf16>
    %3427 = call @relu_9(%3426) : (tensor<256x7x7x512xf16>) -> tensor<256x7x7x512xf16>
    %3428 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x7x7x512xf16>
    %3429 = stablehlo.compare  GT, %3426, %3428,  FLOAT : (tensor<256x7x7x512xf16>, tensor<256x7x7x512xf16>) -> tensor<256x7x7x512xi1>
    %3430 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x7x7x512xf16>
    %3431 = stablehlo.convert %arg68 : (tensor<3x3x512x512xf32>) -> tensor<3x3x512x512xf16>
    %3432 = stablehlo.convolution(%3427, %3431) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x7x7x512xf16>, tensor<3x3x512x512xf16>) -> tensor<256x7x7x512xf16>
    %3433 = stablehlo.convert %3432 : (tensor<256x7x7x512xf16>) -> tensor<256x7x7x512xf32>
    %3434 = stablehlo.multiply %3433, %3433 : tensor<256x7x7x512xf32>
    %3435 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x7x7x512xf32>
    %3436 = stablehlo.multiply %3435, %3433 : tensor<256x7x7x512xf32>
    %cst_118 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3437 = stablehlo.reduce(%3433 init: %cst_118) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x512xf32>, tensor<f32>) -> tensor<512xf32>
    %3438 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3439 = stablehlo.divide %3437, %3438 : tensor<512xf32>
    %cst_119 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3440 = stablehlo.reduce(%3434 init: %cst_119) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x512xf32>, tensor<f32>) -> tensor<512xf32>
    %3441 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3442 = stablehlo.divide %3440, %3441 : tensor<512xf32>
    %3443 = stablehlo.broadcast_in_dim %3439, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %3444 = stablehlo.broadcast_in_dim %3442, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %3445 = stablehlo.concatenate %3443, %3444, dim = 0 : (tensor<1x512xf32>, tensor<1x512xf32>) -> tensor<2x512xf32>
    %3446 = "stablehlo.all_reduce"(%3445) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x512xf32>) -> tensor<2x512xf32>
    %3447 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x512xf32>
    %3448 = stablehlo.divide %3446, %3447 : tensor<2x512xf32>
    %3449 = stablehlo.slice %3448 [0:1, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %3450 = stablehlo.reshape %3449 : (tensor<1x512xf32>) -> tensor<512xf32>
    %3451 = stablehlo.slice %3448 [1:2, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %3452 = stablehlo.reshape %3451 : (tensor<1x512xf32>) -> tensor<512xf32>
    %3453 = stablehlo.multiply %3450, %3450 : tensor<512xf32>
    %3454 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3455 = stablehlo.multiply %3454, %3450 : tensor<512xf32>
    %3456 = stablehlo.subtract %3452, %3453 : tensor<512xf32>
    %3457 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3458 = stablehlo.maximum %3457, %3456 : tensor<512xf32>
    %3459 = stablehlo.compare  EQ, %3456, %3458,  FLOAT : (tensor<512xf32>, tensor<512xf32>) -> tensor<512xi1>
    %3460 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3461 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3462 = stablehlo.select %3459, %3460, %3461 : tensor<512xi1>, tensor<512xf32>
    %3463 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3464 = stablehlo.compare  EQ, %3463, %3458,  FLOAT : (tensor<512xf32>, tensor<512xf32>) -> tensor<512xi1>
    %3465 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3466 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3467 = stablehlo.select %3464, %3465, %3466 : tensor<512xi1>, tensor<512xf32>
    %3468 = stablehlo.divide %3462, %3467 : tensor<512xf32>
    %3469 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3470 = stablehlo.multiply %3469, %arg366 : tensor<512xf32>
    %3471 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3472 = stablehlo.multiply %3471, %3450 : tensor<512xf32>
    %3473 = stablehlo.add %3470, %3472 : tensor<512xf32>
    %3474 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3475 = stablehlo.multiply %3474, %arg367 : tensor<512xf32>
    %3476 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3477 = stablehlo.multiply %3476, %3458 : tensor<512xf32>
    %3478 = stablehlo.add %3475, %3477 : tensor<512xf32>
    %3479 = stablehlo.broadcast_in_dim %3450, dims = [3] : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %3480 = stablehlo.broadcast_in_dim %3458, dims = [3] : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %3481 = stablehlo.convert %3432 : (tensor<256x7x7x512xf16>) -> tensor<256x7x7x512xf32>
    %3482 = stablehlo.broadcast_in_dim %3479, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x7x7x512xf32>
    %3483 = stablehlo.subtract %3481, %3482 : tensor<256x7x7x512xf32>
    %3484 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x512xf32>
    %3485 = stablehlo.add %3480, %3484 : tensor<1x1x1x512xf32>
    %3486 = stablehlo.rsqrt %3485 : tensor<1x1x1x512xf32>
    %3487 = stablehlo.divide %3486, %3485 : tensor<1x1x1x512xf32>
    %3488 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x512xf32>
    %3489 = stablehlo.multiply %3488, %3487 : tensor<1x1x1x512xf32>
    %3490 = stablehlo.reshape %arg64 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %3491 = stablehlo.multiply %3486, %3490 : tensor<1x1x1x512xf32>
    %3492 = stablehlo.broadcast_in_dim %3491, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x7x7x512xf32>
    %3493 = stablehlo.multiply %3483, %3492 : tensor<256x7x7x512xf32>
    %3494 = stablehlo.reshape %arg63 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %3495 = stablehlo.broadcast_in_dim %3494, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x7x7x512xf32>
    %3496 = stablehlo.add %3493, %3495 : tensor<256x7x7x512xf32>
    %3497 = stablehlo.convert %3496 : (tensor<256x7x7x512xf32>) -> tensor<256x7x7x512xf16>
    %3498 = call @relu_9(%3497) : (tensor<256x7x7x512xf16>) -> tensor<256x7x7x512xf16>
    %3499 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x7x7x512xf16>
    %3500 = stablehlo.compare  GT, %3497, %3499,  FLOAT : (tensor<256x7x7x512xf16>, tensor<256x7x7x512xf16>) -> tensor<256x7x7x512xi1>
    %3501 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x7x7x512xf16>
    %3502 = stablehlo.convert %arg69 : (tensor<1x1x512x2048xf32>) -> tensor<1x1x512x2048xf16>
    %3503 = stablehlo.convolution(%3498, %3502) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x7x7x512xf16>, tensor<1x1x512x2048xf16>) -> tensor<256x7x7x2048xf16>
    %3504 = stablehlo.convert %3503 : (tensor<256x7x7x2048xf16>) -> tensor<256x7x7x2048xf32>
    %3505 = stablehlo.multiply %3504, %3504 : tensor<256x7x7x2048xf32>
    %3506 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x7x7x2048xf32>
    %3507 = stablehlo.multiply %3506, %3504 : tensor<256x7x7x2048xf32>
    %cst_120 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3508 = stablehlo.reduce(%3504 init: %cst_120) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %3509 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3510 = stablehlo.divide %3508, %3509 : tensor<2048xf32>
    %cst_121 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3511 = stablehlo.reduce(%3505 init: %cst_121) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %3512 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3513 = stablehlo.divide %3511, %3512 : tensor<2048xf32>
    %3514 = stablehlo.broadcast_in_dim %3510, dims = [1] : (tensor<2048xf32>) -> tensor<1x2048xf32>
    %3515 = stablehlo.broadcast_in_dim %3513, dims = [1] : (tensor<2048xf32>) -> tensor<1x2048xf32>
    %3516 = stablehlo.concatenate %3514, %3515, dim = 0 : (tensor<1x2048xf32>, tensor<1x2048xf32>) -> tensor<2x2048xf32>
    %3517 = "stablehlo.all_reduce"(%3516) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x2048xf32>) -> tensor<2x2048xf32>
    %3518 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x2048xf32>
    %3519 = stablehlo.divide %3517, %3518 : tensor<2x2048xf32>
    %3520 = stablehlo.slice %3519 [0:1, 0:2048] : (tensor<2x2048xf32>) -> tensor<1x2048xf32>
    %3521 = stablehlo.reshape %3520 : (tensor<1x2048xf32>) -> tensor<2048xf32>
    %3522 = stablehlo.slice %3519 [1:2, 0:2048] : (tensor<2x2048xf32>) -> tensor<1x2048xf32>
    %3523 = stablehlo.reshape %3522 : (tensor<1x2048xf32>) -> tensor<2048xf32>
    %3524 = stablehlo.multiply %3521, %3521 : tensor<2048xf32>
    %3525 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3526 = stablehlo.multiply %3525, %3521 : tensor<2048xf32>
    %3527 = stablehlo.subtract %3523, %3524 : tensor<2048xf32>
    %3528 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3529 = stablehlo.maximum %3528, %3527 : tensor<2048xf32>
    %3530 = stablehlo.compare  EQ, %3527, %3529,  FLOAT : (tensor<2048xf32>, tensor<2048xf32>) -> tensor<2048xi1>
    %3531 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3532 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3533 = stablehlo.select %3530, %3531, %3532 : tensor<2048xi1>, tensor<2048xf32>
    %3534 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3535 = stablehlo.compare  EQ, %3534, %3529,  FLOAT : (tensor<2048xf32>, tensor<2048xf32>) -> tensor<2048xi1>
    %3536 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3537 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3538 = stablehlo.select %3535, %3536, %3537 : tensor<2048xi1>, tensor<2048xf32>
    %3539 = stablehlo.divide %3533, %3538 : tensor<2048xf32>
    %3540 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3541 = stablehlo.multiply %3540, %arg368 : tensor<2048xf32>
    %3542 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3543 = stablehlo.multiply %3542, %3521 : tensor<2048xf32>
    %3544 = stablehlo.add %3541, %3543 : tensor<2048xf32>
    %3545 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3546 = stablehlo.multiply %3545, %arg369 : tensor<2048xf32>
    %3547 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3548 = stablehlo.multiply %3547, %3529 : tensor<2048xf32>
    %3549 = stablehlo.add %3546, %3548 : tensor<2048xf32>
    %3550 = stablehlo.broadcast_in_dim %3521, dims = [3] : (tensor<2048xf32>) -> tensor<1x1x1x2048xf32>
    %3551 = stablehlo.broadcast_in_dim %3529, dims = [3] : (tensor<2048xf32>) -> tensor<1x1x1x2048xf32>
    %3552 = stablehlo.convert %3503 : (tensor<256x7x7x2048xf16>) -> tensor<256x7x7x2048xf32>
    %3553 = stablehlo.broadcast_in_dim %3550, dims = [0, 1, 2, 3] : (tensor<1x1x1x2048xf32>) -> tensor<256x7x7x2048xf32>
    %3554 = stablehlo.subtract %3552, %3553 : tensor<256x7x7x2048xf32>
    %3555 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x2048xf32>
    %3556 = stablehlo.add %3551, %3555 : tensor<1x1x1x2048xf32>
    %3557 = stablehlo.rsqrt %3556 : tensor<1x1x1x2048xf32>
    %3558 = stablehlo.divide %3557, %3556 : tensor<1x1x1x2048xf32>
    %3559 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x2048xf32>
    %3560 = stablehlo.multiply %3559, %3558 : tensor<1x1x1x2048xf32>
    %3561 = stablehlo.reshape %arg66 : (tensor<2048xf32>) -> tensor<1x1x1x2048xf32>
    %3562 = stablehlo.multiply %3557, %3561 : tensor<1x1x1x2048xf32>
    %3563 = stablehlo.broadcast_in_dim %3562, dims = [0, 1, 2, 3] : (tensor<1x1x1x2048xf32>) -> tensor<256x7x7x2048xf32>
    %3564 = stablehlo.multiply %3554, %3563 : tensor<256x7x7x2048xf32>
    %3565 = stablehlo.reshape %arg65 : (tensor<2048xf32>) -> tensor<1x1x1x2048xf32>
    %3566 = stablehlo.broadcast_in_dim %3565, dims = [0, 1, 2, 3] : (tensor<1x1x1x2048xf32>) -> tensor<256x7x7x2048xf32>
    %3567 = stablehlo.add %3564, %3566 : tensor<256x7x7x2048xf32>
    %3568 = stablehlo.convert %3567 : (tensor<256x7x7x2048xf32>) -> tensor<256x7x7x2048xf16>
    %3569 = stablehlo.add %3356, %3568 : tensor<256x7x7x2048xf16>
    %3570 = call @relu_10(%3569) : (tensor<256x7x7x2048xf16>) -> tensor<256x7x7x2048xf16>
    %3571 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x7x7x2048xf16>
    %3572 = stablehlo.compare  GT, %3569, %3571,  FLOAT : (tensor<256x7x7x2048xf16>, tensor<256x7x7x2048xf16>) -> tensor<256x7x7x2048xi1>
    %3573 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x7x7x2048xf16>
    %3574 = stablehlo.convert %arg76 : (tensor<1x1x2048x512xf32>) -> tensor<1x1x2048x512xf16>
    %3575 = stablehlo.convolution(%3570, %3574) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x7x7x2048xf16>, tensor<1x1x2048x512xf16>) -> tensor<256x7x7x512xf16>
    %3576 = stablehlo.convert %3575 : (tensor<256x7x7x512xf16>) -> tensor<256x7x7x512xf32>
    %3577 = stablehlo.multiply %3576, %3576 : tensor<256x7x7x512xf32>
    %3578 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x7x7x512xf32>
    %3579 = stablehlo.multiply %3578, %3576 : tensor<256x7x7x512xf32>
    %cst_122 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3580 = stablehlo.reduce(%3576 init: %cst_122) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x512xf32>, tensor<f32>) -> tensor<512xf32>
    %3581 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3582 = stablehlo.divide %3580, %3581 : tensor<512xf32>
    %cst_123 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3583 = stablehlo.reduce(%3577 init: %cst_123) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x512xf32>, tensor<f32>) -> tensor<512xf32>
    %3584 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3585 = stablehlo.divide %3583, %3584 : tensor<512xf32>
    %3586 = stablehlo.broadcast_in_dim %3582, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %3587 = stablehlo.broadcast_in_dim %3585, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %3588 = stablehlo.concatenate %3586, %3587, dim = 0 : (tensor<1x512xf32>, tensor<1x512xf32>) -> tensor<2x512xf32>
    %3589 = "stablehlo.all_reduce"(%3588) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x512xf32>) -> tensor<2x512xf32>
    %3590 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x512xf32>
    %3591 = stablehlo.divide %3589, %3590 : tensor<2x512xf32>
    %3592 = stablehlo.slice %3591 [0:1, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %3593 = stablehlo.reshape %3592 : (tensor<1x512xf32>) -> tensor<512xf32>
    %3594 = stablehlo.slice %3591 [1:2, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %3595 = stablehlo.reshape %3594 : (tensor<1x512xf32>) -> tensor<512xf32>
    %3596 = stablehlo.multiply %3593, %3593 : tensor<512xf32>
    %3597 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3598 = stablehlo.multiply %3597, %3593 : tensor<512xf32>
    %3599 = stablehlo.subtract %3595, %3596 : tensor<512xf32>
    %3600 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3601 = stablehlo.maximum %3600, %3599 : tensor<512xf32>
    %3602 = stablehlo.compare  EQ, %3599, %3601,  FLOAT : (tensor<512xf32>, tensor<512xf32>) -> tensor<512xi1>
    %3603 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3604 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3605 = stablehlo.select %3602, %3603, %3604 : tensor<512xi1>, tensor<512xf32>
    %3606 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3607 = stablehlo.compare  EQ, %3606, %3601,  FLOAT : (tensor<512xf32>, tensor<512xf32>) -> tensor<512xi1>
    %3608 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3609 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3610 = stablehlo.select %3607, %3608, %3609 : tensor<512xi1>, tensor<512xf32>
    %3611 = stablehlo.divide %3605, %3610 : tensor<512xf32>
    %3612 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3613 = stablehlo.multiply %3612, %arg370 : tensor<512xf32>
    %3614 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3615 = stablehlo.multiply %3614, %3593 : tensor<512xf32>
    %3616 = stablehlo.add %3613, %3615 : tensor<512xf32>
    %3617 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3618 = stablehlo.multiply %3617, %arg371 : tensor<512xf32>
    %3619 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3620 = stablehlo.multiply %3619, %3601 : tensor<512xf32>
    %3621 = stablehlo.add %3618, %3620 : tensor<512xf32>
    %3622 = stablehlo.broadcast_in_dim %3593, dims = [3] : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %3623 = stablehlo.broadcast_in_dim %3601, dims = [3] : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %3624 = stablehlo.convert %3575 : (tensor<256x7x7x512xf16>) -> tensor<256x7x7x512xf32>
    %3625 = stablehlo.broadcast_in_dim %3622, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x7x7x512xf32>
    %3626 = stablehlo.subtract %3624, %3625 : tensor<256x7x7x512xf32>
    %3627 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x512xf32>
    %3628 = stablehlo.add %3623, %3627 : tensor<1x1x1x512xf32>
    %3629 = stablehlo.rsqrt %3628 : tensor<1x1x1x512xf32>
    %3630 = stablehlo.divide %3629, %3628 : tensor<1x1x1x512xf32>
    %3631 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x512xf32>
    %3632 = stablehlo.multiply %3631, %3630 : tensor<1x1x1x512xf32>
    %3633 = stablehlo.reshape %arg71 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %3634 = stablehlo.multiply %3629, %3633 : tensor<1x1x1x512xf32>
    %3635 = stablehlo.broadcast_in_dim %3634, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x7x7x512xf32>
    %3636 = stablehlo.multiply %3626, %3635 : tensor<256x7x7x512xf32>
    %3637 = stablehlo.reshape %arg70 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %3638 = stablehlo.broadcast_in_dim %3637, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x7x7x512xf32>
    %3639 = stablehlo.add %3636, %3638 : tensor<256x7x7x512xf32>
    %3640 = stablehlo.convert %3639 : (tensor<256x7x7x512xf32>) -> tensor<256x7x7x512xf16>
    %3641 = call @relu_9(%3640) : (tensor<256x7x7x512xf16>) -> tensor<256x7x7x512xf16>
    %3642 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x7x7x512xf16>
    %3643 = stablehlo.compare  GT, %3640, %3642,  FLOAT : (tensor<256x7x7x512xf16>, tensor<256x7x7x512xf16>) -> tensor<256x7x7x512xi1>
    %3644 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x7x7x512xf16>
    %3645 = stablehlo.convert %arg77 : (tensor<3x3x512x512xf32>) -> tensor<3x3x512x512xf16>
    %3646 = stablehlo.convolution(%3641, %3645) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x7x7x512xf16>, tensor<3x3x512x512xf16>) -> tensor<256x7x7x512xf16>
    %3647 = stablehlo.convert %3646 : (tensor<256x7x7x512xf16>) -> tensor<256x7x7x512xf32>
    %3648 = stablehlo.multiply %3647, %3647 : tensor<256x7x7x512xf32>
    %3649 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x7x7x512xf32>
    %3650 = stablehlo.multiply %3649, %3647 : tensor<256x7x7x512xf32>
    %cst_124 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3651 = stablehlo.reduce(%3647 init: %cst_124) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x512xf32>, tensor<f32>) -> tensor<512xf32>
    %3652 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3653 = stablehlo.divide %3651, %3652 : tensor<512xf32>
    %cst_125 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3654 = stablehlo.reduce(%3648 init: %cst_125) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x512xf32>, tensor<f32>) -> tensor<512xf32>
    %3655 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3656 = stablehlo.divide %3654, %3655 : tensor<512xf32>
    %3657 = stablehlo.broadcast_in_dim %3653, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %3658 = stablehlo.broadcast_in_dim %3656, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %3659 = stablehlo.concatenate %3657, %3658, dim = 0 : (tensor<1x512xf32>, tensor<1x512xf32>) -> tensor<2x512xf32>
    %3660 = "stablehlo.all_reduce"(%3659) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x512xf32>) -> tensor<2x512xf32>
    %3661 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x512xf32>
    %3662 = stablehlo.divide %3660, %3661 : tensor<2x512xf32>
    %3663 = stablehlo.slice %3662 [0:1, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %3664 = stablehlo.reshape %3663 : (tensor<1x512xf32>) -> tensor<512xf32>
    %3665 = stablehlo.slice %3662 [1:2, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %3666 = stablehlo.reshape %3665 : (tensor<1x512xf32>) -> tensor<512xf32>
    %3667 = stablehlo.multiply %3664, %3664 : tensor<512xf32>
    %3668 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3669 = stablehlo.multiply %3668, %3664 : tensor<512xf32>
    %3670 = stablehlo.subtract %3666, %3667 : tensor<512xf32>
    %3671 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3672 = stablehlo.maximum %3671, %3670 : tensor<512xf32>
    %3673 = stablehlo.compare  EQ, %3670, %3672,  FLOAT : (tensor<512xf32>, tensor<512xf32>) -> tensor<512xi1>
    %3674 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3675 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3676 = stablehlo.select %3673, %3674, %3675 : tensor<512xi1>, tensor<512xf32>
    %3677 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3678 = stablehlo.compare  EQ, %3677, %3672,  FLOAT : (tensor<512xf32>, tensor<512xf32>) -> tensor<512xi1>
    %3679 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3680 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3681 = stablehlo.select %3678, %3679, %3680 : tensor<512xi1>, tensor<512xf32>
    %3682 = stablehlo.divide %3676, %3681 : tensor<512xf32>
    %3683 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3684 = stablehlo.multiply %3683, %arg372 : tensor<512xf32>
    %3685 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3686 = stablehlo.multiply %3685, %3664 : tensor<512xf32>
    %3687 = stablehlo.add %3684, %3686 : tensor<512xf32>
    %3688 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3689 = stablehlo.multiply %3688, %arg373 : tensor<512xf32>
    %3690 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %3691 = stablehlo.multiply %3690, %3672 : tensor<512xf32>
    %3692 = stablehlo.add %3689, %3691 : tensor<512xf32>
    %3693 = stablehlo.broadcast_in_dim %3664, dims = [3] : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %3694 = stablehlo.broadcast_in_dim %3672, dims = [3] : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %3695 = stablehlo.convert %3646 : (tensor<256x7x7x512xf16>) -> tensor<256x7x7x512xf32>
    %3696 = stablehlo.broadcast_in_dim %3693, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x7x7x512xf32>
    %3697 = stablehlo.subtract %3695, %3696 : tensor<256x7x7x512xf32>
    %3698 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x512xf32>
    %3699 = stablehlo.add %3694, %3698 : tensor<1x1x1x512xf32>
    %3700 = stablehlo.rsqrt %3699 : tensor<1x1x1x512xf32>
    %3701 = stablehlo.divide %3700, %3699 : tensor<1x1x1x512xf32>
    %3702 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x512xf32>
    %3703 = stablehlo.multiply %3702, %3701 : tensor<1x1x1x512xf32>
    %3704 = stablehlo.reshape %arg73 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %3705 = stablehlo.multiply %3700, %3704 : tensor<1x1x1x512xf32>
    %3706 = stablehlo.broadcast_in_dim %3705, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x7x7x512xf32>
    %3707 = stablehlo.multiply %3697, %3706 : tensor<256x7x7x512xf32>
    %3708 = stablehlo.reshape %arg72 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %3709 = stablehlo.broadcast_in_dim %3708, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x7x7x512xf32>
    %3710 = stablehlo.add %3707, %3709 : tensor<256x7x7x512xf32>
    %3711 = stablehlo.convert %3710 : (tensor<256x7x7x512xf32>) -> tensor<256x7x7x512xf16>
    %3712 = call @relu_9(%3711) : (tensor<256x7x7x512xf16>) -> tensor<256x7x7x512xf16>
    %3713 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x7x7x512xf16>
    %3714 = stablehlo.compare  GT, %3711, %3713,  FLOAT : (tensor<256x7x7x512xf16>, tensor<256x7x7x512xf16>) -> tensor<256x7x7x512xi1>
    %3715 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x7x7x512xf16>
    %3716 = stablehlo.convert %arg78 : (tensor<1x1x512x2048xf32>) -> tensor<1x1x512x2048xf16>
    %3717 = stablehlo.convolution(%3712, %3716) dim_numbers = [b, 0, 1, f]x[0, 1, i, o]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x7x7x512xf16>, tensor<1x1x512x2048xf16>) -> tensor<256x7x7x2048xf16>
    %3718 = stablehlo.convert %3717 : (tensor<256x7x7x2048xf16>) -> tensor<256x7x7x2048xf32>
    %3719 = stablehlo.multiply %3718, %3718 : tensor<256x7x7x2048xf32>
    %3720 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<256x7x7x2048xf32>
    %3721 = stablehlo.multiply %3720, %3718 : tensor<256x7x7x2048xf32>
    %cst_126 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3722 = stablehlo.reduce(%3718 init: %cst_126) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %3723 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3724 = stablehlo.divide %3722, %3723 : tensor<2048xf32>
    %cst_127 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3725 = stablehlo.reduce(%3719 init: %cst_127) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %3726 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3727 = stablehlo.divide %3725, %3726 : tensor<2048xf32>
    %3728 = stablehlo.broadcast_in_dim %3724, dims = [1] : (tensor<2048xf32>) -> tensor<1x2048xf32>
    %3729 = stablehlo.broadcast_in_dim %3727, dims = [1] : (tensor<2048xf32>) -> tensor<1x2048xf32>
    %3730 = stablehlo.concatenate %3728, %3729, dim = 0 : (tensor<1x2048xf32>, tensor<1x2048xf32>) -> tensor<2x2048xf32>
    %3731 = "stablehlo.all_reduce"(%3730) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x2048xf32>) -> tensor<2x2048xf32>
    %3732 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x2048xf32>
    %3733 = stablehlo.divide %3731, %3732 : tensor<2x2048xf32>
    %3734 = stablehlo.slice %3733 [0:1, 0:2048] : (tensor<2x2048xf32>) -> tensor<1x2048xf32>
    %3735 = stablehlo.reshape %3734 : (tensor<1x2048xf32>) -> tensor<2048xf32>
    %3736 = stablehlo.slice %3733 [1:2, 0:2048] : (tensor<2x2048xf32>) -> tensor<1x2048xf32>
    %3737 = stablehlo.reshape %3736 : (tensor<1x2048xf32>) -> tensor<2048xf32>
    %3738 = stablehlo.multiply %3735, %3735 : tensor<2048xf32>
    %3739 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3740 = stablehlo.multiply %3739, %3735 : tensor<2048xf32>
    %3741 = stablehlo.subtract %3737, %3738 : tensor<2048xf32>
    %3742 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3743 = stablehlo.maximum %3742, %3741 : tensor<2048xf32>
    %3744 = stablehlo.compare  EQ, %3741, %3743,  FLOAT : (tensor<2048xf32>, tensor<2048xf32>) -> tensor<2048xi1>
    %3745 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3746 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3747 = stablehlo.select %3744, %3745, %3746 : tensor<2048xi1>, tensor<2048xf32>
    %3748 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3749 = stablehlo.compare  EQ, %3748, %3743,  FLOAT : (tensor<2048xf32>, tensor<2048xf32>) -> tensor<2048xi1>
    %3750 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3751 = stablehlo.broadcast_in_dim %cst_13, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3752 = stablehlo.select %3749, %3750, %3751 : tensor<2048xi1>, tensor<2048xf32>
    %3753 = stablehlo.divide %3747, %3752 : tensor<2048xf32>
    %3754 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3755 = stablehlo.multiply %3754, %arg374 : tensor<2048xf32>
    %3756 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3757 = stablehlo.multiply %3756, %3735 : tensor<2048xf32>
    %3758 = stablehlo.add %3755, %3757 : tensor<2048xf32>
    %3759 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3760 = stablehlo.multiply %3759, %arg375 : tensor<2048xf32>
    %3761 = stablehlo.broadcast_in_dim %cst_15, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %3762 = stablehlo.multiply %3761, %3743 : tensor<2048xf32>
    %3763 = stablehlo.add %3760, %3762 : tensor<2048xf32>
    %3764 = stablehlo.broadcast_in_dim %3735, dims = [3] : (tensor<2048xf32>) -> tensor<1x1x1x2048xf32>
    %3765 = stablehlo.broadcast_in_dim %3743, dims = [3] : (tensor<2048xf32>) -> tensor<1x1x1x2048xf32>
    %3766 = stablehlo.convert %3717 : (tensor<256x7x7x2048xf16>) -> tensor<256x7x7x2048xf32>
    %3767 = stablehlo.broadcast_in_dim %3764, dims = [0, 1, 2, 3] : (tensor<1x1x1x2048xf32>) -> tensor<256x7x7x2048xf32>
    %3768 = stablehlo.subtract %3766, %3767 : tensor<256x7x7x2048xf32>
    %3769 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<1x1x1x2048xf32>
    %3770 = stablehlo.add %3765, %3769 : tensor<1x1x1x2048xf32>
    %3771 = stablehlo.rsqrt %3770 : tensor<1x1x1x2048xf32>
    %3772 = stablehlo.divide %3771, %3770 : tensor<1x1x1x2048xf32>
    %3773 = stablehlo.broadcast_in_dim %cst_17, dims = [] : (tensor<f32>) -> tensor<1x1x1x2048xf32>
    %3774 = stablehlo.multiply %3773, %3772 : tensor<1x1x1x2048xf32>
    %3775 = stablehlo.reshape %arg75 : (tensor<2048xf32>) -> tensor<1x1x1x2048xf32>
    %3776 = stablehlo.multiply %3771, %3775 : tensor<1x1x1x2048xf32>
    %3777 = stablehlo.broadcast_in_dim %3776, dims = [0, 1, 2, 3] : (tensor<1x1x1x2048xf32>) -> tensor<256x7x7x2048xf32>
    %3778 = stablehlo.multiply %3768, %3777 : tensor<256x7x7x2048xf32>
    %3779 = stablehlo.reshape %arg74 : (tensor<2048xf32>) -> tensor<1x1x1x2048xf32>
    %3780 = stablehlo.broadcast_in_dim %3779, dims = [0, 1, 2, 3] : (tensor<1x1x1x2048xf32>) -> tensor<256x7x7x2048xf32>
    %3781 = stablehlo.add %3778, %3780 : tensor<256x7x7x2048xf32>
    %3782 = stablehlo.convert %3781 : (tensor<256x7x7x2048xf32>) -> tensor<256x7x7x2048xf16>
    %3783 = stablehlo.add %3570, %3782 : tensor<256x7x7x2048xf16>
    %3784 = call @relu_10(%3783) : (tensor<256x7x7x2048xf16>) -> tensor<256x7x7x2048xf16>
    %3785 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x7x7x2048xf16>
    %3786 = stablehlo.compare  GT, %3783, %3785,  FLOAT : (tensor<256x7x7x2048xf16>, tensor<256x7x7x2048xf16>) -> tensor<256x7x7x2048xi1>
    %3787 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x7x7x2048xf16>
    %3788 = stablehlo.convert %3784 : (tensor<256x7x7x2048xf16>) -> tensor<256x7x7x2048xf32>
    %cst_128 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3789 = stablehlo.reduce(%3788 init: %cst_128) applies stablehlo.add across dimensions = [1, 2] : (tensor<256x7x7x2048xf32>, tensor<f32>) -> tensor<256x2048xf32>
    %cst_129 = stablehlo.constant dense<4.900000e+01> : tensor<f32>
    %3790 = stablehlo.broadcast_in_dim %cst_129, dims = [] : (tensor<f32>) -> tensor<256x2048xf32>
    %3791 = stablehlo.divide %3789, %3790 : tensor<256x2048xf32>
    %3792 = stablehlo.convert %3791 : (tensor<256x2048xf32>) -> tensor<256x2048xf16>
    %3793 = stablehlo.convert %arg158 : (tensor<2048x1000xf32>) -> tensor<2048x1000xf16>
    %3794 = stablehlo.convert %arg157 : (tensor<1000xf32>) -> tensor<1000xf16>
    %3795 = stablehlo.dot_general %3792, %3793, contracting_dims = [1] x [0], precision = [DEFAULT, DEFAULT] : (tensor<256x2048xf16>, tensor<2048x1000xf16>) -> tensor<256x1000xf16>
    %3796 = stablehlo.reshape %3794 : (tensor<1000xf16>) -> tensor<1x1000xf16>
    %3797 = stablehlo.broadcast_in_dim %3796, dims = [0, 1] : (tensor<1x1000xf16>) -> tensor<256x1000xf16>
    %3798 = stablehlo.add %3795, %3797 : tensor<256x1000xf16>
    %3799 = stablehlo.broadcast_in_dim %1, dims = [0] : (tensor<256xi32>) -> tensor<256x1xi32>
    %3800 = stablehlo.iota dim = 0 : tensor<1000xi32>
    %3801 = stablehlo.reshape %3800 : (tensor<1000xi32>) -> tensor<1x1000xi32>
    %3802 = stablehlo.broadcast_in_dim %3799, dims = [0, 1] : (tensor<256x1xi32>) -> tensor<256x1000xi32>
    %3803 = stablehlo.broadcast_in_dim %3801, dims = [0, 1] : (tensor<1x1000xi32>) -> tensor<256x1000xi32>
    %3804 = stablehlo.compare  EQ, %3802, %3803,  SIGNED : (tensor<256x1000xi32>, tensor<256x1000xi32>) -> tensor<256x1000xi1>
    %3805 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<256x1000xf32>
    %3806 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<f32>) -> tensor<256x1000xf32>
    %3807 = stablehlo.select %3804, %3805, %3806 : tensor<256x1000xi1>, tensor<256x1000xf32>
    %3808 = stablehlo.convert %3807 : tensor<256x1000xf32>
    %3809:3 = call @log_softmax(%3798) : (tensor<256x1000xf16>) -> (tensor<256x1000xf16>, tensor<256x1000xf16>, tensor<256x1xf16>)
    %3810 = stablehlo.convert %3809#0 : (tensor<256x1000xf16>) -> tensor<256x1000xf32>
    %3811 = stablehlo.multiply %3808, %3810 : tensor<256x1000xf32>
    %cst_130 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3812 = stablehlo.reduce(%3811 init: %cst_130) applies stablehlo.add across dimensions = [1] : (tensor<256x1000xf32>, tensor<f32>) -> tensor<256xf32>
    %3813 = stablehlo.negate %3812 : tensor<256xf32>
    %cst_131 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3814 = stablehlo.reduce(%3813 init: %cst_131) applies stablehlo.add across dimensions = [0] : (tensor<256xf32>, tensor<f32>) -> tensor<f32>
    %cst_132 = stablehlo.constant dense<2.560000e+02> : tensor<f32>
    %3815 = stablehlo.divide %3814, %cst_132 : tensor<f32>
    %3816 = stablehlo.multiply %arg7, %arg7 : tensor<1x1x64x64xf32>
    %3817 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x64x64xf32>
    %3818 = stablehlo.multiply %3817, %arg7 : tensor<1x1x64x64xf32>
    %cst_133 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3819 = stablehlo.reduce(%3816 init: %cst_133) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x64x64xf32>, tensor<f32>) -> tensor<f32>
    %3820 = stablehlo.add %cst_12, %3819 : tensor<f32>
    %3821 = stablehlo.multiply %arg8, %arg8 : tensor<3x3x64x64xf32>
    %3822 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<3x3x64x64xf32>
    %3823 = stablehlo.multiply %3822, %arg8 : tensor<3x3x64x64xf32>
    %cst_134 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3824 = stablehlo.reduce(%3821 init: %cst_134) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<3x3x64x64xf32>, tensor<f32>) -> tensor<f32>
    %3825 = stablehlo.add %3820, %3824 : tensor<f32>
    %3826 = stablehlo.multiply %arg9, %arg9 : tensor<1x1x64x256xf32>
    %3827 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x64x256xf32>
    %3828 = stablehlo.multiply %3827, %arg9 : tensor<1x1x64x256xf32>
    %cst_135 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3829 = stablehlo.reduce(%3826 init: %cst_135) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x64x256xf32>, tensor<f32>) -> tensor<f32>
    %3830 = stablehlo.add %3825, %3829 : tensor<f32>
    %3831 = stablehlo.multiply %arg10, %arg10 : tensor<1x1x64x256xf32>
    %3832 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x64x256xf32>
    %3833 = stablehlo.multiply %3832, %arg10 : tensor<1x1x64x256xf32>
    %cst_136 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3834 = stablehlo.reduce(%3831 init: %cst_136) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x64x256xf32>, tensor<f32>) -> tensor<f32>
    %3835 = stablehlo.add %3830, %3834 : tensor<f32>
    %3836 = stablehlo.multiply %arg19, %arg19 : tensor<1x1x256x64xf32>
    %3837 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x256x64xf32>
    %3838 = stablehlo.multiply %3837, %arg19 : tensor<1x1x256x64xf32>
    %cst_137 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3839 = stablehlo.reduce(%3836 init: %cst_137) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x256x64xf32>, tensor<f32>) -> tensor<f32>
    %3840 = stablehlo.add %3835, %3839 : tensor<f32>
    %3841 = stablehlo.multiply %arg20, %arg20 : tensor<3x3x64x64xf32>
    %3842 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<3x3x64x64xf32>
    %3843 = stablehlo.multiply %3842, %arg20 : tensor<3x3x64x64xf32>
    %cst_138 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3844 = stablehlo.reduce(%3841 init: %cst_138) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<3x3x64x64xf32>, tensor<f32>) -> tensor<f32>
    %3845 = stablehlo.add %3840, %3844 : tensor<f32>
    %3846 = stablehlo.multiply %arg21, %arg21 : tensor<1x1x64x256xf32>
    %3847 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x64x256xf32>
    %3848 = stablehlo.multiply %3847, %arg21 : tensor<1x1x64x256xf32>
    %cst_139 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3849 = stablehlo.reduce(%3846 init: %cst_139) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x64x256xf32>, tensor<f32>) -> tensor<f32>
    %3850 = stablehlo.add %3845, %3849 : tensor<f32>
    %3851 = stablehlo.multiply %arg28, %arg28 : tensor<1x1x1024x256xf32>
    %3852 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x1024x256xf32>
    %3853 = stablehlo.multiply %3852, %arg28 : tensor<1x1x1024x256xf32>
    %cst_140 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3854 = stablehlo.reduce(%3851 init: %cst_140) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x1024x256xf32>, tensor<f32>) -> tensor<f32>
    %3855 = stablehlo.add %3850, %3854 : tensor<f32>
    %3856 = stablehlo.multiply %arg29, %arg29 : tensor<3x3x256x256xf32>
    %3857 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %3858 = stablehlo.multiply %3857, %arg29 : tensor<3x3x256x256xf32>
    %cst_141 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3859 = stablehlo.reduce(%3856 init: %cst_141) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<3x3x256x256xf32>, tensor<f32>) -> tensor<f32>
    %3860 = stablehlo.add %3855, %3859 : tensor<f32>
    %3861 = stablehlo.multiply %arg30, %arg30 : tensor<1x1x256x1024xf32>
    %3862 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %3863 = stablehlo.multiply %3862, %arg30 : tensor<1x1x256x1024xf32>
    %cst_142 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3864 = stablehlo.reduce(%3861 init: %cst_142) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x256x1024xf32>, tensor<f32>) -> tensor<f32>
    %3865 = stablehlo.add %3860, %3864 : tensor<f32>
    %3866 = stablehlo.multiply %arg37, %arg37 : tensor<1x1x1024x256xf32>
    %3867 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x1024x256xf32>
    %3868 = stablehlo.multiply %3867, %arg37 : tensor<1x1x1024x256xf32>
    %cst_143 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3869 = stablehlo.reduce(%3866 init: %cst_143) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x1024x256xf32>, tensor<f32>) -> tensor<f32>
    %3870 = stablehlo.add %3865, %3869 : tensor<f32>
    %3871 = stablehlo.multiply %arg38, %arg38 : tensor<3x3x256x256xf32>
    %3872 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %3873 = stablehlo.multiply %3872, %arg38 : tensor<3x3x256x256xf32>
    %cst_144 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3874 = stablehlo.reduce(%3871 init: %cst_144) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<3x3x256x256xf32>, tensor<f32>) -> tensor<f32>
    %3875 = stablehlo.add %3870, %3874 : tensor<f32>
    %3876 = stablehlo.multiply %arg39, %arg39 : tensor<1x1x256x1024xf32>
    %3877 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %3878 = stablehlo.multiply %3877, %arg39 : tensor<1x1x256x1024xf32>
    %cst_145 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3879 = stablehlo.reduce(%3876 init: %cst_145) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x256x1024xf32>, tensor<f32>) -> tensor<f32>
    %3880 = stablehlo.add %3875, %3879 : tensor<f32>
    %3881 = stablehlo.multiply %arg46, %arg46 : tensor<1x1x1024x256xf32>
    %3882 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x1024x256xf32>
    %3883 = stablehlo.multiply %3882, %arg46 : tensor<1x1x1024x256xf32>
    %cst_146 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3884 = stablehlo.reduce(%3881 init: %cst_146) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x1024x256xf32>, tensor<f32>) -> tensor<f32>
    %3885 = stablehlo.add %3880, %3884 : tensor<f32>
    %3886 = stablehlo.multiply %arg47, %arg47 : tensor<3x3x256x256xf32>
    %3887 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %3888 = stablehlo.multiply %3887, %arg47 : tensor<3x3x256x256xf32>
    %cst_147 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3889 = stablehlo.reduce(%3886 init: %cst_147) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<3x3x256x256xf32>, tensor<f32>) -> tensor<f32>
    %3890 = stablehlo.add %3885, %3889 : tensor<f32>
    %3891 = stablehlo.multiply %arg48, %arg48 : tensor<1x1x256x1024xf32>
    %3892 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %3893 = stablehlo.multiply %3892, %arg48 : tensor<1x1x256x1024xf32>
    %cst_148 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3894 = stablehlo.reduce(%3891 init: %cst_148) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x256x1024xf32>, tensor<f32>) -> tensor<f32>
    %3895 = stablehlo.add %3890, %3894 : tensor<f32>
    %3896 = stablehlo.multiply %arg55, %arg55 : tensor<1x1x1024x512xf32>
    %3897 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x1024x512xf32>
    %3898 = stablehlo.multiply %3897, %arg55 : tensor<1x1x1024x512xf32>
    %cst_149 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3899 = stablehlo.reduce(%3896 init: %cst_149) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x1024x512xf32>, tensor<f32>) -> tensor<f32>
    %3900 = stablehlo.add %3895, %3899 : tensor<f32>
    %3901 = stablehlo.multiply %arg56, %arg56 : tensor<3x3x512x512xf32>
    %3902 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<3x3x512x512xf32>
    %3903 = stablehlo.multiply %3902, %arg56 : tensor<3x3x512x512xf32>
    %cst_150 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3904 = stablehlo.reduce(%3901 init: %cst_150) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<3x3x512x512xf32>, tensor<f32>) -> tensor<f32>
    %3905 = stablehlo.add %3900, %3904 : tensor<f32>
    %3906 = stablehlo.multiply %arg57, %arg57 : tensor<1x1x512x2048xf32>
    %3907 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x512x2048xf32>
    %3908 = stablehlo.multiply %3907, %arg57 : tensor<1x1x512x2048xf32>
    %cst_151 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3909 = stablehlo.reduce(%3906 init: %cst_151) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x512x2048xf32>, tensor<f32>) -> tensor<f32>
    %3910 = stablehlo.add %3905, %3909 : tensor<f32>
    %3911 = stablehlo.multiply %arg58, %arg58 : tensor<1x1x1024x2048xf32>
    %3912 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x1024x2048xf32>
    %3913 = stablehlo.multiply %3912, %arg58 : tensor<1x1x1024x2048xf32>
    %cst_152 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3914 = stablehlo.reduce(%3911 init: %cst_152) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x1024x2048xf32>, tensor<f32>) -> tensor<f32>
    %3915 = stablehlo.add %3910, %3914 : tensor<f32>
    %3916 = stablehlo.multiply %arg67, %arg67 : tensor<1x1x2048x512xf32>
    %3917 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x2048x512xf32>
    %3918 = stablehlo.multiply %3917, %arg67 : tensor<1x1x2048x512xf32>
    %cst_153 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3919 = stablehlo.reduce(%3916 init: %cst_153) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x2048x512xf32>, tensor<f32>) -> tensor<f32>
    %3920 = stablehlo.add %3915, %3919 : tensor<f32>
    %3921 = stablehlo.multiply %arg68, %arg68 : tensor<3x3x512x512xf32>
    %3922 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<3x3x512x512xf32>
    %3923 = stablehlo.multiply %3922, %arg68 : tensor<3x3x512x512xf32>
    %cst_154 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3924 = stablehlo.reduce(%3921 init: %cst_154) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<3x3x512x512xf32>, tensor<f32>) -> tensor<f32>
    %3925 = stablehlo.add %3920, %3924 : tensor<f32>
    %3926 = stablehlo.multiply %arg69, %arg69 : tensor<1x1x512x2048xf32>
    %3927 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x512x2048xf32>
    %3928 = stablehlo.multiply %3927, %arg69 : tensor<1x1x512x2048xf32>
    %cst_155 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3929 = stablehlo.reduce(%3926 init: %cst_155) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x512x2048xf32>, tensor<f32>) -> tensor<f32>
    %3930 = stablehlo.add %3925, %3929 : tensor<f32>
    %3931 = stablehlo.multiply %arg76, %arg76 : tensor<1x1x2048x512xf32>
    %3932 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x2048x512xf32>
    %3933 = stablehlo.multiply %3932, %arg76 : tensor<1x1x2048x512xf32>
    %cst_156 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3934 = stablehlo.reduce(%3931 init: %cst_156) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x2048x512xf32>, tensor<f32>) -> tensor<f32>
    %3935 = stablehlo.add %3930, %3934 : tensor<f32>
    %3936 = stablehlo.multiply %arg77, %arg77 : tensor<3x3x512x512xf32>
    %3937 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<3x3x512x512xf32>
    %3938 = stablehlo.multiply %3937, %arg77 : tensor<3x3x512x512xf32>
    %cst_157 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3939 = stablehlo.reduce(%3936 init: %cst_157) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<3x3x512x512xf32>, tensor<f32>) -> tensor<f32>
    %3940 = stablehlo.add %3935, %3939 : tensor<f32>
    %3941 = stablehlo.multiply %arg78, %arg78 : tensor<1x1x512x2048xf32>
    %3942 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x512x2048xf32>
    %3943 = stablehlo.multiply %3942, %arg78 : tensor<1x1x512x2048xf32>
    %cst_158 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3944 = stablehlo.reduce(%3941 init: %cst_158) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x512x2048xf32>, tensor<f32>) -> tensor<f32>
    %3945 = stablehlo.add %3940, %3944 : tensor<f32>
    %3946 = stablehlo.multiply %arg85, %arg85 : tensor<1x1x256x64xf32>
    %3947 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x256x64xf32>
    %3948 = stablehlo.multiply %3947, %arg85 : tensor<1x1x256x64xf32>
    %cst_159 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3949 = stablehlo.reduce(%3946 init: %cst_159) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x256x64xf32>, tensor<f32>) -> tensor<f32>
    %3950 = stablehlo.add %3945, %3949 : tensor<f32>
    %3951 = stablehlo.multiply %arg86, %arg86 : tensor<3x3x64x64xf32>
    %3952 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<3x3x64x64xf32>
    %3953 = stablehlo.multiply %3952, %arg86 : tensor<3x3x64x64xf32>
    %cst_160 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3954 = stablehlo.reduce(%3951 init: %cst_160) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<3x3x64x64xf32>, tensor<f32>) -> tensor<f32>
    %3955 = stablehlo.add %3950, %3954 : tensor<f32>
    %3956 = stablehlo.multiply %arg87, %arg87 : tensor<1x1x64x256xf32>
    %3957 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x64x256xf32>
    %3958 = stablehlo.multiply %3957, %arg87 : tensor<1x1x64x256xf32>
    %cst_161 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3959 = stablehlo.reduce(%3956 init: %cst_161) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x64x256xf32>, tensor<f32>) -> tensor<f32>
    %3960 = stablehlo.add %3955, %3959 : tensor<f32>
    %3961 = stablehlo.multiply %arg94, %arg94 : tensor<1x1x256x128xf32>
    %3962 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x256x128xf32>
    %3963 = stablehlo.multiply %3962, %arg94 : tensor<1x1x256x128xf32>
    %cst_162 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3964 = stablehlo.reduce(%3961 init: %cst_162) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x256x128xf32>, tensor<f32>) -> tensor<f32>
    %3965 = stablehlo.add %3960, %3964 : tensor<f32>
    %3966 = stablehlo.multiply %arg95, %arg95 : tensor<3x3x128x128xf32>
    %3967 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<3x3x128x128xf32>
    %3968 = stablehlo.multiply %3967, %arg95 : tensor<3x3x128x128xf32>
    %cst_163 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3969 = stablehlo.reduce(%3966 init: %cst_163) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<3x3x128x128xf32>, tensor<f32>) -> tensor<f32>
    %3970 = stablehlo.add %3965, %3969 : tensor<f32>
    %3971 = stablehlo.multiply %arg96, %arg96 : tensor<1x1x128x512xf32>
    %3972 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x128x512xf32>
    %3973 = stablehlo.multiply %3972, %arg96 : tensor<1x1x128x512xf32>
    %cst_164 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3974 = stablehlo.reduce(%3971 init: %cst_164) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x128x512xf32>, tensor<f32>) -> tensor<f32>
    %3975 = stablehlo.add %3970, %3974 : tensor<f32>
    %3976 = stablehlo.multiply %arg97, %arg97 : tensor<1x1x256x512xf32>
    %3977 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x256x512xf32>
    %3978 = stablehlo.multiply %3977, %arg97 : tensor<1x1x256x512xf32>
    %cst_165 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3979 = stablehlo.reduce(%3976 init: %cst_165) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x256x512xf32>, tensor<f32>) -> tensor<f32>
    %3980 = stablehlo.add %3975, %3979 : tensor<f32>
    %3981 = stablehlo.multiply %arg106, %arg106 : tensor<1x1x512x128xf32>
    %3982 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x512x128xf32>
    %3983 = stablehlo.multiply %3982, %arg106 : tensor<1x1x512x128xf32>
    %cst_166 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3984 = stablehlo.reduce(%3981 init: %cst_166) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x512x128xf32>, tensor<f32>) -> tensor<f32>
    %3985 = stablehlo.add %3980, %3984 : tensor<f32>
    %3986 = stablehlo.multiply %arg107, %arg107 : tensor<3x3x128x128xf32>
    %3987 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<3x3x128x128xf32>
    %3988 = stablehlo.multiply %3987, %arg107 : tensor<3x3x128x128xf32>
    %cst_167 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3989 = stablehlo.reduce(%3986 init: %cst_167) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<3x3x128x128xf32>, tensor<f32>) -> tensor<f32>
    %3990 = stablehlo.add %3985, %3989 : tensor<f32>
    %3991 = stablehlo.multiply %arg108, %arg108 : tensor<1x1x128x512xf32>
    %3992 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x128x512xf32>
    %3993 = stablehlo.multiply %3992, %arg108 : tensor<1x1x128x512xf32>
    %cst_168 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3994 = stablehlo.reduce(%3991 init: %cst_168) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x128x512xf32>, tensor<f32>) -> tensor<f32>
    %3995 = stablehlo.add %3990, %3994 : tensor<f32>
    %3996 = stablehlo.multiply %arg115, %arg115 : tensor<1x1x512x128xf32>
    %3997 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x512x128xf32>
    %3998 = stablehlo.multiply %3997, %arg115 : tensor<1x1x512x128xf32>
    %cst_169 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3999 = stablehlo.reduce(%3996 init: %cst_169) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x512x128xf32>, tensor<f32>) -> tensor<f32>
    %4000 = stablehlo.add %3995, %3999 : tensor<f32>
    %4001 = stablehlo.multiply %arg116, %arg116 : tensor<3x3x128x128xf32>
    %4002 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<3x3x128x128xf32>
    %4003 = stablehlo.multiply %4002, %arg116 : tensor<3x3x128x128xf32>
    %cst_170 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4004 = stablehlo.reduce(%4001 init: %cst_170) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<3x3x128x128xf32>, tensor<f32>) -> tensor<f32>
    %4005 = stablehlo.add %4000, %4004 : tensor<f32>
    %4006 = stablehlo.multiply %arg117, %arg117 : tensor<1x1x128x512xf32>
    %4007 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x128x512xf32>
    %4008 = stablehlo.multiply %4007, %arg117 : tensor<1x1x128x512xf32>
    %cst_171 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4009 = stablehlo.reduce(%4006 init: %cst_171) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x128x512xf32>, tensor<f32>) -> tensor<f32>
    %4010 = stablehlo.add %4005, %4009 : tensor<f32>
    %4011 = stablehlo.multiply %arg124, %arg124 : tensor<1x1x512x128xf32>
    %4012 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x512x128xf32>
    %4013 = stablehlo.multiply %4012, %arg124 : tensor<1x1x512x128xf32>
    %cst_172 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4014 = stablehlo.reduce(%4011 init: %cst_172) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x512x128xf32>, tensor<f32>) -> tensor<f32>
    %4015 = stablehlo.add %4010, %4014 : tensor<f32>
    %4016 = stablehlo.multiply %arg125, %arg125 : tensor<3x3x128x128xf32>
    %4017 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<3x3x128x128xf32>
    %4018 = stablehlo.multiply %4017, %arg125 : tensor<3x3x128x128xf32>
    %cst_173 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4019 = stablehlo.reduce(%4016 init: %cst_173) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<3x3x128x128xf32>, tensor<f32>) -> tensor<f32>
    %4020 = stablehlo.add %4015, %4019 : tensor<f32>
    %4021 = stablehlo.multiply %arg126, %arg126 : tensor<1x1x128x512xf32>
    %4022 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x128x512xf32>
    %4023 = stablehlo.multiply %4022, %arg126 : tensor<1x1x128x512xf32>
    %cst_174 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4024 = stablehlo.reduce(%4021 init: %cst_174) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x128x512xf32>, tensor<f32>) -> tensor<f32>
    %4025 = stablehlo.add %4020, %4024 : tensor<f32>
    %4026 = stablehlo.multiply %arg133, %arg133 : tensor<1x1x512x256xf32>
    %4027 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x512x256xf32>
    %4028 = stablehlo.multiply %4027, %arg133 : tensor<1x1x512x256xf32>
    %cst_175 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4029 = stablehlo.reduce(%4026 init: %cst_175) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x512x256xf32>, tensor<f32>) -> tensor<f32>
    %4030 = stablehlo.add %4025, %4029 : tensor<f32>
    %4031 = stablehlo.multiply %arg134, %arg134 : tensor<3x3x256x256xf32>
    %4032 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %4033 = stablehlo.multiply %4032, %arg134 : tensor<3x3x256x256xf32>
    %cst_176 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4034 = stablehlo.reduce(%4031 init: %cst_176) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<3x3x256x256xf32>, tensor<f32>) -> tensor<f32>
    %4035 = stablehlo.add %4030, %4034 : tensor<f32>
    %4036 = stablehlo.multiply %arg135, %arg135 : tensor<1x1x256x1024xf32>
    %4037 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %4038 = stablehlo.multiply %4037, %arg135 : tensor<1x1x256x1024xf32>
    %cst_177 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4039 = stablehlo.reduce(%4036 init: %cst_177) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x256x1024xf32>, tensor<f32>) -> tensor<f32>
    %4040 = stablehlo.add %4035, %4039 : tensor<f32>
    %4041 = stablehlo.multiply %arg136, %arg136 : tensor<1x1x512x1024xf32>
    %4042 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x512x1024xf32>
    %4043 = stablehlo.multiply %4042, %arg136 : tensor<1x1x512x1024xf32>
    %cst_178 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4044 = stablehlo.reduce(%4041 init: %cst_178) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x512x1024xf32>, tensor<f32>) -> tensor<f32>
    %4045 = stablehlo.add %4040, %4044 : tensor<f32>
    %4046 = stablehlo.multiply %arg145, %arg145 : tensor<1x1x1024x256xf32>
    %4047 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x1024x256xf32>
    %4048 = stablehlo.multiply %4047, %arg145 : tensor<1x1x1024x256xf32>
    %cst_179 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4049 = stablehlo.reduce(%4046 init: %cst_179) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x1024x256xf32>, tensor<f32>) -> tensor<f32>
    %4050 = stablehlo.add %4045, %4049 : tensor<f32>
    %4051 = stablehlo.multiply %arg146, %arg146 : tensor<3x3x256x256xf32>
    %4052 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %4053 = stablehlo.multiply %4052, %arg146 : tensor<3x3x256x256xf32>
    %cst_180 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4054 = stablehlo.reduce(%4051 init: %cst_180) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<3x3x256x256xf32>, tensor<f32>) -> tensor<f32>
    %4055 = stablehlo.add %4050, %4054 : tensor<f32>
    %4056 = stablehlo.multiply %arg147, %arg147 : tensor<1x1x256x1024xf32>
    %4057 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %4058 = stablehlo.multiply %4057, %arg147 : tensor<1x1x256x1024xf32>
    %cst_181 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4059 = stablehlo.reduce(%4056 init: %cst_181) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x256x1024xf32>, tensor<f32>) -> tensor<f32>
    %4060 = stablehlo.add %4055, %4059 : tensor<f32>
    %4061 = stablehlo.multiply %arg154, %arg154 : tensor<1x1x1024x256xf32>
    %4062 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x1024x256xf32>
    %4063 = stablehlo.multiply %4062, %arg154 : tensor<1x1x1024x256xf32>
    %cst_182 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4064 = stablehlo.reduce(%4061 init: %cst_182) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x1024x256xf32>, tensor<f32>) -> tensor<f32>
    %4065 = stablehlo.add %4060, %4064 : tensor<f32>
    %4066 = stablehlo.multiply %arg155, %arg155 : tensor<3x3x256x256xf32>
    %4067 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %4068 = stablehlo.multiply %4067, %arg155 : tensor<3x3x256x256xf32>
    %cst_183 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4069 = stablehlo.reduce(%4066 init: %cst_183) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<3x3x256x256xf32>, tensor<f32>) -> tensor<f32>
    %4070 = stablehlo.add %4065, %4069 : tensor<f32>
    %4071 = stablehlo.multiply %arg156, %arg156 : tensor<1x1x256x1024xf32>
    %4072 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %4073 = stablehlo.multiply %4072, %arg156 : tensor<1x1x256x1024xf32>
    %cst_184 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4074 = stablehlo.reduce(%4071 init: %cst_184) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<1x1x256x1024xf32>, tensor<f32>) -> tensor<f32>
    %4075 = stablehlo.add %4070, %4074 : tensor<f32>
    %4076 = stablehlo.multiply %arg158, %arg158 : tensor<2048x1000xf32>
    %4077 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<2048x1000xf32>
    %4078 = stablehlo.multiply %4077, %arg158 : tensor<2048x1000xf32>
    %cst_185 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4079 = stablehlo.reduce(%4076 init: %cst_185) applies stablehlo.add across dimensions = [0, 1] : (tensor<2048x1000xf32>, tensor<f32>) -> tensor<f32>
    %4080 = stablehlo.add %4075, %4079 : tensor<f32>
    %4081 = stablehlo.multiply %arg161, %arg161 : tensor<7x7x3x64xf32>
    %4082 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<7x7x3x64xf32>
    %4083 = stablehlo.multiply %4082, %arg161 : tensor<7x7x3x64xf32>
    %cst_186 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4084 = stablehlo.reduce(%4081 init: %cst_186) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<7x7x3x64xf32>, tensor<f32>) -> tensor<f32>
    %4085 = stablehlo.add %4080, %4084 : tensor<f32>
    %cst_187 = stablehlo.constant dense<5.000000e-05> : tensor<f32>
    %4086 = stablehlo.multiply %cst_187, %4085 : tensor<f32>
    %4087 = stablehlo.add %3815, %4086 : tensor<f32>
    %4088 = stablehlo.multiply %cst_187, %cst_13 : tensor<f32>
    %4089 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<7x7x3x64xf32>
    %4090 = stablehlo.multiply %4089, %4083 : tensor<7x7x3x64xf32>
    %4091 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<2048x1000xf32>
    %4092 = stablehlo.multiply %4091, %4078 : tensor<2048x1000xf32>
    %4093 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %4094 = stablehlo.multiply %4093, %4073 : tensor<1x1x256x1024xf32>
    %4095 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %4096 = stablehlo.multiply %4095, %4068 : tensor<3x3x256x256xf32>
    %4097 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x1024x256xf32>
    %4098 = stablehlo.multiply %4097, %4063 : tensor<1x1x1024x256xf32>
    %4099 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %4100 = stablehlo.multiply %4099, %4058 : tensor<1x1x256x1024xf32>
    %4101 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %4102 = stablehlo.multiply %4101, %4053 : tensor<3x3x256x256xf32>
    %4103 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x1024x256xf32>
    %4104 = stablehlo.multiply %4103, %4048 : tensor<1x1x1024x256xf32>
    %4105 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x512x1024xf32>
    %4106 = stablehlo.multiply %4105, %4043 : tensor<1x1x512x1024xf32>
    %4107 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %4108 = stablehlo.multiply %4107, %4038 : tensor<1x1x256x1024xf32>
    %4109 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %4110 = stablehlo.multiply %4109, %4033 : tensor<3x3x256x256xf32>
    %4111 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x512x256xf32>
    %4112 = stablehlo.multiply %4111, %4028 : tensor<1x1x512x256xf32>
    %4113 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x128x512xf32>
    %4114 = stablehlo.multiply %4113, %4023 : tensor<1x1x128x512xf32>
    %4115 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<3x3x128x128xf32>
    %4116 = stablehlo.multiply %4115, %4018 : tensor<3x3x128x128xf32>
    %4117 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x512x128xf32>
    %4118 = stablehlo.multiply %4117, %4013 : tensor<1x1x512x128xf32>
    %4119 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x128x512xf32>
    %4120 = stablehlo.multiply %4119, %4008 : tensor<1x1x128x512xf32>
    %4121 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<3x3x128x128xf32>
    %4122 = stablehlo.multiply %4121, %4003 : tensor<3x3x128x128xf32>
    %4123 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x512x128xf32>
    %4124 = stablehlo.multiply %4123, %3998 : tensor<1x1x512x128xf32>
    %4125 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x128x512xf32>
    %4126 = stablehlo.multiply %4125, %3993 : tensor<1x1x128x512xf32>
    %4127 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<3x3x128x128xf32>
    %4128 = stablehlo.multiply %4127, %3988 : tensor<3x3x128x128xf32>
    %4129 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x512x128xf32>
    %4130 = stablehlo.multiply %4129, %3983 : tensor<1x1x512x128xf32>
    %4131 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x256x512xf32>
    %4132 = stablehlo.multiply %4131, %3978 : tensor<1x1x256x512xf32>
    %4133 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x128x512xf32>
    %4134 = stablehlo.multiply %4133, %3973 : tensor<1x1x128x512xf32>
    %4135 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<3x3x128x128xf32>
    %4136 = stablehlo.multiply %4135, %3968 : tensor<3x3x128x128xf32>
    %4137 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x256x128xf32>
    %4138 = stablehlo.multiply %4137, %3963 : tensor<1x1x256x128xf32>
    %4139 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x64x256xf32>
    %4140 = stablehlo.multiply %4139, %3958 : tensor<1x1x64x256xf32>
    %4141 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<3x3x64x64xf32>
    %4142 = stablehlo.multiply %4141, %3953 : tensor<3x3x64x64xf32>
    %4143 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x256x64xf32>
    %4144 = stablehlo.multiply %4143, %3948 : tensor<1x1x256x64xf32>
    %4145 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x512x2048xf32>
    %4146 = stablehlo.multiply %4145, %3943 : tensor<1x1x512x2048xf32>
    %4147 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<3x3x512x512xf32>
    %4148 = stablehlo.multiply %4147, %3938 : tensor<3x3x512x512xf32>
    %4149 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x2048x512xf32>
    %4150 = stablehlo.multiply %4149, %3933 : tensor<1x1x2048x512xf32>
    %4151 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x512x2048xf32>
    %4152 = stablehlo.multiply %4151, %3928 : tensor<1x1x512x2048xf32>
    %4153 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<3x3x512x512xf32>
    %4154 = stablehlo.multiply %4153, %3923 : tensor<3x3x512x512xf32>
    %4155 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x2048x512xf32>
    %4156 = stablehlo.multiply %4155, %3918 : tensor<1x1x2048x512xf32>
    %4157 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x1024x2048xf32>
    %4158 = stablehlo.multiply %4157, %3913 : tensor<1x1x1024x2048xf32>
    %4159 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x512x2048xf32>
    %4160 = stablehlo.multiply %4159, %3908 : tensor<1x1x512x2048xf32>
    %4161 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<3x3x512x512xf32>
    %4162 = stablehlo.multiply %4161, %3903 : tensor<3x3x512x512xf32>
    %4163 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x1024x512xf32>
    %4164 = stablehlo.multiply %4163, %3898 : tensor<1x1x1024x512xf32>
    %4165 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %4166 = stablehlo.multiply %4165, %3893 : tensor<1x1x256x1024xf32>
    %4167 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %4168 = stablehlo.multiply %4167, %3888 : tensor<3x3x256x256xf32>
    %4169 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x1024x256xf32>
    %4170 = stablehlo.multiply %4169, %3883 : tensor<1x1x1024x256xf32>
    %4171 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %4172 = stablehlo.multiply %4171, %3878 : tensor<1x1x256x1024xf32>
    %4173 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %4174 = stablehlo.multiply %4173, %3873 : tensor<3x3x256x256xf32>
    %4175 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x1024x256xf32>
    %4176 = stablehlo.multiply %4175, %3868 : tensor<1x1x1024x256xf32>
    %4177 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %4178 = stablehlo.multiply %4177, %3863 : tensor<1x1x256x1024xf32>
    %4179 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %4180 = stablehlo.multiply %4179, %3858 : tensor<3x3x256x256xf32>
    %4181 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x1024x256xf32>
    %4182 = stablehlo.multiply %4181, %3853 : tensor<1x1x1024x256xf32>
    %4183 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x64x256xf32>
    %4184 = stablehlo.multiply %4183, %3848 : tensor<1x1x64x256xf32>
    %4185 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<3x3x64x64xf32>
    %4186 = stablehlo.multiply %4185, %3843 : tensor<3x3x64x64xf32>
    %4187 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x256x64xf32>
    %4188 = stablehlo.multiply %4187, %3838 : tensor<1x1x256x64xf32>
    %4189 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x64x256xf32>
    %4190 = stablehlo.multiply %4189, %3833 : tensor<1x1x64x256xf32>
    %4191 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x64x256xf32>
    %4192 = stablehlo.multiply %4191, %3828 : tensor<1x1x64x256xf32>
    %4193 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<3x3x64x64xf32>
    %4194 = stablehlo.multiply %4193, %3823 : tensor<3x3x64x64xf32>
    %4195 = stablehlo.broadcast_in_dim %4088, dims = [] : (tensor<f32>) -> tensor<1x1x64x64xf32>
    %4196 = stablehlo.multiply %4195, %3818 : tensor<1x1x64x64xf32>
    %4197 = stablehlo.divide %cst_13, %cst_132 : tensor<f32>
    %4198 = stablehlo.broadcast_in_dim %4197, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %4199 = stablehlo.negate %4198 : tensor<256xf32>
    %4200 = stablehlo.broadcast_in_dim %4199, dims = [0] : (tensor<256xf32>) -> tensor<256x1000xf32>
    %4201 = stablehlo.multiply %3808, %4200 : tensor<256x1000xf32>
    %4202 = stablehlo.convert %4201 : (tensor<256x1000xf32>) -> tensor<256x1000xf16>
    %4203 = call @log_softmax_11(%3809#1, %3809#2, %4202) : (tensor<256x1000xf16>, tensor<256x1xf16>, tensor<256x1000xf16>) -> tensor<256x1000xf16>
    %cst_188 = stablehlo.constant dense<0.000000e+00> : tensor<f16>
    %4204 = stablehlo.reduce(%4203 init: %cst_188) applies stablehlo.add across dimensions = [0] : (tensor<256x1000xf16>, tensor<f16>) -> tensor<1000xf16>
    %4205 = stablehlo.reshape %4204 : (tensor<1000xf16>) -> tensor<1x1000xf16>
    %4206 = stablehlo.reshape %4205 : (tensor<1x1000xf16>) -> tensor<1000xf16>
    %4207 = stablehlo.convert %4206 : (tensor<1000xf16>) -> tensor<1000xf32>
    %4208 = stablehlo.dot_general %4203, %3792, contracting_dims = [0] x [0], precision = [DEFAULT, DEFAULT] : (tensor<256x1000xf16>, tensor<256x2048xf16>) -> tensor<1000x2048xf16>
    %4209 = stablehlo.transpose %4208, dims = [1, 0] : (tensor<1000x2048xf16>) -> tensor<2048x1000xf16>
    %4210 = stablehlo.convert %4209 : (tensor<2048x1000xf16>) -> tensor<2048x1000xf32>
    %4211 = stablehlo.add %4092, %4210 : tensor<2048x1000xf32>
    %4212 = stablehlo.dot_general %4203, %3793, contracting_dims = [1] x [1], precision = [DEFAULT, DEFAULT] : (tensor<256x1000xf16>, tensor<2048x1000xf16>) -> tensor<256x2048xf16>
    %4213 = stablehlo.convert %4212 : (tensor<256x2048xf16>) -> tensor<256x2048xf32>
    %4214 = stablehlo.broadcast_in_dim %cst_129, dims = [] : (tensor<f32>) -> tensor<256x2048xf32>
    %4215 = stablehlo.divide %4213, %4214 : tensor<256x2048xf32>
    %4216 = stablehlo.broadcast_in_dim %4215, dims = [0, 3] : (tensor<256x2048xf32>) -> tensor<256x7x7x2048xf32>
    %4217 = stablehlo.convert %4216 : (tensor<256x7x7x2048xf32>) -> tensor<256x7x7x2048xf16>
    %4218 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x7x7x2048xf16>
    %4219 = stablehlo.select %3786, %4217, %4218 : tensor<256x7x7x2048xi1>, tensor<256x7x7x2048xf16>
    %4220 = stablehlo.convert %4219 : (tensor<256x7x7x2048xf16>) -> tensor<256x7x7x2048xf32>
    %cst_189 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4221 = stablehlo.reduce(%4220 init: %cst_189) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %4222 = stablehlo.reshape %4221 : (tensor<2048xf32>) -> tensor<1x1x1x2048xf32>
    %4223 = stablehlo.reshape %4222 : (tensor<1x1x1x2048xf32>) -> tensor<2048xf32>
    %4224 = stablehlo.multiply %3768, %4220 : tensor<256x7x7x2048xf32>
    %cst_190 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4225 = stablehlo.reduce(%4224 init: %cst_190) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %4226 = stablehlo.reshape %4225 : (tensor<2048xf32>) -> tensor<1x1x1x2048xf32>
    %4227 = stablehlo.broadcast_in_dim %3776, dims = [0, 1, 2, 3] : (tensor<1x1x1x2048xf32>) -> tensor<256x7x7x2048xf32>
    %4228 = stablehlo.multiply %4220, %4227 : tensor<256x7x7x2048xf32>
    %4229 = stablehlo.multiply %3771, %4226 : tensor<1x1x1x2048xf32>
    %4230 = stablehlo.multiply %4226, %3775 : tensor<1x1x1x2048xf32>
    %4231 = stablehlo.reshape %4229 : (tensor<1x1x1x2048xf32>) -> tensor<2048xf32>
    %4232 = stablehlo.multiply %4230, %3774 : tensor<1x1x1x2048xf32>
    %cst_191 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4233 = stablehlo.reduce(%4232 init: %cst_191) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %4234 = stablehlo.multiply %4233, %3753 : tensor<2048xf32>
    %4235 = stablehlo.negate %4234 : tensor<2048xf32>
    %4236 = stablehlo.multiply %4235, %3740 : tensor<2048xf32>
    %4237 = stablehlo.broadcast_in_dim %4234, dims = [1] : (tensor<2048xf32>) -> tensor<1x2048xf32>
    %4238 = stablehlo.pad %4237, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x2048xf32>, tensor<f32>) -> tensor<2x2048xf32>
    %4239 = stablehlo.negate %4228 : tensor<256x7x7x2048xf32>
    %cst_192 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4240 = stablehlo.reduce(%4239 init: %cst_192) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %4241 = stablehlo.reshape %4240 : (tensor<2048xf32>) -> tensor<1x1x1x2048xf32>
    %4242 = stablehlo.convert %4228 : (tensor<256x7x7x2048xf32>) -> tensor<256x7x7x2048xf16>
    %cst_193 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4243 = stablehlo.reduce(%4241 init: %cst_193) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %4244 = stablehlo.add %4236, %4243 : tensor<2048xf32>
    %4245 = stablehlo.broadcast_in_dim %4244, dims = [1] : (tensor<2048xf32>) -> tensor<1x2048xf32>
    %4246 = stablehlo.pad %4245, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x2048xf32>, tensor<f32>) -> tensor<2x2048xf32>
    %4247 = stablehlo.add %4238, %4246 : tensor<2x2048xf32>
    %4248 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x2048xf32>
    %4249 = stablehlo.divide %4247, %4248 : tensor<2x2048xf32>
    %4250 = "stablehlo.all_reduce"(%4249) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x2048xf32>) -> tensor<2x2048xf32>
    %4251 = stablehlo.slice %4250 [0:1, 0:2048] : (tensor<2x2048xf32>) -> tensor<1x2048xf32>
    %4252 = stablehlo.slice %4250 [1:2, 0:2048] : (tensor<2x2048xf32>) -> tensor<1x2048xf32>
    %cst_194 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4253 = stablehlo.reduce(%4252 init: %cst_194) applies stablehlo.add across dimensions = [0] : (tensor<1x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %4254 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %4255 = stablehlo.divide %4253, %4254 : tensor<2048xf32>
    %4256 = stablehlo.broadcast_in_dim %4255, dims = [3] : (tensor<2048xf32>) -> tensor<256x7x7x2048xf32>
    %4257 = stablehlo.multiply %4256, %3721 : tensor<256x7x7x2048xf32>
    %cst_195 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4258 = stablehlo.reduce(%4251 init: %cst_195) applies stablehlo.add across dimensions = [0] : (tensor<1x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %4259 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %4260 = stablehlo.divide %4258, %4259 : tensor<2048xf32>
    %4261 = stablehlo.broadcast_in_dim %4260, dims = [3] : (tensor<2048xf32>) -> tensor<256x7x7x2048xf32>
    %4262 = stablehlo.add %4257, %4261 : tensor<256x7x7x2048xf32>
    %4263 = stablehlo.convert %4262 : (tensor<256x7x7x2048xf32>) -> tensor<256x7x7x2048xf16>
    %4264 = stablehlo.add %4242, %4263 : tensor<256x7x7x2048xf16>
    %4265 = stablehlo.convolution(%3712, %4264) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x7x7x512xf16>, tensor<256x7x7x2048xf16>) -> tensor<1x1x512x2048xf16>
    %4266 = stablehlo.convert %4265 : (tensor<1x1x512x2048xf16>) -> tensor<1x1x512x2048xf32>
    %4267 = stablehlo.add %4146, %4266 : tensor<1x1x512x2048xf32>
    %4268 = stablehlo.reverse %3716, dims = [0, 1] : tensor<1x1x512x2048xf16>
    %4269 = stablehlo.convolution(%4264, %4268) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x7x7x2048xf16>, tensor<1x1x512x2048xf16>) -> tensor<256x7x7x512xf16>
    %4270 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x7x7x512xf16>
    %4271 = stablehlo.select %3714, %4269, %4270 : tensor<256x7x7x512xi1>, tensor<256x7x7x512xf16>
    %4272 = stablehlo.convert %4271 : (tensor<256x7x7x512xf16>) -> tensor<256x7x7x512xf32>
    %cst_196 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4273 = stablehlo.reduce(%4272 init: %cst_196) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4274 = stablehlo.reshape %4273 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %4275 = stablehlo.reshape %4274 : (tensor<1x1x1x512xf32>) -> tensor<512xf32>
    %4276 = stablehlo.multiply %3697, %4272 : tensor<256x7x7x512xf32>
    %cst_197 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4277 = stablehlo.reduce(%4276 init: %cst_197) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4278 = stablehlo.reshape %4277 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %4279 = stablehlo.broadcast_in_dim %3705, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x7x7x512xf32>
    %4280 = stablehlo.multiply %4272, %4279 : tensor<256x7x7x512xf32>
    %4281 = stablehlo.multiply %3700, %4278 : tensor<1x1x1x512xf32>
    %4282 = stablehlo.multiply %4278, %3704 : tensor<1x1x1x512xf32>
    %4283 = stablehlo.reshape %4281 : (tensor<1x1x1x512xf32>) -> tensor<512xf32>
    %4284 = stablehlo.multiply %4282, %3703 : tensor<1x1x1x512xf32>
    %cst_198 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4285 = stablehlo.reduce(%4284 init: %cst_198) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4286 = stablehlo.multiply %4285, %3682 : tensor<512xf32>
    %4287 = stablehlo.negate %4286 : tensor<512xf32>
    %4288 = stablehlo.multiply %4287, %3669 : tensor<512xf32>
    %4289 = stablehlo.broadcast_in_dim %4286, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %4290 = stablehlo.pad %4289, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<2x512xf32>
    %4291 = stablehlo.negate %4280 : tensor<256x7x7x512xf32>
    %cst_199 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4292 = stablehlo.reduce(%4291 init: %cst_199) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4293 = stablehlo.reshape %4292 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %4294 = stablehlo.convert %4280 : (tensor<256x7x7x512xf32>) -> tensor<256x7x7x512xf16>
    %cst_200 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4295 = stablehlo.reduce(%4293 init: %cst_200) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4296 = stablehlo.add %4288, %4295 : tensor<512xf32>
    %4297 = stablehlo.broadcast_in_dim %4296, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %4298 = stablehlo.pad %4297, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<2x512xf32>
    %4299 = stablehlo.add %4290, %4298 : tensor<2x512xf32>
    %4300 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x512xf32>
    %4301 = stablehlo.divide %4299, %4300 : tensor<2x512xf32>
    %4302 = "stablehlo.all_reduce"(%4301) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x512xf32>) -> tensor<2x512xf32>
    %4303 = stablehlo.slice %4302 [0:1, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %4304 = stablehlo.slice %4302 [1:2, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %cst_201 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4305 = stablehlo.reduce(%4304 init: %cst_201) applies stablehlo.add across dimensions = [0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4306 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %4307 = stablehlo.divide %4305, %4306 : tensor<512xf32>
    %4308 = stablehlo.broadcast_in_dim %4307, dims = [3] : (tensor<512xf32>) -> tensor<256x7x7x512xf32>
    %4309 = stablehlo.multiply %4308, %3650 : tensor<256x7x7x512xf32>
    %cst_202 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4310 = stablehlo.reduce(%4303 init: %cst_202) applies stablehlo.add across dimensions = [0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4311 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %4312 = stablehlo.divide %4310, %4311 : tensor<512xf32>
    %4313 = stablehlo.broadcast_in_dim %4312, dims = [3] : (tensor<512xf32>) -> tensor<256x7x7x512xf32>
    %4314 = stablehlo.add %4309, %4313 : tensor<256x7x7x512xf32>
    %4315 = stablehlo.convert %4314 : (tensor<256x7x7x512xf32>) -> tensor<256x7x7x512xf16>
    %4316 = stablehlo.add %4294, %4315 : tensor<256x7x7x512xf16>
    %4317 = stablehlo.convolution(%3641, %4316) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x7x7x512xf16>, tensor<256x7x7x512xf16>) -> tensor<3x3x512x512xf16>
    %4318 = stablehlo.convert %4317 : (tensor<3x3x512x512xf16>) -> tensor<3x3x512x512xf32>
    %4319 = stablehlo.add %4148, %4318 : tensor<3x3x512x512xf32>
    %4320 = stablehlo.reverse %3645, dims = [0, 1] : tensor<3x3x512x512xf16>
    %4321 = stablehlo.convolution(%4316, %4320) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x7x7x512xf16>, tensor<3x3x512x512xf16>) -> tensor<256x7x7x512xf16>
    %4322 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x7x7x512xf16>
    %4323 = stablehlo.select %3643, %4321, %4322 : tensor<256x7x7x512xi1>, tensor<256x7x7x512xf16>
    %4324 = stablehlo.convert %4323 : (tensor<256x7x7x512xf16>) -> tensor<256x7x7x512xf32>
    %cst_203 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4325 = stablehlo.reduce(%4324 init: %cst_203) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4326 = stablehlo.reshape %4325 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %4327 = stablehlo.reshape %4326 : (tensor<1x1x1x512xf32>) -> tensor<512xf32>
    %4328 = stablehlo.multiply %3626, %4324 : tensor<256x7x7x512xf32>
    %cst_204 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4329 = stablehlo.reduce(%4328 init: %cst_204) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4330 = stablehlo.reshape %4329 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %4331 = stablehlo.broadcast_in_dim %3634, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x7x7x512xf32>
    %4332 = stablehlo.multiply %4324, %4331 : tensor<256x7x7x512xf32>
    %4333 = stablehlo.multiply %3629, %4330 : tensor<1x1x1x512xf32>
    %4334 = stablehlo.multiply %4330, %3633 : tensor<1x1x1x512xf32>
    %4335 = stablehlo.reshape %4333 : (tensor<1x1x1x512xf32>) -> tensor<512xf32>
    %4336 = stablehlo.multiply %4334, %3632 : tensor<1x1x1x512xf32>
    %cst_205 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4337 = stablehlo.reduce(%4336 init: %cst_205) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4338 = stablehlo.multiply %4337, %3611 : tensor<512xf32>
    %4339 = stablehlo.negate %4338 : tensor<512xf32>
    %4340 = stablehlo.multiply %4339, %3598 : tensor<512xf32>
    %4341 = stablehlo.broadcast_in_dim %4338, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %4342 = stablehlo.pad %4341, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<2x512xf32>
    %4343 = stablehlo.negate %4332 : tensor<256x7x7x512xf32>
    %cst_206 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4344 = stablehlo.reduce(%4343 init: %cst_206) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4345 = stablehlo.reshape %4344 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %4346 = stablehlo.convert %4332 : (tensor<256x7x7x512xf32>) -> tensor<256x7x7x512xf16>
    %cst_207 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4347 = stablehlo.reduce(%4345 init: %cst_207) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4348 = stablehlo.add %4340, %4347 : tensor<512xf32>
    %4349 = stablehlo.broadcast_in_dim %4348, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %4350 = stablehlo.pad %4349, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<2x512xf32>
    %4351 = stablehlo.add %4342, %4350 : tensor<2x512xf32>
    %4352 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x512xf32>
    %4353 = stablehlo.divide %4351, %4352 : tensor<2x512xf32>
    %4354 = "stablehlo.all_reduce"(%4353) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x512xf32>) -> tensor<2x512xf32>
    %4355 = stablehlo.slice %4354 [0:1, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %4356 = stablehlo.slice %4354 [1:2, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %cst_208 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4357 = stablehlo.reduce(%4356 init: %cst_208) applies stablehlo.add across dimensions = [0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4358 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %4359 = stablehlo.divide %4357, %4358 : tensor<512xf32>
    %4360 = stablehlo.broadcast_in_dim %4359, dims = [3] : (tensor<512xf32>) -> tensor<256x7x7x512xf32>
    %4361 = stablehlo.multiply %4360, %3579 : tensor<256x7x7x512xf32>
    %cst_209 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4362 = stablehlo.reduce(%4355 init: %cst_209) applies stablehlo.add across dimensions = [0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4363 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %4364 = stablehlo.divide %4362, %4363 : tensor<512xf32>
    %4365 = stablehlo.broadcast_in_dim %4364, dims = [3] : (tensor<512xf32>) -> tensor<256x7x7x512xf32>
    %4366 = stablehlo.add %4361, %4365 : tensor<256x7x7x512xf32>
    %4367 = stablehlo.convert %4366 : (tensor<256x7x7x512xf32>) -> tensor<256x7x7x512xf16>
    %4368 = stablehlo.add %4346, %4367 : tensor<256x7x7x512xf16>
    %4369 = stablehlo.convolution(%3570, %4368) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x7x7x2048xf16>, tensor<256x7x7x512xf16>) -> tensor<1x1x2048x512xf16>
    %4370 = stablehlo.convert %4369 : (tensor<1x1x2048x512xf16>) -> tensor<1x1x2048x512xf32>
    %4371 = stablehlo.add %4150, %4370 : tensor<1x1x2048x512xf32>
    %4372 = stablehlo.reverse %3574, dims = [0, 1] : tensor<1x1x2048x512xf16>
    %4373 = stablehlo.convolution(%4368, %4372) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x7x7x512xf16>, tensor<1x1x2048x512xf16>) -> tensor<256x7x7x2048xf16>
    %4374 = stablehlo.add %4219, %4373 : tensor<256x7x7x2048xf16>
    %4375 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x7x7x2048xf16>
    %4376 = stablehlo.select %3572, %4374, %4375 : tensor<256x7x7x2048xi1>, tensor<256x7x7x2048xf16>
    %4377 = stablehlo.convert %4376 : (tensor<256x7x7x2048xf16>) -> tensor<256x7x7x2048xf32>
    %cst_210 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4378 = stablehlo.reduce(%4377 init: %cst_210) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %4379 = stablehlo.reshape %4378 : (tensor<2048xf32>) -> tensor<1x1x1x2048xf32>
    %4380 = stablehlo.reshape %4379 : (tensor<1x1x1x2048xf32>) -> tensor<2048xf32>
    %4381 = stablehlo.multiply %3554, %4377 : tensor<256x7x7x2048xf32>
    %cst_211 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4382 = stablehlo.reduce(%4381 init: %cst_211) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %4383 = stablehlo.reshape %4382 : (tensor<2048xf32>) -> tensor<1x1x1x2048xf32>
    %4384 = stablehlo.broadcast_in_dim %3562, dims = [0, 1, 2, 3] : (tensor<1x1x1x2048xf32>) -> tensor<256x7x7x2048xf32>
    %4385 = stablehlo.multiply %4377, %4384 : tensor<256x7x7x2048xf32>
    %4386 = stablehlo.multiply %3557, %4383 : tensor<1x1x1x2048xf32>
    %4387 = stablehlo.multiply %4383, %3561 : tensor<1x1x1x2048xf32>
    %4388 = stablehlo.reshape %4386 : (tensor<1x1x1x2048xf32>) -> tensor<2048xf32>
    %4389 = stablehlo.multiply %4387, %3560 : tensor<1x1x1x2048xf32>
    %cst_212 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4390 = stablehlo.reduce(%4389 init: %cst_212) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %4391 = stablehlo.multiply %4390, %3539 : tensor<2048xf32>
    %4392 = stablehlo.negate %4391 : tensor<2048xf32>
    %4393 = stablehlo.multiply %4392, %3526 : tensor<2048xf32>
    %4394 = stablehlo.broadcast_in_dim %4391, dims = [1] : (tensor<2048xf32>) -> tensor<1x2048xf32>
    %4395 = stablehlo.pad %4394, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x2048xf32>, tensor<f32>) -> tensor<2x2048xf32>
    %4396 = stablehlo.negate %4385 : tensor<256x7x7x2048xf32>
    %cst_213 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4397 = stablehlo.reduce(%4396 init: %cst_213) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %4398 = stablehlo.reshape %4397 : (tensor<2048xf32>) -> tensor<1x1x1x2048xf32>
    %4399 = stablehlo.convert %4385 : (tensor<256x7x7x2048xf32>) -> tensor<256x7x7x2048xf16>
    %cst_214 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4400 = stablehlo.reduce(%4398 init: %cst_214) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %4401 = stablehlo.add %4393, %4400 : tensor<2048xf32>
    %4402 = stablehlo.broadcast_in_dim %4401, dims = [1] : (tensor<2048xf32>) -> tensor<1x2048xf32>
    %4403 = stablehlo.pad %4402, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x2048xf32>, tensor<f32>) -> tensor<2x2048xf32>
    %4404 = stablehlo.add %4395, %4403 : tensor<2x2048xf32>
    %4405 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x2048xf32>
    %4406 = stablehlo.divide %4404, %4405 : tensor<2x2048xf32>
    %4407 = "stablehlo.all_reduce"(%4406) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x2048xf32>) -> tensor<2x2048xf32>
    %4408 = stablehlo.slice %4407 [0:1, 0:2048] : (tensor<2x2048xf32>) -> tensor<1x2048xf32>
    %4409 = stablehlo.slice %4407 [1:2, 0:2048] : (tensor<2x2048xf32>) -> tensor<1x2048xf32>
    %cst_215 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4410 = stablehlo.reduce(%4409 init: %cst_215) applies stablehlo.add across dimensions = [0] : (tensor<1x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %4411 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %4412 = stablehlo.divide %4410, %4411 : tensor<2048xf32>
    %4413 = stablehlo.broadcast_in_dim %4412, dims = [3] : (tensor<2048xf32>) -> tensor<256x7x7x2048xf32>
    %4414 = stablehlo.multiply %4413, %3507 : tensor<256x7x7x2048xf32>
    %cst_216 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4415 = stablehlo.reduce(%4408 init: %cst_216) applies stablehlo.add across dimensions = [0] : (tensor<1x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %4416 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %4417 = stablehlo.divide %4415, %4416 : tensor<2048xf32>
    %4418 = stablehlo.broadcast_in_dim %4417, dims = [3] : (tensor<2048xf32>) -> tensor<256x7x7x2048xf32>
    %4419 = stablehlo.add %4414, %4418 : tensor<256x7x7x2048xf32>
    %4420 = stablehlo.convert %4419 : (tensor<256x7x7x2048xf32>) -> tensor<256x7x7x2048xf16>
    %4421 = stablehlo.add %4399, %4420 : tensor<256x7x7x2048xf16>
    %4422 = stablehlo.convolution(%3498, %4421) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x7x7x512xf16>, tensor<256x7x7x2048xf16>) -> tensor<1x1x512x2048xf16>
    %4423 = stablehlo.convert %4422 : (tensor<1x1x512x2048xf16>) -> tensor<1x1x512x2048xf32>
    %4424 = stablehlo.add %4152, %4423 : tensor<1x1x512x2048xf32>
    %4425 = stablehlo.reverse %3502, dims = [0, 1] : tensor<1x1x512x2048xf16>
    %4426 = stablehlo.convolution(%4421, %4425) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x7x7x2048xf16>, tensor<1x1x512x2048xf16>) -> tensor<256x7x7x512xf16>
    %4427 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x7x7x512xf16>
    %4428 = stablehlo.select %3500, %4426, %4427 : tensor<256x7x7x512xi1>, tensor<256x7x7x512xf16>
    %4429 = stablehlo.convert %4428 : (tensor<256x7x7x512xf16>) -> tensor<256x7x7x512xf32>
    %cst_217 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4430 = stablehlo.reduce(%4429 init: %cst_217) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4431 = stablehlo.reshape %4430 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %4432 = stablehlo.reshape %4431 : (tensor<1x1x1x512xf32>) -> tensor<512xf32>
    %4433 = stablehlo.multiply %3483, %4429 : tensor<256x7x7x512xf32>
    %cst_218 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4434 = stablehlo.reduce(%4433 init: %cst_218) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4435 = stablehlo.reshape %4434 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %4436 = stablehlo.broadcast_in_dim %3491, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x7x7x512xf32>
    %4437 = stablehlo.multiply %4429, %4436 : tensor<256x7x7x512xf32>
    %4438 = stablehlo.multiply %3486, %4435 : tensor<1x1x1x512xf32>
    %4439 = stablehlo.multiply %4435, %3490 : tensor<1x1x1x512xf32>
    %4440 = stablehlo.reshape %4438 : (tensor<1x1x1x512xf32>) -> tensor<512xf32>
    %4441 = stablehlo.multiply %4439, %3489 : tensor<1x1x1x512xf32>
    %cst_219 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4442 = stablehlo.reduce(%4441 init: %cst_219) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4443 = stablehlo.multiply %4442, %3468 : tensor<512xf32>
    %4444 = stablehlo.negate %4443 : tensor<512xf32>
    %4445 = stablehlo.multiply %4444, %3455 : tensor<512xf32>
    %4446 = stablehlo.broadcast_in_dim %4443, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %4447 = stablehlo.pad %4446, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<2x512xf32>
    %4448 = stablehlo.negate %4437 : tensor<256x7x7x512xf32>
    %cst_220 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4449 = stablehlo.reduce(%4448 init: %cst_220) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4450 = stablehlo.reshape %4449 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %4451 = stablehlo.convert %4437 : (tensor<256x7x7x512xf32>) -> tensor<256x7x7x512xf16>
    %cst_221 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4452 = stablehlo.reduce(%4450 init: %cst_221) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4453 = stablehlo.add %4445, %4452 : tensor<512xf32>
    %4454 = stablehlo.broadcast_in_dim %4453, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %4455 = stablehlo.pad %4454, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<2x512xf32>
    %4456 = stablehlo.add %4447, %4455 : tensor<2x512xf32>
    %4457 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x512xf32>
    %4458 = stablehlo.divide %4456, %4457 : tensor<2x512xf32>
    %4459 = "stablehlo.all_reduce"(%4458) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x512xf32>) -> tensor<2x512xf32>
    %4460 = stablehlo.slice %4459 [0:1, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %4461 = stablehlo.slice %4459 [1:2, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %cst_222 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4462 = stablehlo.reduce(%4461 init: %cst_222) applies stablehlo.add across dimensions = [0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4463 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %4464 = stablehlo.divide %4462, %4463 : tensor<512xf32>
    %4465 = stablehlo.broadcast_in_dim %4464, dims = [3] : (tensor<512xf32>) -> tensor<256x7x7x512xf32>
    %4466 = stablehlo.multiply %4465, %3436 : tensor<256x7x7x512xf32>
    %cst_223 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4467 = stablehlo.reduce(%4460 init: %cst_223) applies stablehlo.add across dimensions = [0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4468 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %4469 = stablehlo.divide %4467, %4468 : tensor<512xf32>
    %4470 = stablehlo.broadcast_in_dim %4469, dims = [3] : (tensor<512xf32>) -> tensor<256x7x7x512xf32>
    %4471 = stablehlo.add %4466, %4470 : tensor<256x7x7x512xf32>
    %4472 = stablehlo.convert %4471 : (tensor<256x7x7x512xf32>) -> tensor<256x7x7x512xf16>
    %4473 = stablehlo.add %4451, %4472 : tensor<256x7x7x512xf16>
    %4474 = stablehlo.convolution(%3427, %4473) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x7x7x512xf16>, tensor<256x7x7x512xf16>) -> tensor<3x3x512x512xf16>
    %4475 = stablehlo.convert %4474 : (tensor<3x3x512x512xf16>) -> tensor<3x3x512x512xf32>
    %4476 = stablehlo.add %4154, %4475 : tensor<3x3x512x512xf32>
    %4477 = stablehlo.reverse %3431, dims = [0, 1] : tensor<3x3x512x512xf16>
    %4478 = stablehlo.convolution(%4473, %4477) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x7x7x512xf16>, tensor<3x3x512x512xf16>) -> tensor<256x7x7x512xf16>
    %4479 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x7x7x512xf16>
    %4480 = stablehlo.select %3429, %4478, %4479 : tensor<256x7x7x512xi1>, tensor<256x7x7x512xf16>
    %4481 = stablehlo.convert %4480 : (tensor<256x7x7x512xf16>) -> tensor<256x7x7x512xf32>
    %cst_224 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4482 = stablehlo.reduce(%4481 init: %cst_224) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4483 = stablehlo.reshape %4482 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %4484 = stablehlo.reshape %4483 : (tensor<1x1x1x512xf32>) -> tensor<512xf32>
    %4485 = stablehlo.multiply %3412, %4481 : tensor<256x7x7x512xf32>
    %cst_225 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4486 = stablehlo.reduce(%4485 init: %cst_225) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4487 = stablehlo.reshape %4486 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %4488 = stablehlo.broadcast_in_dim %3420, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x7x7x512xf32>
    %4489 = stablehlo.multiply %4481, %4488 : tensor<256x7x7x512xf32>
    %4490 = stablehlo.multiply %3415, %4487 : tensor<1x1x1x512xf32>
    %4491 = stablehlo.multiply %4487, %3419 : tensor<1x1x1x512xf32>
    %4492 = stablehlo.reshape %4490 : (tensor<1x1x1x512xf32>) -> tensor<512xf32>
    %4493 = stablehlo.multiply %4491, %3418 : tensor<1x1x1x512xf32>
    %cst_226 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4494 = stablehlo.reduce(%4493 init: %cst_226) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4495 = stablehlo.multiply %4494, %3397 : tensor<512xf32>
    %4496 = stablehlo.negate %4495 : tensor<512xf32>
    %4497 = stablehlo.multiply %4496, %3384 : tensor<512xf32>
    %4498 = stablehlo.broadcast_in_dim %4495, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %4499 = stablehlo.pad %4498, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<2x512xf32>
    %4500 = stablehlo.negate %4489 : tensor<256x7x7x512xf32>
    %cst_227 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4501 = stablehlo.reduce(%4500 init: %cst_227) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4502 = stablehlo.reshape %4501 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %4503 = stablehlo.convert %4489 : (tensor<256x7x7x512xf32>) -> tensor<256x7x7x512xf16>
    %cst_228 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4504 = stablehlo.reduce(%4502 init: %cst_228) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4505 = stablehlo.add %4497, %4504 : tensor<512xf32>
    %4506 = stablehlo.broadcast_in_dim %4505, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %4507 = stablehlo.pad %4506, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<2x512xf32>
    %4508 = stablehlo.add %4499, %4507 : tensor<2x512xf32>
    %4509 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x512xf32>
    %4510 = stablehlo.divide %4508, %4509 : tensor<2x512xf32>
    %4511 = "stablehlo.all_reduce"(%4510) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x512xf32>) -> tensor<2x512xf32>
    %4512 = stablehlo.slice %4511 [0:1, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %4513 = stablehlo.slice %4511 [1:2, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %cst_229 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4514 = stablehlo.reduce(%4513 init: %cst_229) applies stablehlo.add across dimensions = [0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4515 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %4516 = stablehlo.divide %4514, %4515 : tensor<512xf32>
    %4517 = stablehlo.broadcast_in_dim %4516, dims = [3] : (tensor<512xf32>) -> tensor<256x7x7x512xf32>
    %4518 = stablehlo.multiply %4517, %3365 : tensor<256x7x7x512xf32>
    %cst_230 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4519 = stablehlo.reduce(%4512 init: %cst_230) applies stablehlo.add across dimensions = [0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4520 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %4521 = stablehlo.divide %4519, %4520 : tensor<512xf32>
    %4522 = stablehlo.broadcast_in_dim %4521, dims = [3] : (tensor<512xf32>) -> tensor<256x7x7x512xf32>
    %4523 = stablehlo.add %4518, %4522 : tensor<256x7x7x512xf32>
    %4524 = stablehlo.convert %4523 : (tensor<256x7x7x512xf32>) -> tensor<256x7x7x512xf16>
    %4525 = stablehlo.add %4503, %4524 : tensor<256x7x7x512xf16>
    %4526 = stablehlo.convolution(%3356, %4525) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x7x7x2048xf16>, tensor<256x7x7x512xf16>) -> tensor<1x1x2048x512xf16>
    %4527 = stablehlo.convert %4526 : (tensor<1x1x2048x512xf16>) -> tensor<1x1x2048x512xf32>
    %4528 = stablehlo.add %4156, %4527 : tensor<1x1x2048x512xf32>
    %4529 = stablehlo.reverse %3360, dims = [0, 1] : tensor<1x1x2048x512xf16>
    %4530 = stablehlo.convolution(%4525, %4529) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x7x7x512xf16>, tensor<1x1x2048x512xf16>) -> tensor<256x7x7x2048xf16>
    %4531 = stablehlo.add %4376, %4530 : tensor<256x7x7x2048xf16>
    %4532 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x7x7x2048xf16>
    %4533 = stablehlo.select %3358, %4531, %4532 : tensor<256x7x7x2048xi1>, tensor<256x7x7x2048xf16>
    %4534 = stablehlo.convert %4533 : (tensor<256x7x7x2048xf16>) -> tensor<256x7x7x2048xf32>
    %cst_231 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4535 = stablehlo.reduce(%4534 init: %cst_231) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %4536 = stablehlo.reshape %4535 : (tensor<2048xf32>) -> tensor<1x1x1x2048xf32>
    %4537 = stablehlo.reshape %4536 : (tensor<1x1x1x2048xf32>) -> tensor<2048xf32>
    %4538 = stablehlo.multiply %3273, %4534 : tensor<256x7x7x2048xf32>
    %cst_232 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4539 = stablehlo.reduce(%4538 init: %cst_232) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %4540 = stablehlo.reshape %4539 : (tensor<2048xf32>) -> tensor<1x1x1x2048xf32>
    %4541 = stablehlo.broadcast_in_dim %3281, dims = [0, 1, 2, 3] : (tensor<1x1x1x2048xf32>) -> tensor<256x7x7x2048xf32>
    %4542 = stablehlo.multiply %4534, %4541 : tensor<256x7x7x2048xf32>
    %4543 = stablehlo.multiply %3276, %4540 : tensor<1x1x1x2048xf32>
    %4544 = stablehlo.multiply %4540, %3280 : tensor<1x1x1x2048xf32>
    %4545 = stablehlo.reshape %4543 : (tensor<1x1x1x2048xf32>) -> tensor<2048xf32>
    %4546 = stablehlo.multiply %4544, %3279 : tensor<1x1x1x2048xf32>
    %cst_233 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4547 = stablehlo.reduce(%4546 init: %cst_233) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %4548 = stablehlo.multiply %4547, %3258 : tensor<2048xf32>
    %4549 = stablehlo.negate %4548 : tensor<2048xf32>
    %4550 = stablehlo.multiply %4549, %3245 : tensor<2048xf32>
    %4551 = stablehlo.broadcast_in_dim %4548, dims = [1] : (tensor<2048xf32>) -> tensor<1x2048xf32>
    %4552 = stablehlo.pad %4551, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x2048xf32>, tensor<f32>) -> tensor<2x2048xf32>
    %4553 = stablehlo.negate %4542 : tensor<256x7x7x2048xf32>
    %cst_234 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4554 = stablehlo.reduce(%4553 init: %cst_234) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %4555 = stablehlo.reshape %4554 : (tensor<2048xf32>) -> tensor<1x1x1x2048xf32>
    %4556 = stablehlo.convert %4542 : (tensor<256x7x7x2048xf32>) -> tensor<256x7x7x2048xf16>
    %cst_235 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4557 = stablehlo.reduce(%4555 init: %cst_235) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %4558 = stablehlo.add %4550, %4557 : tensor<2048xf32>
    %4559 = stablehlo.broadcast_in_dim %4558, dims = [1] : (tensor<2048xf32>) -> tensor<1x2048xf32>
    %4560 = stablehlo.pad %4559, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x2048xf32>, tensor<f32>) -> tensor<2x2048xf32>
    %4561 = stablehlo.add %4552, %4560 : tensor<2x2048xf32>
    %4562 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x2048xf32>
    %4563 = stablehlo.divide %4561, %4562 : tensor<2x2048xf32>
    %4564 = "stablehlo.all_reduce"(%4563) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x2048xf32>) -> tensor<2x2048xf32>
    %4565 = stablehlo.slice %4564 [0:1, 0:2048] : (tensor<2x2048xf32>) -> tensor<1x2048xf32>
    %4566 = stablehlo.slice %4564 [1:2, 0:2048] : (tensor<2x2048xf32>) -> tensor<1x2048xf32>
    %cst_236 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4567 = stablehlo.reduce(%4566 init: %cst_236) applies stablehlo.add across dimensions = [0] : (tensor<1x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %4568 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %4569 = stablehlo.divide %4567, %4568 : tensor<2048xf32>
    %4570 = stablehlo.broadcast_in_dim %4569, dims = [3] : (tensor<2048xf32>) -> tensor<256x7x7x2048xf32>
    %4571 = stablehlo.multiply %4570, %3226 : tensor<256x7x7x2048xf32>
    %cst_237 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4572 = stablehlo.reduce(%4565 init: %cst_237) applies stablehlo.add across dimensions = [0] : (tensor<1x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %4573 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %4574 = stablehlo.divide %4572, %4573 : tensor<2048xf32>
    %4575 = stablehlo.broadcast_in_dim %4574, dims = [3] : (tensor<2048xf32>) -> tensor<256x7x7x2048xf32>
    %4576 = stablehlo.add %4571, %4575 : tensor<256x7x7x2048xf32>
    %4577 = stablehlo.convert %4576 : (tensor<256x7x7x2048xf32>) -> tensor<256x7x7x2048xf16>
    %4578 = stablehlo.add %4556, %4577 : tensor<256x7x7x2048xf16>
    %4579 = stablehlo.convolution(%3217, %4578) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x7x7x512xf16>, tensor<256x7x7x2048xf16>) -> tensor<1x1x512x2048xf16>
    %4580 = stablehlo.convert %4579 : (tensor<1x1x512x2048xf16>) -> tensor<1x1x512x2048xf32>
    %4581 = stablehlo.add %4160, %4580 : tensor<1x1x512x2048xf32>
    %4582 = stablehlo.reverse %3221, dims = [0, 1] : tensor<1x1x512x2048xf16>
    %4583 = stablehlo.convolution(%4578, %4582) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x7x7x2048xf16>, tensor<1x1x512x2048xf16>) -> tensor<256x7x7x512xf16>
    %4584 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x7x7x512xf16>
    %4585 = stablehlo.select %3219, %4583, %4584 : tensor<256x7x7x512xi1>, tensor<256x7x7x512xf16>
    %4586 = stablehlo.convert %4585 : (tensor<256x7x7x512xf16>) -> tensor<256x7x7x512xf32>
    %cst_238 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4587 = stablehlo.reduce(%4586 init: %cst_238) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4588 = stablehlo.reshape %4587 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %4589 = stablehlo.reshape %4588 : (tensor<1x1x1x512xf32>) -> tensor<512xf32>
    %4590 = stablehlo.multiply %3202, %4586 : tensor<256x7x7x512xf32>
    %cst_239 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4591 = stablehlo.reduce(%4590 init: %cst_239) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4592 = stablehlo.reshape %4591 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %4593 = stablehlo.broadcast_in_dim %3210, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x7x7x512xf32>
    %4594 = stablehlo.multiply %4586, %4593 : tensor<256x7x7x512xf32>
    %4595 = stablehlo.multiply %3205, %4592 : tensor<1x1x1x512xf32>
    %4596 = stablehlo.multiply %4592, %3209 : tensor<1x1x1x512xf32>
    %4597 = stablehlo.reshape %4595 : (tensor<1x1x1x512xf32>) -> tensor<512xf32>
    %4598 = stablehlo.multiply %4596, %3208 : tensor<1x1x1x512xf32>
    %cst_240 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4599 = stablehlo.reduce(%4598 init: %cst_240) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4600 = stablehlo.multiply %4599, %3187 : tensor<512xf32>
    %4601 = stablehlo.negate %4600 : tensor<512xf32>
    %4602 = stablehlo.multiply %4601, %3174 : tensor<512xf32>
    %4603 = stablehlo.broadcast_in_dim %4600, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %4604 = stablehlo.pad %4603, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<2x512xf32>
    %4605 = stablehlo.negate %4594 : tensor<256x7x7x512xf32>
    %cst_241 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4606 = stablehlo.reduce(%4605 init: %cst_241) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4607 = stablehlo.reshape %4606 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %4608 = stablehlo.convert %4594 : (tensor<256x7x7x512xf32>) -> tensor<256x7x7x512xf16>
    %cst_242 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4609 = stablehlo.reduce(%4607 init: %cst_242) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4610 = stablehlo.add %4602, %4609 : tensor<512xf32>
    %4611 = stablehlo.broadcast_in_dim %4610, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %4612 = stablehlo.pad %4611, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<2x512xf32>
    %4613 = stablehlo.add %4604, %4612 : tensor<2x512xf32>
    %4614 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x512xf32>
    %4615 = stablehlo.divide %4613, %4614 : tensor<2x512xf32>
    %4616 = "stablehlo.all_reduce"(%4615) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x512xf32>) -> tensor<2x512xf32>
    %4617 = stablehlo.slice %4616 [0:1, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %4618 = stablehlo.slice %4616 [1:2, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %cst_243 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4619 = stablehlo.reduce(%4618 init: %cst_243) applies stablehlo.add across dimensions = [0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4620 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %4621 = stablehlo.divide %4619, %4620 : tensor<512xf32>
    %4622 = stablehlo.broadcast_in_dim %4621, dims = [3] : (tensor<512xf32>) -> tensor<256x7x7x512xf32>
    %4623 = stablehlo.multiply %4622, %3155 : tensor<256x7x7x512xf32>
    %cst_244 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4624 = stablehlo.reduce(%4617 init: %cst_244) applies stablehlo.add across dimensions = [0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4625 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %4626 = stablehlo.divide %4624, %4625 : tensor<512xf32>
    %4627 = stablehlo.broadcast_in_dim %4626, dims = [3] : (tensor<512xf32>) -> tensor<256x7x7x512xf32>
    %4628 = stablehlo.add %4623, %4627 : tensor<256x7x7x512xf32>
    %4629 = stablehlo.convert %4628 : (tensor<256x7x7x512xf32>) -> tensor<256x7x7x512xf16>
    %4630 = stablehlo.add %4608, %4629 : tensor<256x7x7x512xf16>
    %4631 = stablehlo.convolution(%3146, %4630) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 1], [0, 1]], lhs_dilate = [1, 1], rhs_dilate = [2, 2], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x512xf16>, tensor<256x7x7x512xf16>) -> tensor<3x3x512x512xf16>
    %4632 = stablehlo.convert %4631 : (tensor<3x3x512x512xf16>) -> tensor<3x3x512x512xf32>
    %4633 = stablehlo.add %4162, %4632 : tensor<3x3x512x512xf32>
    %4634 = stablehlo.reverse %3150, dims = [0, 1] : tensor<3x3x512x512xf16>
    %4635 = stablehlo.convolution(%4630, %4634) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[2, 1], [2, 1]], lhs_dilate = [2, 2], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x7x7x512xf16>, tensor<3x3x512x512xf16>) -> tensor<256x14x14x512xf16>
    %4636 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x512xf16>
    %4637 = stablehlo.select %3148, %4635, %4636 : tensor<256x14x14x512xi1>, tensor<256x14x14x512xf16>
    %4638 = stablehlo.convert %4637 : (tensor<256x14x14x512xf16>) -> tensor<256x14x14x512xf32>
    %cst_245 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4639 = stablehlo.reduce(%4638 init: %cst_245) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4640 = stablehlo.reshape %4639 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %4641 = stablehlo.reshape %4640 : (tensor<1x1x1x512xf32>) -> tensor<512xf32>
    %4642 = stablehlo.multiply %3131, %4638 : tensor<256x14x14x512xf32>
    %cst_246 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4643 = stablehlo.reduce(%4642 init: %cst_246) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4644 = stablehlo.reshape %4643 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %4645 = stablehlo.broadcast_in_dim %3139, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x14x14x512xf32>
    %4646 = stablehlo.multiply %4638, %4645 : tensor<256x14x14x512xf32>
    %4647 = stablehlo.multiply %3134, %4644 : tensor<1x1x1x512xf32>
    %4648 = stablehlo.multiply %4644, %3138 : tensor<1x1x1x512xf32>
    %4649 = stablehlo.reshape %4647 : (tensor<1x1x1x512xf32>) -> tensor<512xf32>
    %4650 = stablehlo.multiply %4648, %3137 : tensor<1x1x1x512xf32>
    %cst_247 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4651 = stablehlo.reduce(%4650 init: %cst_247) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4652 = stablehlo.multiply %4651, %3116 : tensor<512xf32>
    %4653 = stablehlo.negate %4652 : tensor<512xf32>
    %4654 = stablehlo.multiply %4653, %3103 : tensor<512xf32>
    %4655 = stablehlo.broadcast_in_dim %4652, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %4656 = stablehlo.pad %4655, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<2x512xf32>
    %4657 = stablehlo.negate %4646 : tensor<256x14x14x512xf32>
    %cst_248 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4658 = stablehlo.reduce(%4657 init: %cst_248) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4659 = stablehlo.reshape %4658 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %4660 = stablehlo.convert %4646 : (tensor<256x14x14x512xf32>) -> tensor<256x14x14x512xf16>
    %cst_249 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4661 = stablehlo.reduce(%4659 init: %cst_249) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4662 = stablehlo.add %4654, %4661 : tensor<512xf32>
    %4663 = stablehlo.broadcast_in_dim %4662, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %4664 = stablehlo.pad %4663, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<2x512xf32>
    %4665 = stablehlo.add %4656, %4664 : tensor<2x512xf32>
    %4666 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x512xf32>
    %4667 = stablehlo.divide %4665, %4666 : tensor<2x512xf32>
    %4668 = "stablehlo.all_reduce"(%4667) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x512xf32>) -> tensor<2x512xf32>
    %4669 = stablehlo.slice %4668 [0:1, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %4670 = stablehlo.slice %4668 [1:2, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %cst_250 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4671 = stablehlo.reduce(%4670 init: %cst_250) applies stablehlo.add across dimensions = [0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4672 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %4673 = stablehlo.divide %4671, %4672 : tensor<512xf32>
    %4674 = stablehlo.broadcast_in_dim %4673, dims = [3] : (tensor<512xf32>) -> tensor<256x14x14x512xf32>
    %4675 = stablehlo.multiply %4674, %3084 : tensor<256x14x14x512xf32>
    %cst_251 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4676 = stablehlo.reduce(%4669 init: %cst_251) applies stablehlo.add across dimensions = [0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %4677 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %4678 = stablehlo.divide %4676, %4677 : tensor<512xf32>
    %4679 = stablehlo.broadcast_in_dim %4678, dims = [3] : (tensor<512xf32>) -> tensor<256x14x14x512xf32>
    %4680 = stablehlo.add %4675, %4679 : tensor<256x14x14x512xf32>
    %4681 = stablehlo.convert %4680 : (tensor<256x14x14x512xf32>) -> tensor<256x14x14x512xf16>
    %4682 = stablehlo.add %4660, %4681 : tensor<256x14x14x512xf16>
    %4683 = stablehlo.convolution(%3075, %4682) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x1024xf16>, tensor<256x14x14x512xf16>) -> tensor<1x1x1024x512xf16>
    %4684 = stablehlo.convert %4683 : (tensor<1x1x1024x512xf16>) -> tensor<1x1x1024x512xf32>
    %4685 = stablehlo.add %4164, %4684 : tensor<1x1x1024x512xf32>
    %4686 = stablehlo.reverse %3079, dims = [0, 1] : tensor<1x1x1024x512xf16>
    %4687 = stablehlo.convolution(%4682, %4686) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x512xf16>, tensor<1x1x1024x512xf16>) -> tensor<256x14x14x1024xf16>
    %4688 = stablehlo.convert %4533 : (tensor<256x7x7x2048xf16>) -> tensor<256x7x7x2048xf32>
    %cst_252 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4689 = stablehlo.reduce(%4688 init: %cst_252) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %4690 = stablehlo.reshape %4689 : (tensor<2048xf32>) -> tensor<1x1x1x2048xf32>
    %4691 = stablehlo.reshape %4690 : (tensor<1x1x1x2048xf32>) -> tensor<2048xf32>
    %4692 = stablehlo.multiply %3340, %4688 : tensor<256x7x7x2048xf32>
    %cst_253 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4693 = stablehlo.reduce(%4692 init: %cst_253) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %4694 = stablehlo.reshape %4693 : (tensor<2048xf32>) -> tensor<1x1x1x2048xf32>
    %4695 = stablehlo.broadcast_in_dim %3348, dims = [0, 1, 2, 3] : (tensor<1x1x1x2048xf32>) -> tensor<256x7x7x2048xf32>
    %4696 = stablehlo.multiply %4688, %4695 : tensor<256x7x7x2048xf32>
    %4697 = stablehlo.multiply %3343, %4694 : tensor<1x1x1x2048xf32>
    %4698 = stablehlo.multiply %4694, %3347 : tensor<1x1x1x2048xf32>
    %4699 = stablehlo.reshape %4697 : (tensor<1x1x1x2048xf32>) -> tensor<2048xf32>
    %4700 = stablehlo.multiply %4698, %3346 : tensor<1x1x1x2048xf32>
    %cst_254 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4701 = stablehlo.reduce(%4700 init: %cst_254) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %4702 = stablehlo.multiply %4701, %3325 : tensor<2048xf32>
    %4703 = stablehlo.negate %4702 : tensor<2048xf32>
    %4704 = stablehlo.multiply %4703, %3312 : tensor<2048xf32>
    %4705 = stablehlo.broadcast_in_dim %4702, dims = [1] : (tensor<2048xf32>) -> tensor<1x2048xf32>
    %4706 = stablehlo.pad %4705, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x2048xf32>, tensor<f32>) -> tensor<2x2048xf32>
    %4707 = stablehlo.negate %4696 : tensor<256x7x7x2048xf32>
    %cst_255 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4708 = stablehlo.reduce(%4707 init: %cst_255) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x7x7x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %4709 = stablehlo.reshape %4708 : (tensor<2048xf32>) -> tensor<1x1x1x2048xf32>
    %4710 = stablehlo.convert %4696 : (tensor<256x7x7x2048xf32>) -> tensor<256x7x7x2048xf16>
    %cst_256 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4711 = stablehlo.reduce(%4709 init: %cst_256) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %4712 = stablehlo.add %4704, %4711 : tensor<2048xf32>
    %4713 = stablehlo.broadcast_in_dim %4712, dims = [1] : (tensor<2048xf32>) -> tensor<1x2048xf32>
    %4714 = stablehlo.pad %4713, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x2048xf32>, tensor<f32>) -> tensor<2x2048xf32>
    %4715 = stablehlo.add %4706, %4714 : tensor<2x2048xf32>
    %4716 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x2048xf32>
    %4717 = stablehlo.divide %4715, %4716 : tensor<2x2048xf32>
    %4718 = "stablehlo.all_reduce"(%4717) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x2048xf32>) -> tensor<2x2048xf32>
    %4719 = stablehlo.slice %4718 [0:1, 0:2048] : (tensor<2x2048xf32>) -> tensor<1x2048xf32>
    %4720 = stablehlo.slice %4718 [1:2, 0:2048] : (tensor<2x2048xf32>) -> tensor<1x2048xf32>
    %cst_257 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4721 = stablehlo.reduce(%4720 init: %cst_257) applies stablehlo.add across dimensions = [0] : (tensor<1x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %4722 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %4723 = stablehlo.divide %4721, %4722 : tensor<2048xf32>
    %4724 = stablehlo.broadcast_in_dim %4723, dims = [3] : (tensor<2048xf32>) -> tensor<256x7x7x2048xf32>
    %4725 = stablehlo.multiply %4724, %3293 : tensor<256x7x7x2048xf32>
    %cst_258 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4726 = stablehlo.reduce(%4719 init: %cst_258) applies stablehlo.add across dimensions = [0] : (tensor<1x2048xf32>, tensor<f32>) -> tensor<2048xf32>
    %4727 = stablehlo.broadcast_in_dim %cst_110, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %4728 = stablehlo.divide %4726, %4727 : tensor<2048xf32>
    %4729 = stablehlo.broadcast_in_dim %4728, dims = [3] : (tensor<2048xf32>) -> tensor<256x7x7x2048xf32>
    %4730 = stablehlo.add %4725, %4729 : tensor<256x7x7x2048xf32>
    %4731 = stablehlo.convert %4730 : (tensor<256x7x7x2048xf32>) -> tensor<256x7x7x2048xf16>
    %4732 = stablehlo.add %4710, %4731 : tensor<256x7x7x2048xf16>
    %4733 = stablehlo.convolution(%3075, %4732) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, -1], [0, -1]], lhs_dilate = [1, 1], rhs_dilate = [2, 2], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x1024xf16>, tensor<256x7x7x2048xf16>) -> tensor<1x1x1024x2048xf16>
    %4734 = stablehlo.convert %4733 : (tensor<1x1x1024x2048xf16>) -> tensor<1x1x1024x2048xf32>
    %4735 = stablehlo.add %4158, %4734 : tensor<1x1x1024x2048xf32>
    %4736 = stablehlo.reverse %3288, dims = [0, 1] : tensor<1x1x1024x2048xf16>
    %4737 = stablehlo.convolution(%4732, %4736) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 1], [0, 1]], lhs_dilate = [2, 2], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x7x7x2048xf16>, tensor<1x1x1024x2048xf16>) -> tensor<256x14x14x1024xf16>
    %4738 = stablehlo.add %4687, %4737 : tensor<256x14x14x1024xf16>
    %4739 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x1024xf16>
    %4740 = stablehlo.select %3077, %4738, %4739 : tensor<256x14x14x1024xi1>, tensor<256x14x14x1024xf16>
    %4741 = stablehlo.convert %4740 : (tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xf32>
    %cst_259 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4742 = stablehlo.reduce(%4741 init: %cst_259) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %4743 = stablehlo.reshape %4742 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %4744 = stablehlo.reshape %4743 : (tensor<1x1x1x1024xf32>) -> tensor<1024xf32>
    %4745 = stablehlo.multiply %3059, %4741 : tensor<256x14x14x1024xf32>
    %cst_260 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4746 = stablehlo.reduce(%4745 init: %cst_260) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %4747 = stablehlo.reshape %4746 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %4748 = stablehlo.broadcast_in_dim %3067, dims = [0, 1, 2, 3] : (tensor<1x1x1x1024xf32>) -> tensor<256x14x14x1024xf32>
    %4749 = stablehlo.multiply %4741, %4748 : tensor<256x14x14x1024xf32>
    %4750 = stablehlo.multiply %3062, %4747 : tensor<1x1x1x1024xf32>
    %4751 = stablehlo.multiply %4747, %3066 : tensor<1x1x1x1024xf32>
    %4752 = stablehlo.reshape %4750 : (tensor<1x1x1x1024xf32>) -> tensor<1024xf32>
    %4753 = stablehlo.multiply %4751, %3065 : tensor<1x1x1x1024xf32>
    %cst_261 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4754 = stablehlo.reduce(%4753 init: %cst_261) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %4755 = stablehlo.multiply %4754, %3044 : tensor<1024xf32>
    %4756 = stablehlo.negate %4755 : tensor<1024xf32>
    %4757 = stablehlo.multiply %4756, %3031 : tensor<1024xf32>
    %4758 = stablehlo.broadcast_in_dim %4755, dims = [1] : (tensor<1024xf32>) -> tensor<1x1024xf32>
    %4759 = stablehlo.pad %4758, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x1024xf32>, tensor<f32>) -> tensor<2x1024xf32>
    %4760 = stablehlo.negate %4749 : tensor<256x14x14x1024xf32>
    %cst_262 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4761 = stablehlo.reduce(%4760 init: %cst_262) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %4762 = stablehlo.reshape %4761 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %4763 = stablehlo.convert %4749 : (tensor<256x14x14x1024xf32>) -> tensor<256x14x14x1024xf16>
    %cst_263 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4764 = stablehlo.reduce(%4762 init: %cst_263) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %4765 = stablehlo.add %4757, %4764 : tensor<1024xf32>
    %4766 = stablehlo.broadcast_in_dim %4765, dims = [1] : (tensor<1024xf32>) -> tensor<1x1024xf32>
    %4767 = stablehlo.pad %4766, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x1024xf32>, tensor<f32>) -> tensor<2x1024xf32>
    %4768 = stablehlo.add %4759, %4767 : tensor<2x1024xf32>
    %4769 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x1024xf32>
    %4770 = stablehlo.divide %4768, %4769 : tensor<2x1024xf32>
    %4771 = "stablehlo.all_reduce"(%4770) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x1024xf32>) -> tensor<2x1024xf32>
    %4772 = stablehlo.slice %4771 [0:1, 0:1024] : (tensor<2x1024xf32>) -> tensor<1x1024xf32>
    %4773 = stablehlo.slice %4771 [1:2, 0:1024] : (tensor<2x1024xf32>) -> tensor<1x1024xf32>
    %cst_264 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4774 = stablehlo.reduce(%4773 init: %cst_264) applies stablehlo.add across dimensions = [0] : (tensor<1x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %4775 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %4776 = stablehlo.divide %4774, %4775 : tensor<1024xf32>
    %4777 = stablehlo.broadcast_in_dim %4776, dims = [3] : (tensor<1024xf32>) -> tensor<256x14x14x1024xf32>
    %4778 = stablehlo.multiply %4777, %3012 : tensor<256x14x14x1024xf32>
    %cst_265 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4779 = stablehlo.reduce(%4772 init: %cst_265) applies stablehlo.add across dimensions = [0] : (tensor<1x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %4780 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %4781 = stablehlo.divide %4779, %4780 : tensor<1024xf32>
    %4782 = stablehlo.broadcast_in_dim %4781, dims = [3] : (tensor<1024xf32>) -> tensor<256x14x14x1024xf32>
    %4783 = stablehlo.add %4778, %4782 : tensor<256x14x14x1024xf32>
    %4784 = stablehlo.convert %4783 : (tensor<256x14x14x1024xf32>) -> tensor<256x14x14x1024xf16>
    %4785 = stablehlo.add %4763, %4784 : tensor<256x14x14x1024xf16>
    %4786 = stablehlo.convolution(%3003, %4785) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x256xf16>, tensor<256x14x14x1024xf16>) -> tensor<1x1x256x1024xf16>
    %4787 = stablehlo.convert %4786 : (tensor<1x1x256x1024xf16>) -> tensor<1x1x256x1024xf32>
    %4788 = stablehlo.add %4166, %4787 : tensor<1x1x256x1024xf32>
    %4789 = stablehlo.reverse %3007, dims = [0, 1] : tensor<1x1x256x1024xf16>
    %4790 = stablehlo.convolution(%4785, %4789) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x1024xf16>, tensor<1x1x256x1024xf16>) -> tensor<256x14x14x256xf16>
    %4791 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %4792 = stablehlo.select %3005, %4790, %4791 : tensor<256x14x14x256xi1>, tensor<256x14x14x256xf16>
    %4793 = stablehlo.convert %4792 : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf32>
    %cst_266 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4794 = stablehlo.reduce(%4793 init: %cst_266) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %4795 = stablehlo.reshape %4794 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %4796 = stablehlo.reshape %4795 : (tensor<1x1x1x256xf32>) -> tensor<256xf32>
    %4797 = stablehlo.multiply %2988, %4793 : tensor<256x14x14x256xf32>
    %cst_267 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4798 = stablehlo.reduce(%4797 init: %cst_267) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %4799 = stablehlo.reshape %4798 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %4800 = stablehlo.broadcast_in_dim %2996, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %4801 = stablehlo.multiply %4793, %4800 : tensor<256x14x14x256xf32>
    %4802 = stablehlo.multiply %2991, %4799 : tensor<1x1x1x256xf32>
    %4803 = stablehlo.multiply %4799, %2995 : tensor<1x1x1x256xf32>
    %4804 = stablehlo.reshape %4802 : (tensor<1x1x1x256xf32>) -> tensor<256xf32>
    %4805 = stablehlo.multiply %4803, %2994 : tensor<1x1x1x256xf32>
    %cst_268 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4806 = stablehlo.reduce(%4805 init: %cst_268) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %4807 = stablehlo.multiply %4806, %2973 : tensor<256xf32>
    %4808 = stablehlo.negate %4807 : tensor<256xf32>
    %4809 = stablehlo.multiply %4808, %2960 : tensor<256xf32>
    %4810 = stablehlo.broadcast_in_dim %4807, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %4811 = stablehlo.pad %4810, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<2x256xf32>
    %4812 = stablehlo.negate %4801 : tensor<256x14x14x256xf32>
    %cst_269 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4813 = stablehlo.reduce(%4812 init: %cst_269) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %4814 = stablehlo.reshape %4813 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %4815 = stablehlo.convert %4801 : (tensor<256x14x14x256xf32>) -> tensor<256x14x14x256xf16>
    %cst_270 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4816 = stablehlo.reduce(%4814 init: %cst_270) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %4817 = stablehlo.add %4809, %4816 : tensor<256xf32>
    %4818 = stablehlo.broadcast_in_dim %4817, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %4819 = stablehlo.pad %4818, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<2x256xf32>
    %4820 = stablehlo.add %4811, %4819 : tensor<2x256xf32>
    %4821 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x256xf32>
    %4822 = stablehlo.divide %4820, %4821 : tensor<2x256xf32>
    %4823 = "stablehlo.all_reduce"(%4822) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x256xf32>) -> tensor<2x256xf32>
    %4824 = stablehlo.slice %4823 [0:1, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %4825 = stablehlo.slice %4823 [1:2, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %cst_271 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4826 = stablehlo.reduce(%4825 init: %cst_271) applies stablehlo.add across dimensions = [0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %4827 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %4828 = stablehlo.divide %4826, %4827 : tensor<256xf32>
    %4829 = stablehlo.broadcast_in_dim %4828, dims = [3] : (tensor<256xf32>) -> tensor<256x14x14x256xf32>
    %4830 = stablehlo.multiply %4829, %2941 : tensor<256x14x14x256xf32>
    %cst_272 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4831 = stablehlo.reduce(%4824 init: %cst_272) applies stablehlo.add across dimensions = [0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %4832 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %4833 = stablehlo.divide %4831, %4832 : tensor<256xf32>
    %4834 = stablehlo.broadcast_in_dim %4833, dims = [3] : (tensor<256xf32>) -> tensor<256x14x14x256xf32>
    %4835 = stablehlo.add %4830, %4834 : tensor<256x14x14x256xf32>
    %4836 = stablehlo.convert %4835 : (tensor<256x14x14x256xf32>) -> tensor<256x14x14x256xf16>
    %4837 = stablehlo.add %4815, %4836 : tensor<256x14x14x256xf16>
    %4838 = stablehlo.convolution(%2932, %4837) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x256xf16>, tensor<256x14x14x256xf16>) -> tensor<3x3x256x256xf16>
    %4839 = stablehlo.convert %4838 : (tensor<3x3x256x256xf16>) -> tensor<3x3x256x256xf32>
    %4840 = stablehlo.add %4168, %4839 : tensor<3x3x256x256xf32>
    %4841 = stablehlo.reverse %2936, dims = [0, 1] : tensor<3x3x256x256xf16>
    %4842 = stablehlo.convolution(%4837, %4841) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x256xf16>, tensor<3x3x256x256xf16>) -> tensor<256x14x14x256xf16>
    %4843 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %4844 = stablehlo.select %2934, %4842, %4843 : tensor<256x14x14x256xi1>, tensor<256x14x14x256xf16>
    %4845 = stablehlo.convert %4844 : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf32>
    %cst_273 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4846 = stablehlo.reduce(%4845 init: %cst_273) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %4847 = stablehlo.reshape %4846 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %4848 = stablehlo.reshape %4847 : (tensor<1x1x1x256xf32>) -> tensor<256xf32>
    %4849 = stablehlo.multiply %2917, %4845 : tensor<256x14x14x256xf32>
    %cst_274 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4850 = stablehlo.reduce(%4849 init: %cst_274) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %4851 = stablehlo.reshape %4850 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %4852 = stablehlo.broadcast_in_dim %2925, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %4853 = stablehlo.multiply %4845, %4852 : tensor<256x14x14x256xf32>
    %4854 = stablehlo.multiply %2920, %4851 : tensor<1x1x1x256xf32>
    %4855 = stablehlo.multiply %4851, %2924 : tensor<1x1x1x256xf32>
    %4856 = stablehlo.reshape %4854 : (tensor<1x1x1x256xf32>) -> tensor<256xf32>
    %4857 = stablehlo.multiply %4855, %2923 : tensor<1x1x1x256xf32>
    %cst_275 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4858 = stablehlo.reduce(%4857 init: %cst_275) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %4859 = stablehlo.multiply %4858, %2902 : tensor<256xf32>
    %4860 = stablehlo.negate %4859 : tensor<256xf32>
    %4861 = stablehlo.multiply %4860, %2889 : tensor<256xf32>
    %4862 = stablehlo.broadcast_in_dim %4859, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %4863 = stablehlo.pad %4862, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<2x256xf32>
    %4864 = stablehlo.negate %4853 : tensor<256x14x14x256xf32>
    %cst_276 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4865 = stablehlo.reduce(%4864 init: %cst_276) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %4866 = stablehlo.reshape %4865 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %4867 = stablehlo.convert %4853 : (tensor<256x14x14x256xf32>) -> tensor<256x14x14x256xf16>
    %cst_277 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4868 = stablehlo.reduce(%4866 init: %cst_277) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %4869 = stablehlo.add %4861, %4868 : tensor<256xf32>
    %4870 = stablehlo.broadcast_in_dim %4869, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %4871 = stablehlo.pad %4870, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<2x256xf32>
    %4872 = stablehlo.add %4863, %4871 : tensor<2x256xf32>
    %4873 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x256xf32>
    %4874 = stablehlo.divide %4872, %4873 : tensor<2x256xf32>
    %4875 = "stablehlo.all_reduce"(%4874) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x256xf32>) -> tensor<2x256xf32>
    %4876 = stablehlo.slice %4875 [0:1, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %4877 = stablehlo.slice %4875 [1:2, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %cst_278 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4878 = stablehlo.reduce(%4877 init: %cst_278) applies stablehlo.add across dimensions = [0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %4879 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %4880 = stablehlo.divide %4878, %4879 : tensor<256xf32>
    %4881 = stablehlo.broadcast_in_dim %4880, dims = [3] : (tensor<256xf32>) -> tensor<256x14x14x256xf32>
    %4882 = stablehlo.multiply %4881, %2870 : tensor<256x14x14x256xf32>
    %cst_279 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4883 = stablehlo.reduce(%4876 init: %cst_279) applies stablehlo.add across dimensions = [0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %4884 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %4885 = stablehlo.divide %4883, %4884 : tensor<256xf32>
    %4886 = stablehlo.broadcast_in_dim %4885, dims = [3] : (tensor<256xf32>) -> tensor<256x14x14x256xf32>
    %4887 = stablehlo.add %4882, %4886 : tensor<256x14x14x256xf32>
    %4888 = stablehlo.convert %4887 : (tensor<256x14x14x256xf32>) -> tensor<256x14x14x256xf16>
    %4889 = stablehlo.add %4867, %4888 : tensor<256x14x14x256xf16>
    %4890 = stablehlo.convolution(%2861, %4889) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x1024xf16>, tensor<256x14x14x256xf16>) -> tensor<1x1x1024x256xf16>
    %4891 = stablehlo.convert %4890 : (tensor<1x1x1024x256xf16>) -> tensor<1x1x1024x256xf32>
    %4892 = stablehlo.add %4170, %4891 : tensor<1x1x1024x256xf32>
    %4893 = stablehlo.reverse %2865, dims = [0, 1] : tensor<1x1x1024x256xf16>
    %4894 = stablehlo.convolution(%4889, %4893) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x256xf16>, tensor<1x1x1024x256xf16>) -> tensor<256x14x14x1024xf16>
    %4895 = stablehlo.add %4740, %4894 : tensor<256x14x14x1024xf16>
    %4896 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x1024xf16>
    %4897 = stablehlo.select %2863, %4895, %4896 : tensor<256x14x14x1024xi1>, tensor<256x14x14x1024xf16>
    %4898 = stablehlo.convert %4897 : (tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xf32>
    %cst_280 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4899 = stablehlo.reduce(%4898 init: %cst_280) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %4900 = stablehlo.reshape %4899 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %4901 = stablehlo.reshape %4900 : (tensor<1x1x1x1024xf32>) -> tensor<1024xf32>
    %4902 = stablehlo.multiply %2845, %4898 : tensor<256x14x14x1024xf32>
    %cst_281 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4903 = stablehlo.reduce(%4902 init: %cst_281) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %4904 = stablehlo.reshape %4903 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %4905 = stablehlo.broadcast_in_dim %2853, dims = [0, 1, 2, 3] : (tensor<1x1x1x1024xf32>) -> tensor<256x14x14x1024xf32>
    %4906 = stablehlo.multiply %4898, %4905 : tensor<256x14x14x1024xf32>
    %4907 = stablehlo.multiply %2848, %4904 : tensor<1x1x1x1024xf32>
    %4908 = stablehlo.multiply %4904, %2852 : tensor<1x1x1x1024xf32>
    %4909 = stablehlo.reshape %4907 : (tensor<1x1x1x1024xf32>) -> tensor<1024xf32>
    %4910 = stablehlo.multiply %4908, %2851 : tensor<1x1x1x1024xf32>
    %cst_282 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4911 = stablehlo.reduce(%4910 init: %cst_282) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %4912 = stablehlo.multiply %4911, %2830 : tensor<1024xf32>
    %4913 = stablehlo.negate %4912 : tensor<1024xf32>
    %4914 = stablehlo.multiply %4913, %2817 : tensor<1024xf32>
    %4915 = stablehlo.broadcast_in_dim %4912, dims = [1] : (tensor<1024xf32>) -> tensor<1x1024xf32>
    %4916 = stablehlo.pad %4915, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x1024xf32>, tensor<f32>) -> tensor<2x1024xf32>
    %4917 = stablehlo.negate %4906 : tensor<256x14x14x1024xf32>
    %cst_283 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4918 = stablehlo.reduce(%4917 init: %cst_283) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %4919 = stablehlo.reshape %4918 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %4920 = stablehlo.convert %4906 : (tensor<256x14x14x1024xf32>) -> tensor<256x14x14x1024xf16>
    %cst_284 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4921 = stablehlo.reduce(%4919 init: %cst_284) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %4922 = stablehlo.add %4914, %4921 : tensor<1024xf32>
    %4923 = stablehlo.broadcast_in_dim %4922, dims = [1] : (tensor<1024xf32>) -> tensor<1x1024xf32>
    %4924 = stablehlo.pad %4923, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x1024xf32>, tensor<f32>) -> tensor<2x1024xf32>
    %4925 = stablehlo.add %4916, %4924 : tensor<2x1024xf32>
    %4926 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x1024xf32>
    %4927 = stablehlo.divide %4925, %4926 : tensor<2x1024xf32>
    %4928 = "stablehlo.all_reduce"(%4927) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x1024xf32>) -> tensor<2x1024xf32>
    %4929 = stablehlo.slice %4928 [0:1, 0:1024] : (tensor<2x1024xf32>) -> tensor<1x1024xf32>
    %4930 = stablehlo.slice %4928 [1:2, 0:1024] : (tensor<2x1024xf32>) -> tensor<1x1024xf32>
    %cst_285 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4931 = stablehlo.reduce(%4930 init: %cst_285) applies stablehlo.add across dimensions = [0] : (tensor<1x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %4932 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %4933 = stablehlo.divide %4931, %4932 : tensor<1024xf32>
    %4934 = stablehlo.broadcast_in_dim %4933, dims = [3] : (tensor<1024xf32>) -> tensor<256x14x14x1024xf32>
    %4935 = stablehlo.multiply %4934, %2798 : tensor<256x14x14x1024xf32>
    %cst_286 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4936 = stablehlo.reduce(%4929 init: %cst_286) applies stablehlo.add across dimensions = [0] : (tensor<1x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %4937 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %4938 = stablehlo.divide %4936, %4937 : tensor<1024xf32>
    %4939 = stablehlo.broadcast_in_dim %4938, dims = [3] : (tensor<1024xf32>) -> tensor<256x14x14x1024xf32>
    %4940 = stablehlo.add %4935, %4939 : tensor<256x14x14x1024xf32>
    %4941 = stablehlo.convert %4940 : (tensor<256x14x14x1024xf32>) -> tensor<256x14x14x1024xf16>
    %4942 = stablehlo.add %4920, %4941 : tensor<256x14x14x1024xf16>
    %4943 = stablehlo.convolution(%2789, %4942) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x256xf16>, tensor<256x14x14x1024xf16>) -> tensor<1x1x256x1024xf16>
    %4944 = stablehlo.convert %4943 : (tensor<1x1x256x1024xf16>) -> tensor<1x1x256x1024xf32>
    %4945 = stablehlo.add %4172, %4944 : tensor<1x1x256x1024xf32>
    %4946 = stablehlo.reverse %2793, dims = [0, 1] : tensor<1x1x256x1024xf16>
    %4947 = stablehlo.convolution(%4942, %4946) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x1024xf16>, tensor<1x1x256x1024xf16>) -> tensor<256x14x14x256xf16>
    %4948 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %4949 = stablehlo.select %2791, %4947, %4948 : tensor<256x14x14x256xi1>, tensor<256x14x14x256xf16>
    %4950 = stablehlo.convert %4949 : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf32>
    %cst_287 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4951 = stablehlo.reduce(%4950 init: %cst_287) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %4952 = stablehlo.reshape %4951 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %4953 = stablehlo.reshape %4952 : (tensor<1x1x1x256xf32>) -> tensor<256xf32>
    %4954 = stablehlo.multiply %2774, %4950 : tensor<256x14x14x256xf32>
    %cst_288 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4955 = stablehlo.reduce(%4954 init: %cst_288) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %4956 = stablehlo.reshape %4955 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %4957 = stablehlo.broadcast_in_dim %2782, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %4958 = stablehlo.multiply %4950, %4957 : tensor<256x14x14x256xf32>
    %4959 = stablehlo.multiply %2777, %4956 : tensor<1x1x1x256xf32>
    %4960 = stablehlo.multiply %4956, %2781 : tensor<1x1x1x256xf32>
    %4961 = stablehlo.reshape %4959 : (tensor<1x1x1x256xf32>) -> tensor<256xf32>
    %4962 = stablehlo.multiply %4960, %2780 : tensor<1x1x1x256xf32>
    %cst_289 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4963 = stablehlo.reduce(%4962 init: %cst_289) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %4964 = stablehlo.multiply %4963, %2759 : tensor<256xf32>
    %4965 = stablehlo.negate %4964 : tensor<256xf32>
    %4966 = stablehlo.multiply %4965, %2746 : tensor<256xf32>
    %4967 = stablehlo.broadcast_in_dim %4964, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %4968 = stablehlo.pad %4967, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<2x256xf32>
    %4969 = stablehlo.negate %4958 : tensor<256x14x14x256xf32>
    %cst_290 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4970 = stablehlo.reduce(%4969 init: %cst_290) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %4971 = stablehlo.reshape %4970 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %4972 = stablehlo.convert %4958 : (tensor<256x14x14x256xf32>) -> tensor<256x14x14x256xf16>
    %cst_291 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4973 = stablehlo.reduce(%4971 init: %cst_291) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %4974 = stablehlo.add %4966, %4973 : tensor<256xf32>
    %4975 = stablehlo.broadcast_in_dim %4974, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %4976 = stablehlo.pad %4975, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<2x256xf32>
    %4977 = stablehlo.add %4968, %4976 : tensor<2x256xf32>
    %4978 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x256xf32>
    %4979 = stablehlo.divide %4977, %4978 : tensor<2x256xf32>
    %4980 = "stablehlo.all_reduce"(%4979) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x256xf32>) -> tensor<2x256xf32>
    %4981 = stablehlo.slice %4980 [0:1, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %4982 = stablehlo.slice %4980 [1:2, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %cst_292 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4983 = stablehlo.reduce(%4982 init: %cst_292) applies stablehlo.add across dimensions = [0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %4984 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %4985 = stablehlo.divide %4983, %4984 : tensor<256xf32>
    %4986 = stablehlo.broadcast_in_dim %4985, dims = [3] : (tensor<256xf32>) -> tensor<256x14x14x256xf32>
    %4987 = stablehlo.multiply %4986, %2727 : tensor<256x14x14x256xf32>
    %cst_293 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %4988 = stablehlo.reduce(%4981 init: %cst_293) applies stablehlo.add across dimensions = [0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %4989 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %4990 = stablehlo.divide %4988, %4989 : tensor<256xf32>
    %4991 = stablehlo.broadcast_in_dim %4990, dims = [3] : (tensor<256xf32>) -> tensor<256x14x14x256xf32>
    %4992 = stablehlo.add %4987, %4991 : tensor<256x14x14x256xf32>
    %4993 = stablehlo.convert %4992 : (tensor<256x14x14x256xf32>) -> tensor<256x14x14x256xf16>
    %4994 = stablehlo.add %4972, %4993 : tensor<256x14x14x256xf16>
    %4995 = stablehlo.convolution(%2718, %4994) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x256xf16>, tensor<256x14x14x256xf16>) -> tensor<3x3x256x256xf16>
    %4996 = stablehlo.convert %4995 : (tensor<3x3x256x256xf16>) -> tensor<3x3x256x256xf32>
    %4997 = stablehlo.add %4174, %4996 : tensor<3x3x256x256xf32>
    %4998 = stablehlo.reverse %2722, dims = [0, 1] : tensor<3x3x256x256xf16>
    %4999 = stablehlo.convolution(%4994, %4998) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x256xf16>, tensor<3x3x256x256xf16>) -> tensor<256x14x14x256xf16>
    %5000 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %5001 = stablehlo.select %2720, %4999, %5000 : tensor<256x14x14x256xi1>, tensor<256x14x14x256xf16>
    %5002 = stablehlo.convert %5001 : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf32>
    %cst_294 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5003 = stablehlo.reduce(%5002 init: %cst_294) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5004 = stablehlo.reshape %5003 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %5005 = stablehlo.reshape %5004 : (tensor<1x1x1x256xf32>) -> tensor<256xf32>
    %5006 = stablehlo.multiply %2703, %5002 : tensor<256x14x14x256xf32>
    %cst_295 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5007 = stablehlo.reduce(%5006 init: %cst_295) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5008 = stablehlo.reshape %5007 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %5009 = stablehlo.broadcast_in_dim %2711, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %5010 = stablehlo.multiply %5002, %5009 : tensor<256x14x14x256xf32>
    %5011 = stablehlo.multiply %2706, %5008 : tensor<1x1x1x256xf32>
    %5012 = stablehlo.multiply %5008, %2710 : tensor<1x1x1x256xf32>
    %5013 = stablehlo.reshape %5011 : (tensor<1x1x1x256xf32>) -> tensor<256xf32>
    %5014 = stablehlo.multiply %5012, %2709 : tensor<1x1x1x256xf32>
    %cst_296 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5015 = stablehlo.reduce(%5014 init: %cst_296) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5016 = stablehlo.multiply %5015, %2688 : tensor<256xf32>
    %5017 = stablehlo.negate %5016 : tensor<256xf32>
    %5018 = stablehlo.multiply %5017, %2675 : tensor<256xf32>
    %5019 = stablehlo.broadcast_in_dim %5016, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %5020 = stablehlo.pad %5019, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<2x256xf32>
    %5021 = stablehlo.negate %5010 : tensor<256x14x14x256xf32>
    %cst_297 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5022 = stablehlo.reduce(%5021 init: %cst_297) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5023 = stablehlo.reshape %5022 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %5024 = stablehlo.convert %5010 : (tensor<256x14x14x256xf32>) -> tensor<256x14x14x256xf16>
    %cst_298 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5025 = stablehlo.reduce(%5023 init: %cst_298) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5026 = stablehlo.add %5018, %5025 : tensor<256xf32>
    %5027 = stablehlo.broadcast_in_dim %5026, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %5028 = stablehlo.pad %5027, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<2x256xf32>
    %5029 = stablehlo.add %5020, %5028 : tensor<2x256xf32>
    %5030 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x256xf32>
    %5031 = stablehlo.divide %5029, %5030 : tensor<2x256xf32>
    %5032 = "stablehlo.all_reduce"(%5031) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x256xf32>) -> tensor<2x256xf32>
    %5033 = stablehlo.slice %5032 [0:1, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %5034 = stablehlo.slice %5032 [1:2, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %cst_299 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5035 = stablehlo.reduce(%5034 init: %cst_299) applies stablehlo.add across dimensions = [0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5036 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %5037 = stablehlo.divide %5035, %5036 : tensor<256xf32>
    %5038 = stablehlo.broadcast_in_dim %5037, dims = [3] : (tensor<256xf32>) -> tensor<256x14x14x256xf32>
    %5039 = stablehlo.multiply %5038, %2656 : tensor<256x14x14x256xf32>
    %cst_300 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5040 = stablehlo.reduce(%5033 init: %cst_300) applies stablehlo.add across dimensions = [0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5041 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %5042 = stablehlo.divide %5040, %5041 : tensor<256xf32>
    %5043 = stablehlo.broadcast_in_dim %5042, dims = [3] : (tensor<256xf32>) -> tensor<256x14x14x256xf32>
    %5044 = stablehlo.add %5039, %5043 : tensor<256x14x14x256xf32>
    %5045 = stablehlo.convert %5044 : (tensor<256x14x14x256xf32>) -> tensor<256x14x14x256xf16>
    %5046 = stablehlo.add %5024, %5045 : tensor<256x14x14x256xf16>
    %5047 = stablehlo.convolution(%2647, %5046) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x1024xf16>, tensor<256x14x14x256xf16>) -> tensor<1x1x1024x256xf16>
    %5048 = stablehlo.convert %5047 : (tensor<1x1x1024x256xf16>) -> tensor<1x1x1024x256xf32>
    %5049 = stablehlo.add %4176, %5048 : tensor<1x1x1024x256xf32>
    %5050 = stablehlo.reverse %2651, dims = [0, 1] : tensor<1x1x1024x256xf16>
    %5051 = stablehlo.convolution(%5046, %5050) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x256xf16>, tensor<1x1x1024x256xf16>) -> tensor<256x14x14x1024xf16>
    %5052 = stablehlo.add %4897, %5051 : tensor<256x14x14x1024xf16>
    %5053 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x1024xf16>
    %5054 = stablehlo.select %2649, %5052, %5053 : tensor<256x14x14x1024xi1>, tensor<256x14x14x1024xf16>
    %5055 = stablehlo.convert %5054 : (tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xf32>
    %cst_301 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5056 = stablehlo.reduce(%5055 init: %cst_301) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5057 = stablehlo.reshape %5056 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %5058 = stablehlo.reshape %5057 : (tensor<1x1x1x1024xf32>) -> tensor<1024xf32>
    %5059 = stablehlo.multiply %2631, %5055 : tensor<256x14x14x1024xf32>
    %cst_302 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5060 = stablehlo.reduce(%5059 init: %cst_302) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5061 = stablehlo.reshape %5060 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %5062 = stablehlo.broadcast_in_dim %2639, dims = [0, 1, 2, 3] : (tensor<1x1x1x1024xf32>) -> tensor<256x14x14x1024xf32>
    %5063 = stablehlo.multiply %5055, %5062 : tensor<256x14x14x1024xf32>
    %5064 = stablehlo.multiply %2634, %5061 : tensor<1x1x1x1024xf32>
    %5065 = stablehlo.multiply %5061, %2638 : tensor<1x1x1x1024xf32>
    %5066 = stablehlo.reshape %5064 : (tensor<1x1x1x1024xf32>) -> tensor<1024xf32>
    %5067 = stablehlo.multiply %5065, %2637 : tensor<1x1x1x1024xf32>
    %cst_303 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5068 = stablehlo.reduce(%5067 init: %cst_303) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5069 = stablehlo.multiply %5068, %2616 : tensor<1024xf32>
    %5070 = stablehlo.negate %5069 : tensor<1024xf32>
    %5071 = stablehlo.multiply %5070, %2603 : tensor<1024xf32>
    %5072 = stablehlo.broadcast_in_dim %5069, dims = [1] : (tensor<1024xf32>) -> tensor<1x1024xf32>
    %5073 = stablehlo.pad %5072, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x1024xf32>, tensor<f32>) -> tensor<2x1024xf32>
    %5074 = stablehlo.negate %5063 : tensor<256x14x14x1024xf32>
    %cst_304 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5075 = stablehlo.reduce(%5074 init: %cst_304) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5076 = stablehlo.reshape %5075 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %5077 = stablehlo.convert %5063 : (tensor<256x14x14x1024xf32>) -> tensor<256x14x14x1024xf16>
    %cst_305 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5078 = stablehlo.reduce(%5076 init: %cst_305) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5079 = stablehlo.add %5071, %5078 : tensor<1024xf32>
    %5080 = stablehlo.broadcast_in_dim %5079, dims = [1] : (tensor<1024xf32>) -> tensor<1x1024xf32>
    %5081 = stablehlo.pad %5080, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x1024xf32>, tensor<f32>) -> tensor<2x1024xf32>
    %5082 = stablehlo.add %5073, %5081 : tensor<2x1024xf32>
    %5083 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x1024xf32>
    %5084 = stablehlo.divide %5082, %5083 : tensor<2x1024xf32>
    %5085 = "stablehlo.all_reduce"(%5084) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x1024xf32>) -> tensor<2x1024xf32>
    %5086 = stablehlo.slice %5085 [0:1, 0:1024] : (tensor<2x1024xf32>) -> tensor<1x1024xf32>
    %5087 = stablehlo.slice %5085 [1:2, 0:1024] : (tensor<2x1024xf32>) -> tensor<1x1024xf32>
    %cst_306 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5088 = stablehlo.reduce(%5087 init: %cst_306) applies stablehlo.add across dimensions = [0] : (tensor<1x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5089 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %5090 = stablehlo.divide %5088, %5089 : tensor<1024xf32>
    %5091 = stablehlo.broadcast_in_dim %5090, dims = [3] : (tensor<1024xf32>) -> tensor<256x14x14x1024xf32>
    %5092 = stablehlo.multiply %5091, %2584 : tensor<256x14x14x1024xf32>
    %cst_307 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5093 = stablehlo.reduce(%5086 init: %cst_307) applies stablehlo.add across dimensions = [0] : (tensor<1x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5094 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %5095 = stablehlo.divide %5093, %5094 : tensor<1024xf32>
    %5096 = stablehlo.broadcast_in_dim %5095, dims = [3] : (tensor<1024xf32>) -> tensor<256x14x14x1024xf32>
    %5097 = stablehlo.add %5092, %5096 : tensor<256x14x14x1024xf32>
    %5098 = stablehlo.convert %5097 : (tensor<256x14x14x1024xf32>) -> tensor<256x14x14x1024xf16>
    %5099 = stablehlo.add %5077, %5098 : tensor<256x14x14x1024xf16>
    %5100 = stablehlo.convolution(%2575, %5099) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x256xf16>, tensor<256x14x14x1024xf16>) -> tensor<1x1x256x1024xf16>
    %5101 = stablehlo.convert %5100 : (tensor<1x1x256x1024xf16>) -> tensor<1x1x256x1024xf32>
    %5102 = stablehlo.add %4178, %5101 : tensor<1x1x256x1024xf32>
    %5103 = stablehlo.reverse %2579, dims = [0, 1] : tensor<1x1x256x1024xf16>
    %5104 = stablehlo.convolution(%5099, %5103) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x1024xf16>, tensor<1x1x256x1024xf16>) -> tensor<256x14x14x256xf16>
    %5105 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %5106 = stablehlo.select %2577, %5104, %5105 : tensor<256x14x14x256xi1>, tensor<256x14x14x256xf16>
    %5107 = stablehlo.convert %5106 : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf32>
    %cst_308 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5108 = stablehlo.reduce(%5107 init: %cst_308) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5109 = stablehlo.reshape %5108 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %5110 = stablehlo.reshape %5109 : (tensor<1x1x1x256xf32>) -> tensor<256xf32>
    %5111 = stablehlo.multiply %2560, %5107 : tensor<256x14x14x256xf32>
    %cst_309 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5112 = stablehlo.reduce(%5111 init: %cst_309) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5113 = stablehlo.reshape %5112 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %5114 = stablehlo.broadcast_in_dim %2568, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %5115 = stablehlo.multiply %5107, %5114 : tensor<256x14x14x256xf32>
    %5116 = stablehlo.multiply %2563, %5113 : tensor<1x1x1x256xf32>
    %5117 = stablehlo.multiply %5113, %2567 : tensor<1x1x1x256xf32>
    %5118 = stablehlo.reshape %5116 : (tensor<1x1x1x256xf32>) -> tensor<256xf32>
    %5119 = stablehlo.multiply %5117, %2566 : tensor<1x1x1x256xf32>
    %cst_310 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5120 = stablehlo.reduce(%5119 init: %cst_310) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5121 = stablehlo.multiply %5120, %2545 : tensor<256xf32>
    %5122 = stablehlo.negate %5121 : tensor<256xf32>
    %5123 = stablehlo.multiply %5122, %2532 : tensor<256xf32>
    %5124 = stablehlo.broadcast_in_dim %5121, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %5125 = stablehlo.pad %5124, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<2x256xf32>
    %5126 = stablehlo.negate %5115 : tensor<256x14x14x256xf32>
    %cst_311 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5127 = stablehlo.reduce(%5126 init: %cst_311) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5128 = stablehlo.reshape %5127 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %5129 = stablehlo.convert %5115 : (tensor<256x14x14x256xf32>) -> tensor<256x14x14x256xf16>
    %cst_312 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5130 = stablehlo.reduce(%5128 init: %cst_312) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5131 = stablehlo.add %5123, %5130 : tensor<256xf32>
    %5132 = stablehlo.broadcast_in_dim %5131, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %5133 = stablehlo.pad %5132, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<2x256xf32>
    %5134 = stablehlo.add %5125, %5133 : tensor<2x256xf32>
    %5135 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x256xf32>
    %5136 = stablehlo.divide %5134, %5135 : tensor<2x256xf32>
    %5137 = "stablehlo.all_reduce"(%5136) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x256xf32>) -> tensor<2x256xf32>
    %5138 = stablehlo.slice %5137 [0:1, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %5139 = stablehlo.slice %5137 [1:2, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %cst_313 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5140 = stablehlo.reduce(%5139 init: %cst_313) applies stablehlo.add across dimensions = [0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5141 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %5142 = stablehlo.divide %5140, %5141 : tensor<256xf32>
    %5143 = stablehlo.broadcast_in_dim %5142, dims = [3] : (tensor<256xf32>) -> tensor<256x14x14x256xf32>
    %5144 = stablehlo.multiply %5143, %2513 : tensor<256x14x14x256xf32>
    %cst_314 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5145 = stablehlo.reduce(%5138 init: %cst_314) applies stablehlo.add across dimensions = [0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5146 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %5147 = stablehlo.divide %5145, %5146 : tensor<256xf32>
    %5148 = stablehlo.broadcast_in_dim %5147, dims = [3] : (tensor<256xf32>) -> tensor<256x14x14x256xf32>
    %5149 = stablehlo.add %5144, %5148 : tensor<256x14x14x256xf32>
    %5150 = stablehlo.convert %5149 : (tensor<256x14x14x256xf32>) -> tensor<256x14x14x256xf16>
    %5151 = stablehlo.add %5129, %5150 : tensor<256x14x14x256xf16>
    %5152 = stablehlo.convolution(%2504, %5151) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x256xf16>, tensor<256x14x14x256xf16>) -> tensor<3x3x256x256xf16>
    %5153 = stablehlo.convert %5152 : (tensor<3x3x256x256xf16>) -> tensor<3x3x256x256xf32>
    %5154 = stablehlo.add %4180, %5153 : tensor<3x3x256x256xf32>
    %5155 = stablehlo.reverse %2508, dims = [0, 1] : tensor<3x3x256x256xf16>
    %5156 = stablehlo.convolution(%5151, %5155) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x256xf16>, tensor<3x3x256x256xf16>) -> tensor<256x14x14x256xf16>
    %5157 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %5158 = stablehlo.select %2506, %5156, %5157 : tensor<256x14x14x256xi1>, tensor<256x14x14x256xf16>
    %5159 = stablehlo.convert %5158 : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf32>
    %cst_315 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5160 = stablehlo.reduce(%5159 init: %cst_315) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5161 = stablehlo.reshape %5160 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %5162 = stablehlo.reshape %5161 : (tensor<1x1x1x256xf32>) -> tensor<256xf32>
    %5163 = stablehlo.multiply %2489, %5159 : tensor<256x14x14x256xf32>
    %cst_316 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5164 = stablehlo.reduce(%5163 init: %cst_316) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5165 = stablehlo.reshape %5164 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %5166 = stablehlo.broadcast_in_dim %2497, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %5167 = stablehlo.multiply %5159, %5166 : tensor<256x14x14x256xf32>
    %5168 = stablehlo.multiply %2492, %5165 : tensor<1x1x1x256xf32>
    %5169 = stablehlo.multiply %5165, %2496 : tensor<1x1x1x256xf32>
    %5170 = stablehlo.reshape %5168 : (tensor<1x1x1x256xf32>) -> tensor<256xf32>
    %5171 = stablehlo.multiply %5169, %2495 : tensor<1x1x1x256xf32>
    %cst_317 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5172 = stablehlo.reduce(%5171 init: %cst_317) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5173 = stablehlo.multiply %5172, %2474 : tensor<256xf32>
    %5174 = stablehlo.negate %5173 : tensor<256xf32>
    %5175 = stablehlo.multiply %5174, %2461 : tensor<256xf32>
    %5176 = stablehlo.broadcast_in_dim %5173, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %5177 = stablehlo.pad %5176, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<2x256xf32>
    %5178 = stablehlo.negate %5167 : tensor<256x14x14x256xf32>
    %cst_318 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5179 = stablehlo.reduce(%5178 init: %cst_318) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5180 = stablehlo.reshape %5179 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %5181 = stablehlo.convert %5167 : (tensor<256x14x14x256xf32>) -> tensor<256x14x14x256xf16>
    %cst_319 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5182 = stablehlo.reduce(%5180 init: %cst_319) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5183 = stablehlo.add %5175, %5182 : tensor<256xf32>
    %5184 = stablehlo.broadcast_in_dim %5183, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %5185 = stablehlo.pad %5184, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<2x256xf32>
    %5186 = stablehlo.add %5177, %5185 : tensor<2x256xf32>
    %5187 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x256xf32>
    %5188 = stablehlo.divide %5186, %5187 : tensor<2x256xf32>
    %5189 = "stablehlo.all_reduce"(%5188) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x256xf32>) -> tensor<2x256xf32>
    %5190 = stablehlo.slice %5189 [0:1, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %5191 = stablehlo.slice %5189 [1:2, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %cst_320 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5192 = stablehlo.reduce(%5191 init: %cst_320) applies stablehlo.add across dimensions = [0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5193 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %5194 = stablehlo.divide %5192, %5193 : tensor<256xf32>
    %5195 = stablehlo.broadcast_in_dim %5194, dims = [3] : (tensor<256xf32>) -> tensor<256x14x14x256xf32>
    %5196 = stablehlo.multiply %5195, %2442 : tensor<256x14x14x256xf32>
    %cst_321 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5197 = stablehlo.reduce(%5190 init: %cst_321) applies stablehlo.add across dimensions = [0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5198 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %5199 = stablehlo.divide %5197, %5198 : tensor<256xf32>
    %5200 = stablehlo.broadcast_in_dim %5199, dims = [3] : (tensor<256xf32>) -> tensor<256x14x14x256xf32>
    %5201 = stablehlo.add %5196, %5200 : tensor<256x14x14x256xf32>
    %5202 = stablehlo.convert %5201 : (tensor<256x14x14x256xf32>) -> tensor<256x14x14x256xf16>
    %5203 = stablehlo.add %5181, %5202 : tensor<256x14x14x256xf16>
    %5204 = stablehlo.convolution(%2433, %5203) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x1024xf16>, tensor<256x14x14x256xf16>) -> tensor<1x1x1024x256xf16>
    %5205 = stablehlo.convert %5204 : (tensor<1x1x1024x256xf16>) -> tensor<1x1x1024x256xf32>
    %5206 = stablehlo.add %4182, %5205 : tensor<1x1x1024x256xf32>
    %5207 = stablehlo.reverse %2437, dims = [0, 1] : tensor<1x1x1024x256xf16>
    %5208 = stablehlo.convolution(%5203, %5207) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x256xf16>, tensor<1x1x1024x256xf16>) -> tensor<256x14x14x1024xf16>
    %5209 = stablehlo.add %5054, %5208 : tensor<256x14x14x1024xf16>
    %5210 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x1024xf16>
    %5211 = stablehlo.select %2435, %5209, %5210 : tensor<256x14x14x1024xi1>, tensor<256x14x14x1024xf16>
    %5212 = stablehlo.convert %5211 : (tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xf32>
    %cst_322 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5213 = stablehlo.reduce(%5212 init: %cst_322) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5214 = stablehlo.reshape %5213 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %5215 = stablehlo.reshape %5214 : (tensor<1x1x1x1024xf32>) -> tensor<1024xf32>
    %5216 = stablehlo.multiply %2417, %5212 : tensor<256x14x14x1024xf32>
    %cst_323 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5217 = stablehlo.reduce(%5216 init: %cst_323) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5218 = stablehlo.reshape %5217 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %5219 = stablehlo.broadcast_in_dim %2425, dims = [0, 1, 2, 3] : (tensor<1x1x1x1024xf32>) -> tensor<256x14x14x1024xf32>
    %5220 = stablehlo.multiply %5212, %5219 : tensor<256x14x14x1024xf32>
    %5221 = stablehlo.multiply %2420, %5218 : tensor<1x1x1x1024xf32>
    %5222 = stablehlo.multiply %5218, %2424 : tensor<1x1x1x1024xf32>
    %5223 = stablehlo.reshape %5221 : (tensor<1x1x1x1024xf32>) -> tensor<1024xf32>
    %5224 = stablehlo.multiply %5222, %2423 : tensor<1x1x1x1024xf32>
    %cst_324 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5225 = stablehlo.reduce(%5224 init: %cst_324) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5226 = stablehlo.multiply %5225, %2402 : tensor<1024xf32>
    %5227 = stablehlo.negate %5226 : tensor<1024xf32>
    %5228 = stablehlo.multiply %5227, %2389 : tensor<1024xf32>
    %5229 = stablehlo.broadcast_in_dim %5226, dims = [1] : (tensor<1024xf32>) -> tensor<1x1024xf32>
    %5230 = stablehlo.pad %5229, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x1024xf32>, tensor<f32>) -> tensor<2x1024xf32>
    %5231 = stablehlo.negate %5220 : tensor<256x14x14x1024xf32>
    %cst_325 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5232 = stablehlo.reduce(%5231 init: %cst_325) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5233 = stablehlo.reshape %5232 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %5234 = stablehlo.convert %5220 : (tensor<256x14x14x1024xf32>) -> tensor<256x14x14x1024xf16>
    %cst_326 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5235 = stablehlo.reduce(%5233 init: %cst_326) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5236 = stablehlo.add %5228, %5235 : tensor<1024xf32>
    %5237 = stablehlo.broadcast_in_dim %5236, dims = [1] : (tensor<1024xf32>) -> tensor<1x1024xf32>
    %5238 = stablehlo.pad %5237, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x1024xf32>, tensor<f32>) -> tensor<2x1024xf32>
    %5239 = stablehlo.add %5230, %5238 : tensor<2x1024xf32>
    %5240 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x1024xf32>
    %5241 = stablehlo.divide %5239, %5240 : tensor<2x1024xf32>
    %5242 = "stablehlo.all_reduce"(%5241) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x1024xf32>) -> tensor<2x1024xf32>
    %5243 = stablehlo.slice %5242 [0:1, 0:1024] : (tensor<2x1024xf32>) -> tensor<1x1024xf32>
    %5244 = stablehlo.slice %5242 [1:2, 0:1024] : (tensor<2x1024xf32>) -> tensor<1x1024xf32>
    %cst_327 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5245 = stablehlo.reduce(%5244 init: %cst_327) applies stablehlo.add across dimensions = [0] : (tensor<1x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5246 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %5247 = stablehlo.divide %5245, %5246 : tensor<1024xf32>
    %5248 = stablehlo.broadcast_in_dim %5247, dims = [3] : (tensor<1024xf32>) -> tensor<256x14x14x1024xf32>
    %5249 = stablehlo.multiply %5248, %2370 : tensor<256x14x14x1024xf32>
    %cst_328 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5250 = stablehlo.reduce(%5243 init: %cst_328) applies stablehlo.add across dimensions = [0] : (tensor<1x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5251 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %5252 = stablehlo.divide %5250, %5251 : tensor<1024xf32>
    %5253 = stablehlo.broadcast_in_dim %5252, dims = [3] : (tensor<1024xf32>) -> tensor<256x14x14x1024xf32>
    %5254 = stablehlo.add %5249, %5253 : tensor<256x14x14x1024xf32>
    %5255 = stablehlo.convert %5254 : (tensor<256x14x14x1024xf32>) -> tensor<256x14x14x1024xf16>
    %5256 = stablehlo.add %5234, %5255 : tensor<256x14x14x1024xf16>
    %5257 = stablehlo.convolution(%2361, %5256) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x256xf16>, tensor<256x14x14x1024xf16>) -> tensor<1x1x256x1024xf16>
    %5258 = stablehlo.convert %5257 : (tensor<1x1x256x1024xf16>) -> tensor<1x1x256x1024xf32>
    %5259 = stablehlo.add %4094, %5258 : tensor<1x1x256x1024xf32>
    %5260 = stablehlo.reverse %2365, dims = [0, 1] : tensor<1x1x256x1024xf16>
    %5261 = stablehlo.convolution(%5256, %5260) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x1024xf16>, tensor<1x1x256x1024xf16>) -> tensor<256x14x14x256xf16>
    %5262 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %5263 = stablehlo.select %2363, %5261, %5262 : tensor<256x14x14x256xi1>, tensor<256x14x14x256xf16>
    %5264 = stablehlo.convert %5263 : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf32>
    %cst_329 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5265 = stablehlo.reduce(%5264 init: %cst_329) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5266 = stablehlo.reshape %5265 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %5267 = stablehlo.reshape %5266 : (tensor<1x1x1x256xf32>) -> tensor<256xf32>
    %5268 = stablehlo.multiply %2346, %5264 : tensor<256x14x14x256xf32>
    %cst_330 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5269 = stablehlo.reduce(%5268 init: %cst_330) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5270 = stablehlo.reshape %5269 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %5271 = stablehlo.broadcast_in_dim %2354, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %5272 = stablehlo.multiply %5264, %5271 : tensor<256x14x14x256xf32>
    %5273 = stablehlo.multiply %2349, %5270 : tensor<1x1x1x256xf32>
    %5274 = stablehlo.multiply %5270, %2353 : tensor<1x1x1x256xf32>
    %5275 = stablehlo.reshape %5273 : (tensor<1x1x1x256xf32>) -> tensor<256xf32>
    %5276 = stablehlo.multiply %5274, %2352 : tensor<1x1x1x256xf32>
    %cst_331 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5277 = stablehlo.reduce(%5276 init: %cst_331) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5278 = stablehlo.multiply %5277, %2331 : tensor<256xf32>
    %5279 = stablehlo.negate %5278 : tensor<256xf32>
    %5280 = stablehlo.multiply %5279, %2318 : tensor<256xf32>
    %5281 = stablehlo.broadcast_in_dim %5278, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %5282 = stablehlo.pad %5281, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<2x256xf32>
    %5283 = stablehlo.negate %5272 : tensor<256x14x14x256xf32>
    %cst_332 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5284 = stablehlo.reduce(%5283 init: %cst_332) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5285 = stablehlo.reshape %5284 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %5286 = stablehlo.convert %5272 : (tensor<256x14x14x256xf32>) -> tensor<256x14x14x256xf16>
    %cst_333 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5287 = stablehlo.reduce(%5285 init: %cst_333) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5288 = stablehlo.add %5280, %5287 : tensor<256xf32>
    %5289 = stablehlo.broadcast_in_dim %5288, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %5290 = stablehlo.pad %5289, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<2x256xf32>
    %5291 = stablehlo.add %5282, %5290 : tensor<2x256xf32>
    %5292 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x256xf32>
    %5293 = stablehlo.divide %5291, %5292 : tensor<2x256xf32>
    %5294 = "stablehlo.all_reduce"(%5293) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x256xf32>) -> tensor<2x256xf32>
    %5295 = stablehlo.slice %5294 [0:1, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %5296 = stablehlo.slice %5294 [1:2, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %cst_334 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5297 = stablehlo.reduce(%5296 init: %cst_334) applies stablehlo.add across dimensions = [0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5298 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %5299 = stablehlo.divide %5297, %5298 : tensor<256xf32>
    %5300 = stablehlo.broadcast_in_dim %5299, dims = [3] : (tensor<256xf32>) -> tensor<256x14x14x256xf32>
    %5301 = stablehlo.multiply %5300, %2299 : tensor<256x14x14x256xf32>
    %cst_335 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5302 = stablehlo.reduce(%5295 init: %cst_335) applies stablehlo.add across dimensions = [0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5303 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %5304 = stablehlo.divide %5302, %5303 : tensor<256xf32>
    %5305 = stablehlo.broadcast_in_dim %5304, dims = [3] : (tensor<256xf32>) -> tensor<256x14x14x256xf32>
    %5306 = stablehlo.add %5301, %5305 : tensor<256x14x14x256xf32>
    %5307 = stablehlo.convert %5306 : (tensor<256x14x14x256xf32>) -> tensor<256x14x14x256xf16>
    %5308 = stablehlo.add %5286, %5307 : tensor<256x14x14x256xf16>
    %5309 = stablehlo.convolution(%2290, %5308) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x256xf16>, tensor<256x14x14x256xf16>) -> tensor<3x3x256x256xf16>
    %5310 = stablehlo.convert %5309 : (tensor<3x3x256x256xf16>) -> tensor<3x3x256x256xf32>
    %5311 = stablehlo.add %4096, %5310 : tensor<3x3x256x256xf32>
    %5312 = stablehlo.reverse %2294, dims = [0, 1] : tensor<3x3x256x256xf16>
    %5313 = stablehlo.convolution(%5308, %5312) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x256xf16>, tensor<3x3x256x256xf16>) -> tensor<256x14x14x256xf16>
    %5314 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %5315 = stablehlo.select %2292, %5313, %5314 : tensor<256x14x14x256xi1>, tensor<256x14x14x256xf16>
    %5316 = stablehlo.convert %5315 : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf32>
    %cst_336 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5317 = stablehlo.reduce(%5316 init: %cst_336) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5318 = stablehlo.reshape %5317 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %5319 = stablehlo.reshape %5318 : (tensor<1x1x1x256xf32>) -> tensor<256xf32>
    %5320 = stablehlo.multiply %2275, %5316 : tensor<256x14x14x256xf32>
    %cst_337 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5321 = stablehlo.reduce(%5320 init: %cst_337) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5322 = stablehlo.reshape %5321 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %5323 = stablehlo.broadcast_in_dim %2283, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %5324 = stablehlo.multiply %5316, %5323 : tensor<256x14x14x256xf32>
    %5325 = stablehlo.multiply %2278, %5322 : tensor<1x1x1x256xf32>
    %5326 = stablehlo.multiply %5322, %2282 : tensor<1x1x1x256xf32>
    %5327 = stablehlo.reshape %5325 : (tensor<1x1x1x256xf32>) -> tensor<256xf32>
    %5328 = stablehlo.multiply %5326, %2281 : tensor<1x1x1x256xf32>
    %cst_338 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5329 = stablehlo.reduce(%5328 init: %cst_338) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5330 = stablehlo.multiply %5329, %2260 : tensor<256xf32>
    %5331 = stablehlo.negate %5330 : tensor<256xf32>
    %5332 = stablehlo.multiply %5331, %2247 : tensor<256xf32>
    %5333 = stablehlo.broadcast_in_dim %5330, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %5334 = stablehlo.pad %5333, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<2x256xf32>
    %5335 = stablehlo.negate %5324 : tensor<256x14x14x256xf32>
    %cst_339 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5336 = stablehlo.reduce(%5335 init: %cst_339) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5337 = stablehlo.reshape %5336 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %5338 = stablehlo.convert %5324 : (tensor<256x14x14x256xf32>) -> tensor<256x14x14x256xf16>
    %cst_340 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5339 = stablehlo.reduce(%5337 init: %cst_340) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5340 = stablehlo.add %5332, %5339 : tensor<256xf32>
    %5341 = stablehlo.broadcast_in_dim %5340, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %5342 = stablehlo.pad %5341, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<2x256xf32>
    %5343 = stablehlo.add %5334, %5342 : tensor<2x256xf32>
    %5344 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x256xf32>
    %5345 = stablehlo.divide %5343, %5344 : tensor<2x256xf32>
    %5346 = "stablehlo.all_reduce"(%5345) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x256xf32>) -> tensor<2x256xf32>
    %5347 = stablehlo.slice %5346 [0:1, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %5348 = stablehlo.slice %5346 [1:2, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %cst_341 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5349 = stablehlo.reduce(%5348 init: %cst_341) applies stablehlo.add across dimensions = [0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5350 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %5351 = stablehlo.divide %5349, %5350 : tensor<256xf32>
    %5352 = stablehlo.broadcast_in_dim %5351, dims = [3] : (tensor<256xf32>) -> tensor<256x14x14x256xf32>
    %5353 = stablehlo.multiply %5352, %2228 : tensor<256x14x14x256xf32>
    %cst_342 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5354 = stablehlo.reduce(%5347 init: %cst_342) applies stablehlo.add across dimensions = [0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5355 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %5356 = stablehlo.divide %5354, %5355 : tensor<256xf32>
    %5357 = stablehlo.broadcast_in_dim %5356, dims = [3] : (tensor<256xf32>) -> tensor<256x14x14x256xf32>
    %5358 = stablehlo.add %5353, %5357 : tensor<256x14x14x256xf32>
    %5359 = stablehlo.convert %5358 : (tensor<256x14x14x256xf32>) -> tensor<256x14x14x256xf16>
    %5360 = stablehlo.add %5338, %5359 : tensor<256x14x14x256xf16>
    %5361 = stablehlo.convolution(%2219, %5360) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x1024xf16>, tensor<256x14x14x256xf16>) -> tensor<1x1x1024x256xf16>
    %5362 = stablehlo.convert %5361 : (tensor<1x1x1024x256xf16>) -> tensor<1x1x1024x256xf32>
    %5363 = stablehlo.add %4098, %5362 : tensor<1x1x1024x256xf32>
    %5364 = stablehlo.reverse %2223, dims = [0, 1] : tensor<1x1x1024x256xf16>
    %5365 = stablehlo.convolution(%5360, %5364) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x256xf16>, tensor<1x1x1024x256xf16>) -> tensor<256x14x14x1024xf16>
    %5366 = stablehlo.add %5211, %5365 : tensor<256x14x14x1024xf16>
    %5367 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x1024xf16>
    %5368 = stablehlo.select %2221, %5366, %5367 : tensor<256x14x14x1024xi1>, tensor<256x14x14x1024xf16>
    %5369 = stablehlo.convert %5368 : (tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xf32>
    %cst_343 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5370 = stablehlo.reduce(%5369 init: %cst_343) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5371 = stablehlo.reshape %5370 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %5372 = stablehlo.reshape %5371 : (tensor<1x1x1x1024xf32>) -> tensor<1024xf32>
    %5373 = stablehlo.multiply %2203, %5369 : tensor<256x14x14x1024xf32>
    %cst_344 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5374 = stablehlo.reduce(%5373 init: %cst_344) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5375 = stablehlo.reshape %5374 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %5376 = stablehlo.broadcast_in_dim %2211, dims = [0, 1, 2, 3] : (tensor<1x1x1x1024xf32>) -> tensor<256x14x14x1024xf32>
    %5377 = stablehlo.multiply %5369, %5376 : tensor<256x14x14x1024xf32>
    %5378 = stablehlo.multiply %2206, %5375 : tensor<1x1x1x1024xf32>
    %5379 = stablehlo.multiply %5375, %2210 : tensor<1x1x1x1024xf32>
    %5380 = stablehlo.reshape %5378 : (tensor<1x1x1x1024xf32>) -> tensor<1024xf32>
    %5381 = stablehlo.multiply %5379, %2209 : tensor<1x1x1x1024xf32>
    %cst_345 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5382 = stablehlo.reduce(%5381 init: %cst_345) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5383 = stablehlo.multiply %5382, %2188 : tensor<1024xf32>
    %5384 = stablehlo.negate %5383 : tensor<1024xf32>
    %5385 = stablehlo.multiply %5384, %2175 : tensor<1024xf32>
    %5386 = stablehlo.broadcast_in_dim %5383, dims = [1] : (tensor<1024xf32>) -> tensor<1x1024xf32>
    %5387 = stablehlo.pad %5386, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x1024xf32>, tensor<f32>) -> tensor<2x1024xf32>
    %5388 = stablehlo.negate %5377 : tensor<256x14x14x1024xf32>
    %cst_346 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5389 = stablehlo.reduce(%5388 init: %cst_346) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5390 = stablehlo.reshape %5389 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %5391 = stablehlo.convert %5377 : (tensor<256x14x14x1024xf32>) -> tensor<256x14x14x1024xf16>
    %cst_347 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5392 = stablehlo.reduce(%5390 init: %cst_347) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5393 = stablehlo.add %5385, %5392 : tensor<1024xf32>
    %5394 = stablehlo.broadcast_in_dim %5393, dims = [1] : (tensor<1024xf32>) -> tensor<1x1024xf32>
    %5395 = stablehlo.pad %5394, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x1024xf32>, tensor<f32>) -> tensor<2x1024xf32>
    %5396 = stablehlo.add %5387, %5395 : tensor<2x1024xf32>
    %5397 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x1024xf32>
    %5398 = stablehlo.divide %5396, %5397 : tensor<2x1024xf32>
    %5399 = "stablehlo.all_reduce"(%5398) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x1024xf32>) -> tensor<2x1024xf32>
    %5400 = stablehlo.slice %5399 [0:1, 0:1024] : (tensor<2x1024xf32>) -> tensor<1x1024xf32>
    %5401 = stablehlo.slice %5399 [1:2, 0:1024] : (tensor<2x1024xf32>) -> tensor<1x1024xf32>
    %cst_348 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5402 = stablehlo.reduce(%5401 init: %cst_348) applies stablehlo.add across dimensions = [0] : (tensor<1x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5403 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %5404 = stablehlo.divide %5402, %5403 : tensor<1024xf32>
    %5405 = stablehlo.broadcast_in_dim %5404, dims = [3] : (tensor<1024xf32>) -> tensor<256x14x14x1024xf32>
    %5406 = stablehlo.multiply %5405, %2156 : tensor<256x14x14x1024xf32>
    %cst_349 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5407 = stablehlo.reduce(%5400 init: %cst_349) applies stablehlo.add across dimensions = [0] : (tensor<1x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5408 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %5409 = stablehlo.divide %5407, %5408 : tensor<1024xf32>
    %5410 = stablehlo.broadcast_in_dim %5409, dims = [3] : (tensor<1024xf32>) -> tensor<256x14x14x1024xf32>
    %5411 = stablehlo.add %5406, %5410 : tensor<256x14x14x1024xf32>
    %5412 = stablehlo.convert %5411 : (tensor<256x14x14x1024xf32>) -> tensor<256x14x14x1024xf16>
    %5413 = stablehlo.add %5391, %5412 : tensor<256x14x14x1024xf16>
    %5414 = stablehlo.convolution(%2147, %5413) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x256xf16>, tensor<256x14x14x1024xf16>) -> tensor<1x1x256x1024xf16>
    %5415 = stablehlo.convert %5414 : (tensor<1x1x256x1024xf16>) -> tensor<1x1x256x1024xf32>
    %5416 = stablehlo.add %4100, %5415 : tensor<1x1x256x1024xf32>
    %5417 = stablehlo.reverse %2151, dims = [0, 1] : tensor<1x1x256x1024xf16>
    %5418 = stablehlo.convolution(%5413, %5417) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x1024xf16>, tensor<1x1x256x1024xf16>) -> tensor<256x14x14x256xf16>
    %5419 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %5420 = stablehlo.select %2149, %5418, %5419 : tensor<256x14x14x256xi1>, tensor<256x14x14x256xf16>
    %5421 = stablehlo.convert %5420 : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf32>
    %cst_350 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5422 = stablehlo.reduce(%5421 init: %cst_350) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5423 = stablehlo.reshape %5422 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %5424 = stablehlo.reshape %5423 : (tensor<1x1x1x256xf32>) -> tensor<256xf32>
    %5425 = stablehlo.multiply %2132, %5421 : tensor<256x14x14x256xf32>
    %cst_351 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5426 = stablehlo.reduce(%5425 init: %cst_351) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5427 = stablehlo.reshape %5426 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %5428 = stablehlo.broadcast_in_dim %2140, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %5429 = stablehlo.multiply %5421, %5428 : tensor<256x14x14x256xf32>
    %5430 = stablehlo.multiply %2135, %5427 : tensor<1x1x1x256xf32>
    %5431 = stablehlo.multiply %5427, %2139 : tensor<1x1x1x256xf32>
    %5432 = stablehlo.reshape %5430 : (tensor<1x1x1x256xf32>) -> tensor<256xf32>
    %5433 = stablehlo.multiply %5431, %2138 : tensor<1x1x1x256xf32>
    %cst_352 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5434 = stablehlo.reduce(%5433 init: %cst_352) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5435 = stablehlo.multiply %5434, %2117 : tensor<256xf32>
    %5436 = stablehlo.negate %5435 : tensor<256xf32>
    %5437 = stablehlo.multiply %5436, %2104 : tensor<256xf32>
    %5438 = stablehlo.broadcast_in_dim %5435, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %5439 = stablehlo.pad %5438, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<2x256xf32>
    %5440 = stablehlo.negate %5429 : tensor<256x14x14x256xf32>
    %cst_353 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5441 = stablehlo.reduce(%5440 init: %cst_353) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5442 = stablehlo.reshape %5441 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %5443 = stablehlo.convert %5429 : (tensor<256x14x14x256xf32>) -> tensor<256x14x14x256xf16>
    %cst_354 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5444 = stablehlo.reduce(%5442 init: %cst_354) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5445 = stablehlo.add %5437, %5444 : tensor<256xf32>
    %5446 = stablehlo.broadcast_in_dim %5445, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %5447 = stablehlo.pad %5446, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<2x256xf32>
    %5448 = stablehlo.add %5439, %5447 : tensor<2x256xf32>
    %5449 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x256xf32>
    %5450 = stablehlo.divide %5448, %5449 : tensor<2x256xf32>
    %5451 = "stablehlo.all_reduce"(%5450) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x256xf32>) -> tensor<2x256xf32>
    %5452 = stablehlo.slice %5451 [0:1, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %5453 = stablehlo.slice %5451 [1:2, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %cst_355 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5454 = stablehlo.reduce(%5453 init: %cst_355) applies stablehlo.add across dimensions = [0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5455 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %5456 = stablehlo.divide %5454, %5455 : tensor<256xf32>
    %5457 = stablehlo.broadcast_in_dim %5456, dims = [3] : (tensor<256xf32>) -> tensor<256x14x14x256xf32>
    %5458 = stablehlo.multiply %5457, %2085 : tensor<256x14x14x256xf32>
    %cst_356 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5459 = stablehlo.reduce(%5452 init: %cst_356) applies stablehlo.add across dimensions = [0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5460 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %5461 = stablehlo.divide %5459, %5460 : tensor<256xf32>
    %5462 = stablehlo.broadcast_in_dim %5461, dims = [3] : (tensor<256xf32>) -> tensor<256x14x14x256xf32>
    %5463 = stablehlo.add %5458, %5462 : tensor<256x14x14x256xf32>
    %5464 = stablehlo.convert %5463 : (tensor<256x14x14x256xf32>) -> tensor<256x14x14x256xf16>
    %5465 = stablehlo.add %5443, %5464 : tensor<256x14x14x256xf16>
    %5466 = stablehlo.convolution(%2076, %5465) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x256xf16>, tensor<256x14x14x256xf16>) -> tensor<3x3x256x256xf16>
    %5467 = stablehlo.convert %5466 : (tensor<3x3x256x256xf16>) -> tensor<3x3x256x256xf32>
    %5468 = stablehlo.add %4102, %5467 : tensor<3x3x256x256xf32>
    %5469 = stablehlo.reverse %2080, dims = [0, 1] : tensor<3x3x256x256xf16>
    %5470 = stablehlo.convolution(%5465, %5469) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x256xf16>, tensor<3x3x256x256xf16>) -> tensor<256x14x14x256xf16>
    %5471 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %5472 = stablehlo.select %2078, %5470, %5471 : tensor<256x14x14x256xi1>, tensor<256x14x14x256xf16>
    %5473 = stablehlo.convert %5472 : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf32>
    %cst_357 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5474 = stablehlo.reduce(%5473 init: %cst_357) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5475 = stablehlo.reshape %5474 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %5476 = stablehlo.reshape %5475 : (tensor<1x1x1x256xf32>) -> tensor<256xf32>
    %5477 = stablehlo.multiply %2061, %5473 : tensor<256x14x14x256xf32>
    %cst_358 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5478 = stablehlo.reduce(%5477 init: %cst_358) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5479 = stablehlo.reshape %5478 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %5480 = stablehlo.broadcast_in_dim %2069, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %5481 = stablehlo.multiply %5473, %5480 : tensor<256x14x14x256xf32>
    %5482 = stablehlo.multiply %2064, %5479 : tensor<1x1x1x256xf32>
    %5483 = stablehlo.multiply %5479, %2068 : tensor<1x1x1x256xf32>
    %5484 = stablehlo.reshape %5482 : (tensor<1x1x1x256xf32>) -> tensor<256xf32>
    %5485 = stablehlo.multiply %5483, %2067 : tensor<1x1x1x256xf32>
    %cst_359 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5486 = stablehlo.reduce(%5485 init: %cst_359) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5487 = stablehlo.multiply %5486, %2046 : tensor<256xf32>
    %5488 = stablehlo.negate %5487 : tensor<256xf32>
    %5489 = stablehlo.multiply %5488, %2033 : tensor<256xf32>
    %5490 = stablehlo.broadcast_in_dim %5487, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %5491 = stablehlo.pad %5490, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<2x256xf32>
    %5492 = stablehlo.negate %5481 : tensor<256x14x14x256xf32>
    %cst_360 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5493 = stablehlo.reduce(%5492 init: %cst_360) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5494 = stablehlo.reshape %5493 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %5495 = stablehlo.convert %5481 : (tensor<256x14x14x256xf32>) -> tensor<256x14x14x256xf16>
    %cst_361 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5496 = stablehlo.reduce(%5494 init: %cst_361) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5497 = stablehlo.add %5489, %5496 : tensor<256xf32>
    %5498 = stablehlo.broadcast_in_dim %5497, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %5499 = stablehlo.pad %5498, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<2x256xf32>
    %5500 = stablehlo.add %5491, %5499 : tensor<2x256xf32>
    %5501 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x256xf32>
    %5502 = stablehlo.divide %5500, %5501 : tensor<2x256xf32>
    %5503 = "stablehlo.all_reduce"(%5502) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x256xf32>) -> tensor<2x256xf32>
    %5504 = stablehlo.slice %5503 [0:1, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %5505 = stablehlo.slice %5503 [1:2, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %cst_362 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5506 = stablehlo.reduce(%5505 init: %cst_362) applies stablehlo.add across dimensions = [0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5507 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %5508 = stablehlo.divide %5506, %5507 : tensor<256xf32>
    %5509 = stablehlo.broadcast_in_dim %5508, dims = [3] : (tensor<256xf32>) -> tensor<256x14x14x256xf32>
    %5510 = stablehlo.multiply %5509, %2014 : tensor<256x14x14x256xf32>
    %cst_363 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5511 = stablehlo.reduce(%5504 init: %cst_363) applies stablehlo.add across dimensions = [0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5512 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %5513 = stablehlo.divide %5511, %5512 : tensor<256xf32>
    %5514 = stablehlo.broadcast_in_dim %5513, dims = [3] : (tensor<256xf32>) -> tensor<256x14x14x256xf32>
    %5515 = stablehlo.add %5510, %5514 : tensor<256x14x14x256xf32>
    %5516 = stablehlo.convert %5515 : (tensor<256x14x14x256xf32>) -> tensor<256x14x14x256xf16>
    %5517 = stablehlo.add %5495, %5516 : tensor<256x14x14x256xf16>
    %5518 = stablehlo.convolution(%2005, %5517) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x1024xf16>, tensor<256x14x14x256xf16>) -> tensor<1x1x1024x256xf16>
    %5519 = stablehlo.convert %5518 : (tensor<1x1x1024x256xf16>) -> tensor<1x1x1024x256xf32>
    %5520 = stablehlo.add %4104, %5519 : tensor<1x1x1024x256xf32>
    %5521 = stablehlo.reverse %2009, dims = [0, 1] : tensor<1x1x1024x256xf16>
    %5522 = stablehlo.convolution(%5517, %5521) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x256xf16>, tensor<1x1x1024x256xf16>) -> tensor<256x14x14x1024xf16>
    %5523 = stablehlo.add %5368, %5522 : tensor<256x14x14x1024xf16>
    %5524 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x1024xf16>
    %5525 = stablehlo.select %2007, %5523, %5524 : tensor<256x14x14x1024xi1>, tensor<256x14x14x1024xf16>
    %5526 = stablehlo.convert %5525 : (tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xf32>
    %cst_364 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5527 = stablehlo.reduce(%5526 init: %cst_364) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5528 = stablehlo.reshape %5527 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %5529 = stablehlo.reshape %5528 : (tensor<1x1x1x1024xf32>) -> tensor<1024xf32>
    %5530 = stablehlo.multiply %1922, %5526 : tensor<256x14x14x1024xf32>
    %cst_365 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5531 = stablehlo.reduce(%5530 init: %cst_365) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5532 = stablehlo.reshape %5531 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %5533 = stablehlo.broadcast_in_dim %1930, dims = [0, 1, 2, 3] : (tensor<1x1x1x1024xf32>) -> tensor<256x14x14x1024xf32>
    %5534 = stablehlo.multiply %5526, %5533 : tensor<256x14x14x1024xf32>
    %5535 = stablehlo.multiply %1925, %5532 : tensor<1x1x1x1024xf32>
    %5536 = stablehlo.multiply %5532, %1929 : tensor<1x1x1x1024xf32>
    %5537 = stablehlo.reshape %5535 : (tensor<1x1x1x1024xf32>) -> tensor<1024xf32>
    %5538 = stablehlo.multiply %5536, %1928 : tensor<1x1x1x1024xf32>
    %cst_366 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5539 = stablehlo.reduce(%5538 init: %cst_366) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5540 = stablehlo.multiply %5539, %1907 : tensor<1024xf32>
    %5541 = stablehlo.negate %5540 : tensor<1024xf32>
    %5542 = stablehlo.multiply %5541, %1894 : tensor<1024xf32>
    %5543 = stablehlo.broadcast_in_dim %5540, dims = [1] : (tensor<1024xf32>) -> tensor<1x1024xf32>
    %5544 = stablehlo.pad %5543, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x1024xf32>, tensor<f32>) -> tensor<2x1024xf32>
    %5545 = stablehlo.negate %5534 : tensor<256x14x14x1024xf32>
    %cst_367 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5546 = stablehlo.reduce(%5545 init: %cst_367) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5547 = stablehlo.reshape %5546 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %5548 = stablehlo.convert %5534 : (tensor<256x14x14x1024xf32>) -> tensor<256x14x14x1024xf16>
    %cst_368 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5549 = stablehlo.reduce(%5547 init: %cst_368) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5550 = stablehlo.add %5542, %5549 : tensor<1024xf32>
    %5551 = stablehlo.broadcast_in_dim %5550, dims = [1] : (tensor<1024xf32>) -> tensor<1x1024xf32>
    %5552 = stablehlo.pad %5551, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x1024xf32>, tensor<f32>) -> tensor<2x1024xf32>
    %5553 = stablehlo.add %5544, %5552 : tensor<2x1024xf32>
    %5554 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x1024xf32>
    %5555 = stablehlo.divide %5553, %5554 : tensor<2x1024xf32>
    %5556 = "stablehlo.all_reduce"(%5555) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x1024xf32>) -> tensor<2x1024xf32>
    %5557 = stablehlo.slice %5556 [0:1, 0:1024] : (tensor<2x1024xf32>) -> tensor<1x1024xf32>
    %5558 = stablehlo.slice %5556 [1:2, 0:1024] : (tensor<2x1024xf32>) -> tensor<1x1024xf32>
    %cst_369 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5559 = stablehlo.reduce(%5558 init: %cst_369) applies stablehlo.add across dimensions = [0] : (tensor<1x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5560 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %5561 = stablehlo.divide %5559, %5560 : tensor<1024xf32>
    %5562 = stablehlo.broadcast_in_dim %5561, dims = [3] : (tensor<1024xf32>) -> tensor<256x14x14x1024xf32>
    %5563 = stablehlo.multiply %5562, %1875 : tensor<256x14x14x1024xf32>
    %cst_370 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5564 = stablehlo.reduce(%5557 init: %cst_370) applies stablehlo.add across dimensions = [0] : (tensor<1x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5565 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %5566 = stablehlo.divide %5564, %5565 : tensor<1024xf32>
    %5567 = stablehlo.broadcast_in_dim %5566, dims = [3] : (tensor<1024xf32>) -> tensor<256x14x14x1024xf32>
    %5568 = stablehlo.add %5563, %5567 : tensor<256x14x14x1024xf32>
    %5569 = stablehlo.convert %5568 : (tensor<256x14x14x1024xf32>) -> tensor<256x14x14x1024xf16>
    %5570 = stablehlo.add %5548, %5569 : tensor<256x14x14x1024xf16>
    %5571 = stablehlo.convolution(%1866, %5570) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x256xf16>, tensor<256x14x14x1024xf16>) -> tensor<1x1x256x1024xf16>
    %5572 = stablehlo.convert %5571 : (tensor<1x1x256x1024xf16>) -> tensor<1x1x256x1024xf32>
    %5573 = stablehlo.add %4108, %5572 : tensor<1x1x256x1024xf32>
    %5574 = stablehlo.reverse %1870, dims = [0, 1] : tensor<1x1x256x1024xf16>
    %5575 = stablehlo.convolution(%5570, %5574) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x1024xf16>, tensor<1x1x256x1024xf16>) -> tensor<256x14x14x256xf16>
    %5576 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %5577 = stablehlo.select %1868, %5575, %5576 : tensor<256x14x14x256xi1>, tensor<256x14x14x256xf16>
    %5578 = stablehlo.convert %5577 : (tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf32>
    %cst_371 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5579 = stablehlo.reduce(%5578 init: %cst_371) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5580 = stablehlo.reshape %5579 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %5581 = stablehlo.reshape %5580 : (tensor<1x1x1x256xf32>) -> tensor<256xf32>
    %5582 = stablehlo.multiply %1851, %5578 : tensor<256x14x14x256xf32>
    %cst_372 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5583 = stablehlo.reduce(%5582 init: %cst_372) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5584 = stablehlo.reshape %5583 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %5585 = stablehlo.broadcast_in_dim %1859, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x14x14x256xf32>
    %5586 = stablehlo.multiply %5578, %5585 : tensor<256x14x14x256xf32>
    %5587 = stablehlo.multiply %1854, %5584 : tensor<1x1x1x256xf32>
    %5588 = stablehlo.multiply %5584, %1858 : tensor<1x1x1x256xf32>
    %5589 = stablehlo.reshape %5587 : (tensor<1x1x1x256xf32>) -> tensor<256xf32>
    %5590 = stablehlo.multiply %5588, %1857 : tensor<1x1x1x256xf32>
    %cst_373 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5591 = stablehlo.reduce(%5590 init: %cst_373) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5592 = stablehlo.multiply %5591, %1836 : tensor<256xf32>
    %5593 = stablehlo.negate %5592 : tensor<256xf32>
    %5594 = stablehlo.multiply %5593, %1823 : tensor<256xf32>
    %5595 = stablehlo.broadcast_in_dim %5592, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %5596 = stablehlo.pad %5595, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<2x256xf32>
    %5597 = stablehlo.negate %5586 : tensor<256x14x14x256xf32>
    %cst_374 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5598 = stablehlo.reduce(%5597 init: %cst_374) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5599 = stablehlo.reshape %5598 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %5600 = stablehlo.convert %5586 : (tensor<256x14x14x256xf32>) -> tensor<256x14x14x256xf16>
    %cst_375 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5601 = stablehlo.reduce(%5599 init: %cst_375) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5602 = stablehlo.add %5594, %5601 : tensor<256xf32>
    %5603 = stablehlo.broadcast_in_dim %5602, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %5604 = stablehlo.pad %5603, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<2x256xf32>
    %5605 = stablehlo.add %5596, %5604 : tensor<2x256xf32>
    %5606 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x256xf32>
    %5607 = stablehlo.divide %5605, %5606 : tensor<2x256xf32>
    %5608 = "stablehlo.all_reduce"(%5607) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x256xf32>) -> tensor<2x256xf32>
    %5609 = stablehlo.slice %5608 [0:1, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %5610 = stablehlo.slice %5608 [1:2, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %cst_376 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5611 = stablehlo.reduce(%5610 init: %cst_376) applies stablehlo.add across dimensions = [0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5612 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %5613 = stablehlo.divide %5611, %5612 : tensor<256xf32>
    %5614 = stablehlo.broadcast_in_dim %5613, dims = [3] : (tensor<256xf32>) -> tensor<256x14x14x256xf32>
    %5615 = stablehlo.multiply %5614, %1804 : tensor<256x14x14x256xf32>
    %cst_377 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5616 = stablehlo.reduce(%5609 init: %cst_377) applies stablehlo.add across dimensions = [0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5617 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %5618 = stablehlo.divide %5616, %5617 : tensor<256xf32>
    %5619 = stablehlo.broadcast_in_dim %5618, dims = [3] : (tensor<256xf32>) -> tensor<256x14x14x256xf32>
    %5620 = stablehlo.add %5615, %5619 : tensor<256x14x14x256xf32>
    %5621 = stablehlo.convert %5620 : (tensor<256x14x14x256xf32>) -> tensor<256x14x14x256xf16>
    %5622 = stablehlo.add %5600, %5621 : tensor<256x14x14x256xf16>
    %5623 = stablehlo.convolution(%1795, %5622) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 1], [0, 1]], lhs_dilate = [1, 1], rhs_dilate = [2, 2], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x256xf16>, tensor<256x14x14x256xf16>) -> tensor<3x3x256x256xf16>
    %5624 = stablehlo.convert %5623 : (tensor<3x3x256x256xf16>) -> tensor<3x3x256x256xf32>
    %5625 = stablehlo.add %4110, %5624 : tensor<3x3x256x256xf32>
    %5626 = stablehlo.reverse %1799, dims = [0, 1] : tensor<3x3x256x256xf16>
    %5627 = stablehlo.convolution(%5622, %5626) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[2, 1], [2, 1]], lhs_dilate = [2, 2], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x256xf16>, tensor<3x3x256x256xf16>) -> tensor<256x28x28x256xf16>
    %5628 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x256xf16>
    %5629 = stablehlo.select %1797, %5627, %5628 : tensor<256x28x28x256xi1>, tensor<256x28x28x256xf16>
    %5630 = stablehlo.convert %5629 : (tensor<256x28x28x256xf16>) -> tensor<256x28x28x256xf32>
    %cst_378 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5631 = stablehlo.reduce(%5630 init: %cst_378) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5632 = stablehlo.reshape %5631 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %5633 = stablehlo.reshape %5632 : (tensor<1x1x1x256xf32>) -> tensor<256xf32>
    %5634 = stablehlo.multiply %1780, %5630 : tensor<256x28x28x256xf32>
    %cst_379 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5635 = stablehlo.reduce(%5634 init: %cst_379) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5636 = stablehlo.reshape %5635 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %5637 = stablehlo.broadcast_in_dim %1788, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x28x28x256xf32>
    %5638 = stablehlo.multiply %5630, %5637 : tensor<256x28x28x256xf32>
    %5639 = stablehlo.multiply %1783, %5636 : tensor<1x1x1x256xf32>
    %5640 = stablehlo.multiply %5636, %1787 : tensor<1x1x1x256xf32>
    %5641 = stablehlo.reshape %5639 : (tensor<1x1x1x256xf32>) -> tensor<256xf32>
    %5642 = stablehlo.multiply %5640, %1786 : tensor<1x1x1x256xf32>
    %cst_380 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5643 = stablehlo.reduce(%5642 init: %cst_380) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5644 = stablehlo.multiply %5643, %1765 : tensor<256xf32>
    %5645 = stablehlo.negate %5644 : tensor<256xf32>
    %5646 = stablehlo.multiply %5645, %1752 : tensor<256xf32>
    %5647 = stablehlo.broadcast_in_dim %5644, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %5648 = stablehlo.pad %5647, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<2x256xf32>
    %5649 = stablehlo.negate %5638 : tensor<256x28x28x256xf32>
    %cst_381 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5650 = stablehlo.reduce(%5649 init: %cst_381) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5651 = stablehlo.reshape %5650 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %5652 = stablehlo.convert %5638 : (tensor<256x28x28x256xf32>) -> tensor<256x28x28x256xf16>
    %cst_382 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5653 = stablehlo.reduce(%5651 init: %cst_382) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5654 = stablehlo.add %5646, %5653 : tensor<256xf32>
    %5655 = stablehlo.broadcast_in_dim %5654, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %5656 = stablehlo.pad %5655, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<2x256xf32>
    %5657 = stablehlo.add %5648, %5656 : tensor<2x256xf32>
    %5658 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x256xf32>
    %5659 = stablehlo.divide %5657, %5658 : tensor<2x256xf32>
    %5660 = "stablehlo.all_reduce"(%5659) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x256xf32>) -> tensor<2x256xf32>
    %5661 = stablehlo.slice %5660 [0:1, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %5662 = stablehlo.slice %5660 [1:2, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %cst_383 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5663 = stablehlo.reduce(%5662 init: %cst_383) applies stablehlo.add across dimensions = [0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5664 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %5665 = stablehlo.divide %5663, %5664 : tensor<256xf32>
    %5666 = stablehlo.broadcast_in_dim %5665, dims = [3] : (tensor<256xf32>) -> tensor<256x28x28x256xf32>
    %5667 = stablehlo.multiply %5666, %1733 : tensor<256x28x28x256xf32>
    %cst_384 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5668 = stablehlo.reduce(%5661 init: %cst_384) applies stablehlo.add across dimensions = [0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %5669 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %5670 = stablehlo.divide %5668, %5669 : tensor<256xf32>
    %5671 = stablehlo.broadcast_in_dim %5670, dims = [3] : (tensor<256xf32>) -> tensor<256x28x28x256xf32>
    %5672 = stablehlo.add %5667, %5671 : tensor<256x28x28x256xf32>
    %5673 = stablehlo.convert %5672 : (tensor<256x28x28x256xf32>) -> tensor<256x28x28x256xf16>
    %5674 = stablehlo.add %5652, %5673 : tensor<256x28x28x256xf16>
    %5675 = stablehlo.convolution(%1724, %5674) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x512xf16>, tensor<256x28x28x256xf16>) -> tensor<1x1x512x256xf16>
    %5676 = stablehlo.convert %5675 : (tensor<1x1x512x256xf16>) -> tensor<1x1x512x256xf32>
    %5677 = stablehlo.add %4112, %5676 : tensor<1x1x512x256xf32>
    %5678 = stablehlo.reverse %1728, dims = [0, 1] : tensor<1x1x512x256xf16>
    %5679 = stablehlo.convolution(%5674, %5678) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x256xf16>, tensor<1x1x512x256xf16>) -> tensor<256x28x28x512xf16>
    %5680 = stablehlo.convert %5525 : (tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xf32>
    %cst_385 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5681 = stablehlo.reduce(%5680 init: %cst_385) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5682 = stablehlo.reshape %5681 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %5683 = stablehlo.reshape %5682 : (tensor<1x1x1x1024xf32>) -> tensor<1024xf32>
    %5684 = stablehlo.multiply %1989, %5680 : tensor<256x14x14x1024xf32>
    %cst_386 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5685 = stablehlo.reduce(%5684 init: %cst_386) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5686 = stablehlo.reshape %5685 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %5687 = stablehlo.broadcast_in_dim %1997, dims = [0, 1, 2, 3] : (tensor<1x1x1x1024xf32>) -> tensor<256x14x14x1024xf32>
    %5688 = stablehlo.multiply %5680, %5687 : tensor<256x14x14x1024xf32>
    %5689 = stablehlo.multiply %1992, %5686 : tensor<1x1x1x1024xf32>
    %5690 = stablehlo.multiply %5686, %1996 : tensor<1x1x1x1024xf32>
    %5691 = stablehlo.reshape %5689 : (tensor<1x1x1x1024xf32>) -> tensor<1024xf32>
    %5692 = stablehlo.multiply %5690, %1995 : tensor<1x1x1x1024xf32>
    %cst_387 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5693 = stablehlo.reduce(%5692 init: %cst_387) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5694 = stablehlo.multiply %5693, %1974 : tensor<1024xf32>
    %5695 = stablehlo.negate %5694 : tensor<1024xf32>
    %5696 = stablehlo.multiply %5695, %1961 : tensor<1024xf32>
    %5697 = stablehlo.broadcast_in_dim %5694, dims = [1] : (tensor<1024xf32>) -> tensor<1x1024xf32>
    %5698 = stablehlo.pad %5697, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x1024xf32>, tensor<f32>) -> tensor<2x1024xf32>
    %5699 = stablehlo.negate %5688 : tensor<256x14x14x1024xf32>
    %cst_388 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5700 = stablehlo.reduce(%5699 init: %cst_388) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x14x14x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5701 = stablehlo.reshape %5700 : (tensor<1024xf32>) -> tensor<1x1x1x1024xf32>
    %5702 = stablehlo.convert %5688 : (tensor<256x14x14x1024xf32>) -> tensor<256x14x14x1024xf16>
    %cst_389 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5703 = stablehlo.reduce(%5701 init: %cst_389) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5704 = stablehlo.add %5696, %5703 : tensor<1024xf32>
    %5705 = stablehlo.broadcast_in_dim %5704, dims = [1] : (tensor<1024xf32>) -> tensor<1x1024xf32>
    %5706 = stablehlo.pad %5705, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x1024xf32>, tensor<f32>) -> tensor<2x1024xf32>
    %5707 = stablehlo.add %5698, %5706 : tensor<2x1024xf32>
    %5708 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x1024xf32>
    %5709 = stablehlo.divide %5707, %5708 : tensor<2x1024xf32>
    %5710 = "stablehlo.all_reduce"(%5709) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x1024xf32>) -> tensor<2x1024xf32>
    %5711 = stablehlo.slice %5710 [0:1, 0:1024] : (tensor<2x1024xf32>) -> tensor<1x1024xf32>
    %5712 = stablehlo.slice %5710 [1:2, 0:1024] : (tensor<2x1024xf32>) -> tensor<1x1024xf32>
    %cst_390 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5713 = stablehlo.reduce(%5712 init: %cst_390) applies stablehlo.add across dimensions = [0] : (tensor<1x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5714 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %5715 = stablehlo.divide %5713, %5714 : tensor<1024xf32>
    %5716 = stablehlo.broadcast_in_dim %5715, dims = [3] : (tensor<1024xf32>) -> tensor<256x14x14x1024xf32>
    %5717 = stablehlo.multiply %5716, %1942 : tensor<256x14x14x1024xf32>
    %cst_391 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5718 = stablehlo.reduce(%5711 init: %cst_391) applies stablehlo.add across dimensions = [0] : (tensor<1x1024xf32>, tensor<f32>) -> tensor<1024xf32>
    %5719 = stablehlo.broadcast_in_dim %cst_71, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %5720 = stablehlo.divide %5718, %5719 : tensor<1024xf32>
    %5721 = stablehlo.broadcast_in_dim %5720, dims = [3] : (tensor<1024xf32>) -> tensor<256x14x14x1024xf32>
    %5722 = stablehlo.add %5717, %5721 : tensor<256x14x14x1024xf32>
    %5723 = stablehlo.convert %5722 : (tensor<256x14x14x1024xf32>) -> tensor<256x14x14x1024xf16>
    %5724 = stablehlo.add %5702, %5723 : tensor<256x14x14x1024xf16>
    %5725 = stablehlo.convolution(%1724, %5724) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, -1], [0, -1]], lhs_dilate = [1, 1], rhs_dilate = [2, 2], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x512xf16>, tensor<256x14x14x1024xf16>) -> tensor<1x1x512x1024xf16>
    %5726 = stablehlo.convert %5725 : (tensor<1x1x512x1024xf16>) -> tensor<1x1x512x1024xf32>
    %5727 = stablehlo.add %4106, %5726 : tensor<1x1x512x1024xf32>
    %5728 = stablehlo.reverse %1937, dims = [0, 1] : tensor<1x1x512x1024xf16>
    %5729 = stablehlo.convolution(%5724, %5728) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 1], [0, 1]], lhs_dilate = [2, 2], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x14x14x1024xf16>, tensor<1x1x512x1024xf16>) -> tensor<256x28x28x512xf16>
    %5730 = stablehlo.add %5679, %5729 : tensor<256x28x28x512xf16>
    %5731 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x512xf16>
    %5732 = stablehlo.select %1726, %5730, %5731 : tensor<256x28x28x512xi1>, tensor<256x28x28x512xf16>
    %5733 = stablehlo.convert %5732 : (tensor<256x28x28x512xf16>) -> tensor<256x28x28x512xf32>
    %cst_392 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5734 = stablehlo.reduce(%5733 init: %cst_392) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x512xf32>, tensor<f32>) -> tensor<512xf32>
    %5735 = stablehlo.reshape %5734 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %5736 = stablehlo.reshape %5735 : (tensor<1x1x1x512xf32>) -> tensor<512xf32>
    %5737 = stablehlo.multiply %1708, %5733 : tensor<256x28x28x512xf32>
    %cst_393 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5738 = stablehlo.reduce(%5737 init: %cst_393) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x512xf32>, tensor<f32>) -> tensor<512xf32>
    %5739 = stablehlo.reshape %5738 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %5740 = stablehlo.broadcast_in_dim %1716, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x28x28x512xf32>
    %5741 = stablehlo.multiply %5733, %5740 : tensor<256x28x28x512xf32>
    %5742 = stablehlo.multiply %1711, %5739 : tensor<1x1x1x512xf32>
    %5743 = stablehlo.multiply %5739, %1715 : tensor<1x1x1x512xf32>
    %5744 = stablehlo.reshape %5742 : (tensor<1x1x1x512xf32>) -> tensor<512xf32>
    %5745 = stablehlo.multiply %5743, %1714 : tensor<1x1x1x512xf32>
    %cst_394 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5746 = stablehlo.reduce(%5745 init: %cst_394) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %5747 = stablehlo.multiply %5746, %1693 : tensor<512xf32>
    %5748 = stablehlo.negate %5747 : tensor<512xf32>
    %5749 = stablehlo.multiply %5748, %1680 : tensor<512xf32>
    %5750 = stablehlo.broadcast_in_dim %5747, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %5751 = stablehlo.pad %5750, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<2x512xf32>
    %5752 = stablehlo.negate %5741 : tensor<256x28x28x512xf32>
    %cst_395 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5753 = stablehlo.reduce(%5752 init: %cst_395) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x512xf32>, tensor<f32>) -> tensor<512xf32>
    %5754 = stablehlo.reshape %5753 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %5755 = stablehlo.convert %5741 : (tensor<256x28x28x512xf32>) -> tensor<256x28x28x512xf16>
    %cst_396 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5756 = stablehlo.reduce(%5754 init: %cst_396) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %5757 = stablehlo.add %5749, %5756 : tensor<512xf32>
    %5758 = stablehlo.broadcast_in_dim %5757, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %5759 = stablehlo.pad %5758, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<2x512xf32>
    %5760 = stablehlo.add %5751, %5759 : tensor<2x512xf32>
    %5761 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x512xf32>
    %5762 = stablehlo.divide %5760, %5761 : tensor<2x512xf32>
    %5763 = "stablehlo.all_reduce"(%5762) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x512xf32>) -> tensor<2x512xf32>
    %5764 = stablehlo.slice %5763 [0:1, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %5765 = stablehlo.slice %5763 [1:2, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %cst_397 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5766 = stablehlo.reduce(%5765 init: %cst_397) applies stablehlo.add across dimensions = [0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %5767 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %5768 = stablehlo.divide %5766, %5767 : tensor<512xf32>
    %5769 = stablehlo.broadcast_in_dim %5768, dims = [3] : (tensor<512xf32>) -> tensor<256x28x28x512xf32>
    %5770 = stablehlo.multiply %5769, %1661 : tensor<256x28x28x512xf32>
    %cst_398 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5771 = stablehlo.reduce(%5764 init: %cst_398) applies stablehlo.add across dimensions = [0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %5772 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %5773 = stablehlo.divide %5771, %5772 : tensor<512xf32>
    %5774 = stablehlo.broadcast_in_dim %5773, dims = [3] : (tensor<512xf32>) -> tensor<256x28x28x512xf32>
    %5775 = stablehlo.add %5770, %5774 : tensor<256x28x28x512xf32>
    %5776 = stablehlo.convert %5775 : (tensor<256x28x28x512xf32>) -> tensor<256x28x28x512xf16>
    %5777 = stablehlo.add %5755, %5776 : tensor<256x28x28x512xf16>
    %5778 = stablehlo.convolution(%1652, %5777) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x128xf16>, tensor<256x28x28x512xf16>) -> tensor<1x1x128x512xf16>
    %5779 = stablehlo.convert %5778 : (tensor<1x1x128x512xf16>) -> tensor<1x1x128x512xf32>
    %5780 = stablehlo.add %4114, %5779 : tensor<1x1x128x512xf32>
    %5781 = stablehlo.reverse %1656, dims = [0, 1] : tensor<1x1x128x512xf16>
    %5782 = stablehlo.convolution(%5777, %5781) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x512xf16>, tensor<1x1x128x512xf16>) -> tensor<256x28x28x128xf16>
    %5783 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x128xf16>
    %5784 = stablehlo.select %1654, %5782, %5783 : tensor<256x28x28x128xi1>, tensor<256x28x28x128xf16>
    %5785 = stablehlo.convert %5784 : (tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xf32>
    %cst_399 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5786 = stablehlo.reduce(%5785 init: %cst_399) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %5787 = stablehlo.reshape %5786 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %5788 = stablehlo.reshape %5787 : (tensor<1x1x1x128xf32>) -> tensor<128xf32>
    %5789 = stablehlo.multiply %1637, %5785 : tensor<256x28x28x128xf32>
    %cst_400 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5790 = stablehlo.reduce(%5789 init: %cst_400) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %5791 = stablehlo.reshape %5790 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %5792 = stablehlo.broadcast_in_dim %1645, dims = [0, 1, 2, 3] : (tensor<1x1x1x128xf32>) -> tensor<256x28x28x128xf32>
    %5793 = stablehlo.multiply %5785, %5792 : tensor<256x28x28x128xf32>
    %5794 = stablehlo.multiply %1640, %5791 : tensor<1x1x1x128xf32>
    %5795 = stablehlo.multiply %5791, %1644 : tensor<1x1x1x128xf32>
    %5796 = stablehlo.reshape %5794 : (tensor<1x1x1x128xf32>) -> tensor<128xf32>
    %5797 = stablehlo.multiply %5795, %1643 : tensor<1x1x1x128xf32>
    %cst_401 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5798 = stablehlo.reduce(%5797 init: %cst_401) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x128xf32>, tensor<f32>) -> tensor<128xf32>
    %5799 = stablehlo.multiply %5798, %1622 : tensor<128xf32>
    %5800 = stablehlo.negate %5799 : tensor<128xf32>
    %5801 = stablehlo.multiply %5800, %1609 : tensor<128xf32>
    %5802 = stablehlo.broadcast_in_dim %5799, dims = [1] : (tensor<128xf32>) -> tensor<1x128xf32>
    %5803 = stablehlo.pad %5802, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x128xf32>, tensor<f32>) -> tensor<2x128xf32>
    %5804 = stablehlo.negate %5793 : tensor<256x28x28x128xf32>
    %cst_402 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5805 = stablehlo.reduce(%5804 init: %cst_402) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %5806 = stablehlo.reshape %5805 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %5807 = stablehlo.convert %5793 : (tensor<256x28x28x128xf32>) -> tensor<256x28x28x128xf16>
    %cst_403 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5808 = stablehlo.reduce(%5806 init: %cst_403) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x128xf32>, tensor<f32>) -> tensor<128xf32>
    %5809 = stablehlo.add %5801, %5808 : tensor<128xf32>
    %5810 = stablehlo.broadcast_in_dim %5809, dims = [1] : (tensor<128xf32>) -> tensor<1x128xf32>
    %5811 = stablehlo.pad %5810, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x128xf32>, tensor<f32>) -> tensor<2x128xf32>
    %5812 = stablehlo.add %5803, %5811 : tensor<2x128xf32>
    %5813 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x128xf32>
    %5814 = stablehlo.divide %5812, %5813 : tensor<2x128xf32>
    %5815 = "stablehlo.all_reduce"(%5814) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x128xf32>) -> tensor<2x128xf32>
    %5816 = stablehlo.slice %5815 [0:1, 0:128] : (tensor<2x128xf32>) -> tensor<1x128xf32>
    %5817 = stablehlo.slice %5815 [1:2, 0:128] : (tensor<2x128xf32>) -> tensor<1x128xf32>
    %cst_404 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5818 = stablehlo.reduce(%5817 init: %cst_404) applies stablehlo.add across dimensions = [0] : (tensor<1x128xf32>, tensor<f32>) -> tensor<128xf32>
    %5819 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %5820 = stablehlo.divide %5818, %5819 : tensor<128xf32>
    %5821 = stablehlo.broadcast_in_dim %5820, dims = [3] : (tensor<128xf32>) -> tensor<256x28x28x128xf32>
    %5822 = stablehlo.multiply %5821, %1590 : tensor<256x28x28x128xf32>
    %cst_405 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5823 = stablehlo.reduce(%5816 init: %cst_405) applies stablehlo.add across dimensions = [0] : (tensor<1x128xf32>, tensor<f32>) -> tensor<128xf32>
    %5824 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %5825 = stablehlo.divide %5823, %5824 : tensor<128xf32>
    %5826 = stablehlo.broadcast_in_dim %5825, dims = [3] : (tensor<128xf32>) -> tensor<256x28x28x128xf32>
    %5827 = stablehlo.add %5822, %5826 : tensor<256x28x28x128xf32>
    %5828 = stablehlo.convert %5827 : (tensor<256x28x28x128xf32>) -> tensor<256x28x28x128xf16>
    %5829 = stablehlo.add %5807, %5828 : tensor<256x28x28x128xf16>
    %5830 = stablehlo.convolution(%1581, %5829) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x128xf16>, tensor<256x28x28x128xf16>) -> tensor<3x3x128x128xf16>
    %5831 = stablehlo.convert %5830 : (tensor<3x3x128x128xf16>) -> tensor<3x3x128x128xf32>
    %5832 = stablehlo.add %4116, %5831 : tensor<3x3x128x128xf32>
    %5833 = stablehlo.reverse %1585, dims = [0, 1] : tensor<3x3x128x128xf16>
    %5834 = stablehlo.convolution(%5829, %5833) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x128xf16>, tensor<3x3x128x128xf16>) -> tensor<256x28x28x128xf16>
    %5835 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x128xf16>
    %5836 = stablehlo.select %1583, %5834, %5835 : tensor<256x28x28x128xi1>, tensor<256x28x28x128xf16>
    %5837 = stablehlo.convert %5836 : (tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xf32>
    %cst_406 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5838 = stablehlo.reduce(%5837 init: %cst_406) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %5839 = stablehlo.reshape %5838 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %5840 = stablehlo.reshape %5839 : (tensor<1x1x1x128xf32>) -> tensor<128xf32>
    %5841 = stablehlo.multiply %1566, %5837 : tensor<256x28x28x128xf32>
    %cst_407 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5842 = stablehlo.reduce(%5841 init: %cst_407) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %5843 = stablehlo.reshape %5842 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %5844 = stablehlo.broadcast_in_dim %1574, dims = [0, 1, 2, 3] : (tensor<1x1x1x128xf32>) -> tensor<256x28x28x128xf32>
    %5845 = stablehlo.multiply %5837, %5844 : tensor<256x28x28x128xf32>
    %5846 = stablehlo.multiply %1569, %5843 : tensor<1x1x1x128xf32>
    %5847 = stablehlo.multiply %5843, %1573 : tensor<1x1x1x128xf32>
    %5848 = stablehlo.reshape %5846 : (tensor<1x1x1x128xf32>) -> tensor<128xf32>
    %5849 = stablehlo.multiply %5847, %1572 : tensor<1x1x1x128xf32>
    %cst_408 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5850 = stablehlo.reduce(%5849 init: %cst_408) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x128xf32>, tensor<f32>) -> tensor<128xf32>
    %5851 = stablehlo.multiply %5850, %1551 : tensor<128xf32>
    %5852 = stablehlo.negate %5851 : tensor<128xf32>
    %5853 = stablehlo.multiply %5852, %1538 : tensor<128xf32>
    %5854 = stablehlo.broadcast_in_dim %5851, dims = [1] : (tensor<128xf32>) -> tensor<1x128xf32>
    %5855 = stablehlo.pad %5854, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x128xf32>, tensor<f32>) -> tensor<2x128xf32>
    %5856 = stablehlo.negate %5845 : tensor<256x28x28x128xf32>
    %cst_409 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5857 = stablehlo.reduce(%5856 init: %cst_409) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %5858 = stablehlo.reshape %5857 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %5859 = stablehlo.convert %5845 : (tensor<256x28x28x128xf32>) -> tensor<256x28x28x128xf16>
    %cst_410 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5860 = stablehlo.reduce(%5858 init: %cst_410) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x128xf32>, tensor<f32>) -> tensor<128xf32>
    %5861 = stablehlo.add %5853, %5860 : tensor<128xf32>
    %5862 = stablehlo.broadcast_in_dim %5861, dims = [1] : (tensor<128xf32>) -> tensor<1x128xf32>
    %5863 = stablehlo.pad %5862, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x128xf32>, tensor<f32>) -> tensor<2x128xf32>
    %5864 = stablehlo.add %5855, %5863 : tensor<2x128xf32>
    %5865 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x128xf32>
    %5866 = stablehlo.divide %5864, %5865 : tensor<2x128xf32>
    %5867 = "stablehlo.all_reduce"(%5866) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x128xf32>) -> tensor<2x128xf32>
    %5868 = stablehlo.slice %5867 [0:1, 0:128] : (tensor<2x128xf32>) -> tensor<1x128xf32>
    %5869 = stablehlo.slice %5867 [1:2, 0:128] : (tensor<2x128xf32>) -> tensor<1x128xf32>
    %cst_411 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5870 = stablehlo.reduce(%5869 init: %cst_411) applies stablehlo.add across dimensions = [0] : (tensor<1x128xf32>, tensor<f32>) -> tensor<128xf32>
    %5871 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %5872 = stablehlo.divide %5870, %5871 : tensor<128xf32>
    %5873 = stablehlo.broadcast_in_dim %5872, dims = [3] : (tensor<128xf32>) -> tensor<256x28x28x128xf32>
    %5874 = stablehlo.multiply %5873, %1519 : tensor<256x28x28x128xf32>
    %cst_412 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5875 = stablehlo.reduce(%5868 init: %cst_412) applies stablehlo.add across dimensions = [0] : (tensor<1x128xf32>, tensor<f32>) -> tensor<128xf32>
    %5876 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %5877 = stablehlo.divide %5875, %5876 : tensor<128xf32>
    %5878 = stablehlo.broadcast_in_dim %5877, dims = [3] : (tensor<128xf32>) -> tensor<256x28x28x128xf32>
    %5879 = stablehlo.add %5874, %5878 : tensor<256x28x28x128xf32>
    %5880 = stablehlo.convert %5879 : (tensor<256x28x28x128xf32>) -> tensor<256x28x28x128xf16>
    %5881 = stablehlo.add %5859, %5880 : tensor<256x28x28x128xf16>
    %5882 = stablehlo.convolution(%1510, %5881) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x512xf16>, tensor<256x28x28x128xf16>) -> tensor<1x1x512x128xf16>
    %5883 = stablehlo.convert %5882 : (tensor<1x1x512x128xf16>) -> tensor<1x1x512x128xf32>
    %5884 = stablehlo.add %4118, %5883 : tensor<1x1x512x128xf32>
    %5885 = stablehlo.reverse %1514, dims = [0, 1] : tensor<1x1x512x128xf16>
    %5886 = stablehlo.convolution(%5881, %5885) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x128xf16>, tensor<1x1x512x128xf16>) -> tensor<256x28x28x512xf16>
    %5887 = stablehlo.add %5732, %5886 : tensor<256x28x28x512xf16>
    %5888 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x512xf16>
    %5889 = stablehlo.select %1512, %5887, %5888 : tensor<256x28x28x512xi1>, tensor<256x28x28x512xf16>
    %5890 = stablehlo.convert %5889 : (tensor<256x28x28x512xf16>) -> tensor<256x28x28x512xf32>
    %cst_413 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5891 = stablehlo.reduce(%5890 init: %cst_413) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x512xf32>, tensor<f32>) -> tensor<512xf32>
    %5892 = stablehlo.reshape %5891 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %5893 = stablehlo.reshape %5892 : (tensor<1x1x1x512xf32>) -> tensor<512xf32>
    %5894 = stablehlo.multiply %1494, %5890 : tensor<256x28x28x512xf32>
    %cst_414 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5895 = stablehlo.reduce(%5894 init: %cst_414) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x512xf32>, tensor<f32>) -> tensor<512xf32>
    %5896 = stablehlo.reshape %5895 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %5897 = stablehlo.broadcast_in_dim %1502, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x28x28x512xf32>
    %5898 = stablehlo.multiply %5890, %5897 : tensor<256x28x28x512xf32>
    %5899 = stablehlo.multiply %1497, %5896 : tensor<1x1x1x512xf32>
    %5900 = stablehlo.multiply %5896, %1501 : tensor<1x1x1x512xf32>
    %5901 = stablehlo.reshape %5899 : (tensor<1x1x1x512xf32>) -> tensor<512xf32>
    %5902 = stablehlo.multiply %5900, %1500 : tensor<1x1x1x512xf32>
    %cst_415 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5903 = stablehlo.reduce(%5902 init: %cst_415) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %5904 = stablehlo.multiply %5903, %1479 : tensor<512xf32>
    %5905 = stablehlo.negate %5904 : tensor<512xf32>
    %5906 = stablehlo.multiply %5905, %1466 : tensor<512xf32>
    %5907 = stablehlo.broadcast_in_dim %5904, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %5908 = stablehlo.pad %5907, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<2x512xf32>
    %5909 = stablehlo.negate %5898 : tensor<256x28x28x512xf32>
    %cst_416 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5910 = stablehlo.reduce(%5909 init: %cst_416) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x512xf32>, tensor<f32>) -> tensor<512xf32>
    %5911 = stablehlo.reshape %5910 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %5912 = stablehlo.convert %5898 : (tensor<256x28x28x512xf32>) -> tensor<256x28x28x512xf16>
    %cst_417 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5913 = stablehlo.reduce(%5911 init: %cst_417) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %5914 = stablehlo.add %5906, %5913 : tensor<512xf32>
    %5915 = stablehlo.broadcast_in_dim %5914, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %5916 = stablehlo.pad %5915, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<2x512xf32>
    %5917 = stablehlo.add %5908, %5916 : tensor<2x512xf32>
    %5918 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x512xf32>
    %5919 = stablehlo.divide %5917, %5918 : tensor<2x512xf32>
    %5920 = "stablehlo.all_reduce"(%5919) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x512xf32>) -> tensor<2x512xf32>
    %5921 = stablehlo.slice %5920 [0:1, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %5922 = stablehlo.slice %5920 [1:2, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %cst_418 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5923 = stablehlo.reduce(%5922 init: %cst_418) applies stablehlo.add across dimensions = [0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %5924 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %5925 = stablehlo.divide %5923, %5924 : tensor<512xf32>
    %5926 = stablehlo.broadcast_in_dim %5925, dims = [3] : (tensor<512xf32>) -> tensor<256x28x28x512xf32>
    %5927 = stablehlo.multiply %5926, %1447 : tensor<256x28x28x512xf32>
    %cst_419 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5928 = stablehlo.reduce(%5921 init: %cst_419) applies stablehlo.add across dimensions = [0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %5929 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %5930 = stablehlo.divide %5928, %5929 : tensor<512xf32>
    %5931 = stablehlo.broadcast_in_dim %5930, dims = [3] : (tensor<512xf32>) -> tensor<256x28x28x512xf32>
    %5932 = stablehlo.add %5927, %5931 : tensor<256x28x28x512xf32>
    %5933 = stablehlo.convert %5932 : (tensor<256x28x28x512xf32>) -> tensor<256x28x28x512xf16>
    %5934 = stablehlo.add %5912, %5933 : tensor<256x28x28x512xf16>
    %5935 = stablehlo.convolution(%1438, %5934) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x128xf16>, tensor<256x28x28x512xf16>) -> tensor<1x1x128x512xf16>
    %5936 = stablehlo.convert %5935 : (tensor<1x1x128x512xf16>) -> tensor<1x1x128x512xf32>
    %5937 = stablehlo.add %4120, %5936 : tensor<1x1x128x512xf32>
    %5938 = stablehlo.reverse %1442, dims = [0, 1] : tensor<1x1x128x512xf16>
    %5939 = stablehlo.convolution(%5934, %5938) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x512xf16>, tensor<1x1x128x512xf16>) -> tensor<256x28x28x128xf16>
    %5940 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x128xf16>
    %5941 = stablehlo.select %1440, %5939, %5940 : tensor<256x28x28x128xi1>, tensor<256x28x28x128xf16>
    %5942 = stablehlo.convert %5941 : (tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xf32>
    %cst_420 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5943 = stablehlo.reduce(%5942 init: %cst_420) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %5944 = stablehlo.reshape %5943 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %5945 = stablehlo.reshape %5944 : (tensor<1x1x1x128xf32>) -> tensor<128xf32>
    %5946 = stablehlo.multiply %1423, %5942 : tensor<256x28x28x128xf32>
    %cst_421 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5947 = stablehlo.reduce(%5946 init: %cst_421) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %5948 = stablehlo.reshape %5947 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %5949 = stablehlo.broadcast_in_dim %1431, dims = [0, 1, 2, 3] : (tensor<1x1x1x128xf32>) -> tensor<256x28x28x128xf32>
    %5950 = stablehlo.multiply %5942, %5949 : tensor<256x28x28x128xf32>
    %5951 = stablehlo.multiply %1426, %5948 : tensor<1x1x1x128xf32>
    %5952 = stablehlo.multiply %5948, %1430 : tensor<1x1x1x128xf32>
    %5953 = stablehlo.reshape %5951 : (tensor<1x1x1x128xf32>) -> tensor<128xf32>
    %5954 = stablehlo.multiply %5952, %1429 : tensor<1x1x1x128xf32>
    %cst_422 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5955 = stablehlo.reduce(%5954 init: %cst_422) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x128xf32>, tensor<f32>) -> tensor<128xf32>
    %5956 = stablehlo.multiply %5955, %1408 : tensor<128xf32>
    %5957 = stablehlo.negate %5956 : tensor<128xf32>
    %5958 = stablehlo.multiply %5957, %1395 : tensor<128xf32>
    %5959 = stablehlo.broadcast_in_dim %5956, dims = [1] : (tensor<128xf32>) -> tensor<1x128xf32>
    %5960 = stablehlo.pad %5959, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x128xf32>, tensor<f32>) -> tensor<2x128xf32>
    %5961 = stablehlo.negate %5950 : tensor<256x28x28x128xf32>
    %cst_423 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5962 = stablehlo.reduce(%5961 init: %cst_423) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %5963 = stablehlo.reshape %5962 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %5964 = stablehlo.convert %5950 : (tensor<256x28x28x128xf32>) -> tensor<256x28x28x128xf16>
    %cst_424 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5965 = stablehlo.reduce(%5963 init: %cst_424) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x128xf32>, tensor<f32>) -> tensor<128xf32>
    %5966 = stablehlo.add %5958, %5965 : tensor<128xf32>
    %5967 = stablehlo.broadcast_in_dim %5966, dims = [1] : (tensor<128xf32>) -> tensor<1x128xf32>
    %5968 = stablehlo.pad %5967, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x128xf32>, tensor<f32>) -> tensor<2x128xf32>
    %5969 = stablehlo.add %5960, %5968 : tensor<2x128xf32>
    %5970 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x128xf32>
    %5971 = stablehlo.divide %5969, %5970 : tensor<2x128xf32>
    %5972 = "stablehlo.all_reduce"(%5971) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x128xf32>) -> tensor<2x128xf32>
    %5973 = stablehlo.slice %5972 [0:1, 0:128] : (tensor<2x128xf32>) -> tensor<1x128xf32>
    %5974 = stablehlo.slice %5972 [1:2, 0:128] : (tensor<2x128xf32>) -> tensor<1x128xf32>
    %cst_425 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5975 = stablehlo.reduce(%5974 init: %cst_425) applies stablehlo.add across dimensions = [0] : (tensor<1x128xf32>, tensor<f32>) -> tensor<128xf32>
    %5976 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %5977 = stablehlo.divide %5975, %5976 : tensor<128xf32>
    %5978 = stablehlo.broadcast_in_dim %5977, dims = [3] : (tensor<128xf32>) -> tensor<256x28x28x128xf32>
    %5979 = stablehlo.multiply %5978, %1376 : tensor<256x28x28x128xf32>
    %cst_426 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5980 = stablehlo.reduce(%5973 init: %cst_426) applies stablehlo.add across dimensions = [0] : (tensor<1x128xf32>, tensor<f32>) -> tensor<128xf32>
    %5981 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %5982 = stablehlo.divide %5980, %5981 : tensor<128xf32>
    %5983 = stablehlo.broadcast_in_dim %5982, dims = [3] : (tensor<128xf32>) -> tensor<256x28x28x128xf32>
    %5984 = stablehlo.add %5979, %5983 : tensor<256x28x28x128xf32>
    %5985 = stablehlo.convert %5984 : (tensor<256x28x28x128xf32>) -> tensor<256x28x28x128xf16>
    %5986 = stablehlo.add %5964, %5985 : tensor<256x28x28x128xf16>
    %5987 = stablehlo.convolution(%1367, %5986) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x128xf16>, tensor<256x28x28x128xf16>) -> tensor<3x3x128x128xf16>
    %5988 = stablehlo.convert %5987 : (tensor<3x3x128x128xf16>) -> tensor<3x3x128x128xf32>
    %5989 = stablehlo.add %4122, %5988 : tensor<3x3x128x128xf32>
    %5990 = stablehlo.reverse %1371, dims = [0, 1] : tensor<3x3x128x128xf16>
    %5991 = stablehlo.convolution(%5986, %5990) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x128xf16>, tensor<3x3x128x128xf16>) -> tensor<256x28x28x128xf16>
    %5992 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x128xf16>
    %5993 = stablehlo.select %1369, %5991, %5992 : tensor<256x28x28x128xi1>, tensor<256x28x28x128xf16>
    %5994 = stablehlo.convert %5993 : (tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xf32>
    %cst_427 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5995 = stablehlo.reduce(%5994 init: %cst_427) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %5996 = stablehlo.reshape %5995 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %5997 = stablehlo.reshape %5996 : (tensor<1x1x1x128xf32>) -> tensor<128xf32>
    %5998 = stablehlo.multiply %1352, %5994 : tensor<256x28x28x128xf32>
    %cst_428 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5999 = stablehlo.reduce(%5998 init: %cst_428) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6000 = stablehlo.reshape %5999 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %6001 = stablehlo.broadcast_in_dim %1360, dims = [0, 1, 2, 3] : (tensor<1x1x1x128xf32>) -> tensor<256x28x28x128xf32>
    %6002 = stablehlo.multiply %5994, %6001 : tensor<256x28x28x128xf32>
    %6003 = stablehlo.multiply %1355, %6000 : tensor<1x1x1x128xf32>
    %6004 = stablehlo.multiply %6000, %1359 : tensor<1x1x1x128xf32>
    %6005 = stablehlo.reshape %6003 : (tensor<1x1x1x128xf32>) -> tensor<128xf32>
    %6006 = stablehlo.multiply %6004, %1358 : tensor<1x1x1x128xf32>
    %cst_429 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6007 = stablehlo.reduce(%6006 init: %cst_429) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6008 = stablehlo.multiply %6007, %1337 : tensor<128xf32>
    %6009 = stablehlo.negate %6008 : tensor<128xf32>
    %6010 = stablehlo.multiply %6009, %1324 : tensor<128xf32>
    %6011 = stablehlo.broadcast_in_dim %6008, dims = [1] : (tensor<128xf32>) -> tensor<1x128xf32>
    %6012 = stablehlo.pad %6011, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x128xf32>, tensor<f32>) -> tensor<2x128xf32>
    %6013 = stablehlo.negate %6002 : tensor<256x28x28x128xf32>
    %cst_430 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6014 = stablehlo.reduce(%6013 init: %cst_430) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6015 = stablehlo.reshape %6014 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %6016 = stablehlo.convert %6002 : (tensor<256x28x28x128xf32>) -> tensor<256x28x28x128xf16>
    %cst_431 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6017 = stablehlo.reduce(%6015 init: %cst_431) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6018 = stablehlo.add %6010, %6017 : tensor<128xf32>
    %6019 = stablehlo.broadcast_in_dim %6018, dims = [1] : (tensor<128xf32>) -> tensor<1x128xf32>
    %6020 = stablehlo.pad %6019, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x128xf32>, tensor<f32>) -> tensor<2x128xf32>
    %6021 = stablehlo.add %6012, %6020 : tensor<2x128xf32>
    %6022 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x128xf32>
    %6023 = stablehlo.divide %6021, %6022 : tensor<2x128xf32>
    %6024 = "stablehlo.all_reduce"(%6023) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x128xf32>) -> tensor<2x128xf32>
    %6025 = stablehlo.slice %6024 [0:1, 0:128] : (tensor<2x128xf32>) -> tensor<1x128xf32>
    %6026 = stablehlo.slice %6024 [1:2, 0:128] : (tensor<2x128xf32>) -> tensor<1x128xf32>
    %cst_432 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6027 = stablehlo.reduce(%6026 init: %cst_432) applies stablehlo.add across dimensions = [0] : (tensor<1x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6028 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %6029 = stablehlo.divide %6027, %6028 : tensor<128xf32>
    %6030 = stablehlo.broadcast_in_dim %6029, dims = [3] : (tensor<128xf32>) -> tensor<256x28x28x128xf32>
    %6031 = stablehlo.multiply %6030, %1305 : tensor<256x28x28x128xf32>
    %cst_433 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6032 = stablehlo.reduce(%6025 init: %cst_433) applies stablehlo.add across dimensions = [0] : (tensor<1x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6033 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %6034 = stablehlo.divide %6032, %6033 : tensor<128xf32>
    %6035 = stablehlo.broadcast_in_dim %6034, dims = [3] : (tensor<128xf32>) -> tensor<256x28x28x128xf32>
    %6036 = stablehlo.add %6031, %6035 : tensor<256x28x28x128xf32>
    %6037 = stablehlo.convert %6036 : (tensor<256x28x28x128xf32>) -> tensor<256x28x28x128xf16>
    %6038 = stablehlo.add %6016, %6037 : tensor<256x28x28x128xf16>
    %6039 = stablehlo.convolution(%1296, %6038) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x512xf16>, tensor<256x28x28x128xf16>) -> tensor<1x1x512x128xf16>
    %6040 = stablehlo.convert %6039 : (tensor<1x1x512x128xf16>) -> tensor<1x1x512x128xf32>
    %6041 = stablehlo.add %4124, %6040 : tensor<1x1x512x128xf32>
    %6042 = stablehlo.reverse %1300, dims = [0, 1] : tensor<1x1x512x128xf16>
    %6043 = stablehlo.convolution(%6038, %6042) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x128xf16>, tensor<1x1x512x128xf16>) -> tensor<256x28x28x512xf16>
    %6044 = stablehlo.add %5889, %6043 : tensor<256x28x28x512xf16>
    %6045 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x512xf16>
    %6046 = stablehlo.select %1298, %6044, %6045 : tensor<256x28x28x512xi1>, tensor<256x28x28x512xf16>
    %6047 = stablehlo.convert %6046 : (tensor<256x28x28x512xf16>) -> tensor<256x28x28x512xf32>
    %cst_434 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6048 = stablehlo.reduce(%6047 init: %cst_434) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x512xf32>, tensor<f32>) -> tensor<512xf32>
    %6049 = stablehlo.reshape %6048 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %6050 = stablehlo.reshape %6049 : (tensor<1x1x1x512xf32>) -> tensor<512xf32>
    %6051 = stablehlo.multiply %1280, %6047 : tensor<256x28x28x512xf32>
    %cst_435 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6052 = stablehlo.reduce(%6051 init: %cst_435) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x512xf32>, tensor<f32>) -> tensor<512xf32>
    %6053 = stablehlo.reshape %6052 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %6054 = stablehlo.broadcast_in_dim %1288, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x28x28x512xf32>
    %6055 = stablehlo.multiply %6047, %6054 : tensor<256x28x28x512xf32>
    %6056 = stablehlo.multiply %1283, %6053 : tensor<1x1x1x512xf32>
    %6057 = stablehlo.multiply %6053, %1287 : tensor<1x1x1x512xf32>
    %6058 = stablehlo.reshape %6056 : (tensor<1x1x1x512xf32>) -> tensor<512xf32>
    %6059 = stablehlo.multiply %6057, %1286 : tensor<1x1x1x512xf32>
    %cst_436 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6060 = stablehlo.reduce(%6059 init: %cst_436) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %6061 = stablehlo.multiply %6060, %1265 : tensor<512xf32>
    %6062 = stablehlo.negate %6061 : tensor<512xf32>
    %6063 = stablehlo.multiply %6062, %1252 : tensor<512xf32>
    %6064 = stablehlo.broadcast_in_dim %6061, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %6065 = stablehlo.pad %6064, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<2x512xf32>
    %6066 = stablehlo.negate %6055 : tensor<256x28x28x512xf32>
    %cst_437 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6067 = stablehlo.reduce(%6066 init: %cst_437) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x512xf32>, tensor<f32>) -> tensor<512xf32>
    %6068 = stablehlo.reshape %6067 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %6069 = stablehlo.convert %6055 : (tensor<256x28x28x512xf32>) -> tensor<256x28x28x512xf16>
    %cst_438 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6070 = stablehlo.reduce(%6068 init: %cst_438) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %6071 = stablehlo.add %6063, %6070 : tensor<512xf32>
    %6072 = stablehlo.broadcast_in_dim %6071, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %6073 = stablehlo.pad %6072, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<2x512xf32>
    %6074 = stablehlo.add %6065, %6073 : tensor<2x512xf32>
    %6075 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x512xf32>
    %6076 = stablehlo.divide %6074, %6075 : tensor<2x512xf32>
    %6077 = "stablehlo.all_reduce"(%6076) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x512xf32>) -> tensor<2x512xf32>
    %6078 = stablehlo.slice %6077 [0:1, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %6079 = stablehlo.slice %6077 [1:2, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %cst_439 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6080 = stablehlo.reduce(%6079 init: %cst_439) applies stablehlo.add across dimensions = [0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %6081 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %6082 = stablehlo.divide %6080, %6081 : tensor<512xf32>
    %6083 = stablehlo.broadcast_in_dim %6082, dims = [3] : (tensor<512xf32>) -> tensor<256x28x28x512xf32>
    %6084 = stablehlo.multiply %6083, %1233 : tensor<256x28x28x512xf32>
    %cst_440 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6085 = stablehlo.reduce(%6078 init: %cst_440) applies stablehlo.add across dimensions = [0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %6086 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %6087 = stablehlo.divide %6085, %6086 : tensor<512xf32>
    %6088 = stablehlo.broadcast_in_dim %6087, dims = [3] : (tensor<512xf32>) -> tensor<256x28x28x512xf32>
    %6089 = stablehlo.add %6084, %6088 : tensor<256x28x28x512xf32>
    %6090 = stablehlo.convert %6089 : (tensor<256x28x28x512xf32>) -> tensor<256x28x28x512xf16>
    %6091 = stablehlo.add %6069, %6090 : tensor<256x28x28x512xf16>
    %6092 = stablehlo.convolution(%1224, %6091) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x128xf16>, tensor<256x28x28x512xf16>) -> tensor<1x1x128x512xf16>
    %6093 = stablehlo.convert %6092 : (tensor<1x1x128x512xf16>) -> tensor<1x1x128x512xf32>
    %6094 = stablehlo.add %4126, %6093 : tensor<1x1x128x512xf32>
    %6095 = stablehlo.reverse %1228, dims = [0, 1] : tensor<1x1x128x512xf16>
    %6096 = stablehlo.convolution(%6091, %6095) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x512xf16>, tensor<1x1x128x512xf16>) -> tensor<256x28x28x128xf16>
    %6097 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x128xf16>
    %6098 = stablehlo.select %1226, %6096, %6097 : tensor<256x28x28x128xi1>, tensor<256x28x28x128xf16>
    %6099 = stablehlo.convert %6098 : (tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xf32>
    %cst_441 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6100 = stablehlo.reduce(%6099 init: %cst_441) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6101 = stablehlo.reshape %6100 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %6102 = stablehlo.reshape %6101 : (tensor<1x1x1x128xf32>) -> tensor<128xf32>
    %6103 = stablehlo.multiply %1209, %6099 : tensor<256x28x28x128xf32>
    %cst_442 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6104 = stablehlo.reduce(%6103 init: %cst_442) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6105 = stablehlo.reshape %6104 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %6106 = stablehlo.broadcast_in_dim %1217, dims = [0, 1, 2, 3] : (tensor<1x1x1x128xf32>) -> tensor<256x28x28x128xf32>
    %6107 = stablehlo.multiply %6099, %6106 : tensor<256x28x28x128xf32>
    %6108 = stablehlo.multiply %1212, %6105 : tensor<1x1x1x128xf32>
    %6109 = stablehlo.multiply %6105, %1216 : tensor<1x1x1x128xf32>
    %6110 = stablehlo.reshape %6108 : (tensor<1x1x1x128xf32>) -> tensor<128xf32>
    %6111 = stablehlo.multiply %6109, %1215 : tensor<1x1x1x128xf32>
    %cst_443 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6112 = stablehlo.reduce(%6111 init: %cst_443) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6113 = stablehlo.multiply %6112, %1194 : tensor<128xf32>
    %6114 = stablehlo.negate %6113 : tensor<128xf32>
    %6115 = stablehlo.multiply %6114, %1181 : tensor<128xf32>
    %6116 = stablehlo.broadcast_in_dim %6113, dims = [1] : (tensor<128xf32>) -> tensor<1x128xf32>
    %6117 = stablehlo.pad %6116, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x128xf32>, tensor<f32>) -> tensor<2x128xf32>
    %6118 = stablehlo.negate %6107 : tensor<256x28x28x128xf32>
    %cst_444 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6119 = stablehlo.reduce(%6118 init: %cst_444) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6120 = stablehlo.reshape %6119 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %6121 = stablehlo.convert %6107 : (tensor<256x28x28x128xf32>) -> tensor<256x28x28x128xf16>
    %cst_445 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6122 = stablehlo.reduce(%6120 init: %cst_445) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6123 = stablehlo.add %6115, %6122 : tensor<128xf32>
    %6124 = stablehlo.broadcast_in_dim %6123, dims = [1] : (tensor<128xf32>) -> tensor<1x128xf32>
    %6125 = stablehlo.pad %6124, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x128xf32>, tensor<f32>) -> tensor<2x128xf32>
    %6126 = stablehlo.add %6117, %6125 : tensor<2x128xf32>
    %6127 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x128xf32>
    %6128 = stablehlo.divide %6126, %6127 : tensor<2x128xf32>
    %6129 = "stablehlo.all_reduce"(%6128) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x128xf32>) -> tensor<2x128xf32>
    %6130 = stablehlo.slice %6129 [0:1, 0:128] : (tensor<2x128xf32>) -> tensor<1x128xf32>
    %6131 = stablehlo.slice %6129 [1:2, 0:128] : (tensor<2x128xf32>) -> tensor<1x128xf32>
    %cst_446 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6132 = stablehlo.reduce(%6131 init: %cst_446) applies stablehlo.add across dimensions = [0] : (tensor<1x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6133 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %6134 = stablehlo.divide %6132, %6133 : tensor<128xf32>
    %6135 = stablehlo.broadcast_in_dim %6134, dims = [3] : (tensor<128xf32>) -> tensor<256x28x28x128xf32>
    %6136 = stablehlo.multiply %6135, %1162 : tensor<256x28x28x128xf32>
    %cst_447 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6137 = stablehlo.reduce(%6130 init: %cst_447) applies stablehlo.add across dimensions = [0] : (tensor<1x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6138 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %6139 = stablehlo.divide %6137, %6138 : tensor<128xf32>
    %6140 = stablehlo.broadcast_in_dim %6139, dims = [3] : (tensor<128xf32>) -> tensor<256x28x28x128xf32>
    %6141 = stablehlo.add %6136, %6140 : tensor<256x28x28x128xf32>
    %6142 = stablehlo.convert %6141 : (tensor<256x28x28x128xf32>) -> tensor<256x28x28x128xf16>
    %6143 = stablehlo.add %6121, %6142 : tensor<256x28x28x128xf16>
    %6144 = stablehlo.convolution(%1153, %6143) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x128xf16>, tensor<256x28x28x128xf16>) -> tensor<3x3x128x128xf16>
    %6145 = stablehlo.convert %6144 : (tensor<3x3x128x128xf16>) -> tensor<3x3x128x128xf32>
    %6146 = stablehlo.add %4128, %6145 : tensor<3x3x128x128xf32>
    %6147 = stablehlo.reverse %1157, dims = [0, 1] : tensor<3x3x128x128xf16>
    %6148 = stablehlo.convolution(%6143, %6147) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x128xf16>, tensor<3x3x128x128xf16>) -> tensor<256x28x28x128xf16>
    %6149 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x128xf16>
    %6150 = stablehlo.select %1155, %6148, %6149 : tensor<256x28x28x128xi1>, tensor<256x28x28x128xf16>
    %6151 = stablehlo.convert %6150 : (tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xf32>
    %cst_448 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6152 = stablehlo.reduce(%6151 init: %cst_448) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6153 = stablehlo.reshape %6152 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %6154 = stablehlo.reshape %6153 : (tensor<1x1x1x128xf32>) -> tensor<128xf32>
    %6155 = stablehlo.multiply %1138, %6151 : tensor<256x28x28x128xf32>
    %cst_449 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6156 = stablehlo.reduce(%6155 init: %cst_449) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6157 = stablehlo.reshape %6156 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %6158 = stablehlo.broadcast_in_dim %1146, dims = [0, 1, 2, 3] : (tensor<1x1x1x128xf32>) -> tensor<256x28x28x128xf32>
    %6159 = stablehlo.multiply %6151, %6158 : tensor<256x28x28x128xf32>
    %6160 = stablehlo.multiply %1141, %6157 : tensor<1x1x1x128xf32>
    %6161 = stablehlo.multiply %6157, %1145 : tensor<1x1x1x128xf32>
    %6162 = stablehlo.reshape %6160 : (tensor<1x1x1x128xf32>) -> tensor<128xf32>
    %6163 = stablehlo.multiply %6161, %1144 : tensor<1x1x1x128xf32>
    %cst_450 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6164 = stablehlo.reduce(%6163 init: %cst_450) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6165 = stablehlo.multiply %6164, %1123 : tensor<128xf32>
    %6166 = stablehlo.negate %6165 : tensor<128xf32>
    %6167 = stablehlo.multiply %6166, %1110 : tensor<128xf32>
    %6168 = stablehlo.broadcast_in_dim %6165, dims = [1] : (tensor<128xf32>) -> tensor<1x128xf32>
    %6169 = stablehlo.pad %6168, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x128xf32>, tensor<f32>) -> tensor<2x128xf32>
    %6170 = stablehlo.negate %6159 : tensor<256x28x28x128xf32>
    %cst_451 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6171 = stablehlo.reduce(%6170 init: %cst_451) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6172 = stablehlo.reshape %6171 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %6173 = stablehlo.convert %6159 : (tensor<256x28x28x128xf32>) -> tensor<256x28x28x128xf16>
    %cst_452 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6174 = stablehlo.reduce(%6172 init: %cst_452) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6175 = stablehlo.add %6167, %6174 : tensor<128xf32>
    %6176 = stablehlo.broadcast_in_dim %6175, dims = [1] : (tensor<128xf32>) -> tensor<1x128xf32>
    %6177 = stablehlo.pad %6176, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x128xf32>, tensor<f32>) -> tensor<2x128xf32>
    %6178 = stablehlo.add %6169, %6177 : tensor<2x128xf32>
    %6179 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x128xf32>
    %6180 = stablehlo.divide %6178, %6179 : tensor<2x128xf32>
    %6181 = "stablehlo.all_reduce"(%6180) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x128xf32>) -> tensor<2x128xf32>
    %6182 = stablehlo.slice %6181 [0:1, 0:128] : (tensor<2x128xf32>) -> tensor<1x128xf32>
    %6183 = stablehlo.slice %6181 [1:2, 0:128] : (tensor<2x128xf32>) -> tensor<1x128xf32>
    %cst_453 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6184 = stablehlo.reduce(%6183 init: %cst_453) applies stablehlo.add across dimensions = [0] : (tensor<1x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6185 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %6186 = stablehlo.divide %6184, %6185 : tensor<128xf32>
    %6187 = stablehlo.broadcast_in_dim %6186, dims = [3] : (tensor<128xf32>) -> tensor<256x28x28x128xf32>
    %6188 = stablehlo.multiply %6187, %1091 : tensor<256x28x28x128xf32>
    %cst_454 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6189 = stablehlo.reduce(%6182 init: %cst_454) applies stablehlo.add across dimensions = [0] : (tensor<1x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6190 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %6191 = stablehlo.divide %6189, %6190 : tensor<128xf32>
    %6192 = stablehlo.broadcast_in_dim %6191, dims = [3] : (tensor<128xf32>) -> tensor<256x28x28x128xf32>
    %6193 = stablehlo.add %6188, %6192 : tensor<256x28x28x128xf32>
    %6194 = stablehlo.convert %6193 : (tensor<256x28x28x128xf32>) -> tensor<256x28x28x128xf16>
    %6195 = stablehlo.add %6173, %6194 : tensor<256x28x28x128xf16>
    %6196 = stablehlo.convolution(%1082, %6195) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x512xf16>, tensor<256x28x28x128xf16>) -> tensor<1x1x512x128xf16>
    %6197 = stablehlo.convert %6196 : (tensor<1x1x512x128xf16>) -> tensor<1x1x512x128xf32>
    %6198 = stablehlo.add %4130, %6197 : tensor<1x1x512x128xf32>
    %6199 = stablehlo.reverse %1086, dims = [0, 1] : tensor<1x1x512x128xf16>
    %6200 = stablehlo.convolution(%6195, %6199) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x128xf16>, tensor<1x1x512x128xf16>) -> tensor<256x28x28x512xf16>
    %6201 = stablehlo.add %6046, %6200 : tensor<256x28x28x512xf16>
    %6202 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x512xf16>
    %6203 = stablehlo.select %1084, %6201, %6202 : tensor<256x28x28x512xi1>, tensor<256x28x28x512xf16>
    %6204 = stablehlo.convert %6203 : (tensor<256x28x28x512xf16>) -> tensor<256x28x28x512xf32>
    %cst_455 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6205 = stablehlo.reduce(%6204 init: %cst_455) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x512xf32>, tensor<f32>) -> tensor<512xf32>
    %6206 = stablehlo.reshape %6205 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %6207 = stablehlo.reshape %6206 : (tensor<1x1x1x512xf32>) -> tensor<512xf32>
    %6208 = stablehlo.multiply %999, %6204 : tensor<256x28x28x512xf32>
    %cst_456 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6209 = stablehlo.reduce(%6208 init: %cst_456) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x512xf32>, tensor<f32>) -> tensor<512xf32>
    %6210 = stablehlo.reshape %6209 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %6211 = stablehlo.broadcast_in_dim %1007, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x28x28x512xf32>
    %6212 = stablehlo.multiply %6204, %6211 : tensor<256x28x28x512xf32>
    %6213 = stablehlo.multiply %1002, %6210 : tensor<1x1x1x512xf32>
    %6214 = stablehlo.multiply %6210, %1006 : tensor<1x1x1x512xf32>
    %6215 = stablehlo.reshape %6213 : (tensor<1x1x1x512xf32>) -> tensor<512xf32>
    %6216 = stablehlo.multiply %6214, %1005 : tensor<1x1x1x512xf32>
    %cst_457 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6217 = stablehlo.reduce(%6216 init: %cst_457) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %6218 = stablehlo.multiply %6217, %984 : tensor<512xf32>
    %6219 = stablehlo.negate %6218 : tensor<512xf32>
    %6220 = stablehlo.multiply %6219, %971 : tensor<512xf32>
    %6221 = stablehlo.broadcast_in_dim %6218, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %6222 = stablehlo.pad %6221, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<2x512xf32>
    %6223 = stablehlo.negate %6212 : tensor<256x28x28x512xf32>
    %cst_458 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6224 = stablehlo.reduce(%6223 init: %cst_458) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x512xf32>, tensor<f32>) -> tensor<512xf32>
    %6225 = stablehlo.reshape %6224 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %6226 = stablehlo.convert %6212 : (tensor<256x28x28x512xf32>) -> tensor<256x28x28x512xf16>
    %cst_459 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6227 = stablehlo.reduce(%6225 init: %cst_459) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %6228 = stablehlo.add %6220, %6227 : tensor<512xf32>
    %6229 = stablehlo.broadcast_in_dim %6228, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %6230 = stablehlo.pad %6229, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<2x512xf32>
    %6231 = stablehlo.add %6222, %6230 : tensor<2x512xf32>
    %6232 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x512xf32>
    %6233 = stablehlo.divide %6231, %6232 : tensor<2x512xf32>
    %6234 = "stablehlo.all_reduce"(%6233) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x512xf32>) -> tensor<2x512xf32>
    %6235 = stablehlo.slice %6234 [0:1, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %6236 = stablehlo.slice %6234 [1:2, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %cst_460 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6237 = stablehlo.reduce(%6236 init: %cst_460) applies stablehlo.add across dimensions = [0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %6238 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %6239 = stablehlo.divide %6237, %6238 : tensor<512xf32>
    %6240 = stablehlo.broadcast_in_dim %6239, dims = [3] : (tensor<512xf32>) -> tensor<256x28x28x512xf32>
    %6241 = stablehlo.multiply %6240, %952 : tensor<256x28x28x512xf32>
    %cst_461 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6242 = stablehlo.reduce(%6235 init: %cst_461) applies stablehlo.add across dimensions = [0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %6243 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %6244 = stablehlo.divide %6242, %6243 : tensor<512xf32>
    %6245 = stablehlo.broadcast_in_dim %6244, dims = [3] : (tensor<512xf32>) -> tensor<256x28x28x512xf32>
    %6246 = stablehlo.add %6241, %6245 : tensor<256x28x28x512xf32>
    %6247 = stablehlo.convert %6246 : (tensor<256x28x28x512xf32>) -> tensor<256x28x28x512xf16>
    %6248 = stablehlo.add %6226, %6247 : tensor<256x28x28x512xf16>
    %6249 = stablehlo.convolution(%943, %6248) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x128xf16>, tensor<256x28x28x512xf16>) -> tensor<1x1x128x512xf16>
    %6250 = stablehlo.convert %6249 : (tensor<1x1x128x512xf16>) -> tensor<1x1x128x512xf32>
    %6251 = stablehlo.add %4134, %6250 : tensor<1x1x128x512xf32>
    %6252 = stablehlo.reverse %947, dims = [0, 1] : tensor<1x1x128x512xf16>
    %6253 = stablehlo.convolution(%6248, %6252) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x512xf16>, tensor<1x1x128x512xf16>) -> tensor<256x28x28x128xf16>
    %6254 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x28x28x128xf16>
    %6255 = stablehlo.select %945, %6253, %6254 : tensor<256x28x28x128xi1>, tensor<256x28x28x128xf16>
    %6256 = stablehlo.convert %6255 : (tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xf32>
    %cst_462 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6257 = stablehlo.reduce(%6256 init: %cst_462) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6258 = stablehlo.reshape %6257 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %6259 = stablehlo.reshape %6258 : (tensor<1x1x1x128xf32>) -> tensor<128xf32>
    %6260 = stablehlo.multiply %928, %6256 : tensor<256x28x28x128xf32>
    %cst_463 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6261 = stablehlo.reduce(%6260 init: %cst_463) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6262 = stablehlo.reshape %6261 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %6263 = stablehlo.broadcast_in_dim %936, dims = [0, 1, 2, 3] : (tensor<1x1x1x128xf32>) -> tensor<256x28x28x128xf32>
    %6264 = stablehlo.multiply %6256, %6263 : tensor<256x28x28x128xf32>
    %6265 = stablehlo.multiply %931, %6262 : tensor<1x1x1x128xf32>
    %6266 = stablehlo.multiply %6262, %935 : tensor<1x1x1x128xf32>
    %6267 = stablehlo.reshape %6265 : (tensor<1x1x1x128xf32>) -> tensor<128xf32>
    %6268 = stablehlo.multiply %6266, %934 : tensor<1x1x1x128xf32>
    %cst_464 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6269 = stablehlo.reduce(%6268 init: %cst_464) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6270 = stablehlo.multiply %6269, %913 : tensor<128xf32>
    %6271 = stablehlo.negate %6270 : tensor<128xf32>
    %6272 = stablehlo.multiply %6271, %900 : tensor<128xf32>
    %6273 = stablehlo.broadcast_in_dim %6270, dims = [1] : (tensor<128xf32>) -> tensor<1x128xf32>
    %6274 = stablehlo.pad %6273, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x128xf32>, tensor<f32>) -> tensor<2x128xf32>
    %6275 = stablehlo.negate %6264 : tensor<256x28x28x128xf32>
    %cst_465 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6276 = stablehlo.reduce(%6275 init: %cst_465) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6277 = stablehlo.reshape %6276 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %6278 = stablehlo.convert %6264 : (tensor<256x28x28x128xf32>) -> tensor<256x28x28x128xf16>
    %cst_466 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6279 = stablehlo.reduce(%6277 init: %cst_466) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6280 = stablehlo.add %6272, %6279 : tensor<128xf32>
    %6281 = stablehlo.broadcast_in_dim %6280, dims = [1] : (tensor<128xf32>) -> tensor<1x128xf32>
    %6282 = stablehlo.pad %6281, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x128xf32>, tensor<f32>) -> tensor<2x128xf32>
    %6283 = stablehlo.add %6274, %6282 : tensor<2x128xf32>
    %6284 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x128xf32>
    %6285 = stablehlo.divide %6283, %6284 : tensor<2x128xf32>
    %6286 = "stablehlo.all_reduce"(%6285) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x128xf32>) -> tensor<2x128xf32>
    %6287 = stablehlo.slice %6286 [0:1, 0:128] : (tensor<2x128xf32>) -> tensor<1x128xf32>
    %6288 = stablehlo.slice %6286 [1:2, 0:128] : (tensor<2x128xf32>) -> tensor<1x128xf32>
    %cst_467 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6289 = stablehlo.reduce(%6288 init: %cst_467) applies stablehlo.add across dimensions = [0] : (tensor<1x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6290 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %6291 = stablehlo.divide %6289, %6290 : tensor<128xf32>
    %6292 = stablehlo.broadcast_in_dim %6291, dims = [3] : (tensor<128xf32>) -> tensor<256x28x28x128xf32>
    %6293 = stablehlo.multiply %6292, %881 : tensor<256x28x28x128xf32>
    %cst_468 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6294 = stablehlo.reduce(%6287 init: %cst_468) applies stablehlo.add across dimensions = [0] : (tensor<1x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6295 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %6296 = stablehlo.divide %6294, %6295 : tensor<128xf32>
    %6297 = stablehlo.broadcast_in_dim %6296, dims = [3] : (tensor<128xf32>) -> tensor<256x28x28x128xf32>
    %6298 = stablehlo.add %6293, %6297 : tensor<256x28x28x128xf32>
    %6299 = stablehlo.convert %6298 : (tensor<256x28x28x128xf32>) -> tensor<256x28x28x128xf16>
    %6300 = stablehlo.add %6278, %6299 : tensor<256x28x28x128xf16>
    %6301 = stablehlo.convolution(%872, %6300) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 1], [0, 1]], lhs_dilate = [1, 1], rhs_dilate = [2, 2], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x128xf16>, tensor<256x28x28x128xf16>) -> tensor<3x3x128x128xf16>
    %6302 = stablehlo.convert %6301 : (tensor<3x3x128x128xf16>) -> tensor<3x3x128x128xf32>
    %6303 = stablehlo.add %4136, %6302 : tensor<3x3x128x128xf32>
    %6304 = stablehlo.reverse %876, dims = [0, 1] : tensor<3x3x128x128xf16>
    %6305 = stablehlo.convolution(%6300, %6304) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[2, 1], [2, 1]], lhs_dilate = [2, 2], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x128xf16>, tensor<3x3x128x128xf16>) -> tensor<256x56x56x128xf16>
    %6306 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x56x56x128xf16>
    %6307 = stablehlo.select %874, %6305, %6306 : tensor<256x56x56x128xi1>, tensor<256x56x56x128xf16>
    %6308 = stablehlo.convert %6307 : (tensor<256x56x56x128xf16>) -> tensor<256x56x56x128xf32>
    %cst_469 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6309 = stablehlo.reduce(%6308 init: %cst_469) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6310 = stablehlo.reshape %6309 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %6311 = stablehlo.reshape %6310 : (tensor<1x1x1x128xf32>) -> tensor<128xf32>
    %6312 = stablehlo.multiply %857, %6308 : tensor<256x56x56x128xf32>
    %cst_470 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6313 = stablehlo.reduce(%6312 init: %cst_470) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6314 = stablehlo.reshape %6313 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %6315 = stablehlo.broadcast_in_dim %865, dims = [0, 1, 2, 3] : (tensor<1x1x1x128xf32>) -> tensor<256x56x56x128xf32>
    %6316 = stablehlo.multiply %6308, %6315 : tensor<256x56x56x128xf32>
    %6317 = stablehlo.multiply %860, %6314 : tensor<1x1x1x128xf32>
    %6318 = stablehlo.multiply %6314, %864 : tensor<1x1x1x128xf32>
    %6319 = stablehlo.reshape %6317 : (tensor<1x1x1x128xf32>) -> tensor<128xf32>
    %6320 = stablehlo.multiply %6318, %863 : tensor<1x1x1x128xf32>
    %cst_471 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6321 = stablehlo.reduce(%6320 init: %cst_471) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6322 = stablehlo.multiply %6321, %842 : tensor<128xf32>
    %6323 = stablehlo.negate %6322 : tensor<128xf32>
    %6324 = stablehlo.multiply %6323, %829 : tensor<128xf32>
    %6325 = stablehlo.broadcast_in_dim %6322, dims = [1] : (tensor<128xf32>) -> tensor<1x128xf32>
    %6326 = stablehlo.pad %6325, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x128xf32>, tensor<f32>) -> tensor<2x128xf32>
    %6327 = stablehlo.negate %6316 : tensor<256x56x56x128xf32>
    %cst_472 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6328 = stablehlo.reduce(%6327 init: %cst_472) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6329 = stablehlo.reshape %6328 : (tensor<128xf32>) -> tensor<1x1x1x128xf32>
    %6330 = stablehlo.convert %6316 : (tensor<256x56x56x128xf32>) -> tensor<256x56x56x128xf16>
    %cst_473 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6331 = stablehlo.reduce(%6329 init: %cst_473) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6332 = stablehlo.add %6324, %6331 : tensor<128xf32>
    %6333 = stablehlo.broadcast_in_dim %6332, dims = [1] : (tensor<128xf32>) -> tensor<1x128xf32>
    %6334 = stablehlo.pad %6333, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x128xf32>, tensor<f32>) -> tensor<2x128xf32>
    %6335 = stablehlo.add %6326, %6334 : tensor<2x128xf32>
    %6336 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x128xf32>
    %6337 = stablehlo.divide %6335, %6336 : tensor<2x128xf32>
    %6338 = "stablehlo.all_reduce"(%6337) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x128xf32>) -> tensor<2x128xf32>
    %6339 = stablehlo.slice %6338 [0:1, 0:128] : (tensor<2x128xf32>) -> tensor<1x128xf32>
    %6340 = stablehlo.slice %6338 [1:2, 0:128] : (tensor<2x128xf32>) -> tensor<1x128xf32>
    %cst_474 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6341 = stablehlo.reduce(%6340 init: %cst_474) applies stablehlo.add across dimensions = [0] : (tensor<1x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6342 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %6343 = stablehlo.divide %6341, %6342 : tensor<128xf32>
    %6344 = stablehlo.broadcast_in_dim %6343, dims = [3] : (tensor<128xf32>) -> tensor<256x56x56x128xf32>
    %6345 = stablehlo.multiply %6344, %810 : tensor<256x56x56x128xf32>
    %cst_475 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6346 = stablehlo.reduce(%6339 init: %cst_475) applies stablehlo.add across dimensions = [0] : (tensor<1x128xf32>, tensor<f32>) -> tensor<128xf32>
    %6347 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %6348 = stablehlo.divide %6346, %6347 : tensor<128xf32>
    %6349 = stablehlo.broadcast_in_dim %6348, dims = [3] : (tensor<128xf32>) -> tensor<256x56x56x128xf32>
    %6350 = stablehlo.add %6345, %6349 : tensor<256x56x56x128xf32>
    %6351 = stablehlo.convert %6350 : (tensor<256x56x56x128xf32>) -> tensor<256x56x56x128xf16>
    %6352 = stablehlo.add %6330, %6351 : tensor<256x56x56x128xf16>
    %6353 = stablehlo.convolution(%801, %6352) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x256xf16>, tensor<256x56x56x128xf16>) -> tensor<1x1x256x128xf16>
    %6354 = stablehlo.convert %6353 : (tensor<1x1x256x128xf16>) -> tensor<1x1x256x128xf32>
    %6355 = stablehlo.add %4138, %6354 : tensor<1x1x256x128xf32>
    %6356 = stablehlo.reverse %805, dims = [0, 1] : tensor<1x1x256x128xf16>
    %6357 = stablehlo.convolution(%6352, %6356) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x128xf16>, tensor<1x1x256x128xf16>) -> tensor<256x56x56x256xf16>
    %6358 = stablehlo.convert %6203 : (tensor<256x28x28x512xf16>) -> tensor<256x28x28x512xf32>
    %cst_476 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6359 = stablehlo.reduce(%6358 init: %cst_476) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x512xf32>, tensor<f32>) -> tensor<512xf32>
    %6360 = stablehlo.reshape %6359 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %6361 = stablehlo.reshape %6360 : (tensor<1x1x1x512xf32>) -> tensor<512xf32>
    %6362 = stablehlo.multiply %1066, %6358 : tensor<256x28x28x512xf32>
    %cst_477 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6363 = stablehlo.reduce(%6362 init: %cst_477) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x512xf32>, tensor<f32>) -> tensor<512xf32>
    %6364 = stablehlo.reshape %6363 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %6365 = stablehlo.broadcast_in_dim %1074, dims = [0, 1, 2, 3] : (tensor<1x1x1x512xf32>) -> tensor<256x28x28x512xf32>
    %6366 = stablehlo.multiply %6358, %6365 : tensor<256x28x28x512xf32>
    %6367 = stablehlo.multiply %1069, %6364 : tensor<1x1x1x512xf32>
    %6368 = stablehlo.multiply %6364, %1073 : tensor<1x1x1x512xf32>
    %6369 = stablehlo.reshape %6367 : (tensor<1x1x1x512xf32>) -> tensor<512xf32>
    %6370 = stablehlo.multiply %6368, %1072 : tensor<1x1x1x512xf32>
    %cst_478 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6371 = stablehlo.reduce(%6370 init: %cst_478) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %6372 = stablehlo.multiply %6371, %1051 : tensor<512xf32>
    %6373 = stablehlo.negate %6372 : tensor<512xf32>
    %6374 = stablehlo.multiply %6373, %1038 : tensor<512xf32>
    %6375 = stablehlo.broadcast_in_dim %6372, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %6376 = stablehlo.pad %6375, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<2x512xf32>
    %6377 = stablehlo.negate %6366 : tensor<256x28x28x512xf32>
    %cst_479 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6378 = stablehlo.reduce(%6377 init: %cst_479) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x28x28x512xf32>, tensor<f32>) -> tensor<512xf32>
    %6379 = stablehlo.reshape %6378 : (tensor<512xf32>) -> tensor<1x1x1x512xf32>
    %6380 = stablehlo.convert %6366 : (tensor<256x28x28x512xf32>) -> tensor<256x28x28x512xf16>
    %cst_480 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6381 = stablehlo.reduce(%6379 init: %cst_480) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %6382 = stablehlo.add %6374, %6381 : tensor<512xf32>
    %6383 = stablehlo.broadcast_in_dim %6382, dims = [1] : (tensor<512xf32>) -> tensor<1x512xf32>
    %6384 = stablehlo.pad %6383, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<2x512xf32>
    %6385 = stablehlo.add %6376, %6384 : tensor<2x512xf32>
    %6386 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x512xf32>
    %6387 = stablehlo.divide %6385, %6386 : tensor<2x512xf32>
    %6388 = "stablehlo.all_reduce"(%6387) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x512xf32>) -> tensor<2x512xf32>
    %6389 = stablehlo.slice %6388 [0:1, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %6390 = stablehlo.slice %6388 [1:2, 0:512] : (tensor<2x512xf32>) -> tensor<1x512xf32>
    %cst_481 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6391 = stablehlo.reduce(%6390 init: %cst_481) applies stablehlo.add across dimensions = [0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %6392 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %6393 = stablehlo.divide %6391, %6392 : tensor<512xf32>
    %6394 = stablehlo.broadcast_in_dim %6393, dims = [3] : (tensor<512xf32>) -> tensor<256x28x28x512xf32>
    %6395 = stablehlo.multiply %6394, %1019 : tensor<256x28x28x512xf32>
    %cst_482 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6396 = stablehlo.reduce(%6389 init: %cst_482) applies stablehlo.add across dimensions = [0] : (tensor<1x512xf32>, tensor<f32>) -> tensor<512xf32>
    %6397 = stablehlo.broadcast_in_dim %cst_44, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %6398 = stablehlo.divide %6396, %6397 : tensor<512xf32>
    %6399 = stablehlo.broadcast_in_dim %6398, dims = [3] : (tensor<512xf32>) -> tensor<256x28x28x512xf32>
    %6400 = stablehlo.add %6395, %6399 : tensor<256x28x28x512xf32>
    %6401 = stablehlo.convert %6400 : (tensor<256x28x28x512xf32>) -> tensor<256x28x28x512xf16>
    %6402 = stablehlo.add %6380, %6401 : tensor<256x28x28x512xf16>
    %6403 = stablehlo.convolution(%801, %6402) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, -1], [0, -1]], lhs_dilate = [1, 1], rhs_dilate = [2, 2], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x256xf16>, tensor<256x28x28x512xf16>) -> tensor<1x1x256x512xf16>
    %6404 = stablehlo.convert %6403 : (tensor<1x1x256x512xf16>) -> tensor<1x1x256x512xf32>
    %6405 = stablehlo.add %4132, %6404 : tensor<1x1x256x512xf32>
    %6406 = stablehlo.reverse %1014, dims = [0, 1] : tensor<1x1x256x512xf16>
    %6407 = stablehlo.convolution(%6402, %6406) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 1], [0, 1]], lhs_dilate = [2, 2], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x28x28x512xf16>, tensor<1x1x256x512xf16>) -> tensor<256x56x56x256xf16>
    %6408 = stablehlo.add %6357, %6407 : tensor<256x56x56x256xf16>
    %6409 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x56x56x256xf16>
    %6410 = stablehlo.select %803, %6408, %6409 : tensor<256x56x56x256xi1>, tensor<256x56x56x256xf16>
    %6411 = stablehlo.convert %6410 : (tensor<256x56x56x256xf16>) -> tensor<256x56x56x256xf32>
    %cst_483 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6412 = stablehlo.reduce(%6411 init: %cst_483) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x256xf32>, tensor<f32>) -> tensor<256xf32>
    %6413 = stablehlo.reshape %6412 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %6414 = stablehlo.reshape %6413 : (tensor<1x1x1x256xf32>) -> tensor<256xf32>
    %6415 = stablehlo.multiply %785, %6411 : tensor<256x56x56x256xf32>
    %cst_484 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6416 = stablehlo.reduce(%6415 init: %cst_484) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x256xf32>, tensor<f32>) -> tensor<256xf32>
    %6417 = stablehlo.reshape %6416 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %6418 = stablehlo.broadcast_in_dim %793, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x56x56x256xf32>
    %6419 = stablehlo.multiply %6411, %6418 : tensor<256x56x56x256xf32>
    %6420 = stablehlo.multiply %788, %6417 : tensor<1x1x1x256xf32>
    %6421 = stablehlo.multiply %6417, %792 : tensor<1x1x1x256xf32>
    %6422 = stablehlo.reshape %6420 : (tensor<1x1x1x256xf32>) -> tensor<256xf32>
    %6423 = stablehlo.multiply %6421, %791 : tensor<1x1x1x256xf32>
    %cst_485 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6424 = stablehlo.reduce(%6423 init: %cst_485) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %6425 = stablehlo.multiply %6424, %770 : tensor<256xf32>
    %6426 = stablehlo.negate %6425 : tensor<256xf32>
    %6427 = stablehlo.multiply %6426, %757 : tensor<256xf32>
    %6428 = stablehlo.broadcast_in_dim %6425, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %6429 = stablehlo.pad %6428, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<2x256xf32>
    %6430 = stablehlo.negate %6419 : tensor<256x56x56x256xf32>
    %cst_486 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6431 = stablehlo.reduce(%6430 init: %cst_486) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x256xf32>, tensor<f32>) -> tensor<256xf32>
    %6432 = stablehlo.reshape %6431 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %6433 = stablehlo.convert %6419 : (tensor<256x56x56x256xf32>) -> tensor<256x56x56x256xf16>
    %cst_487 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6434 = stablehlo.reduce(%6432 init: %cst_487) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %6435 = stablehlo.add %6427, %6434 : tensor<256xf32>
    %6436 = stablehlo.broadcast_in_dim %6435, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %6437 = stablehlo.pad %6436, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<2x256xf32>
    %6438 = stablehlo.add %6429, %6437 : tensor<2x256xf32>
    %6439 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x256xf32>
    %6440 = stablehlo.divide %6438, %6439 : tensor<2x256xf32>
    %6441 = "stablehlo.all_reduce"(%6440) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x256xf32>) -> tensor<2x256xf32>
    %6442 = stablehlo.slice %6441 [0:1, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %6443 = stablehlo.slice %6441 [1:2, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %cst_488 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6444 = stablehlo.reduce(%6443 init: %cst_488) applies stablehlo.add across dimensions = [0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %6445 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %6446 = stablehlo.divide %6444, %6445 : tensor<256xf32>
    %6447 = stablehlo.broadcast_in_dim %6446, dims = [3] : (tensor<256xf32>) -> tensor<256x56x56x256xf32>
    %6448 = stablehlo.multiply %6447, %738 : tensor<256x56x56x256xf32>
    %cst_489 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6449 = stablehlo.reduce(%6442 init: %cst_489) applies stablehlo.add across dimensions = [0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %6450 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %6451 = stablehlo.divide %6449, %6450 : tensor<256xf32>
    %6452 = stablehlo.broadcast_in_dim %6451, dims = [3] : (tensor<256xf32>) -> tensor<256x56x56x256xf32>
    %6453 = stablehlo.add %6448, %6452 : tensor<256x56x56x256xf32>
    %6454 = stablehlo.convert %6453 : (tensor<256x56x56x256xf32>) -> tensor<256x56x56x256xf16>
    %6455 = stablehlo.add %6433, %6454 : tensor<256x56x56x256xf16>
    %6456 = stablehlo.convolution(%729, %6455) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x64xf16>, tensor<256x56x56x256xf16>) -> tensor<1x1x64x256xf16>
    %6457 = stablehlo.convert %6456 : (tensor<1x1x64x256xf16>) -> tensor<1x1x64x256xf32>
    %6458 = stablehlo.add %4140, %6457 : tensor<1x1x64x256xf32>
    %6459 = stablehlo.reverse %733, dims = [0, 1] : tensor<1x1x64x256xf16>
    %6460 = stablehlo.convolution(%6455, %6459) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x256xf16>, tensor<1x1x64x256xf16>) -> tensor<256x56x56x64xf16>
    %6461 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x56x56x64xf16>
    %6462 = stablehlo.select %731, %6460, %6461 : tensor<256x56x56x64xi1>, tensor<256x56x56x64xf16>
    %6463 = stablehlo.convert %6462 : (tensor<256x56x56x64xf16>) -> tensor<256x56x56x64xf32>
    %cst_490 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6464 = stablehlo.reduce(%6463 init: %cst_490) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6465 = stablehlo.reshape %6464 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %6466 = stablehlo.reshape %6465 : (tensor<1x1x1x64xf32>) -> tensor<64xf32>
    %6467 = stablehlo.multiply %714, %6463 : tensor<256x56x56x64xf32>
    %cst_491 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6468 = stablehlo.reduce(%6467 init: %cst_491) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6469 = stablehlo.reshape %6468 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %6470 = stablehlo.broadcast_in_dim %722, dims = [0, 1, 2, 3] : (tensor<1x1x1x64xf32>) -> tensor<256x56x56x64xf32>
    %6471 = stablehlo.multiply %6463, %6470 : tensor<256x56x56x64xf32>
    %6472 = stablehlo.multiply %717, %6469 : tensor<1x1x1x64xf32>
    %6473 = stablehlo.multiply %6469, %721 : tensor<1x1x1x64xf32>
    %6474 = stablehlo.reshape %6472 : (tensor<1x1x1x64xf32>) -> tensor<64xf32>
    %6475 = stablehlo.multiply %6473, %720 : tensor<1x1x1x64xf32>
    %cst_492 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6476 = stablehlo.reduce(%6475 init: %cst_492) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6477 = stablehlo.multiply %6476, %699 : tensor<64xf32>
    %6478 = stablehlo.negate %6477 : tensor<64xf32>
    %6479 = stablehlo.multiply %6478, %686 : tensor<64xf32>
    %6480 = stablehlo.broadcast_in_dim %6477, dims = [1] : (tensor<64xf32>) -> tensor<1x64xf32>
    %6481 = stablehlo.pad %6480, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x64xf32>, tensor<f32>) -> tensor<2x64xf32>
    %6482 = stablehlo.negate %6471 : tensor<256x56x56x64xf32>
    %cst_493 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6483 = stablehlo.reduce(%6482 init: %cst_493) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6484 = stablehlo.reshape %6483 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %6485 = stablehlo.convert %6471 : (tensor<256x56x56x64xf32>) -> tensor<256x56x56x64xf16>
    %cst_494 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6486 = stablehlo.reduce(%6484 init: %cst_494) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6487 = stablehlo.add %6479, %6486 : tensor<64xf32>
    %6488 = stablehlo.broadcast_in_dim %6487, dims = [1] : (tensor<64xf32>) -> tensor<1x64xf32>
    %6489 = stablehlo.pad %6488, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x64xf32>, tensor<f32>) -> tensor<2x64xf32>
    %6490 = stablehlo.add %6481, %6489 : tensor<2x64xf32>
    %6491 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x64xf32>
    %6492 = stablehlo.divide %6490, %6491 : tensor<2x64xf32>
    %6493 = "stablehlo.all_reduce"(%6492) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x64xf32>) -> tensor<2x64xf32>
    %6494 = stablehlo.slice %6493 [0:1, 0:64] : (tensor<2x64xf32>) -> tensor<1x64xf32>
    %6495 = stablehlo.slice %6493 [1:2, 0:64] : (tensor<2x64xf32>) -> tensor<1x64xf32>
    %cst_495 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6496 = stablehlo.reduce(%6495 init: %cst_495) applies stablehlo.add across dimensions = [0] : (tensor<1x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6497 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %6498 = stablehlo.divide %6496, %6497 : tensor<64xf32>
    %6499 = stablehlo.broadcast_in_dim %6498, dims = [3] : (tensor<64xf32>) -> tensor<256x56x56x64xf32>
    %6500 = stablehlo.multiply %6499, %667 : tensor<256x56x56x64xf32>
    %cst_496 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6501 = stablehlo.reduce(%6494 init: %cst_496) applies stablehlo.add across dimensions = [0] : (tensor<1x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6502 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %6503 = stablehlo.divide %6501, %6502 : tensor<64xf32>
    %6504 = stablehlo.broadcast_in_dim %6503, dims = [3] : (tensor<64xf32>) -> tensor<256x56x56x64xf32>
    %6505 = stablehlo.add %6500, %6504 : tensor<256x56x56x64xf32>
    %6506 = stablehlo.convert %6505 : (tensor<256x56x56x64xf32>) -> tensor<256x56x56x64xf16>
    %6507 = stablehlo.add %6485, %6506 : tensor<256x56x56x64xf16>
    %6508 = stablehlo.convolution(%658, %6507) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x64xf16>, tensor<256x56x56x64xf16>) -> tensor<3x3x64x64xf16>
    %6509 = stablehlo.convert %6508 : (tensor<3x3x64x64xf16>) -> tensor<3x3x64x64xf32>
    %6510 = stablehlo.add %4142, %6509 : tensor<3x3x64x64xf32>
    %6511 = stablehlo.reverse %662, dims = [0, 1] : tensor<3x3x64x64xf16>
    %6512 = stablehlo.convolution(%6507, %6511) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x64xf16>, tensor<3x3x64x64xf16>) -> tensor<256x56x56x64xf16>
    %6513 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x56x56x64xf16>
    %6514 = stablehlo.select %660, %6512, %6513 : tensor<256x56x56x64xi1>, tensor<256x56x56x64xf16>
    %6515 = stablehlo.convert %6514 : (tensor<256x56x56x64xf16>) -> tensor<256x56x56x64xf32>
    %cst_497 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6516 = stablehlo.reduce(%6515 init: %cst_497) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6517 = stablehlo.reshape %6516 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %6518 = stablehlo.reshape %6517 : (tensor<1x1x1x64xf32>) -> tensor<64xf32>
    %6519 = stablehlo.multiply %643, %6515 : tensor<256x56x56x64xf32>
    %cst_498 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6520 = stablehlo.reduce(%6519 init: %cst_498) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6521 = stablehlo.reshape %6520 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %6522 = stablehlo.broadcast_in_dim %651, dims = [0, 1, 2, 3] : (tensor<1x1x1x64xf32>) -> tensor<256x56x56x64xf32>
    %6523 = stablehlo.multiply %6515, %6522 : tensor<256x56x56x64xf32>
    %6524 = stablehlo.multiply %646, %6521 : tensor<1x1x1x64xf32>
    %6525 = stablehlo.multiply %6521, %650 : tensor<1x1x1x64xf32>
    %6526 = stablehlo.reshape %6524 : (tensor<1x1x1x64xf32>) -> tensor<64xf32>
    %6527 = stablehlo.multiply %6525, %649 : tensor<1x1x1x64xf32>
    %cst_499 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6528 = stablehlo.reduce(%6527 init: %cst_499) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6529 = stablehlo.multiply %6528, %628 : tensor<64xf32>
    %6530 = stablehlo.negate %6529 : tensor<64xf32>
    %6531 = stablehlo.multiply %6530, %615 : tensor<64xf32>
    %6532 = stablehlo.broadcast_in_dim %6529, dims = [1] : (tensor<64xf32>) -> tensor<1x64xf32>
    %6533 = stablehlo.pad %6532, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x64xf32>, tensor<f32>) -> tensor<2x64xf32>
    %6534 = stablehlo.negate %6523 : tensor<256x56x56x64xf32>
    %cst_500 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6535 = stablehlo.reduce(%6534 init: %cst_500) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6536 = stablehlo.reshape %6535 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %6537 = stablehlo.convert %6523 : (tensor<256x56x56x64xf32>) -> tensor<256x56x56x64xf16>
    %cst_501 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6538 = stablehlo.reduce(%6536 init: %cst_501) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6539 = stablehlo.add %6531, %6538 : tensor<64xf32>
    %6540 = stablehlo.broadcast_in_dim %6539, dims = [1] : (tensor<64xf32>) -> tensor<1x64xf32>
    %6541 = stablehlo.pad %6540, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x64xf32>, tensor<f32>) -> tensor<2x64xf32>
    %6542 = stablehlo.add %6533, %6541 : tensor<2x64xf32>
    %6543 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x64xf32>
    %6544 = stablehlo.divide %6542, %6543 : tensor<2x64xf32>
    %6545 = "stablehlo.all_reduce"(%6544) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x64xf32>) -> tensor<2x64xf32>
    %6546 = stablehlo.slice %6545 [0:1, 0:64] : (tensor<2x64xf32>) -> tensor<1x64xf32>
    %6547 = stablehlo.slice %6545 [1:2, 0:64] : (tensor<2x64xf32>) -> tensor<1x64xf32>
    %cst_502 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6548 = stablehlo.reduce(%6547 init: %cst_502) applies stablehlo.add across dimensions = [0] : (tensor<1x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6549 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %6550 = stablehlo.divide %6548, %6549 : tensor<64xf32>
    %6551 = stablehlo.broadcast_in_dim %6550, dims = [3] : (tensor<64xf32>) -> tensor<256x56x56x64xf32>
    %6552 = stablehlo.multiply %6551, %596 : tensor<256x56x56x64xf32>
    %cst_503 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6553 = stablehlo.reduce(%6546 init: %cst_503) applies stablehlo.add across dimensions = [0] : (tensor<1x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6554 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %6555 = stablehlo.divide %6553, %6554 : tensor<64xf32>
    %6556 = stablehlo.broadcast_in_dim %6555, dims = [3] : (tensor<64xf32>) -> tensor<256x56x56x64xf32>
    %6557 = stablehlo.add %6552, %6556 : tensor<256x56x56x64xf32>
    %6558 = stablehlo.convert %6557 : (tensor<256x56x56x64xf32>) -> tensor<256x56x56x64xf16>
    %6559 = stablehlo.add %6537, %6558 : tensor<256x56x56x64xf16>
    %6560 = stablehlo.convolution(%587, %6559) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x256xf16>, tensor<256x56x56x64xf16>) -> tensor<1x1x256x64xf16>
    %6561 = stablehlo.convert %6560 : (tensor<1x1x256x64xf16>) -> tensor<1x1x256x64xf32>
    %6562 = stablehlo.add %4144, %6561 : tensor<1x1x256x64xf32>
    %6563 = stablehlo.reverse %591, dims = [0, 1] : tensor<1x1x256x64xf16>
    %6564 = stablehlo.convolution(%6559, %6563) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x64xf16>, tensor<1x1x256x64xf16>) -> tensor<256x56x56x256xf16>
    %6565 = stablehlo.add %6410, %6564 : tensor<256x56x56x256xf16>
    %6566 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x56x56x256xf16>
    %6567 = stablehlo.select %589, %6565, %6566 : tensor<256x56x56x256xi1>, tensor<256x56x56x256xf16>
    %6568 = stablehlo.convert %6567 : (tensor<256x56x56x256xf16>) -> tensor<256x56x56x256xf32>
    %cst_504 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6569 = stablehlo.reduce(%6568 init: %cst_504) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x256xf32>, tensor<f32>) -> tensor<256xf32>
    %6570 = stablehlo.reshape %6569 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %6571 = stablehlo.reshape %6570 : (tensor<1x1x1x256xf32>) -> tensor<256xf32>
    %6572 = stablehlo.multiply %571, %6568 : tensor<256x56x56x256xf32>
    %cst_505 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6573 = stablehlo.reduce(%6572 init: %cst_505) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x256xf32>, tensor<f32>) -> tensor<256xf32>
    %6574 = stablehlo.reshape %6573 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %6575 = stablehlo.broadcast_in_dim %579, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x56x56x256xf32>
    %6576 = stablehlo.multiply %6568, %6575 : tensor<256x56x56x256xf32>
    %6577 = stablehlo.multiply %574, %6574 : tensor<1x1x1x256xf32>
    %6578 = stablehlo.multiply %6574, %578 : tensor<1x1x1x256xf32>
    %6579 = stablehlo.reshape %6577 : (tensor<1x1x1x256xf32>) -> tensor<256xf32>
    %6580 = stablehlo.multiply %6578, %577 : tensor<1x1x1x256xf32>
    %cst_506 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6581 = stablehlo.reduce(%6580 init: %cst_506) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %6582 = stablehlo.multiply %6581, %556 : tensor<256xf32>
    %6583 = stablehlo.negate %6582 : tensor<256xf32>
    %6584 = stablehlo.multiply %6583, %543 : tensor<256xf32>
    %6585 = stablehlo.broadcast_in_dim %6582, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %6586 = stablehlo.pad %6585, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<2x256xf32>
    %6587 = stablehlo.negate %6576 : tensor<256x56x56x256xf32>
    %cst_507 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6588 = stablehlo.reduce(%6587 init: %cst_507) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x256xf32>, tensor<f32>) -> tensor<256xf32>
    %6589 = stablehlo.reshape %6588 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %6590 = stablehlo.convert %6576 : (tensor<256x56x56x256xf32>) -> tensor<256x56x56x256xf16>
    %cst_508 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6591 = stablehlo.reduce(%6589 init: %cst_508) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %6592 = stablehlo.add %6584, %6591 : tensor<256xf32>
    %6593 = stablehlo.broadcast_in_dim %6592, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %6594 = stablehlo.pad %6593, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<2x256xf32>
    %6595 = stablehlo.add %6586, %6594 : tensor<2x256xf32>
    %6596 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x256xf32>
    %6597 = stablehlo.divide %6595, %6596 : tensor<2x256xf32>
    %6598 = "stablehlo.all_reduce"(%6597) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x256xf32>) -> tensor<2x256xf32>
    %6599 = stablehlo.slice %6598 [0:1, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %6600 = stablehlo.slice %6598 [1:2, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %cst_509 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6601 = stablehlo.reduce(%6600 init: %cst_509) applies stablehlo.add across dimensions = [0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %6602 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %6603 = stablehlo.divide %6601, %6602 : tensor<256xf32>
    %6604 = stablehlo.broadcast_in_dim %6603, dims = [3] : (tensor<256xf32>) -> tensor<256x56x56x256xf32>
    %6605 = stablehlo.multiply %6604, %524 : tensor<256x56x56x256xf32>
    %cst_510 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6606 = stablehlo.reduce(%6599 init: %cst_510) applies stablehlo.add across dimensions = [0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %6607 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %6608 = stablehlo.divide %6606, %6607 : tensor<256xf32>
    %6609 = stablehlo.broadcast_in_dim %6608, dims = [3] : (tensor<256xf32>) -> tensor<256x56x56x256xf32>
    %6610 = stablehlo.add %6605, %6609 : tensor<256x56x56x256xf32>
    %6611 = stablehlo.convert %6610 : (tensor<256x56x56x256xf32>) -> tensor<256x56x56x256xf16>
    %6612 = stablehlo.add %6590, %6611 : tensor<256x56x56x256xf16>
    %6613 = stablehlo.convolution(%515, %6612) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x64xf16>, tensor<256x56x56x256xf16>) -> tensor<1x1x64x256xf16>
    %6614 = stablehlo.convert %6613 : (tensor<1x1x64x256xf16>) -> tensor<1x1x64x256xf32>
    %6615 = stablehlo.add %4184, %6614 : tensor<1x1x64x256xf32>
    %6616 = stablehlo.reverse %519, dims = [0, 1] : tensor<1x1x64x256xf16>
    %6617 = stablehlo.convolution(%6612, %6616) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x256xf16>, tensor<1x1x64x256xf16>) -> tensor<256x56x56x64xf16>
    %6618 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x56x56x64xf16>
    %6619 = stablehlo.select %517, %6617, %6618 : tensor<256x56x56x64xi1>, tensor<256x56x56x64xf16>
    %6620 = stablehlo.convert %6619 : (tensor<256x56x56x64xf16>) -> tensor<256x56x56x64xf32>
    %cst_511 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6621 = stablehlo.reduce(%6620 init: %cst_511) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6622 = stablehlo.reshape %6621 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %6623 = stablehlo.reshape %6622 : (tensor<1x1x1x64xf32>) -> tensor<64xf32>
    %6624 = stablehlo.multiply %500, %6620 : tensor<256x56x56x64xf32>
    %cst_512 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6625 = stablehlo.reduce(%6624 init: %cst_512) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6626 = stablehlo.reshape %6625 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %6627 = stablehlo.broadcast_in_dim %508, dims = [0, 1, 2, 3] : (tensor<1x1x1x64xf32>) -> tensor<256x56x56x64xf32>
    %6628 = stablehlo.multiply %6620, %6627 : tensor<256x56x56x64xf32>
    %6629 = stablehlo.multiply %503, %6626 : tensor<1x1x1x64xf32>
    %6630 = stablehlo.multiply %6626, %507 : tensor<1x1x1x64xf32>
    %6631 = stablehlo.reshape %6629 : (tensor<1x1x1x64xf32>) -> tensor<64xf32>
    %6632 = stablehlo.multiply %6630, %506 : tensor<1x1x1x64xf32>
    %cst_513 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6633 = stablehlo.reduce(%6632 init: %cst_513) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6634 = stablehlo.multiply %6633, %485 : tensor<64xf32>
    %6635 = stablehlo.negate %6634 : tensor<64xf32>
    %6636 = stablehlo.multiply %6635, %472 : tensor<64xf32>
    %6637 = stablehlo.broadcast_in_dim %6634, dims = [1] : (tensor<64xf32>) -> tensor<1x64xf32>
    %6638 = stablehlo.pad %6637, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x64xf32>, tensor<f32>) -> tensor<2x64xf32>
    %6639 = stablehlo.negate %6628 : tensor<256x56x56x64xf32>
    %cst_514 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6640 = stablehlo.reduce(%6639 init: %cst_514) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6641 = stablehlo.reshape %6640 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %6642 = stablehlo.convert %6628 : (tensor<256x56x56x64xf32>) -> tensor<256x56x56x64xf16>
    %cst_515 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6643 = stablehlo.reduce(%6641 init: %cst_515) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6644 = stablehlo.add %6636, %6643 : tensor<64xf32>
    %6645 = stablehlo.broadcast_in_dim %6644, dims = [1] : (tensor<64xf32>) -> tensor<1x64xf32>
    %6646 = stablehlo.pad %6645, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x64xf32>, tensor<f32>) -> tensor<2x64xf32>
    %6647 = stablehlo.add %6638, %6646 : tensor<2x64xf32>
    %6648 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x64xf32>
    %6649 = stablehlo.divide %6647, %6648 : tensor<2x64xf32>
    %6650 = "stablehlo.all_reduce"(%6649) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x64xf32>) -> tensor<2x64xf32>
    %6651 = stablehlo.slice %6650 [0:1, 0:64] : (tensor<2x64xf32>) -> tensor<1x64xf32>
    %6652 = stablehlo.slice %6650 [1:2, 0:64] : (tensor<2x64xf32>) -> tensor<1x64xf32>
    %cst_516 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6653 = stablehlo.reduce(%6652 init: %cst_516) applies stablehlo.add across dimensions = [0] : (tensor<1x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6654 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %6655 = stablehlo.divide %6653, %6654 : tensor<64xf32>
    %6656 = stablehlo.broadcast_in_dim %6655, dims = [3] : (tensor<64xf32>) -> tensor<256x56x56x64xf32>
    %6657 = stablehlo.multiply %6656, %453 : tensor<256x56x56x64xf32>
    %cst_517 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6658 = stablehlo.reduce(%6651 init: %cst_517) applies stablehlo.add across dimensions = [0] : (tensor<1x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6659 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %6660 = stablehlo.divide %6658, %6659 : tensor<64xf32>
    %6661 = stablehlo.broadcast_in_dim %6660, dims = [3] : (tensor<64xf32>) -> tensor<256x56x56x64xf32>
    %6662 = stablehlo.add %6657, %6661 : tensor<256x56x56x64xf32>
    %6663 = stablehlo.convert %6662 : (tensor<256x56x56x64xf32>) -> tensor<256x56x56x64xf16>
    %6664 = stablehlo.add %6642, %6663 : tensor<256x56x56x64xf16>
    %6665 = stablehlo.convolution(%444, %6664) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x64xf16>, tensor<256x56x56x64xf16>) -> tensor<3x3x64x64xf16>
    %6666 = stablehlo.convert %6665 : (tensor<3x3x64x64xf16>) -> tensor<3x3x64x64xf32>
    %6667 = stablehlo.add %4186, %6666 : tensor<3x3x64x64xf32>
    %6668 = stablehlo.reverse %448, dims = [0, 1] : tensor<3x3x64x64xf16>
    %6669 = stablehlo.convolution(%6664, %6668) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x64xf16>, tensor<3x3x64x64xf16>) -> tensor<256x56x56x64xf16>
    %6670 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x56x56x64xf16>
    %6671 = stablehlo.select %446, %6669, %6670 : tensor<256x56x56x64xi1>, tensor<256x56x56x64xf16>
    %6672 = stablehlo.convert %6671 : (tensor<256x56x56x64xf16>) -> tensor<256x56x56x64xf32>
    %cst_518 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6673 = stablehlo.reduce(%6672 init: %cst_518) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6674 = stablehlo.reshape %6673 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %6675 = stablehlo.reshape %6674 : (tensor<1x1x1x64xf32>) -> tensor<64xf32>
    %6676 = stablehlo.multiply %429, %6672 : tensor<256x56x56x64xf32>
    %cst_519 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6677 = stablehlo.reduce(%6676 init: %cst_519) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6678 = stablehlo.reshape %6677 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %6679 = stablehlo.broadcast_in_dim %437, dims = [0, 1, 2, 3] : (tensor<1x1x1x64xf32>) -> tensor<256x56x56x64xf32>
    %6680 = stablehlo.multiply %6672, %6679 : tensor<256x56x56x64xf32>
    %6681 = stablehlo.multiply %432, %6678 : tensor<1x1x1x64xf32>
    %6682 = stablehlo.multiply %6678, %436 : tensor<1x1x1x64xf32>
    %6683 = stablehlo.reshape %6681 : (tensor<1x1x1x64xf32>) -> tensor<64xf32>
    %6684 = stablehlo.multiply %6682, %435 : tensor<1x1x1x64xf32>
    %cst_520 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6685 = stablehlo.reduce(%6684 init: %cst_520) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6686 = stablehlo.multiply %6685, %414 : tensor<64xf32>
    %6687 = stablehlo.negate %6686 : tensor<64xf32>
    %6688 = stablehlo.multiply %6687, %401 : tensor<64xf32>
    %6689 = stablehlo.broadcast_in_dim %6686, dims = [1] : (tensor<64xf32>) -> tensor<1x64xf32>
    %6690 = stablehlo.pad %6689, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x64xf32>, tensor<f32>) -> tensor<2x64xf32>
    %6691 = stablehlo.negate %6680 : tensor<256x56x56x64xf32>
    %cst_521 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6692 = stablehlo.reduce(%6691 init: %cst_521) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6693 = stablehlo.reshape %6692 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %6694 = stablehlo.convert %6680 : (tensor<256x56x56x64xf32>) -> tensor<256x56x56x64xf16>
    %cst_522 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6695 = stablehlo.reduce(%6693 init: %cst_522) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6696 = stablehlo.add %6688, %6695 : tensor<64xf32>
    %6697 = stablehlo.broadcast_in_dim %6696, dims = [1] : (tensor<64xf32>) -> tensor<1x64xf32>
    %6698 = stablehlo.pad %6697, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x64xf32>, tensor<f32>) -> tensor<2x64xf32>
    %6699 = stablehlo.add %6690, %6698 : tensor<2x64xf32>
    %6700 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x64xf32>
    %6701 = stablehlo.divide %6699, %6700 : tensor<2x64xf32>
    %6702 = "stablehlo.all_reduce"(%6701) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x64xf32>) -> tensor<2x64xf32>
    %6703 = stablehlo.slice %6702 [0:1, 0:64] : (tensor<2x64xf32>) -> tensor<1x64xf32>
    %6704 = stablehlo.slice %6702 [1:2, 0:64] : (tensor<2x64xf32>) -> tensor<1x64xf32>
    %cst_523 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6705 = stablehlo.reduce(%6704 init: %cst_523) applies stablehlo.add across dimensions = [0] : (tensor<1x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6706 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %6707 = stablehlo.divide %6705, %6706 : tensor<64xf32>
    %6708 = stablehlo.broadcast_in_dim %6707, dims = [3] : (tensor<64xf32>) -> tensor<256x56x56x64xf32>
    %6709 = stablehlo.multiply %6708, %382 : tensor<256x56x56x64xf32>
    %cst_524 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6710 = stablehlo.reduce(%6703 init: %cst_524) applies stablehlo.add across dimensions = [0] : (tensor<1x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6711 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %6712 = stablehlo.divide %6710, %6711 : tensor<64xf32>
    %6713 = stablehlo.broadcast_in_dim %6712, dims = [3] : (tensor<64xf32>) -> tensor<256x56x56x64xf32>
    %6714 = stablehlo.add %6709, %6713 : tensor<256x56x56x64xf32>
    %6715 = stablehlo.convert %6714 : (tensor<256x56x56x64xf32>) -> tensor<256x56x56x64xf16>
    %6716 = stablehlo.add %6694, %6715 : tensor<256x56x56x64xf16>
    %6717 = stablehlo.convolution(%373, %6716) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x256xf16>, tensor<256x56x56x64xf16>) -> tensor<1x1x256x64xf16>
    %6718 = stablehlo.convert %6717 : (tensor<1x1x256x64xf16>) -> tensor<1x1x256x64xf32>
    %6719 = stablehlo.add %4188, %6718 : tensor<1x1x256x64xf32>
    %6720 = stablehlo.reverse %377, dims = [0, 1] : tensor<1x1x256x64xf16>
    %6721 = stablehlo.convolution(%6716, %6720) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x64xf16>, tensor<1x1x256x64xf16>) -> tensor<256x56x56x256xf16>
    %6722 = stablehlo.add %6567, %6721 : tensor<256x56x56x256xf16>
    %6723 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x56x56x256xf16>
    %6724 = stablehlo.select %375, %6722, %6723 : tensor<256x56x56x256xi1>, tensor<256x56x56x256xf16>
    %6725 = stablehlo.convert %6724 : (tensor<256x56x56x256xf16>) -> tensor<256x56x56x256xf32>
    %cst_525 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6726 = stablehlo.reduce(%6725 init: %cst_525) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x256xf32>, tensor<f32>) -> tensor<256xf32>
    %6727 = stablehlo.reshape %6726 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %6728 = stablehlo.reshape %6727 : (tensor<1x1x1x256xf32>) -> tensor<256xf32>
    %6729 = stablehlo.multiply %290, %6725 : tensor<256x56x56x256xf32>
    %cst_526 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6730 = stablehlo.reduce(%6729 init: %cst_526) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x256xf32>, tensor<f32>) -> tensor<256xf32>
    %6731 = stablehlo.reshape %6730 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %6732 = stablehlo.broadcast_in_dim %298, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x56x56x256xf32>
    %6733 = stablehlo.multiply %6725, %6732 : tensor<256x56x56x256xf32>
    %6734 = stablehlo.multiply %293, %6731 : tensor<1x1x1x256xf32>
    %6735 = stablehlo.multiply %6731, %297 : tensor<1x1x1x256xf32>
    %6736 = stablehlo.reshape %6734 : (tensor<1x1x1x256xf32>) -> tensor<256xf32>
    %6737 = stablehlo.multiply %6735, %296 : tensor<1x1x1x256xf32>
    %cst_527 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6738 = stablehlo.reduce(%6737 init: %cst_527) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %6739 = stablehlo.multiply %6738, %275 : tensor<256xf32>
    %6740 = stablehlo.negate %6739 : tensor<256xf32>
    %6741 = stablehlo.multiply %6740, %262 : tensor<256xf32>
    %6742 = stablehlo.broadcast_in_dim %6739, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %6743 = stablehlo.pad %6742, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<2x256xf32>
    %6744 = stablehlo.negate %6733 : tensor<256x56x56x256xf32>
    %cst_528 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6745 = stablehlo.reduce(%6744 init: %cst_528) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x256xf32>, tensor<f32>) -> tensor<256xf32>
    %6746 = stablehlo.reshape %6745 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %6747 = stablehlo.convert %6733 : (tensor<256x56x56x256xf32>) -> tensor<256x56x56x256xf16>
    %cst_529 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6748 = stablehlo.reduce(%6746 init: %cst_529) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %6749 = stablehlo.add %6741, %6748 : tensor<256xf32>
    %6750 = stablehlo.broadcast_in_dim %6749, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %6751 = stablehlo.pad %6750, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<2x256xf32>
    %6752 = stablehlo.add %6743, %6751 : tensor<2x256xf32>
    %6753 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x256xf32>
    %6754 = stablehlo.divide %6752, %6753 : tensor<2x256xf32>
    %6755 = "stablehlo.all_reduce"(%6754) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x256xf32>) -> tensor<2x256xf32>
    %6756 = stablehlo.slice %6755 [0:1, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %6757 = stablehlo.slice %6755 [1:2, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %cst_530 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6758 = stablehlo.reduce(%6757 init: %cst_530) applies stablehlo.add across dimensions = [0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %6759 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %6760 = stablehlo.divide %6758, %6759 : tensor<256xf32>
    %6761 = stablehlo.broadcast_in_dim %6760, dims = [3] : (tensor<256xf32>) -> tensor<256x56x56x256xf32>
    %6762 = stablehlo.multiply %6761, %243 : tensor<256x56x56x256xf32>
    %cst_531 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6763 = stablehlo.reduce(%6756 init: %cst_531) applies stablehlo.add across dimensions = [0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %6764 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %6765 = stablehlo.divide %6763, %6764 : tensor<256xf32>
    %6766 = stablehlo.broadcast_in_dim %6765, dims = [3] : (tensor<256xf32>) -> tensor<256x56x56x256xf32>
    %6767 = stablehlo.add %6762, %6766 : tensor<256x56x56x256xf32>
    %6768 = stablehlo.convert %6767 : (tensor<256x56x56x256xf32>) -> tensor<256x56x56x256xf16>
    %6769 = stablehlo.add %6747, %6768 : tensor<256x56x56x256xf16>
    %6770 = stablehlo.convolution(%234, %6769) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x64xf16>, tensor<256x56x56x256xf16>) -> tensor<1x1x64x256xf16>
    %6771 = stablehlo.convert %6770 : (tensor<1x1x64x256xf16>) -> tensor<1x1x64x256xf32>
    %6772 = stablehlo.add %4192, %6771 : tensor<1x1x64x256xf32>
    %6773 = stablehlo.reverse %238, dims = [0, 1] : tensor<1x1x64x256xf16>
    %6774 = stablehlo.convolution(%6769, %6773) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x256xf16>, tensor<1x1x64x256xf16>) -> tensor<256x56x56x64xf16>
    %6775 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x56x56x64xf16>
    %6776 = stablehlo.select %236, %6774, %6775 : tensor<256x56x56x64xi1>, tensor<256x56x56x64xf16>
    %6777 = stablehlo.convert %6776 : (tensor<256x56x56x64xf16>) -> tensor<256x56x56x64xf32>
    %cst_532 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6778 = stablehlo.reduce(%6777 init: %cst_532) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6779 = stablehlo.reshape %6778 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %6780 = stablehlo.reshape %6779 : (tensor<1x1x1x64xf32>) -> tensor<64xf32>
    %6781 = stablehlo.multiply %219, %6777 : tensor<256x56x56x64xf32>
    %cst_533 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6782 = stablehlo.reduce(%6781 init: %cst_533) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6783 = stablehlo.reshape %6782 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %6784 = stablehlo.broadcast_in_dim %227, dims = [0, 1, 2, 3] : (tensor<1x1x1x64xf32>) -> tensor<256x56x56x64xf32>
    %6785 = stablehlo.multiply %6777, %6784 : tensor<256x56x56x64xf32>
    %6786 = stablehlo.multiply %222, %6783 : tensor<1x1x1x64xf32>
    %6787 = stablehlo.multiply %6783, %226 : tensor<1x1x1x64xf32>
    %6788 = stablehlo.reshape %6786 : (tensor<1x1x1x64xf32>) -> tensor<64xf32>
    %6789 = stablehlo.multiply %6787, %225 : tensor<1x1x1x64xf32>
    %cst_534 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6790 = stablehlo.reduce(%6789 init: %cst_534) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6791 = stablehlo.multiply %6790, %204 : tensor<64xf32>
    %6792 = stablehlo.negate %6791 : tensor<64xf32>
    %6793 = stablehlo.multiply %6792, %191 : tensor<64xf32>
    %6794 = stablehlo.broadcast_in_dim %6791, dims = [1] : (tensor<64xf32>) -> tensor<1x64xf32>
    %6795 = stablehlo.pad %6794, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x64xf32>, tensor<f32>) -> tensor<2x64xf32>
    %6796 = stablehlo.negate %6785 : tensor<256x56x56x64xf32>
    %cst_535 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6797 = stablehlo.reduce(%6796 init: %cst_535) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6798 = stablehlo.reshape %6797 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %6799 = stablehlo.convert %6785 : (tensor<256x56x56x64xf32>) -> tensor<256x56x56x64xf16>
    %cst_536 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6800 = stablehlo.reduce(%6798 init: %cst_536) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6801 = stablehlo.add %6793, %6800 : tensor<64xf32>
    %6802 = stablehlo.broadcast_in_dim %6801, dims = [1] : (tensor<64xf32>) -> tensor<1x64xf32>
    %6803 = stablehlo.pad %6802, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x64xf32>, tensor<f32>) -> tensor<2x64xf32>
    %6804 = stablehlo.add %6795, %6803 : tensor<2x64xf32>
    %6805 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x64xf32>
    %6806 = stablehlo.divide %6804, %6805 : tensor<2x64xf32>
    %6807 = "stablehlo.all_reduce"(%6806) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x64xf32>) -> tensor<2x64xf32>
    %6808 = stablehlo.slice %6807 [0:1, 0:64] : (tensor<2x64xf32>) -> tensor<1x64xf32>
    %6809 = stablehlo.slice %6807 [1:2, 0:64] : (tensor<2x64xf32>) -> tensor<1x64xf32>
    %cst_537 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6810 = stablehlo.reduce(%6809 init: %cst_537) applies stablehlo.add across dimensions = [0] : (tensor<1x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6811 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %6812 = stablehlo.divide %6810, %6811 : tensor<64xf32>
    %6813 = stablehlo.broadcast_in_dim %6812, dims = [3] : (tensor<64xf32>) -> tensor<256x56x56x64xf32>
    %6814 = stablehlo.multiply %6813, %172 : tensor<256x56x56x64xf32>
    %cst_538 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6815 = stablehlo.reduce(%6808 init: %cst_538) applies stablehlo.add across dimensions = [0] : (tensor<1x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6816 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %6817 = stablehlo.divide %6815, %6816 : tensor<64xf32>
    %6818 = stablehlo.broadcast_in_dim %6817, dims = [3] : (tensor<64xf32>) -> tensor<256x56x56x64xf32>
    %6819 = stablehlo.add %6814, %6818 : tensor<256x56x56x64xf32>
    %6820 = stablehlo.convert %6819 : (tensor<256x56x56x64xf32>) -> tensor<256x56x56x64xf16>
    %6821 = stablehlo.add %6799, %6820 : tensor<256x56x56x64xf16>
    %6822 = stablehlo.convolution(%163, %6821) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x64xf16>, tensor<256x56x56x64xf16>) -> tensor<3x3x64x64xf16>
    %6823 = stablehlo.convert %6822 : (tensor<3x3x64x64xf16>) -> tensor<3x3x64x64xf32>
    %6824 = stablehlo.add %4194, %6823 : tensor<3x3x64x64xf32>
    %6825 = stablehlo.reverse %167, dims = [0, 1] : tensor<3x3x64x64xf16>
    %6826 = stablehlo.convolution(%6821, %6825) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x64xf16>, tensor<3x3x64x64xf16>) -> tensor<256x56x56x64xf16>
    %6827 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x56x56x64xf16>
    %6828 = stablehlo.select %165, %6826, %6827 : tensor<256x56x56x64xi1>, tensor<256x56x56x64xf16>
    %6829 = stablehlo.convert %6828 : (tensor<256x56x56x64xf16>) -> tensor<256x56x56x64xf32>
    %cst_539 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6830 = stablehlo.reduce(%6829 init: %cst_539) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6831 = stablehlo.reshape %6830 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %6832 = stablehlo.reshape %6831 : (tensor<1x1x1x64xf32>) -> tensor<64xf32>
    %6833 = stablehlo.multiply %148, %6829 : tensor<256x56x56x64xf32>
    %cst_540 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6834 = stablehlo.reduce(%6833 init: %cst_540) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6835 = stablehlo.reshape %6834 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %6836 = stablehlo.broadcast_in_dim %156, dims = [0, 1, 2, 3] : (tensor<1x1x1x64xf32>) -> tensor<256x56x56x64xf32>
    %6837 = stablehlo.multiply %6829, %6836 : tensor<256x56x56x64xf32>
    %6838 = stablehlo.multiply %151, %6835 : tensor<1x1x1x64xf32>
    %6839 = stablehlo.multiply %6835, %155 : tensor<1x1x1x64xf32>
    %6840 = stablehlo.reshape %6838 : (tensor<1x1x1x64xf32>) -> tensor<64xf32>
    %6841 = stablehlo.multiply %6839, %154 : tensor<1x1x1x64xf32>
    %cst_541 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6842 = stablehlo.reduce(%6841 init: %cst_541) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6843 = stablehlo.multiply %6842, %133 : tensor<64xf32>
    %6844 = stablehlo.negate %6843 : tensor<64xf32>
    %6845 = stablehlo.multiply %6844, %120 : tensor<64xf32>
    %6846 = stablehlo.broadcast_in_dim %6843, dims = [1] : (tensor<64xf32>) -> tensor<1x64xf32>
    %6847 = stablehlo.pad %6846, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x64xf32>, tensor<f32>) -> tensor<2x64xf32>
    %6848 = stablehlo.negate %6837 : tensor<256x56x56x64xf32>
    %cst_542 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6849 = stablehlo.reduce(%6848 init: %cst_542) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6850 = stablehlo.reshape %6849 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %6851 = stablehlo.convert %6837 : (tensor<256x56x56x64xf32>) -> tensor<256x56x56x64xf16>
    %cst_543 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6852 = stablehlo.reduce(%6850 init: %cst_543) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6853 = stablehlo.add %6845, %6852 : tensor<64xf32>
    %6854 = stablehlo.broadcast_in_dim %6853, dims = [1] : (tensor<64xf32>) -> tensor<1x64xf32>
    %6855 = stablehlo.pad %6854, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x64xf32>, tensor<f32>) -> tensor<2x64xf32>
    %6856 = stablehlo.add %6847, %6855 : tensor<2x64xf32>
    %6857 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x64xf32>
    %6858 = stablehlo.divide %6856, %6857 : tensor<2x64xf32>
    %6859 = "stablehlo.all_reduce"(%6858) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x64xf32>) -> tensor<2x64xf32>
    %6860 = stablehlo.slice %6859 [0:1, 0:64] : (tensor<2x64xf32>) -> tensor<1x64xf32>
    %6861 = stablehlo.slice %6859 [1:2, 0:64] : (tensor<2x64xf32>) -> tensor<1x64xf32>
    %cst_544 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6862 = stablehlo.reduce(%6861 init: %cst_544) applies stablehlo.add across dimensions = [0] : (tensor<1x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6863 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %6864 = stablehlo.divide %6862, %6863 : tensor<64xf32>
    %6865 = stablehlo.broadcast_in_dim %6864, dims = [3] : (tensor<64xf32>) -> tensor<256x56x56x64xf32>
    %6866 = stablehlo.multiply %6865, %101 : tensor<256x56x56x64xf32>
    %cst_545 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6867 = stablehlo.reduce(%6860 init: %cst_545) applies stablehlo.add across dimensions = [0] : (tensor<1x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6868 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %6869 = stablehlo.divide %6867, %6868 : tensor<64xf32>
    %6870 = stablehlo.broadcast_in_dim %6869, dims = [3] : (tensor<64xf32>) -> tensor<256x56x56x64xf32>
    %6871 = stablehlo.add %6866, %6870 : tensor<256x56x56x64xf32>
    %6872 = stablehlo.convert %6871 : (tensor<256x56x56x64xf32>) -> tensor<256x56x56x64xf16>
    %6873 = stablehlo.add %6851, %6872 : tensor<256x56x56x64xf16>
    %6874 = stablehlo.convolution(%95, %6873) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x64xf16>, tensor<256x56x56x64xf16>) -> tensor<1x1x64x64xf16>
    %6875 = stablehlo.convert %6874 : (tensor<1x1x64x64xf16>) -> tensor<1x1x64x64xf32>
    %6876 = stablehlo.add %4196, %6875 : tensor<1x1x64x64xf32>
    %6877 = stablehlo.reverse %96, dims = [0, 1] : tensor<1x1x64x64xf16>
    %6878 = stablehlo.convolution(%6873, %6877) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x64xf16>, tensor<1x1x64x64xf16>) -> tensor<256x56x56x64xf16>
    %6879 = stablehlo.convert %6724 : (tensor<256x56x56x256xf16>) -> tensor<256x56x56x256xf32>
    %cst_546 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6880 = stablehlo.reduce(%6879 init: %cst_546) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x256xf32>, tensor<f32>) -> tensor<256xf32>
    %6881 = stablehlo.reshape %6880 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %6882 = stablehlo.reshape %6881 : (tensor<1x1x1x256xf32>) -> tensor<256xf32>
    %6883 = stablehlo.multiply %357, %6879 : tensor<256x56x56x256xf32>
    %cst_547 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6884 = stablehlo.reduce(%6883 init: %cst_547) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x256xf32>, tensor<f32>) -> tensor<256xf32>
    %6885 = stablehlo.reshape %6884 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %6886 = stablehlo.broadcast_in_dim %365, dims = [0, 1, 2, 3] : (tensor<1x1x1x256xf32>) -> tensor<256x56x56x256xf32>
    %6887 = stablehlo.multiply %6879, %6886 : tensor<256x56x56x256xf32>
    %6888 = stablehlo.multiply %360, %6885 : tensor<1x1x1x256xf32>
    %6889 = stablehlo.multiply %6885, %364 : tensor<1x1x1x256xf32>
    %6890 = stablehlo.reshape %6888 : (tensor<1x1x1x256xf32>) -> tensor<256xf32>
    %6891 = stablehlo.multiply %6889, %363 : tensor<1x1x1x256xf32>
    %cst_548 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6892 = stablehlo.reduce(%6891 init: %cst_548) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %6893 = stablehlo.multiply %6892, %342 : tensor<256xf32>
    %6894 = stablehlo.negate %6893 : tensor<256xf32>
    %6895 = stablehlo.multiply %6894, %329 : tensor<256xf32>
    %6896 = stablehlo.broadcast_in_dim %6893, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %6897 = stablehlo.pad %6896, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<2x256xf32>
    %6898 = stablehlo.negate %6887 : tensor<256x56x56x256xf32>
    %cst_549 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6899 = stablehlo.reduce(%6898 init: %cst_549) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x56x56x256xf32>, tensor<f32>) -> tensor<256xf32>
    %6900 = stablehlo.reshape %6899 : (tensor<256xf32>) -> tensor<1x1x1x256xf32>
    %6901 = stablehlo.convert %6887 : (tensor<256x56x56x256xf32>) -> tensor<256x56x56x256xf16>
    %cst_550 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6902 = stablehlo.reduce(%6900 init: %cst_550) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %6903 = stablehlo.add %6895, %6902 : tensor<256xf32>
    %6904 = stablehlo.broadcast_in_dim %6903, dims = [1] : (tensor<256xf32>) -> tensor<1x256xf32>
    %6905 = stablehlo.pad %6904, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<2x256xf32>
    %6906 = stablehlo.add %6897, %6905 : tensor<2x256xf32>
    %6907 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x256xf32>
    %6908 = stablehlo.divide %6906, %6907 : tensor<2x256xf32>
    %6909 = "stablehlo.all_reduce"(%6908) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x256xf32>) -> tensor<2x256xf32>
    %6910 = stablehlo.slice %6909 [0:1, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %6911 = stablehlo.slice %6909 [1:2, 0:256] : (tensor<2x256xf32>) -> tensor<1x256xf32>
    %cst_551 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6912 = stablehlo.reduce(%6911 init: %cst_551) applies stablehlo.add across dimensions = [0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %6913 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %6914 = stablehlo.divide %6912, %6913 : tensor<256xf32>
    %6915 = stablehlo.broadcast_in_dim %6914, dims = [3] : (tensor<256xf32>) -> tensor<256x56x56x256xf32>
    %6916 = stablehlo.multiply %6915, %310 : tensor<256x56x56x256xf32>
    %cst_552 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6917 = stablehlo.reduce(%6910 init: %cst_552) applies stablehlo.add across dimensions = [0] : (tensor<1x256xf32>, tensor<f32>) -> tensor<256xf32>
    %6918 = stablehlo.broadcast_in_dim %cst_21, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %6919 = stablehlo.divide %6917, %6918 : tensor<256xf32>
    %6920 = stablehlo.broadcast_in_dim %6919, dims = [3] : (tensor<256xf32>) -> tensor<256x56x56x256xf32>
    %6921 = stablehlo.add %6916, %6920 : tensor<256x56x56x256xf32>
    %6922 = stablehlo.convert %6921 : (tensor<256x56x56x256xf32>) -> tensor<256x56x56x256xf16>
    %6923 = stablehlo.add %6901, %6922 : tensor<256x56x56x256xf16>
    %6924 = stablehlo.convolution(%95, %6923) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x64xf16>, tensor<256x56x56x256xf16>) -> tensor<1x1x64x256xf16>
    %6925 = stablehlo.convert %6924 : (tensor<1x1x64x256xf16>) -> tensor<1x1x64x256xf32>
    %6926 = stablehlo.add %4190, %6925 : tensor<1x1x64x256xf32>
    %6927 = stablehlo.reverse %305, dims = [0, 1] : tensor<1x1x64x256xf16>
    %6928 = stablehlo.convolution(%6923, %6927) dim_numbers = [b, 0, 1, f]x[0, 1, o, i]->[b, 0, 1, f], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], lhs_dilate = [1, 1], rhs_dilate = [1, 1], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x56x56x256xf16>, tensor<1x1x64x256xf16>) -> tensor<256x56x56x64xf16>
    %6929 = stablehlo.add %6878, %6928 : tensor<256x56x56x64xf16>
    %cst_553 = stablehlo.constant dense<0xFC00> : tensor<f16>
    %6930 = stablehlo.pad %90, %cst_553, low = [0, 0, 0, 0], high = [0, 1, 1, 0], interior = [0, 0, 0, 0] : (tensor<256x112x112x64xf16>, tensor<f16>) -> tensor<256x113x113x64xf16>
    %cst_554 = stablehlo.constant dense<0.000000e+00> : tensor<f16>
    %6931 = "stablehlo.select_and_scatter"(%6930, %6929, %cst_554) <{padding = dense<0> : tensor<4x2xi64>, window_dimensions = array<i64: 1, 3, 3, 1>, window_strides = array<i64: 1, 2, 2, 1>}> ({
    ^bb0(%arg432: tensor<f16>, %arg433: tensor<f16>):
      %9450 = stablehlo.compare  GE, %arg432, %arg433,  FLOAT : (tensor<f16>, tensor<f16>) -> tensor<i1>
      stablehlo.return %9450 : tensor<i1>
    }, {
    ^bb0(%arg432: tensor<f16>, %arg433: tensor<f16>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f16>
      stablehlo.return %9450 : tensor<f16>
    }) : (tensor<256x113x113x64xf16>, tensor<256x56x56x64xf16>, tensor<f16>) -> tensor<256x113x113x64xf16>
    %6932 = stablehlo.slice %6931 [0:256, 0:112, 0:112, 0:64] : (tensor<256x113x113x64xf16>) -> tensor<256x112x112x64xf16>
    %6933 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f16>) -> tensor<256x112x112x64xf16>
    %6934 = stablehlo.select %92, %6932, %6933 : tensor<256x112x112x64xi1>, tensor<256x112x112x64xf16>
    %6935 = stablehlo.convert %6934 : (tensor<256x112x112x64xf16>) -> tensor<256x112x112x64xf32>
    %cst_555 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6936 = stablehlo.reduce(%6935 init: %cst_555) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x112x112x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6937 = stablehlo.reshape %6936 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %6938 = stablehlo.reshape %6937 : (tensor<1x1x1x64xf32>) -> tensor<64xf32>
    %6939 = stablehlo.multiply %75, %6935 : tensor<256x112x112x64xf32>
    %cst_556 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6940 = stablehlo.reduce(%6939 init: %cst_556) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x112x112x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6941 = stablehlo.reshape %6940 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %6942 = stablehlo.broadcast_in_dim %83, dims = [0, 1, 2, 3] : (tensor<1x1x1x64xf32>) -> tensor<256x112x112x64xf32>
    %6943 = stablehlo.multiply %6935, %6942 : tensor<256x112x112x64xf32>
    %6944 = stablehlo.multiply %78, %6941 : tensor<1x1x1x64xf32>
    %6945 = stablehlo.multiply %6941, %82 : tensor<1x1x1x64xf32>
    %6946 = stablehlo.reshape %6944 : (tensor<1x1x1x64xf32>) -> tensor<64xf32>
    %6947 = stablehlo.multiply %6945, %81 : tensor<1x1x1x64xf32>
    %cst_557 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6948 = stablehlo.reduce(%6947 init: %cst_557) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6949 = stablehlo.multiply %6948, %60 : tensor<64xf32>
    %6950 = stablehlo.negate %6949 : tensor<64xf32>
    %6951 = stablehlo.multiply %6950, %47 : tensor<64xf32>
    %6952 = stablehlo.broadcast_in_dim %6949, dims = [1] : (tensor<64xf32>) -> tensor<1x64xf32>
    %6953 = stablehlo.pad %6952, %cst_12, low = [1, 0], high = [0, 0], interior = [0, 0] : (tensor<1x64xf32>, tensor<f32>) -> tensor<2x64xf32>
    %6954 = stablehlo.negate %6943 : tensor<256x112x112x64xf32>
    %cst_558 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6955 = stablehlo.reduce(%6954 init: %cst_558) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<256x112x112x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6956 = stablehlo.reshape %6955 : (tensor<64xf32>) -> tensor<1x1x1x64xf32>
    %6957 = stablehlo.convert %6943 : (tensor<256x112x112x64xf32>) -> tensor<256x112x112x64xf16>
    %cst_559 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6958 = stablehlo.reduce(%6956 init: %cst_559) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<1x1x1x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6959 = stablehlo.add %6951, %6958 : tensor<64xf32>
    %6960 = stablehlo.broadcast_in_dim %6959, dims = [1] : (tensor<64xf32>) -> tensor<1x64xf32>
    %6961 = stablehlo.pad %6960, %cst_12, low = [0, 0], high = [1, 0], interior = [0, 0] : (tensor<1x64xf32>, tensor<f32>) -> tensor<2x64xf32>
    %6962 = stablehlo.add %6953, %6961 : tensor<2x64xf32>
    %6963 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2x64xf32>
    %6964 = stablehlo.divide %6962, %6963 : tensor<2x64xf32>
    %6965 = "stablehlo.all_reduce"(%6964) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2x64xf32>) -> tensor<2x64xf32>
    %6966 = stablehlo.slice %6965 [0:1, 0:64] : (tensor<2x64xf32>) -> tensor<1x64xf32>
    %6967 = stablehlo.slice %6965 [1:2, 0:64] : (tensor<2x64xf32>) -> tensor<1x64xf32>
    %cst_560 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6968 = stablehlo.reduce(%6967 init: %cst_560) applies stablehlo.add across dimensions = [0] : (tensor<1x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6969 = stablehlo.broadcast_in_dim %cst_9, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %6970 = stablehlo.divide %6968, %6969 : tensor<64xf32>
    %6971 = stablehlo.broadcast_in_dim %6970, dims = [3] : (tensor<64xf32>) -> tensor<256x112x112x64xf32>
    %6972 = stablehlo.multiply %6971, %28 : tensor<256x112x112x64xf32>
    %cst_561 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6973 = stablehlo.reduce(%6966 init: %cst_561) applies stablehlo.add across dimensions = [0] : (tensor<1x64xf32>, tensor<f32>) -> tensor<64xf32>
    %6974 = stablehlo.broadcast_in_dim %cst_9, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %6975 = stablehlo.divide %6973, %6974 : tensor<64xf32>
    %6976 = stablehlo.broadcast_in_dim %6975, dims = [3] : (tensor<64xf32>) -> tensor<256x112x112x64xf32>
    %6977 = stablehlo.add %6972, %6976 : tensor<256x112x112x64xf32>
    %6978 = stablehlo.convert %6977 : (tensor<256x112x112x64xf32>) -> tensor<256x112x112x64xf16>
    %6979 = stablehlo.add %6957, %6978 : tensor<256x112x112x64xf16>
    %6980 = stablehlo.convolution(%0, %6979) dim_numbers = [f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f], window = {stride = [1, 1], pad = [[3, 2], [3, 2]], lhs_dilate = [1, 1], rhs_dilate = [2, 2], reverse = [false, false]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64, precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>]} : (tensor<256x224x224x3xf16>, tensor<256x112x112x64xf16>) -> tensor<7x7x3x64xf16>
    %6981 = stablehlo.convert %6980 : (tensor<7x7x3x64xf16>) -> tensor<7x7x3x64xf32>
    %6982 = stablehlo.add %4090, %6981 : tensor<7x7x3x64xf32>
    %6983 = "stablehlo.all_reduce"(%6832) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<64xf32>) -> tensor<64xf32>
    %6984 = "stablehlo.all_reduce"(%6840) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<64xf32>) -> tensor<64xf32>
    %6985 = "stablehlo.all_reduce"(%6780) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<64xf32>) -> tensor<64xf32>
    %6986 = "stablehlo.all_reduce"(%6788) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<64xf32>) -> tensor<64xf32>
    %6987 = "stablehlo.all_reduce"(%6728) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %6988 = "stablehlo.all_reduce"(%6736) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %6989 = "stablehlo.all_reduce"(%6876) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x64x64xf32>) -> tensor<1x1x64x64xf32>
    %6990 = "stablehlo.all_reduce"(%6824) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<3x3x64x64xf32>) -> tensor<3x3x64x64xf32>
    %6991 = "stablehlo.all_reduce"(%6772) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x64x256xf32>) -> tensor<1x1x64x256xf32>
    %6992 = "stablehlo.all_reduce"(%6926) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x64x256xf32>) -> tensor<1x1x64x256xf32>
    %6993 = "stablehlo.all_reduce"(%6882) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %6994 = "stablehlo.all_reduce"(%6890) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %6995 = "stablehlo.all_reduce"(%6675) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<64xf32>) -> tensor<64xf32>
    %6996 = "stablehlo.all_reduce"(%6683) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<64xf32>) -> tensor<64xf32>
    %6997 = "stablehlo.all_reduce"(%6623) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<64xf32>) -> tensor<64xf32>
    %6998 = "stablehlo.all_reduce"(%6631) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<64xf32>) -> tensor<64xf32>
    %6999 = "stablehlo.all_reduce"(%6571) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7000 = "stablehlo.all_reduce"(%6579) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7001 = "stablehlo.all_reduce"(%6719) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x256x64xf32>) -> tensor<1x1x256x64xf32>
    %7002 = "stablehlo.all_reduce"(%6667) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<3x3x64x64xf32>) -> tensor<3x3x64x64xf32>
    %7003 = "stablehlo.all_reduce"(%6615) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x64x256xf32>) -> tensor<1x1x64x256xf32>
    %7004 = "stablehlo.all_reduce"(%5162) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7005 = "stablehlo.all_reduce"(%5170) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7006 = "stablehlo.all_reduce"(%5110) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7007 = "stablehlo.all_reduce"(%5118) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7008 = "stablehlo.all_reduce"(%5058) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1024xf32>) -> tensor<1024xf32>
    %7009 = "stablehlo.all_reduce"(%5066) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1024xf32>) -> tensor<1024xf32>
    %7010 = "stablehlo.all_reduce"(%5206) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x1024x256xf32>) -> tensor<1x1x1024x256xf32>
    %7011 = "stablehlo.all_reduce"(%5154) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<3x3x256x256xf32>) -> tensor<3x3x256x256xf32>
    %7012 = "stablehlo.all_reduce"(%5102) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x256x1024xf32>) -> tensor<1x1x256x1024xf32>
    %7013 = "stablehlo.all_reduce"(%5005) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7014 = "stablehlo.all_reduce"(%5013) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7015 = "stablehlo.all_reduce"(%4953) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7016 = "stablehlo.all_reduce"(%4961) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7017 = "stablehlo.all_reduce"(%4901) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1024xf32>) -> tensor<1024xf32>
    %7018 = "stablehlo.all_reduce"(%4909) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1024xf32>) -> tensor<1024xf32>
    %7019 = "stablehlo.all_reduce"(%5049) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x1024x256xf32>) -> tensor<1x1x1024x256xf32>
    %7020 = "stablehlo.all_reduce"(%4997) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<3x3x256x256xf32>) -> tensor<3x3x256x256xf32>
    %7021 = "stablehlo.all_reduce"(%4945) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x256x1024xf32>) -> tensor<1x1x256x1024xf32>
    %7022 = "stablehlo.all_reduce"(%4848) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7023 = "stablehlo.all_reduce"(%4856) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7024 = "stablehlo.all_reduce"(%4796) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7025 = "stablehlo.all_reduce"(%4804) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7026 = "stablehlo.all_reduce"(%4744) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1024xf32>) -> tensor<1024xf32>
    %7027 = "stablehlo.all_reduce"(%4752) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1024xf32>) -> tensor<1024xf32>
    %7028 = "stablehlo.all_reduce"(%4892) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x1024x256xf32>) -> tensor<1x1x1024x256xf32>
    %7029 = "stablehlo.all_reduce"(%4840) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<3x3x256x256xf32>) -> tensor<3x3x256x256xf32>
    %7030 = "stablehlo.all_reduce"(%4788) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x256x1024xf32>) -> tensor<1x1x256x1024xf32>
    %7031 = "stablehlo.all_reduce"(%4641) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7032 = "stablehlo.all_reduce"(%4649) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7033 = "stablehlo.all_reduce"(%4589) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7034 = "stablehlo.all_reduce"(%4597) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7035 = "stablehlo.all_reduce"(%4537) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2048xf32>) -> tensor<2048xf32>
    %7036 = "stablehlo.all_reduce"(%4545) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2048xf32>) -> tensor<2048xf32>
    %7037 = "stablehlo.all_reduce"(%4685) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x1024x512xf32>) -> tensor<1x1x1024x512xf32>
    %7038 = "stablehlo.all_reduce"(%4633) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<3x3x512x512xf32>) -> tensor<3x3x512x512xf32>
    %7039 = "stablehlo.all_reduce"(%4581) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x512x2048xf32>) -> tensor<1x1x512x2048xf32>
    %7040 = "stablehlo.all_reduce"(%4735) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x1024x2048xf32>) -> tensor<1x1x1024x2048xf32>
    %7041 = "stablehlo.all_reduce"(%4691) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2048xf32>) -> tensor<2048xf32>
    %7042 = "stablehlo.all_reduce"(%4699) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2048xf32>) -> tensor<2048xf32>
    %7043 = "stablehlo.all_reduce"(%4484) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7044 = "stablehlo.all_reduce"(%4492) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7045 = "stablehlo.all_reduce"(%4432) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7046 = "stablehlo.all_reduce"(%4440) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7047 = "stablehlo.all_reduce"(%4380) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2048xf32>) -> tensor<2048xf32>
    %7048 = "stablehlo.all_reduce"(%4388) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2048xf32>) -> tensor<2048xf32>
    %7049 = "stablehlo.all_reduce"(%4528) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x2048x512xf32>) -> tensor<1x1x2048x512xf32>
    %7050 = "stablehlo.all_reduce"(%4476) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<3x3x512x512xf32>) -> tensor<3x3x512x512xf32>
    %7051 = "stablehlo.all_reduce"(%4424) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x512x2048xf32>) -> tensor<1x1x512x2048xf32>
    %7052 = "stablehlo.all_reduce"(%4327) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7053 = "stablehlo.all_reduce"(%4335) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7054 = "stablehlo.all_reduce"(%4275) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7055 = "stablehlo.all_reduce"(%4283) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7056 = "stablehlo.all_reduce"(%4223) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2048xf32>) -> tensor<2048xf32>
    %7057 = "stablehlo.all_reduce"(%4231) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2048xf32>) -> tensor<2048xf32>
    %7058 = "stablehlo.all_reduce"(%4371) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x2048x512xf32>) -> tensor<1x1x2048x512xf32>
    %7059 = "stablehlo.all_reduce"(%4319) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<3x3x512x512xf32>) -> tensor<3x3x512x512xf32>
    %7060 = "stablehlo.all_reduce"(%4267) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x512x2048xf32>) -> tensor<1x1x512x2048xf32>
    %7061 = "stablehlo.all_reduce"(%6518) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<64xf32>) -> tensor<64xf32>
    %7062 = "stablehlo.all_reduce"(%6526) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<64xf32>) -> tensor<64xf32>
    %7063 = "stablehlo.all_reduce"(%6466) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<64xf32>) -> tensor<64xf32>
    %7064 = "stablehlo.all_reduce"(%6474) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<64xf32>) -> tensor<64xf32>
    %7065 = "stablehlo.all_reduce"(%6414) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7066 = "stablehlo.all_reduce"(%6422) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7067 = "stablehlo.all_reduce"(%6562) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x256x64xf32>) -> tensor<1x1x256x64xf32>
    %7068 = "stablehlo.all_reduce"(%6510) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<3x3x64x64xf32>) -> tensor<3x3x64x64xf32>
    %7069 = "stablehlo.all_reduce"(%6458) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x64x256xf32>) -> tensor<1x1x64x256xf32>
    %7070 = "stablehlo.all_reduce"(%6311) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<128xf32>) -> tensor<128xf32>
    %7071 = "stablehlo.all_reduce"(%6319) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<128xf32>) -> tensor<128xf32>
    %7072 = "stablehlo.all_reduce"(%6259) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<128xf32>) -> tensor<128xf32>
    %7073 = "stablehlo.all_reduce"(%6267) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<128xf32>) -> tensor<128xf32>
    %7074 = "stablehlo.all_reduce"(%6207) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7075 = "stablehlo.all_reduce"(%6215) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7076 = "stablehlo.all_reduce"(%6355) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x256x128xf32>) -> tensor<1x1x256x128xf32>
    %7077 = "stablehlo.all_reduce"(%6303) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<3x3x128x128xf32>) -> tensor<3x3x128x128xf32>
    %7078 = "stablehlo.all_reduce"(%6251) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x128x512xf32>) -> tensor<1x1x128x512xf32>
    %7079 = "stablehlo.all_reduce"(%6405) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x256x512xf32>) -> tensor<1x1x256x512xf32>
    %7080 = "stablehlo.all_reduce"(%6361) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7081 = "stablehlo.all_reduce"(%6369) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7082 = "stablehlo.all_reduce"(%6154) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<128xf32>) -> tensor<128xf32>
    %7083 = "stablehlo.all_reduce"(%6162) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<128xf32>) -> tensor<128xf32>
    %7084 = "stablehlo.all_reduce"(%6102) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<128xf32>) -> tensor<128xf32>
    %7085 = "stablehlo.all_reduce"(%6110) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<128xf32>) -> tensor<128xf32>
    %7086 = "stablehlo.all_reduce"(%6050) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7087 = "stablehlo.all_reduce"(%6058) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7088 = "stablehlo.all_reduce"(%6198) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x512x128xf32>) -> tensor<1x1x512x128xf32>
    %7089 = "stablehlo.all_reduce"(%6146) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<3x3x128x128xf32>) -> tensor<3x3x128x128xf32>
    %7090 = "stablehlo.all_reduce"(%6094) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x128x512xf32>) -> tensor<1x1x128x512xf32>
    %7091 = "stablehlo.all_reduce"(%5997) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<128xf32>) -> tensor<128xf32>
    %7092 = "stablehlo.all_reduce"(%6005) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<128xf32>) -> tensor<128xf32>
    %7093 = "stablehlo.all_reduce"(%5945) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<128xf32>) -> tensor<128xf32>
    %7094 = "stablehlo.all_reduce"(%5953) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<128xf32>) -> tensor<128xf32>
    %7095 = "stablehlo.all_reduce"(%5893) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7096 = "stablehlo.all_reduce"(%5901) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7097 = "stablehlo.all_reduce"(%6041) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x512x128xf32>) -> tensor<1x1x512x128xf32>
    %7098 = "stablehlo.all_reduce"(%5989) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<3x3x128x128xf32>) -> tensor<3x3x128x128xf32>
    %7099 = "stablehlo.all_reduce"(%5937) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x128x512xf32>) -> tensor<1x1x128x512xf32>
    %7100 = "stablehlo.all_reduce"(%5840) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<128xf32>) -> tensor<128xf32>
    %7101 = "stablehlo.all_reduce"(%5848) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<128xf32>) -> tensor<128xf32>
    %7102 = "stablehlo.all_reduce"(%5788) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<128xf32>) -> tensor<128xf32>
    %7103 = "stablehlo.all_reduce"(%5796) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<128xf32>) -> tensor<128xf32>
    %7104 = "stablehlo.all_reduce"(%5736) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7105 = "stablehlo.all_reduce"(%5744) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7106 = "stablehlo.all_reduce"(%5884) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x512x128xf32>) -> tensor<1x1x512x128xf32>
    %7107 = "stablehlo.all_reduce"(%5832) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<3x3x128x128xf32>) -> tensor<3x3x128x128xf32>
    %7108 = "stablehlo.all_reduce"(%5780) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x128x512xf32>) -> tensor<1x1x128x512xf32>
    %7109 = "stablehlo.all_reduce"(%5633) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7110 = "stablehlo.all_reduce"(%5641) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7111 = "stablehlo.all_reduce"(%5581) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7112 = "stablehlo.all_reduce"(%5589) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7113 = "stablehlo.all_reduce"(%5529) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1024xf32>) -> tensor<1024xf32>
    %7114 = "stablehlo.all_reduce"(%5537) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1024xf32>) -> tensor<1024xf32>
    %7115 = "stablehlo.all_reduce"(%5677) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x512x256xf32>) -> tensor<1x1x512x256xf32>
    %7116 = "stablehlo.all_reduce"(%5625) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<3x3x256x256xf32>) -> tensor<3x3x256x256xf32>
    %7117 = "stablehlo.all_reduce"(%5573) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x256x1024xf32>) -> tensor<1x1x256x1024xf32>
    %7118 = "stablehlo.all_reduce"(%5727) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x512x1024xf32>) -> tensor<1x1x512x1024xf32>
    %7119 = "stablehlo.all_reduce"(%5683) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1024xf32>) -> tensor<1024xf32>
    %7120 = "stablehlo.all_reduce"(%5691) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1024xf32>) -> tensor<1024xf32>
    %7121 = "stablehlo.all_reduce"(%5476) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7122 = "stablehlo.all_reduce"(%5484) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7123 = "stablehlo.all_reduce"(%5424) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7124 = "stablehlo.all_reduce"(%5432) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7125 = "stablehlo.all_reduce"(%5372) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1024xf32>) -> tensor<1024xf32>
    %7126 = "stablehlo.all_reduce"(%5380) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1024xf32>) -> tensor<1024xf32>
    %7127 = "stablehlo.all_reduce"(%5520) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x1024x256xf32>) -> tensor<1x1x1024x256xf32>
    %7128 = "stablehlo.all_reduce"(%5468) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<3x3x256x256xf32>) -> tensor<3x3x256x256xf32>
    %7129 = "stablehlo.all_reduce"(%5416) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x256x1024xf32>) -> tensor<1x1x256x1024xf32>
    %7130 = "stablehlo.all_reduce"(%5319) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7131 = "stablehlo.all_reduce"(%5327) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7132 = "stablehlo.all_reduce"(%5267) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7133 = "stablehlo.all_reduce"(%5275) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7134 = "stablehlo.all_reduce"(%5215) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1024xf32>) -> tensor<1024xf32>
    %7135 = "stablehlo.all_reduce"(%5223) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1024xf32>) -> tensor<1024xf32>
    %7136 = "stablehlo.all_reduce"(%5363) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x1024x256xf32>) -> tensor<1x1x1024x256xf32>
    %7137 = "stablehlo.all_reduce"(%5311) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<3x3x256x256xf32>) -> tensor<3x3x256x256xf32>
    %7138 = "stablehlo.all_reduce"(%5259) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1x1x256x1024xf32>) -> tensor<1x1x256x1024xf32>
    %7139 = "stablehlo.all_reduce"(%4207) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1000xf32>) -> tensor<1000xf32>
    %7140 = "stablehlo.all_reduce"(%4211) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2048x1000xf32>) -> tensor<2048x1000xf32>
    %7141 = "stablehlo.all_reduce"(%6938) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<64xf32>) -> tensor<64xf32>
    %7142 = "stablehlo.all_reduce"(%6946) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<64xf32>) -> tensor<64xf32>
    %7143 = "stablehlo.all_reduce"(%6982) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<7x7x3x64xf32>) -> tensor<7x7x3x64xf32>
    %7144 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7145 = stablehlo.divide %6983, %7144 : tensor<64xf32>
    %7146 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7147 = stablehlo.divide %6984, %7146 : tensor<64xf32>
    %7148 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7149 = stablehlo.divide %6985, %7148 : tensor<64xf32>
    %7150 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7151 = stablehlo.divide %6986, %7150 : tensor<64xf32>
    %7152 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7153 = stablehlo.divide %6987, %7152 : tensor<256xf32>
    %7154 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7155 = stablehlo.divide %6988, %7154 : tensor<256xf32>
    %7156 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x64x64xf32>
    %7157 = stablehlo.divide %6989, %7156 : tensor<1x1x64x64xf32>
    %7158 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<3x3x64x64xf32>
    %7159 = stablehlo.divide %6990, %7158 : tensor<3x3x64x64xf32>
    %7160 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x64x256xf32>
    %7161 = stablehlo.divide %6991, %7160 : tensor<1x1x64x256xf32>
    %7162 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x64x256xf32>
    %7163 = stablehlo.divide %6992, %7162 : tensor<1x1x64x256xf32>
    %7164 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7165 = stablehlo.divide %6993, %7164 : tensor<256xf32>
    %7166 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7167 = stablehlo.divide %6994, %7166 : tensor<256xf32>
    %7168 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7169 = stablehlo.divide %6995, %7168 : tensor<64xf32>
    %7170 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7171 = stablehlo.divide %6996, %7170 : tensor<64xf32>
    %7172 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7173 = stablehlo.divide %6997, %7172 : tensor<64xf32>
    %7174 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7175 = stablehlo.divide %6998, %7174 : tensor<64xf32>
    %7176 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7177 = stablehlo.divide %6999, %7176 : tensor<256xf32>
    %7178 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7179 = stablehlo.divide %7000, %7178 : tensor<256xf32>
    %7180 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x256x64xf32>
    %7181 = stablehlo.divide %7001, %7180 : tensor<1x1x256x64xf32>
    %7182 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<3x3x64x64xf32>
    %7183 = stablehlo.divide %7002, %7182 : tensor<3x3x64x64xf32>
    %7184 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x64x256xf32>
    %7185 = stablehlo.divide %7003, %7184 : tensor<1x1x64x256xf32>
    %7186 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7187 = stablehlo.divide %7004, %7186 : tensor<256xf32>
    %7188 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7189 = stablehlo.divide %7005, %7188 : tensor<256xf32>
    %7190 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7191 = stablehlo.divide %7006, %7190 : tensor<256xf32>
    %7192 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7193 = stablehlo.divide %7007, %7192 : tensor<256xf32>
    %7194 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7195 = stablehlo.divide %7008, %7194 : tensor<1024xf32>
    %7196 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7197 = stablehlo.divide %7009, %7196 : tensor<1024xf32>
    %7198 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x1024x256xf32>
    %7199 = stablehlo.divide %7010, %7198 : tensor<1x1x1024x256xf32>
    %7200 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %7201 = stablehlo.divide %7011, %7200 : tensor<3x3x256x256xf32>
    %7202 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %7203 = stablehlo.divide %7012, %7202 : tensor<1x1x256x1024xf32>
    %7204 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7205 = stablehlo.divide %7013, %7204 : tensor<256xf32>
    %7206 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7207 = stablehlo.divide %7014, %7206 : tensor<256xf32>
    %7208 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7209 = stablehlo.divide %7015, %7208 : tensor<256xf32>
    %7210 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7211 = stablehlo.divide %7016, %7210 : tensor<256xf32>
    %7212 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7213 = stablehlo.divide %7017, %7212 : tensor<1024xf32>
    %7214 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7215 = stablehlo.divide %7018, %7214 : tensor<1024xf32>
    %7216 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x1024x256xf32>
    %7217 = stablehlo.divide %7019, %7216 : tensor<1x1x1024x256xf32>
    %7218 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %7219 = stablehlo.divide %7020, %7218 : tensor<3x3x256x256xf32>
    %7220 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %7221 = stablehlo.divide %7021, %7220 : tensor<1x1x256x1024xf32>
    %7222 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7223 = stablehlo.divide %7022, %7222 : tensor<256xf32>
    %7224 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7225 = stablehlo.divide %7023, %7224 : tensor<256xf32>
    %7226 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7227 = stablehlo.divide %7024, %7226 : tensor<256xf32>
    %7228 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7229 = stablehlo.divide %7025, %7228 : tensor<256xf32>
    %7230 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7231 = stablehlo.divide %7026, %7230 : tensor<1024xf32>
    %7232 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7233 = stablehlo.divide %7027, %7232 : tensor<1024xf32>
    %7234 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x1024x256xf32>
    %7235 = stablehlo.divide %7028, %7234 : tensor<1x1x1024x256xf32>
    %7236 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %7237 = stablehlo.divide %7029, %7236 : tensor<3x3x256x256xf32>
    %7238 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %7239 = stablehlo.divide %7030, %7238 : tensor<1x1x256x1024xf32>
    %7240 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7241 = stablehlo.divide %7031, %7240 : tensor<512xf32>
    %7242 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7243 = stablehlo.divide %7032, %7242 : tensor<512xf32>
    %7244 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7245 = stablehlo.divide %7033, %7244 : tensor<512xf32>
    %7246 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7247 = stablehlo.divide %7034, %7246 : tensor<512xf32>
    %7248 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %7249 = stablehlo.divide %7035, %7248 : tensor<2048xf32>
    %7250 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %7251 = stablehlo.divide %7036, %7250 : tensor<2048xf32>
    %7252 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x1024x512xf32>
    %7253 = stablehlo.divide %7037, %7252 : tensor<1x1x1024x512xf32>
    %7254 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<3x3x512x512xf32>
    %7255 = stablehlo.divide %7038, %7254 : tensor<3x3x512x512xf32>
    %7256 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x512x2048xf32>
    %7257 = stablehlo.divide %7039, %7256 : tensor<1x1x512x2048xf32>
    %7258 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x1024x2048xf32>
    %7259 = stablehlo.divide %7040, %7258 : tensor<1x1x1024x2048xf32>
    %7260 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %7261 = stablehlo.divide %7041, %7260 : tensor<2048xf32>
    %7262 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %7263 = stablehlo.divide %7042, %7262 : tensor<2048xf32>
    %7264 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7265 = stablehlo.divide %7043, %7264 : tensor<512xf32>
    %7266 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7267 = stablehlo.divide %7044, %7266 : tensor<512xf32>
    %7268 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7269 = stablehlo.divide %7045, %7268 : tensor<512xf32>
    %7270 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7271 = stablehlo.divide %7046, %7270 : tensor<512xf32>
    %7272 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %7273 = stablehlo.divide %7047, %7272 : tensor<2048xf32>
    %7274 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %7275 = stablehlo.divide %7048, %7274 : tensor<2048xf32>
    %7276 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x2048x512xf32>
    %7277 = stablehlo.divide %7049, %7276 : tensor<1x1x2048x512xf32>
    %7278 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<3x3x512x512xf32>
    %7279 = stablehlo.divide %7050, %7278 : tensor<3x3x512x512xf32>
    %7280 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x512x2048xf32>
    %7281 = stablehlo.divide %7051, %7280 : tensor<1x1x512x2048xf32>
    %7282 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7283 = stablehlo.divide %7052, %7282 : tensor<512xf32>
    %7284 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7285 = stablehlo.divide %7053, %7284 : tensor<512xf32>
    %7286 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7287 = stablehlo.divide %7054, %7286 : tensor<512xf32>
    %7288 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7289 = stablehlo.divide %7055, %7288 : tensor<512xf32>
    %7290 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %7291 = stablehlo.divide %7056, %7290 : tensor<2048xf32>
    %7292 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %7293 = stablehlo.divide %7057, %7292 : tensor<2048xf32>
    %7294 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x2048x512xf32>
    %7295 = stablehlo.divide %7058, %7294 : tensor<1x1x2048x512xf32>
    %7296 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<3x3x512x512xf32>
    %7297 = stablehlo.divide %7059, %7296 : tensor<3x3x512x512xf32>
    %7298 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x512x2048xf32>
    %7299 = stablehlo.divide %7060, %7298 : tensor<1x1x512x2048xf32>
    %7300 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7301 = stablehlo.divide %7061, %7300 : tensor<64xf32>
    %7302 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7303 = stablehlo.divide %7062, %7302 : tensor<64xf32>
    %7304 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7305 = stablehlo.divide %7063, %7304 : tensor<64xf32>
    %7306 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7307 = stablehlo.divide %7064, %7306 : tensor<64xf32>
    %7308 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7309 = stablehlo.divide %7065, %7308 : tensor<256xf32>
    %7310 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7311 = stablehlo.divide %7066, %7310 : tensor<256xf32>
    %7312 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x256x64xf32>
    %7313 = stablehlo.divide %7067, %7312 : tensor<1x1x256x64xf32>
    %7314 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<3x3x64x64xf32>
    %7315 = stablehlo.divide %7068, %7314 : tensor<3x3x64x64xf32>
    %7316 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x64x256xf32>
    %7317 = stablehlo.divide %7069, %7316 : tensor<1x1x64x256xf32>
    %7318 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %7319 = stablehlo.divide %7070, %7318 : tensor<128xf32>
    %7320 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %7321 = stablehlo.divide %7071, %7320 : tensor<128xf32>
    %7322 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %7323 = stablehlo.divide %7072, %7322 : tensor<128xf32>
    %7324 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %7325 = stablehlo.divide %7073, %7324 : tensor<128xf32>
    %7326 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7327 = stablehlo.divide %7074, %7326 : tensor<512xf32>
    %7328 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7329 = stablehlo.divide %7075, %7328 : tensor<512xf32>
    %7330 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x256x128xf32>
    %7331 = stablehlo.divide %7076, %7330 : tensor<1x1x256x128xf32>
    %7332 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<3x3x128x128xf32>
    %7333 = stablehlo.divide %7077, %7332 : tensor<3x3x128x128xf32>
    %7334 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x128x512xf32>
    %7335 = stablehlo.divide %7078, %7334 : tensor<1x1x128x512xf32>
    %7336 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x256x512xf32>
    %7337 = stablehlo.divide %7079, %7336 : tensor<1x1x256x512xf32>
    %7338 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7339 = stablehlo.divide %7080, %7338 : tensor<512xf32>
    %7340 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7341 = stablehlo.divide %7081, %7340 : tensor<512xf32>
    %7342 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %7343 = stablehlo.divide %7082, %7342 : tensor<128xf32>
    %7344 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %7345 = stablehlo.divide %7083, %7344 : tensor<128xf32>
    %7346 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %7347 = stablehlo.divide %7084, %7346 : tensor<128xf32>
    %7348 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %7349 = stablehlo.divide %7085, %7348 : tensor<128xf32>
    %7350 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7351 = stablehlo.divide %7086, %7350 : tensor<512xf32>
    %7352 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7353 = stablehlo.divide %7087, %7352 : tensor<512xf32>
    %7354 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x512x128xf32>
    %7355 = stablehlo.divide %7088, %7354 : tensor<1x1x512x128xf32>
    %7356 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<3x3x128x128xf32>
    %7357 = stablehlo.divide %7089, %7356 : tensor<3x3x128x128xf32>
    %7358 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x128x512xf32>
    %7359 = stablehlo.divide %7090, %7358 : tensor<1x1x128x512xf32>
    %7360 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %7361 = stablehlo.divide %7091, %7360 : tensor<128xf32>
    %7362 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %7363 = stablehlo.divide %7092, %7362 : tensor<128xf32>
    %7364 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %7365 = stablehlo.divide %7093, %7364 : tensor<128xf32>
    %7366 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %7367 = stablehlo.divide %7094, %7366 : tensor<128xf32>
    %7368 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7369 = stablehlo.divide %7095, %7368 : tensor<512xf32>
    %7370 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7371 = stablehlo.divide %7096, %7370 : tensor<512xf32>
    %7372 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x512x128xf32>
    %7373 = stablehlo.divide %7097, %7372 : tensor<1x1x512x128xf32>
    %7374 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<3x3x128x128xf32>
    %7375 = stablehlo.divide %7098, %7374 : tensor<3x3x128x128xf32>
    %7376 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x128x512xf32>
    %7377 = stablehlo.divide %7099, %7376 : tensor<1x1x128x512xf32>
    %7378 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %7379 = stablehlo.divide %7100, %7378 : tensor<128xf32>
    %7380 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %7381 = stablehlo.divide %7101, %7380 : tensor<128xf32>
    %7382 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %7383 = stablehlo.divide %7102, %7382 : tensor<128xf32>
    %7384 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %7385 = stablehlo.divide %7103, %7384 : tensor<128xf32>
    %7386 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7387 = stablehlo.divide %7104, %7386 : tensor<512xf32>
    %7388 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7389 = stablehlo.divide %7105, %7388 : tensor<512xf32>
    %7390 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x512x128xf32>
    %7391 = stablehlo.divide %7106, %7390 : tensor<1x1x512x128xf32>
    %7392 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<3x3x128x128xf32>
    %7393 = stablehlo.divide %7107, %7392 : tensor<3x3x128x128xf32>
    %7394 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x128x512xf32>
    %7395 = stablehlo.divide %7108, %7394 : tensor<1x1x128x512xf32>
    %7396 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7397 = stablehlo.divide %7109, %7396 : tensor<256xf32>
    %7398 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7399 = stablehlo.divide %7110, %7398 : tensor<256xf32>
    %7400 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7401 = stablehlo.divide %7111, %7400 : tensor<256xf32>
    %7402 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7403 = stablehlo.divide %7112, %7402 : tensor<256xf32>
    %7404 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7405 = stablehlo.divide %7113, %7404 : tensor<1024xf32>
    %7406 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7407 = stablehlo.divide %7114, %7406 : tensor<1024xf32>
    %7408 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x512x256xf32>
    %7409 = stablehlo.divide %7115, %7408 : tensor<1x1x512x256xf32>
    %7410 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %7411 = stablehlo.divide %7116, %7410 : tensor<3x3x256x256xf32>
    %7412 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %7413 = stablehlo.divide %7117, %7412 : tensor<1x1x256x1024xf32>
    %7414 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x512x1024xf32>
    %7415 = stablehlo.divide %7118, %7414 : tensor<1x1x512x1024xf32>
    %7416 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7417 = stablehlo.divide %7119, %7416 : tensor<1024xf32>
    %7418 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7419 = stablehlo.divide %7120, %7418 : tensor<1024xf32>
    %7420 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7421 = stablehlo.divide %7121, %7420 : tensor<256xf32>
    %7422 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7423 = stablehlo.divide %7122, %7422 : tensor<256xf32>
    %7424 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7425 = stablehlo.divide %7123, %7424 : tensor<256xf32>
    %7426 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7427 = stablehlo.divide %7124, %7426 : tensor<256xf32>
    %7428 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7429 = stablehlo.divide %7125, %7428 : tensor<1024xf32>
    %7430 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7431 = stablehlo.divide %7126, %7430 : tensor<1024xf32>
    %7432 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x1024x256xf32>
    %7433 = stablehlo.divide %7127, %7432 : tensor<1x1x1024x256xf32>
    %7434 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %7435 = stablehlo.divide %7128, %7434 : tensor<3x3x256x256xf32>
    %7436 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %7437 = stablehlo.divide %7129, %7436 : tensor<1x1x256x1024xf32>
    %7438 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7439 = stablehlo.divide %7130, %7438 : tensor<256xf32>
    %7440 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7441 = stablehlo.divide %7131, %7440 : tensor<256xf32>
    %7442 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7443 = stablehlo.divide %7132, %7442 : tensor<256xf32>
    %7444 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7445 = stablehlo.divide %7133, %7444 : tensor<256xf32>
    %7446 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7447 = stablehlo.divide %7134, %7446 : tensor<1024xf32>
    %7448 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7449 = stablehlo.divide %7135, %7448 : tensor<1024xf32>
    %7450 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x1024x256xf32>
    %7451 = stablehlo.divide %7136, %7450 : tensor<1x1x1024x256xf32>
    %7452 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %7453 = stablehlo.divide %7137, %7452 : tensor<3x3x256x256xf32>
    %7454 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %7455 = stablehlo.divide %7138, %7454 : tensor<1x1x256x1024xf32>
    %7456 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1000xf32>
    %7457 = stablehlo.divide %7139, %7456 : tensor<1000xf32>
    %7458 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2048x1000xf32>
    %7459 = stablehlo.divide %7140, %7458 : tensor<2048x1000xf32>
    %7460 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7461 = stablehlo.divide %7141, %7460 : tensor<64xf32>
    %7462 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7463 = stablehlo.divide %7142, %7462 : tensor<64xf32>
    %7464 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<7x7x3x64xf32>
    %7465 = stablehlo.divide %7143, %7464 : tensor<7x7x3x64xf32>
    %7466 = stablehlo.broadcast_in_dim %1, dims = [0] : (tensor<256xi32>) -> tensor<256x1xi32>
    %7467 = stablehlo.iota dim = 0 : tensor<1000xi32>
    %7468 = stablehlo.reshape %7467 : (tensor<1000xi32>) -> tensor<1x1000xi32>
    %7469 = stablehlo.broadcast_in_dim %7466, dims = [0, 1] : (tensor<256x1xi32>) -> tensor<256x1000xi32>
    %7470 = stablehlo.broadcast_in_dim %7468, dims = [0, 1] : (tensor<1x1000xi32>) -> tensor<256x1000xi32>
    %7471 = stablehlo.compare  EQ, %7469, %7470,  SIGNED : (tensor<256x1000xi32>, tensor<256x1000xi32>) -> tensor<256x1000xi1>
    %7472 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<256x1000xf32>
    %7473 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<f32>) -> tensor<256x1000xf32>
    %7474 = stablehlo.select %7471, %7472, %7473 : tensor<256x1000xi1>, tensor<256x1000xf32>
    %7475 = stablehlo.convert %7474 : tensor<256x1000xf32>
    %7476 = call @log_softmax_12(%3798) : (tensor<256x1000xf16>) -> tensor<256x1000xf16>
    %7477 = stablehlo.convert %7476 : (tensor<256x1000xf16>) -> tensor<256x1000xf32>
    %7478 = stablehlo.multiply %7475, %7477 : tensor<256x1000xf32>
    %cst_562 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %7479 = stablehlo.reduce(%7478 init: %cst_562) applies stablehlo.add across dimensions = [1] : (tensor<256x1000xf32>, tensor<f32>) -> tensor<256xf32>
    %7480 = stablehlo.negate %7479 : tensor<256xf32>
    %cst_563 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %7481 = stablehlo.reduce(%7480 init: %cst_563) applies stablehlo.add across dimensions = [0] : (tensor<256xf32>, tensor<f32>) -> tensor<f32>
    %7482 = stablehlo.divide %7481, %cst_132 : tensor<f32>
    %7483 = call @argmax(%3798) : (tensor<256x1000xf16>) -> tensor<256xi32>
    %7484 = stablehlo.compare  EQ, %7483, %1,  SIGNED : (tensor<256xi32>, tensor<256xi32>) -> tensor<256xi1>
    %7485 = stablehlo.convert %7484 : (tensor<256xi1>) -> tensor<256xi32>
    %7486 = stablehlo.convert %7485 : (tensor<256xi32>) -> tensor<256xf32>
    %cst_564 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %7487 = stablehlo.reduce(%7486 init: %cst_564) applies stablehlo.add across dimensions = [0] : (tensor<256xf32>, tensor<f32>) -> tensor<f32>
    %7488 = stablehlo.divide %7487, %cst_132 : tensor<f32>
    %7489 = "stablehlo.all_reduce"(%7488) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<f32>) -> tensor<f32>
    %7490 = "stablehlo.all_reduce"(%7482) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<f32>) -> tensor<f32>
    %7491 = stablehlo.divide %7489, %cst_11 : tensor<f32>
    %7492 = stablehlo.divide %7490, %cst_11 : tensor<f32>
    %7493 = "stablehlo.all_reduce"(%138) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<64xf32>) -> tensor<64xf32>
    %7494 = "stablehlo.all_reduce"(%143) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<64xf32>) -> tensor<64xf32>
    %7495 = "stablehlo.all_reduce"(%209) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<64xf32>) -> tensor<64xf32>
    %7496 = "stablehlo.all_reduce"(%214) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<64xf32>) -> tensor<64xf32>
    %7497 = "stablehlo.all_reduce"(%280) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7498 = "stablehlo.all_reduce"(%285) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7499 = "stablehlo.all_reduce"(%347) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7500 = "stablehlo.all_reduce"(%352) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7501 = "stablehlo.all_reduce"(%419) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<64xf32>) -> tensor<64xf32>
    %7502 = "stablehlo.all_reduce"(%424) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<64xf32>) -> tensor<64xf32>
    %7503 = "stablehlo.all_reduce"(%490) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<64xf32>) -> tensor<64xf32>
    %7504 = "stablehlo.all_reduce"(%495) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<64xf32>) -> tensor<64xf32>
    %7505 = "stablehlo.all_reduce"(%561) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7506 = "stablehlo.all_reduce"(%566) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7507 = "stablehlo.all_reduce"(%2479) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7508 = "stablehlo.all_reduce"(%2484) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7509 = "stablehlo.all_reduce"(%2550) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7510 = "stablehlo.all_reduce"(%2555) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7511 = "stablehlo.all_reduce"(%2621) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1024xf32>) -> tensor<1024xf32>
    %7512 = "stablehlo.all_reduce"(%2626) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1024xf32>) -> tensor<1024xf32>
    %7513 = "stablehlo.all_reduce"(%2693) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7514 = "stablehlo.all_reduce"(%2698) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7515 = "stablehlo.all_reduce"(%2764) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7516 = "stablehlo.all_reduce"(%2769) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7517 = "stablehlo.all_reduce"(%2835) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1024xf32>) -> tensor<1024xf32>
    %7518 = "stablehlo.all_reduce"(%2840) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1024xf32>) -> tensor<1024xf32>
    %7519 = "stablehlo.all_reduce"(%2907) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7520 = "stablehlo.all_reduce"(%2912) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7521 = "stablehlo.all_reduce"(%2978) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7522 = "stablehlo.all_reduce"(%2983) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7523 = "stablehlo.all_reduce"(%3049) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1024xf32>) -> tensor<1024xf32>
    %7524 = "stablehlo.all_reduce"(%3054) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1024xf32>) -> tensor<1024xf32>
    %7525 = "stablehlo.all_reduce"(%3121) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7526 = "stablehlo.all_reduce"(%3126) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7527 = "stablehlo.all_reduce"(%3192) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7528 = "stablehlo.all_reduce"(%3197) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7529 = "stablehlo.all_reduce"(%3263) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2048xf32>) -> tensor<2048xf32>
    %7530 = "stablehlo.all_reduce"(%3268) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2048xf32>) -> tensor<2048xf32>
    %7531 = "stablehlo.all_reduce"(%3330) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2048xf32>) -> tensor<2048xf32>
    %7532 = "stablehlo.all_reduce"(%3335) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2048xf32>) -> tensor<2048xf32>
    %7533 = "stablehlo.all_reduce"(%3402) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7534 = "stablehlo.all_reduce"(%3407) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7535 = "stablehlo.all_reduce"(%3473) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7536 = "stablehlo.all_reduce"(%3478) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7537 = "stablehlo.all_reduce"(%3544) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2048xf32>) -> tensor<2048xf32>
    %7538 = "stablehlo.all_reduce"(%3549) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2048xf32>) -> tensor<2048xf32>
    %7539 = "stablehlo.all_reduce"(%3616) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7540 = "stablehlo.all_reduce"(%3621) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7541 = "stablehlo.all_reduce"(%3687) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7542 = "stablehlo.all_reduce"(%3692) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7543 = "stablehlo.all_reduce"(%3758) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2048xf32>) -> tensor<2048xf32>
    %7544 = "stablehlo.all_reduce"(%3763) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<2048xf32>) -> tensor<2048xf32>
    %7545 = "stablehlo.all_reduce"(%633) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<64xf32>) -> tensor<64xf32>
    %7546 = "stablehlo.all_reduce"(%638) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<64xf32>) -> tensor<64xf32>
    %7547 = "stablehlo.all_reduce"(%704) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<64xf32>) -> tensor<64xf32>
    %7548 = "stablehlo.all_reduce"(%709) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<64xf32>) -> tensor<64xf32>
    %7549 = "stablehlo.all_reduce"(%775) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7550 = "stablehlo.all_reduce"(%780) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7551 = "stablehlo.all_reduce"(%847) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<128xf32>) -> tensor<128xf32>
    %7552 = "stablehlo.all_reduce"(%852) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<128xf32>) -> tensor<128xf32>
    %7553 = "stablehlo.all_reduce"(%918) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<128xf32>) -> tensor<128xf32>
    %7554 = "stablehlo.all_reduce"(%923) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<128xf32>) -> tensor<128xf32>
    %7555 = "stablehlo.all_reduce"(%989) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7556 = "stablehlo.all_reduce"(%994) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7557 = "stablehlo.all_reduce"(%1056) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7558 = "stablehlo.all_reduce"(%1061) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7559 = "stablehlo.all_reduce"(%1128) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<128xf32>) -> tensor<128xf32>
    %7560 = "stablehlo.all_reduce"(%1133) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<128xf32>) -> tensor<128xf32>
    %7561 = "stablehlo.all_reduce"(%1199) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<128xf32>) -> tensor<128xf32>
    %7562 = "stablehlo.all_reduce"(%1204) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<128xf32>) -> tensor<128xf32>
    %7563 = "stablehlo.all_reduce"(%1270) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7564 = "stablehlo.all_reduce"(%1275) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7565 = "stablehlo.all_reduce"(%1342) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<128xf32>) -> tensor<128xf32>
    %7566 = "stablehlo.all_reduce"(%1347) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<128xf32>) -> tensor<128xf32>
    %7567 = "stablehlo.all_reduce"(%1413) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<128xf32>) -> tensor<128xf32>
    %7568 = "stablehlo.all_reduce"(%1418) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<128xf32>) -> tensor<128xf32>
    %7569 = "stablehlo.all_reduce"(%1484) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7570 = "stablehlo.all_reduce"(%1489) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7571 = "stablehlo.all_reduce"(%1556) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<128xf32>) -> tensor<128xf32>
    %7572 = "stablehlo.all_reduce"(%1561) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<128xf32>) -> tensor<128xf32>
    %7573 = "stablehlo.all_reduce"(%1627) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<128xf32>) -> tensor<128xf32>
    %7574 = "stablehlo.all_reduce"(%1632) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<128xf32>) -> tensor<128xf32>
    %7575 = "stablehlo.all_reduce"(%1698) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7576 = "stablehlo.all_reduce"(%1703) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<512xf32>) -> tensor<512xf32>
    %7577 = "stablehlo.all_reduce"(%1770) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7578 = "stablehlo.all_reduce"(%1775) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7579 = "stablehlo.all_reduce"(%1841) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7580 = "stablehlo.all_reduce"(%1846) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7581 = "stablehlo.all_reduce"(%1912) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1024xf32>) -> tensor<1024xf32>
    %7582 = "stablehlo.all_reduce"(%1917) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1024xf32>) -> tensor<1024xf32>
    %7583 = "stablehlo.all_reduce"(%1979) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1024xf32>) -> tensor<1024xf32>
    %7584 = "stablehlo.all_reduce"(%1984) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1024xf32>) -> tensor<1024xf32>
    %7585 = "stablehlo.all_reduce"(%2051) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7586 = "stablehlo.all_reduce"(%2056) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7587 = "stablehlo.all_reduce"(%2122) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7588 = "stablehlo.all_reduce"(%2127) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7589 = "stablehlo.all_reduce"(%2193) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1024xf32>) -> tensor<1024xf32>
    %7590 = "stablehlo.all_reduce"(%2198) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1024xf32>) -> tensor<1024xf32>
    %7591 = "stablehlo.all_reduce"(%2265) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7592 = "stablehlo.all_reduce"(%2270) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7593 = "stablehlo.all_reduce"(%2336) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7594 = "stablehlo.all_reduce"(%2341) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<256xf32>) -> tensor<256xf32>
    %7595 = "stablehlo.all_reduce"(%2407) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1024xf32>) -> tensor<1024xf32>
    %7596 = "stablehlo.all_reduce"(%2412) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<1024xf32>) -> tensor<1024xf32>
    %7597 = "stablehlo.all_reduce"(%65) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<64xf32>) -> tensor<64xf32>
    %7598 = "stablehlo.all_reduce"(%70) <{replica_groups = dense<[[0, 1, 2, 3]]> : tensor<1x4xi64>}> ({
    ^bb0(%arg432: tensor<f32>, %arg433: tensor<f32>):
      %9450 = stablehlo.add %arg432, %arg433 : tensor<f32>
      stablehlo.return %9450 : tensor<f32>
    }) : (tensor<64xf32>) -> tensor<64xf32>
    %7599 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7600 = stablehlo.divide %7493, %7599 : tensor<64xf32>
    %7601 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7602 = stablehlo.divide %7494, %7601 : tensor<64xf32>
    %7603 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7604 = stablehlo.divide %7495, %7603 : tensor<64xf32>
    %7605 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7606 = stablehlo.divide %7496, %7605 : tensor<64xf32>
    %7607 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7608 = stablehlo.divide %7497, %7607 : tensor<256xf32>
    %7609 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7610 = stablehlo.divide %7498, %7609 : tensor<256xf32>
    %7611 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7612 = stablehlo.divide %7499, %7611 : tensor<256xf32>
    %7613 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7614 = stablehlo.divide %7500, %7613 : tensor<256xf32>
    %7615 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7616 = stablehlo.divide %7501, %7615 : tensor<64xf32>
    %7617 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7618 = stablehlo.divide %7502, %7617 : tensor<64xf32>
    %7619 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7620 = stablehlo.divide %7503, %7619 : tensor<64xf32>
    %7621 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7622 = stablehlo.divide %7504, %7621 : tensor<64xf32>
    %7623 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7624 = stablehlo.divide %7505, %7623 : tensor<256xf32>
    %7625 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7626 = stablehlo.divide %7506, %7625 : tensor<256xf32>
    %7627 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7628 = stablehlo.divide %7507, %7627 : tensor<256xf32>
    %7629 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7630 = stablehlo.divide %7508, %7629 : tensor<256xf32>
    %7631 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7632 = stablehlo.divide %7509, %7631 : tensor<256xf32>
    %7633 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7634 = stablehlo.divide %7510, %7633 : tensor<256xf32>
    %7635 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7636 = stablehlo.divide %7511, %7635 : tensor<1024xf32>
    %7637 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7638 = stablehlo.divide %7512, %7637 : tensor<1024xf32>
    %7639 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7640 = stablehlo.divide %7513, %7639 : tensor<256xf32>
    %7641 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7642 = stablehlo.divide %7514, %7641 : tensor<256xf32>
    %7643 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7644 = stablehlo.divide %7515, %7643 : tensor<256xf32>
    %7645 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7646 = stablehlo.divide %7516, %7645 : tensor<256xf32>
    %7647 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7648 = stablehlo.divide %7517, %7647 : tensor<1024xf32>
    %7649 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7650 = stablehlo.divide %7518, %7649 : tensor<1024xf32>
    %7651 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7652 = stablehlo.divide %7519, %7651 : tensor<256xf32>
    %7653 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7654 = stablehlo.divide %7520, %7653 : tensor<256xf32>
    %7655 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7656 = stablehlo.divide %7521, %7655 : tensor<256xf32>
    %7657 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7658 = stablehlo.divide %7522, %7657 : tensor<256xf32>
    %7659 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7660 = stablehlo.divide %7523, %7659 : tensor<1024xf32>
    %7661 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7662 = stablehlo.divide %7524, %7661 : tensor<1024xf32>
    %7663 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7664 = stablehlo.divide %7525, %7663 : tensor<512xf32>
    %7665 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7666 = stablehlo.divide %7526, %7665 : tensor<512xf32>
    %7667 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7668 = stablehlo.divide %7527, %7667 : tensor<512xf32>
    %7669 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7670 = stablehlo.divide %7528, %7669 : tensor<512xf32>
    %7671 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %7672 = stablehlo.divide %7529, %7671 : tensor<2048xf32>
    %7673 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %7674 = stablehlo.divide %7530, %7673 : tensor<2048xf32>
    %7675 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %7676 = stablehlo.divide %7531, %7675 : tensor<2048xf32>
    %7677 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %7678 = stablehlo.divide %7532, %7677 : tensor<2048xf32>
    %7679 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7680 = stablehlo.divide %7533, %7679 : tensor<512xf32>
    %7681 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7682 = stablehlo.divide %7534, %7681 : tensor<512xf32>
    %7683 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7684 = stablehlo.divide %7535, %7683 : tensor<512xf32>
    %7685 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7686 = stablehlo.divide %7536, %7685 : tensor<512xf32>
    %7687 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %7688 = stablehlo.divide %7537, %7687 : tensor<2048xf32>
    %7689 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %7690 = stablehlo.divide %7538, %7689 : tensor<2048xf32>
    %7691 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7692 = stablehlo.divide %7539, %7691 : tensor<512xf32>
    %7693 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7694 = stablehlo.divide %7540, %7693 : tensor<512xf32>
    %7695 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7696 = stablehlo.divide %7541, %7695 : tensor<512xf32>
    %7697 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7698 = stablehlo.divide %7542, %7697 : tensor<512xf32>
    %7699 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %7700 = stablehlo.divide %7543, %7699 : tensor<2048xf32>
    %7701 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %7702 = stablehlo.divide %7544, %7701 : tensor<2048xf32>
    %7703 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7704 = stablehlo.divide %7545, %7703 : tensor<64xf32>
    %7705 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7706 = stablehlo.divide %7546, %7705 : tensor<64xf32>
    %7707 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7708 = stablehlo.divide %7547, %7707 : tensor<64xf32>
    %7709 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7710 = stablehlo.divide %7548, %7709 : tensor<64xf32>
    %7711 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7712 = stablehlo.divide %7549, %7711 : tensor<256xf32>
    %7713 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7714 = stablehlo.divide %7550, %7713 : tensor<256xf32>
    %7715 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %7716 = stablehlo.divide %7551, %7715 : tensor<128xf32>
    %7717 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %7718 = stablehlo.divide %7552, %7717 : tensor<128xf32>
    %7719 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %7720 = stablehlo.divide %7553, %7719 : tensor<128xf32>
    %7721 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %7722 = stablehlo.divide %7554, %7721 : tensor<128xf32>
    %7723 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7724 = stablehlo.divide %7555, %7723 : tensor<512xf32>
    %7725 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7726 = stablehlo.divide %7556, %7725 : tensor<512xf32>
    %7727 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7728 = stablehlo.divide %7557, %7727 : tensor<512xf32>
    %7729 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7730 = stablehlo.divide %7558, %7729 : tensor<512xf32>
    %7731 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %7732 = stablehlo.divide %7559, %7731 : tensor<128xf32>
    %7733 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %7734 = stablehlo.divide %7560, %7733 : tensor<128xf32>
    %7735 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %7736 = stablehlo.divide %7561, %7735 : tensor<128xf32>
    %7737 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %7738 = stablehlo.divide %7562, %7737 : tensor<128xf32>
    %7739 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7740 = stablehlo.divide %7563, %7739 : tensor<512xf32>
    %7741 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7742 = stablehlo.divide %7564, %7741 : tensor<512xf32>
    %7743 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %7744 = stablehlo.divide %7565, %7743 : tensor<128xf32>
    %7745 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %7746 = stablehlo.divide %7566, %7745 : tensor<128xf32>
    %7747 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %7748 = stablehlo.divide %7567, %7747 : tensor<128xf32>
    %7749 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %7750 = stablehlo.divide %7568, %7749 : tensor<128xf32>
    %7751 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7752 = stablehlo.divide %7569, %7751 : tensor<512xf32>
    %7753 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7754 = stablehlo.divide %7570, %7753 : tensor<512xf32>
    %7755 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %7756 = stablehlo.divide %7571, %7755 : tensor<128xf32>
    %7757 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %7758 = stablehlo.divide %7572, %7757 : tensor<128xf32>
    %7759 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %7760 = stablehlo.divide %7573, %7759 : tensor<128xf32>
    %7761 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %7762 = stablehlo.divide %7574, %7761 : tensor<128xf32>
    %7763 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7764 = stablehlo.divide %7575, %7763 : tensor<512xf32>
    %7765 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7766 = stablehlo.divide %7576, %7765 : tensor<512xf32>
    %7767 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7768 = stablehlo.divide %7577, %7767 : tensor<256xf32>
    %7769 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7770 = stablehlo.divide %7578, %7769 : tensor<256xf32>
    %7771 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7772 = stablehlo.divide %7579, %7771 : tensor<256xf32>
    %7773 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7774 = stablehlo.divide %7580, %7773 : tensor<256xf32>
    %7775 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7776 = stablehlo.divide %7581, %7775 : tensor<1024xf32>
    %7777 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7778 = stablehlo.divide %7582, %7777 : tensor<1024xf32>
    %7779 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7780 = stablehlo.divide %7583, %7779 : tensor<1024xf32>
    %7781 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7782 = stablehlo.divide %7584, %7781 : tensor<1024xf32>
    %7783 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7784 = stablehlo.divide %7585, %7783 : tensor<256xf32>
    %7785 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7786 = stablehlo.divide %7586, %7785 : tensor<256xf32>
    %7787 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7788 = stablehlo.divide %7587, %7787 : tensor<256xf32>
    %7789 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7790 = stablehlo.divide %7588, %7789 : tensor<256xf32>
    %7791 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7792 = stablehlo.divide %7589, %7791 : tensor<1024xf32>
    %7793 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7794 = stablehlo.divide %7590, %7793 : tensor<1024xf32>
    %7795 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7796 = stablehlo.divide %7591, %7795 : tensor<256xf32>
    %7797 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7798 = stablehlo.divide %7592, %7797 : tensor<256xf32>
    %7799 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7800 = stablehlo.divide %7593, %7799 : tensor<256xf32>
    %7801 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7802 = stablehlo.divide %7594, %7801 : tensor<256xf32>
    %7803 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7804 = stablehlo.divide %7595, %7803 : tensor<1024xf32>
    %7805 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7806 = stablehlo.divide %7596, %7805 : tensor<1024xf32>
    %7807 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7808 = stablehlo.divide %7597, %7807 : tensor<64xf32>
    %7809 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7810 = stablehlo.divide %7598, %7809 : tensor<64xf32>
    %7811 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7812 = stablehlo.multiply %7811, %arg162 : tensor<64xf32>
    %7813 = stablehlo.add %7145, %7812 : tensor<64xf32>
    %7814 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7815 = stablehlo.multiply %7814, %arg163 : tensor<64xf32>
    %7816 = stablehlo.add %7147, %7815 : tensor<64xf32>
    %7817 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7818 = stablehlo.multiply %7817, %arg164 : tensor<64xf32>
    %7819 = stablehlo.add %7149, %7818 : tensor<64xf32>
    %7820 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7821 = stablehlo.multiply %7820, %arg165 : tensor<64xf32>
    %7822 = stablehlo.add %7151, %7821 : tensor<64xf32>
    %7823 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7824 = stablehlo.multiply %7823, %arg166 : tensor<256xf32>
    %7825 = stablehlo.add %7153, %7824 : tensor<256xf32>
    %7826 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7827 = stablehlo.multiply %7826, %arg167 : tensor<256xf32>
    %7828 = stablehlo.add %7155, %7827 : tensor<256xf32>
    %7829 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x64x64xf32>
    %7830 = stablehlo.multiply %7829, %arg168 : tensor<1x1x64x64xf32>
    %7831 = stablehlo.add %7157, %7830 : tensor<1x1x64x64xf32>
    %7832 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<3x3x64x64xf32>
    %7833 = stablehlo.multiply %7832, %arg169 : tensor<3x3x64x64xf32>
    %7834 = stablehlo.add %7159, %7833 : tensor<3x3x64x64xf32>
    %7835 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x64x256xf32>
    %7836 = stablehlo.multiply %7835, %arg170 : tensor<1x1x64x256xf32>
    %7837 = stablehlo.add %7161, %7836 : tensor<1x1x64x256xf32>
    %7838 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x64x256xf32>
    %7839 = stablehlo.multiply %7838, %arg171 : tensor<1x1x64x256xf32>
    %7840 = stablehlo.add %7163, %7839 : tensor<1x1x64x256xf32>
    %7841 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7842 = stablehlo.multiply %7841, %arg172 : tensor<256xf32>
    %7843 = stablehlo.add %7165, %7842 : tensor<256xf32>
    %7844 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7845 = stablehlo.multiply %7844, %arg173 : tensor<256xf32>
    %7846 = stablehlo.add %7167, %7845 : tensor<256xf32>
    %7847 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7848 = stablehlo.multiply %7847, %arg174 : tensor<64xf32>
    %7849 = stablehlo.add %7169, %7848 : tensor<64xf32>
    %7850 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7851 = stablehlo.multiply %7850, %arg175 : tensor<64xf32>
    %7852 = stablehlo.add %7171, %7851 : tensor<64xf32>
    %7853 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7854 = stablehlo.multiply %7853, %arg176 : tensor<64xf32>
    %7855 = stablehlo.add %7173, %7854 : tensor<64xf32>
    %7856 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %7857 = stablehlo.multiply %7856, %arg177 : tensor<64xf32>
    %7858 = stablehlo.add %7175, %7857 : tensor<64xf32>
    %7859 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7860 = stablehlo.multiply %7859, %arg178 : tensor<256xf32>
    %7861 = stablehlo.add %7177, %7860 : tensor<256xf32>
    %7862 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7863 = stablehlo.multiply %7862, %arg179 : tensor<256xf32>
    %7864 = stablehlo.add %7179, %7863 : tensor<256xf32>
    %7865 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x256x64xf32>
    %7866 = stablehlo.multiply %7865, %arg180 : tensor<1x1x256x64xf32>
    %7867 = stablehlo.add %7181, %7866 : tensor<1x1x256x64xf32>
    %7868 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<3x3x64x64xf32>
    %7869 = stablehlo.multiply %7868, %arg181 : tensor<3x3x64x64xf32>
    %7870 = stablehlo.add %7183, %7869 : tensor<3x3x64x64xf32>
    %7871 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x64x256xf32>
    %7872 = stablehlo.multiply %7871, %arg182 : tensor<1x1x64x256xf32>
    %7873 = stablehlo.add %7185, %7872 : tensor<1x1x64x256xf32>
    %7874 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7875 = stablehlo.multiply %7874, %arg183 : tensor<256xf32>
    %7876 = stablehlo.add %7187, %7875 : tensor<256xf32>
    %7877 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7878 = stablehlo.multiply %7877, %arg184 : tensor<256xf32>
    %7879 = stablehlo.add %7189, %7878 : tensor<256xf32>
    %7880 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7881 = stablehlo.multiply %7880, %arg185 : tensor<256xf32>
    %7882 = stablehlo.add %7191, %7881 : tensor<256xf32>
    %7883 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7884 = stablehlo.multiply %7883, %arg186 : tensor<256xf32>
    %7885 = stablehlo.add %7193, %7884 : tensor<256xf32>
    %7886 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7887 = stablehlo.multiply %7886, %arg187 : tensor<1024xf32>
    %7888 = stablehlo.add %7195, %7887 : tensor<1024xf32>
    %7889 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7890 = stablehlo.multiply %7889, %arg188 : tensor<1024xf32>
    %7891 = stablehlo.add %7197, %7890 : tensor<1024xf32>
    %7892 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x1024x256xf32>
    %7893 = stablehlo.multiply %7892, %arg189 : tensor<1x1x1024x256xf32>
    %7894 = stablehlo.add %7199, %7893 : tensor<1x1x1024x256xf32>
    %7895 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %7896 = stablehlo.multiply %7895, %arg190 : tensor<3x3x256x256xf32>
    %7897 = stablehlo.add %7201, %7896 : tensor<3x3x256x256xf32>
    %7898 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %7899 = stablehlo.multiply %7898, %arg191 : tensor<1x1x256x1024xf32>
    %7900 = stablehlo.add %7203, %7899 : tensor<1x1x256x1024xf32>
    %7901 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7902 = stablehlo.multiply %7901, %arg192 : tensor<256xf32>
    %7903 = stablehlo.add %7205, %7902 : tensor<256xf32>
    %7904 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7905 = stablehlo.multiply %7904, %arg193 : tensor<256xf32>
    %7906 = stablehlo.add %7207, %7905 : tensor<256xf32>
    %7907 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7908 = stablehlo.multiply %7907, %arg194 : tensor<256xf32>
    %7909 = stablehlo.add %7209, %7908 : tensor<256xf32>
    %7910 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7911 = stablehlo.multiply %7910, %arg195 : tensor<256xf32>
    %7912 = stablehlo.add %7211, %7911 : tensor<256xf32>
    %7913 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7914 = stablehlo.multiply %7913, %arg196 : tensor<1024xf32>
    %7915 = stablehlo.add %7213, %7914 : tensor<1024xf32>
    %7916 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7917 = stablehlo.multiply %7916, %arg197 : tensor<1024xf32>
    %7918 = stablehlo.add %7215, %7917 : tensor<1024xf32>
    %7919 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x1024x256xf32>
    %7920 = stablehlo.multiply %7919, %arg198 : tensor<1x1x1024x256xf32>
    %7921 = stablehlo.add %7217, %7920 : tensor<1x1x1024x256xf32>
    %7922 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %7923 = stablehlo.multiply %7922, %arg199 : tensor<3x3x256x256xf32>
    %7924 = stablehlo.add %7219, %7923 : tensor<3x3x256x256xf32>
    %7925 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %7926 = stablehlo.multiply %7925, %arg200 : tensor<1x1x256x1024xf32>
    %7927 = stablehlo.add %7221, %7926 : tensor<1x1x256x1024xf32>
    %7928 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7929 = stablehlo.multiply %7928, %arg201 : tensor<256xf32>
    %7930 = stablehlo.add %7223, %7929 : tensor<256xf32>
    %7931 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7932 = stablehlo.multiply %7931, %arg202 : tensor<256xf32>
    %7933 = stablehlo.add %7225, %7932 : tensor<256xf32>
    %7934 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7935 = stablehlo.multiply %7934, %arg203 : tensor<256xf32>
    %7936 = stablehlo.add %7227, %7935 : tensor<256xf32>
    %7937 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %7938 = stablehlo.multiply %7937, %arg204 : tensor<256xf32>
    %7939 = stablehlo.add %7229, %7938 : tensor<256xf32>
    %7940 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7941 = stablehlo.multiply %7940, %arg205 : tensor<1024xf32>
    %7942 = stablehlo.add %7231, %7941 : tensor<1024xf32>
    %7943 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %7944 = stablehlo.multiply %7943, %arg206 : tensor<1024xf32>
    %7945 = stablehlo.add %7233, %7944 : tensor<1024xf32>
    %7946 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x1024x256xf32>
    %7947 = stablehlo.multiply %7946, %arg207 : tensor<1x1x1024x256xf32>
    %7948 = stablehlo.add %7235, %7947 : tensor<1x1x1024x256xf32>
    %7949 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %7950 = stablehlo.multiply %7949, %arg208 : tensor<3x3x256x256xf32>
    %7951 = stablehlo.add %7237, %7950 : tensor<3x3x256x256xf32>
    %7952 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %7953 = stablehlo.multiply %7952, %arg209 : tensor<1x1x256x1024xf32>
    %7954 = stablehlo.add %7239, %7953 : tensor<1x1x256x1024xf32>
    %7955 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7956 = stablehlo.multiply %7955, %arg210 : tensor<512xf32>
    %7957 = stablehlo.add %7241, %7956 : tensor<512xf32>
    %7958 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7959 = stablehlo.multiply %7958, %arg211 : tensor<512xf32>
    %7960 = stablehlo.add %7243, %7959 : tensor<512xf32>
    %7961 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7962 = stablehlo.multiply %7961, %arg212 : tensor<512xf32>
    %7963 = stablehlo.add %7245, %7962 : tensor<512xf32>
    %7964 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7965 = stablehlo.multiply %7964, %arg213 : tensor<512xf32>
    %7966 = stablehlo.add %7247, %7965 : tensor<512xf32>
    %7967 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %7968 = stablehlo.multiply %7967, %arg214 : tensor<2048xf32>
    %7969 = stablehlo.add %7249, %7968 : tensor<2048xf32>
    %7970 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %7971 = stablehlo.multiply %7970, %arg215 : tensor<2048xf32>
    %7972 = stablehlo.add %7251, %7971 : tensor<2048xf32>
    %7973 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x1024x512xf32>
    %7974 = stablehlo.multiply %7973, %arg216 : tensor<1x1x1024x512xf32>
    %7975 = stablehlo.add %7253, %7974 : tensor<1x1x1024x512xf32>
    %7976 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<3x3x512x512xf32>
    %7977 = stablehlo.multiply %7976, %arg217 : tensor<3x3x512x512xf32>
    %7978 = stablehlo.add %7255, %7977 : tensor<3x3x512x512xf32>
    %7979 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x512x2048xf32>
    %7980 = stablehlo.multiply %7979, %arg218 : tensor<1x1x512x2048xf32>
    %7981 = stablehlo.add %7257, %7980 : tensor<1x1x512x2048xf32>
    %7982 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x1024x2048xf32>
    %7983 = stablehlo.multiply %7982, %arg219 : tensor<1x1x1024x2048xf32>
    %7984 = stablehlo.add %7259, %7983 : tensor<1x1x1024x2048xf32>
    %7985 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %7986 = stablehlo.multiply %7985, %arg220 : tensor<2048xf32>
    %7987 = stablehlo.add %7261, %7986 : tensor<2048xf32>
    %7988 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %7989 = stablehlo.multiply %7988, %arg221 : tensor<2048xf32>
    %7990 = stablehlo.add %7263, %7989 : tensor<2048xf32>
    %7991 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7992 = stablehlo.multiply %7991, %arg222 : tensor<512xf32>
    %7993 = stablehlo.add %7265, %7992 : tensor<512xf32>
    %7994 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7995 = stablehlo.multiply %7994, %arg223 : tensor<512xf32>
    %7996 = stablehlo.add %7267, %7995 : tensor<512xf32>
    %7997 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %7998 = stablehlo.multiply %7997, %arg224 : tensor<512xf32>
    %7999 = stablehlo.add %7269, %7998 : tensor<512xf32>
    %8000 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8001 = stablehlo.multiply %8000, %arg225 : tensor<512xf32>
    %8002 = stablehlo.add %7271, %8001 : tensor<512xf32>
    %8003 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %8004 = stablehlo.multiply %8003, %arg226 : tensor<2048xf32>
    %8005 = stablehlo.add %7273, %8004 : tensor<2048xf32>
    %8006 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %8007 = stablehlo.multiply %8006, %arg227 : tensor<2048xf32>
    %8008 = stablehlo.add %7275, %8007 : tensor<2048xf32>
    %8009 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x2048x512xf32>
    %8010 = stablehlo.multiply %8009, %arg228 : tensor<1x1x2048x512xf32>
    %8011 = stablehlo.add %7277, %8010 : tensor<1x1x2048x512xf32>
    %8012 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<3x3x512x512xf32>
    %8013 = stablehlo.multiply %8012, %arg229 : tensor<3x3x512x512xf32>
    %8014 = stablehlo.add %7279, %8013 : tensor<3x3x512x512xf32>
    %8015 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x512x2048xf32>
    %8016 = stablehlo.multiply %8015, %arg230 : tensor<1x1x512x2048xf32>
    %8017 = stablehlo.add %7281, %8016 : tensor<1x1x512x2048xf32>
    %8018 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8019 = stablehlo.multiply %8018, %arg231 : tensor<512xf32>
    %8020 = stablehlo.add %7283, %8019 : tensor<512xf32>
    %8021 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8022 = stablehlo.multiply %8021, %arg232 : tensor<512xf32>
    %8023 = stablehlo.add %7285, %8022 : tensor<512xf32>
    %8024 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8025 = stablehlo.multiply %8024, %arg233 : tensor<512xf32>
    %8026 = stablehlo.add %7287, %8025 : tensor<512xf32>
    %8027 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8028 = stablehlo.multiply %8027, %arg234 : tensor<512xf32>
    %8029 = stablehlo.add %7289, %8028 : tensor<512xf32>
    %8030 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %8031 = stablehlo.multiply %8030, %arg235 : tensor<2048xf32>
    %8032 = stablehlo.add %7291, %8031 : tensor<2048xf32>
    %8033 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %8034 = stablehlo.multiply %8033, %arg236 : tensor<2048xf32>
    %8035 = stablehlo.add %7293, %8034 : tensor<2048xf32>
    %8036 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x2048x512xf32>
    %8037 = stablehlo.multiply %8036, %arg237 : tensor<1x1x2048x512xf32>
    %8038 = stablehlo.add %7295, %8037 : tensor<1x1x2048x512xf32>
    %8039 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<3x3x512x512xf32>
    %8040 = stablehlo.multiply %8039, %arg238 : tensor<3x3x512x512xf32>
    %8041 = stablehlo.add %7297, %8040 : tensor<3x3x512x512xf32>
    %8042 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x512x2048xf32>
    %8043 = stablehlo.multiply %8042, %arg239 : tensor<1x1x512x2048xf32>
    %8044 = stablehlo.add %7299, %8043 : tensor<1x1x512x2048xf32>
    %8045 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %8046 = stablehlo.multiply %8045, %arg240 : tensor<64xf32>
    %8047 = stablehlo.add %7301, %8046 : tensor<64xf32>
    %8048 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %8049 = stablehlo.multiply %8048, %arg241 : tensor<64xf32>
    %8050 = stablehlo.add %7303, %8049 : tensor<64xf32>
    %8051 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %8052 = stablehlo.multiply %8051, %arg242 : tensor<64xf32>
    %8053 = stablehlo.add %7305, %8052 : tensor<64xf32>
    %8054 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %8055 = stablehlo.multiply %8054, %arg243 : tensor<64xf32>
    %8056 = stablehlo.add %7307, %8055 : tensor<64xf32>
    %8057 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8058 = stablehlo.multiply %8057, %arg244 : tensor<256xf32>
    %8059 = stablehlo.add %7309, %8058 : tensor<256xf32>
    %8060 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8061 = stablehlo.multiply %8060, %arg245 : tensor<256xf32>
    %8062 = stablehlo.add %7311, %8061 : tensor<256xf32>
    %8063 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x256x64xf32>
    %8064 = stablehlo.multiply %8063, %arg246 : tensor<1x1x256x64xf32>
    %8065 = stablehlo.add %7313, %8064 : tensor<1x1x256x64xf32>
    %8066 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<3x3x64x64xf32>
    %8067 = stablehlo.multiply %8066, %arg247 : tensor<3x3x64x64xf32>
    %8068 = stablehlo.add %7315, %8067 : tensor<3x3x64x64xf32>
    %8069 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x64x256xf32>
    %8070 = stablehlo.multiply %8069, %arg248 : tensor<1x1x64x256xf32>
    %8071 = stablehlo.add %7317, %8070 : tensor<1x1x64x256xf32>
    %8072 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %8073 = stablehlo.multiply %8072, %arg249 : tensor<128xf32>
    %8074 = stablehlo.add %7319, %8073 : tensor<128xf32>
    %8075 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %8076 = stablehlo.multiply %8075, %arg250 : tensor<128xf32>
    %8077 = stablehlo.add %7321, %8076 : tensor<128xf32>
    %8078 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %8079 = stablehlo.multiply %8078, %arg251 : tensor<128xf32>
    %8080 = stablehlo.add %7323, %8079 : tensor<128xf32>
    %8081 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %8082 = stablehlo.multiply %8081, %arg252 : tensor<128xf32>
    %8083 = stablehlo.add %7325, %8082 : tensor<128xf32>
    %8084 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8085 = stablehlo.multiply %8084, %arg253 : tensor<512xf32>
    %8086 = stablehlo.add %7327, %8085 : tensor<512xf32>
    %8087 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8088 = stablehlo.multiply %8087, %arg254 : tensor<512xf32>
    %8089 = stablehlo.add %7329, %8088 : tensor<512xf32>
    %8090 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x256x128xf32>
    %8091 = stablehlo.multiply %8090, %arg255 : tensor<1x1x256x128xf32>
    %8092 = stablehlo.add %7331, %8091 : tensor<1x1x256x128xf32>
    %8093 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<3x3x128x128xf32>
    %8094 = stablehlo.multiply %8093, %arg256 : tensor<3x3x128x128xf32>
    %8095 = stablehlo.add %7333, %8094 : tensor<3x3x128x128xf32>
    %8096 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x128x512xf32>
    %8097 = stablehlo.multiply %8096, %arg257 : tensor<1x1x128x512xf32>
    %8098 = stablehlo.add %7335, %8097 : tensor<1x1x128x512xf32>
    %8099 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x256x512xf32>
    %8100 = stablehlo.multiply %8099, %arg258 : tensor<1x1x256x512xf32>
    %8101 = stablehlo.add %7337, %8100 : tensor<1x1x256x512xf32>
    %8102 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8103 = stablehlo.multiply %8102, %arg259 : tensor<512xf32>
    %8104 = stablehlo.add %7339, %8103 : tensor<512xf32>
    %8105 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8106 = stablehlo.multiply %8105, %arg260 : tensor<512xf32>
    %8107 = stablehlo.add %7341, %8106 : tensor<512xf32>
    %8108 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %8109 = stablehlo.multiply %8108, %arg261 : tensor<128xf32>
    %8110 = stablehlo.add %7343, %8109 : tensor<128xf32>
    %8111 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %8112 = stablehlo.multiply %8111, %arg262 : tensor<128xf32>
    %8113 = stablehlo.add %7345, %8112 : tensor<128xf32>
    %8114 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %8115 = stablehlo.multiply %8114, %arg263 : tensor<128xf32>
    %8116 = stablehlo.add %7347, %8115 : tensor<128xf32>
    %8117 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %8118 = stablehlo.multiply %8117, %arg264 : tensor<128xf32>
    %8119 = stablehlo.add %7349, %8118 : tensor<128xf32>
    %8120 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8121 = stablehlo.multiply %8120, %arg265 : tensor<512xf32>
    %8122 = stablehlo.add %7351, %8121 : tensor<512xf32>
    %8123 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8124 = stablehlo.multiply %8123, %arg266 : tensor<512xf32>
    %8125 = stablehlo.add %7353, %8124 : tensor<512xf32>
    %8126 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x512x128xf32>
    %8127 = stablehlo.multiply %8126, %arg267 : tensor<1x1x512x128xf32>
    %8128 = stablehlo.add %7355, %8127 : tensor<1x1x512x128xf32>
    %8129 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<3x3x128x128xf32>
    %8130 = stablehlo.multiply %8129, %arg268 : tensor<3x3x128x128xf32>
    %8131 = stablehlo.add %7357, %8130 : tensor<3x3x128x128xf32>
    %8132 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x128x512xf32>
    %8133 = stablehlo.multiply %8132, %arg269 : tensor<1x1x128x512xf32>
    %8134 = stablehlo.add %7359, %8133 : tensor<1x1x128x512xf32>
    %8135 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %8136 = stablehlo.multiply %8135, %arg270 : tensor<128xf32>
    %8137 = stablehlo.add %7361, %8136 : tensor<128xf32>
    %8138 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %8139 = stablehlo.multiply %8138, %arg271 : tensor<128xf32>
    %8140 = stablehlo.add %7363, %8139 : tensor<128xf32>
    %8141 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %8142 = stablehlo.multiply %8141, %arg272 : tensor<128xf32>
    %8143 = stablehlo.add %7365, %8142 : tensor<128xf32>
    %8144 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %8145 = stablehlo.multiply %8144, %arg273 : tensor<128xf32>
    %8146 = stablehlo.add %7367, %8145 : tensor<128xf32>
    %8147 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8148 = stablehlo.multiply %8147, %arg274 : tensor<512xf32>
    %8149 = stablehlo.add %7369, %8148 : tensor<512xf32>
    %8150 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8151 = stablehlo.multiply %8150, %arg275 : tensor<512xf32>
    %8152 = stablehlo.add %7371, %8151 : tensor<512xf32>
    %8153 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x512x128xf32>
    %8154 = stablehlo.multiply %8153, %arg276 : tensor<1x1x512x128xf32>
    %8155 = stablehlo.add %7373, %8154 : tensor<1x1x512x128xf32>
    %8156 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<3x3x128x128xf32>
    %8157 = stablehlo.multiply %8156, %arg277 : tensor<3x3x128x128xf32>
    %8158 = stablehlo.add %7375, %8157 : tensor<3x3x128x128xf32>
    %8159 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x128x512xf32>
    %8160 = stablehlo.multiply %8159, %arg278 : tensor<1x1x128x512xf32>
    %8161 = stablehlo.add %7377, %8160 : tensor<1x1x128x512xf32>
    %8162 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %8163 = stablehlo.multiply %8162, %arg279 : tensor<128xf32>
    %8164 = stablehlo.add %7379, %8163 : tensor<128xf32>
    %8165 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %8166 = stablehlo.multiply %8165, %arg280 : tensor<128xf32>
    %8167 = stablehlo.add %7381, %8166 : tensor<128xf32>
    %8168 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %8169 = stablehlo.multiply %8168, %arg281 : tensor<128xf32>
    %8170 = stablehlo.add %7383, %8169 : tensor<128xf32>
    %8171 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %8172 = stablehlo.multiply %8171, %arg282 : tensor<128xf32>
    %8173 = stablehlo.add %7385, %8172 : tensor<128xf32>
    %8174 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8175 = stablehlo.multiply %8174, %arg283 : tensor<512xf32>
    %8176 = stablehlo.add %7387, %8175 : tensor<512xf32>
    %8177 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8178 = stablehlo.multiply %8177, %arg284 : tensor<512xf32>
    %8179 = stablehlo.add %7389, %8178 : tensor<512xf32>
    %8180 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x512x128xf32>
    %8181 = stablehlo.multiply %8180, %arg285 : tensor<1x1x512x128xf32>
    %8182 = stablehlo.add %7391, %8181 : tensor<1x1x512x128xf32>
    %8183 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<3x3x128x128xf32>
    %8184 = stablehlo.multiply %8183, %arg286 : tensor<3x3x128x128xf32>
    %8185 = stablehlo.add %7393, %8184 : tensor<3x3x128x128xf32>
    %8186 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x128x512xf32>
    %8187 = stablehlo.multiply %8186, %arg287 : tensor<1x1x128x512xf32>
    %8188 = stablehlo.add %7395, %8187 : tensor<1x1x128x512xf32>
    %8189 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8190 = stablehlo.multiply %8189, %arg288 : tensor<256xf32>
    %8191 = stablehlo.add %7397, %8190 : tensor<256xf32>
    %8192 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8193 = stablehlo.multiply %8192, %arg289 : tensor<256xf32>
    %8194 = stablehlo.add %7399, %8193 : tensor<256xf32>
    %8195 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8196 = stablehlo.multiply %8195, %arg290 : tensor<256xf32>
    %8197 = stablehlo.add %7401, %8196 : tensor<256xf32>
    %8198 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8199 = stablehlo.multiply %8198, %arg291 : tensor<256xf32>
    %8200 = stablehlo.add %7403, %8199 : tensor<256xf32>
    %8201 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %8202 = stablehlo.multiply %8201, %arg292 : tensor<1024xf32>
    %8203 = stablehlo.add %7405, %8202 : tensor<1024xf32>
    %8204 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %8205 = stablehlo.multiply %8204, %arg293 : tensor<1024xf32>
    %8206 = stablehlo.add %7407, %8205 : tensor<1024xf32>
    %8207 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x512x256xf32>
    %8208 = stablehlo.multiply %8207, %arg294 : tensor<1x1x512x256xf32>
    %8209 = stablehlo.add %7409, %8208 : tensor<1x1x512x256xf32>
    %8210 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %8211 = stablehlo.multiply %8210, %arg295 : tensor<3x3x256x256xf32>
    %8212 = stablehlo.add %7411, %8211 : tensor<3x3x256x256xf32>
    %8213 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %8214 = stablehlo.multiply %8213, %arg296 : tensor<1x1x256x1024xf32>
    %8215 = stablehlo.add %7413, %8214 : tensor<1x1x256x1024xf32>
    %8216 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x512x1024xf32>
    %8217 = stablehlo.multiply %8216, %arg297 : tensor<1x1x512x1024xf32>
    %8218 = stablehlo.add %7415, %8217 : tensor<1x1x512x1024xf32>
    %8219 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %8220 = stablehlo.multiply %8219, %arg298 : tensor<1024xf32>
    %8221 = stablehlo.add %7417, %8220 : tensor<1024xf32>
    %8222 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %8223 = stablehlo.multiply %8222, %arg299 : tensor<1024xf32>
    %8224 = stablehlo.add %7419, %8223 : tensor<1024xf32>
    %8225 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8226 = stablehlo.multiply %8225, %arg300 : tensor<256xf32>
    %8227 = stablehlo.add %7421, %8226 : tensor<256xf32>
    %8228 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8229 = stablehlo.multiply %8228, %arg301 : tensor<256xf32>
    %8230 = stablehlo.add %7423, %8229 : tensor<256xf32>
    %8231 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8232 = stablehlo.multiply %8231, %arg302 : tensor<256xf32>
    %8233 = stablehlo.add %7425, %8232 : tensor<256xf32>
    %8234 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8235 = stablehlo.multiply %8234, %arg303 : tensor<256xf32>
    %8236 = stablehlo.add %7427, %8235 : tensor<256xf32>
    %8237 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %8238 = stablehlo.multiply %8237, %arg304 : tensor<1024xf32>
    %8239 = stablehlo.add %7429, %8238 : tensor<1024xf32>
    %8240 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %8241 = stablehlo.multiply %8240, %arg305 : tensor<1024xf32>
    %8242 = stablehlo.add %7431, %8241 : tensor<1024xf32>
    %8243 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x1024x256xf32>
    %8244 = stablehlo.multiply %8243, %arg306 : tensor<1x1x1024x256xf32>
    %8245 = stablehlo.add %7433, %8244 : tensor<1x1x1024x256xf32>
    %8246 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %8247 = stablehlo.multiply %8246, %arg307 : tensor<3x3x256x256xf32>
    %8248 = stablehlo.add %7435, %8247 : tensor<3x3x256x256xf32>
    %8249 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %8250 = stablehlo.multiply %8249, %arg308 : tensor<1x1x256x1024xf32>
    %8251 = stablehlo.add %7437, %8250 : tensor<1x1x256x1024xf32>
    %8252 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8253 = stablehlo.multiply %8252, %arg309 : tensor<256xf32>
    %8254 = stablehlo.add %7439, %8253 : tensor<256xf32>
    %8255 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8256 = stablehlo.multiply %8255, %arg310 : tensor<256xf32>
    %8257 = stablehlo.add %7441, %8256 : tensor<256xf32>
    %8258 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8259 = stablehlo.multiply %8258, %arg311 : tensor<256xf32>
    %8260 = stablehlo.add %7443, %8259 : tensor<256xf32>
    %8261 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8262 = stablehlo.multiply %8261, %arg312 : tensor<256xf32>
    %8263 = stablehlo.add %7445, %8262 : tensor<256xf32>
    %8264 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %8265 = stablehlo.multiply %8264, %arg313 : tensor<1024xf32>
    %8266 = stablehlo.add %7447, %8265 : tensor<1024xf32>
    %8267 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %8268 = stablehlo.multiply %8267, %arg314 : tensor<1024xf32>
    %8269 = stablehlo.add %7449, %8268 : tensor<1024xf32>
    %8270 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x1024x256xf32>
    %8271 = stablehlo.multiply %8270, %arg315 : tensor<1x1x1024x256xf32>
    %8272 = stablehlo.add %7451, %8271 : tensor<1x1x1024x256xf32>
    %8273 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %8274 = stablehlo.multiply %8273, %arg316 : tensor<3x3x256x256xf32>
    %8275 = stablehlo.add %7453, %8274 : tensor<3x3x256x256xf32>
    %8276 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %8277 = stablehlo.multiply %8276, %arg317 : tensor<1x1x256x1024xf32>
    %8278 = stablehlo.add %7455, %8277 : tensor<1x1x256x1024xf32>
    %8279 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1000xf32>
    %8280 = stablehlo.multiply %8279, %arg318 : tensor<1000xf32>
    %8281 = stablehlo.add %7457, %8280 : tensor<1000xf32>
    %8282 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<2048x1000xf32>
    %8283 = stablehlo.multiply %8282, %arg319 : tensor<2048x1000xf32>
    %8284 = stablehlo.add %7459, %8283 : tensor<2048x1000xf32>
    %8285 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %8286 = stablehlo.multiply %8285, %arg320 : tensor<64xf32>
    %8287 = stablehlo.add %7461, %8286 : tensor<64xf32>
    %8288 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %8289 = stablehlo.multiply %8288, %arg321 : tensor<64xf32>
    %8290 = stablehlo.add %7463, %8289 : tensor<64xf32>
    %8291 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<7x7x3x64xf32>
    %8292 = stablehlo.multiply %8291, %arg322 : tensor<7x7x3x64xf32>
    %8293 = stablehlo.add %7465, %8292 : tensor<7x7x3x64xf32>
    %8294 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %8295 = stablehlo.multiply %8294, %7813 : tensor<64xf32>
    %8296 = stablehlo.add %7145, %8295 : tensor<64xf32>
    %8297 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %8298 = stablehlo.multiply %8297, %7816 : tensor<64xf32>
    %8299 = stablehlo.add %7147, %8298 : tensor<64xf32>
    %8300 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %8301 = stablehlo.multiply %8300, %7819 : tensor<64xf32>
    %8302 = stablehlo.add %7149, %8301 : tensor<64xf32>
    %8303 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %8304 = stablehlo.multiply %8303, %7822 : tensor<64xf32>
    %8305 = stablehlo.add %7151, %8304 : tensor<64xf32>
    %8306 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8307 = stablehlo.multiply %8306, %7825 : tensor<256xf32>
    %8308 = stablehlo.add %7153, %8307 : tensor<256xf32>
    %8309 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8310 = stablehlo.multiply %8309, %7828 : tensor<256xf32>
    %8311 = stablehlo.add %7155, %8310 : tensor<256xf32>
    %8312 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x64x64xf32>
    %8313 = stablehlo.multiply %8312, %7831 : tensor<1x1x64x64xf32>
    %8314 = stablehlo.add %7157, %8313 : tensor<1x1x64x64xf32>
    %8315 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<3x3x64x64xf32>
    %8316 = stablehlo.multiply %8315, %7834 : tensor<3x3x64x64xf32>
    %8317 = stablehlo.add %7159, %8316 : tensor<3x3x64x64xf32>
    %8318 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x64x256xf32>
    %8319 = stablehlo.multiply %8318, %7837 : tensor<1x1x64x256xf32>
    %8320 = stablehlo.add %7161, %8319 : tensor<1x1x64x256xf32>
    %8321 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x64x256xf32>
    %8322 = stablehlo.multiply %8321, %7840 : tensor<1x1x64x256xf32>
    %8323 = stablehlo.add %7163, %8322 : tensor<1x1x64x256xf32>
    %8324 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8325 = stablehlo.multiply %8324, %7843 : tensor<256xf32>
    %8326 = stablehlo.add %7165, %8325 : tensor<256xf32>
    %8327 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8328 = stablehlo.multiply %8327, %7846 : tensor<256xf32>
    %8329 = stablehlo.add %7167, %8328 : tensor<256xf32>
    %8330 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %8331 = stablehlo.multiply %8330, %7849 : tensor<64xf32>
    %8332 = stablehlo.add %7169, %8331 : tensor<64xf32>
    %8333 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %8334 = stablehlo.multiply %8333, %7852 : tensor<64xf32>
    %8335 = stablehlo.add %7171, %8334 : tensor<64xf32>
    %8336 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %8337 = stablehlo.multiply %8336, %7855 : tensor<64xf32>
    %8338 = stablehlo.add %7173, %8337 : tensor<64xf32>
    %8339 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %8340 = stablehlo.multiply %8339, %7858 : tensor<64xf32>
    %8341 = stablehlo.add %7175, %8340 : tensor<64xf32>
    %8342 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8343 = stablehlo.multiply %8342, %7861 : tensor<256xf32>
    %8344 = stablehlo.add %7177, %8343 : tensor<256xf32>
    %8345 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8346 = stablehlo.multiply %8345, %7864 : tensor<256xf32>
    %8347 = stablehlo.add %7179, %8346 : tensor<256xf32>
    %8348 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x256x64xf32>
    %8349 = stablehlo.multiply %8348, %7867 : tensor<1x1x256x64xf32>
    %8350 = stablehlo.add %7181, %8349 : tensor<1x1x256x64xf32>
    %8351 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<3x3x64x64xf32>
    %8352 = stablehlo.multiply %8351, %7870 : tensor<3x3x64x64xf32>
    %8353 = stablehlo.add %7183, %8352 : tensor<3x3x64x64xf32>
    %8354 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x64x256xf32>
    %8355 = stablehlo.multiply %8354, %7873 : tensor<1x1x64x256xf32>
    %8356 = stablehlo.add %7185, %8355 : tensor<1x1x64x256xf32>
    %8357 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8358 = stablehlo.multiply %8357, %7876 : tensor<256xf32>
    %8359 = stablehlo.add %7187, %8358 : tensor<256xf32>
    %8360 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8361 = stablehlo.multiply %8360, %7879 : tensor<256xf32>
    %8362 = stablehlo.add %7189, %8361 : tensor<256xf32>
    %8363 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8364 = stablehlo.multiply %8363, %7882 : tensor<256xf32>
    %8365 = stablehlo.add %7191, %8364 : tensor<256xf32>
    %8366 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8367 = stablehlo.multiply %8366, %7885 : tensor<256xf32>
    %8368 = stablehlo.add %7193, %8367 : tensor<256xf32>
    %8369 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %8370 = stablehlo.multiply %8369, %7888 : tensor<1024xf32>
    %8371 = stablehlo.add %7195, %8370 : tensor<1024xf32>
    %8372 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %8373 = stablehlo.multiply %8372, %7891 : tensor<1024xf32>
    %8374 = stablehlo.add %7197, %8373 : tensor<1024xf32>
    %8375 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x1024x256xf32>
    %8376 = stablehlo.multiply %8375, %7894 : tensor<1x1x1024x256xf32>
    %8377 = stablehlo.add %7199, %8376 : tensor<1x1x1024x256xf32>
    %8378 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %8379 = stablehlo.multiply %8378, %7897 : tensor<3x3x256x256xf32>
    %8380 = stablehlo.add %7201, %8379 : tensor<3x3x256x256xf32>
    %8381 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %8382 = stablehlo.multiply %8381, %7900 : tensor<1x1x256x1024xf32>
    %8383 = stablehlo.add %7203, %8382 : tensor<1x1x256x1024xf32>
    %8384 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8385 = stablehlo.multiply %8384, %7903 : tensor<256xf32>
    %8386 = stablehlo.add %7205, %8385 : tensor<256xf32>
    %8387 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8388 = stablehlo.multiply %8387, %7906 : tensor<256xf32>
    %8389 = stablehlo.add %7207, %8388 : tensor<256xf32>
    %8390 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8391 = stablehlo.multiply %8390, %7909 : tensor<256xf32>
    %8392 = stablehlo.add %7209, %8391 : tensor<256xf32>
    %8393 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8394 = stablehlo.multiply %8393, %7912 : tensor<256xf32>
    %8395 = stablehlo.add %7211, %8394 : tensor<256xf32>
    %8396 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %8397 = stablehlo.multiply %8396, %7915 : tensor<1024xf32>
    %8398 = stablehlo.add %7213, %8397 : tensor<1024xf32>
    %8399 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %8400 = stablehlo.multiply %8399, %7918 : tensor<1024xf32>
    %8401 = stablehlo.add %7215, %8400 : tensor<1024xf32>
    %8402 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x1024x256xf32>
    %8403 = stablehlo.multiply %8402, %7921 : tensor<1x1x1024x256xf32>
    %8404 = stablehlo.add %7217, %8403 : tensor<1x1x1024x256xf32>
    %8405 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %8406 = stablehlo.multiply %8405, %7924 : tensor<3x3x256x256xf32>
    %8407 = stablehlo.add %7219, %8406 : tensor<3x3x256x256xf32>
    %8408 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %8409 = stablehlo.multiply %8408, %7927 : tensor<1x1x256x1024xf32>
    %8410 = stablehlo.add %7221, %8409 : tensor<1x1x256x1024xf32>
    %8411 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8412 = stablehlo.multiply %8411, %7930 : tensor<256xf32>
    %8413 = stablehlo.add %7223, %8412 : tensor<256xf32>
    %8414 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8415 = stablehlo.multiply %8414, %7933 : tensor<256xf32>
    %8416 = stablehlo.add %7225, %8415 : tensor<256xf32>
    %8417 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8418 = stablehlo.multiply %8417, %7936 : tensor<256xf32>
    %8419 = stablehlo.add %7227, %8418 : tensor<256xf32>
    %8420 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8421 = stablehlo.multiply %8420, %7939 : tensor<256xf32>
    %8422 = stablehlo.add %7229, %8421 : tensor<256xf32>
    %8423 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %8424 = stablehlo.multiply %8423, %7942 : tensor<1024xf32>
    %8425 = stablehlo.add %7231, %8424 : tensor<1024xf32>
    %8426 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %8427 = stablehlo.multiply %8426, %7945 : tensor<1024xf32>
    %8428 = stablehlo.add %7233, %8427 : tensor<1024xf32>
    %8429 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x1024x256xf32>
    %8430 = stablehlo.multiply %8429, %7948 : tensor<1x1x1024x256xf32>
    %8431 = stablehlo.add %7235, %8430 : tensor<1x1x1024x256xf32>
    %8432 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %8433 = stablehlo.multiply %8432, %7951 : tensor<3x3x256x256xf32>
    %8434 = stablehlo.add %7237, %8433 : tensor<3x3x256x256xf32>
    %8435 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %8436 = stablehlo.multiply %8435, %7954 : tensor<1x1x256x1024xf32>
    %8437 = stablehlo.add %7239, %8436 : tensor<1x1x256x1024xf32>
    %8438 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8439 = stablehlo.multiply %8438, %7957 : tensor<512xf32>
    %8440 = stablehlo.add %7241, %8439 : tensor<512xf32>
    %8441 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8442 = stablehlo.multiply %8441, %7960 : tensor<512xf32>
    %8443 = stablehlo.add %7243, %8442 : tensor<512xf32>
    %8444 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8445 = stablehlo.multiply %8444, %7963 : tensor<512xf32>
    %8446 = stablehlo.add %7245, %8445 : tensor<512xf32>
    %8447 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8448 = stablehlo.multiply %8447, %7966 : tensor<512xf32>
    %8449 = stablehlo.add %7247, %8448 : tensor<512xf32>
    %8450 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %8451 = stablehlo.multiply %8450, %7969 : tensor<2048xf32>
    %8452 = stablehlo.add %7249, %8451 : tensor<2048xf32>
    %8453 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %8454 = stablehlo.multiply %8453, %7972 : tensor<2048xf32>
    %8455 = stablehlo.add %7251, %8454 : tensor<2048xf32>
    %8456 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x1024x512xf32>
    %8457 = stablehlo.multiply %8456, %7975 : tensor<1x1x1024x512xf32>
    %8458 = stablehlo.add %7253, %8457 : tensor<1x1x1024x512xf32>
    %8459 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<3x3x512x512xf32>
    %8460 = stablehlo.multiply %8459, %7978 : tensor<3x3x512x512xf32>
    %8461 = stablehlo.add %7255, %8460 : tensor<3x3x512x512xf32>
    %8462 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x512x2048xf32>
    %8463 = stablehlo.multiply %8462, %7981 : tensor<1x1x512x2048xf32>
    %8464 = stablehlo.add %7257, %8463 : tensor<1x1x512x2048xf32>
    %8465 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x1024x2048xf32>
    %8466 = stablehlo.multiply %8465, %7984 : tensor<1x1x1024x2048xf32>
    %8467 = stablehlo.add %7259, %8466 : tensor<1x1x1024x2048xf32>
    %8468 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %8469 = stablehlo.multiply %8468, %7987 : tensor<2048xf32>
    %8470 = stablehlo.add %7261, %8469 : tensor<2048xf32>
    %8471 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %8472 = stablehlo.multiply %8471, %7990 : tensor<2048xf32>
    %8473 = stablehlo.add %7263, %8472 : tensor<2048xf32>
    %8474 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8475 = stablehlo.multiply %8474, %7993 : tensor<512xf32>
    %8476 = stablehlo.add %7265, %8475 : tensor<512xf32>
    %8477 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8478 = stablehlo.multiply %8477, %7996 : tensor<512xf32>
    %8479 = stablehlo.add %7267, %8478 : tensor<512xf32>
    %8480 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8481 = stablehlo.multiply %8480, %7999 : tensor<512xf32>
    %8482 = stablehlo.add %7269, %8481 : tensor<512xf32>
    %8483 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8484 = stablehlo.multiply %8483, %8002 : tensor<512xf32>
    %8485 = stablehlo.add %7271, %8484 : tensor<512xf32>
    %8486 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %8487 = stablehlo.multiply %8486, %8005 : tensor<2048xf32>
    %8488 = stablehlo.add %7273, %8487 : tensor<2048xf32>
    %8489 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %8490 = stablehlo.multiply %8489, %8008 : tensor<2048xf32>
    %8491 = stablehlo.add %7275, %8490 : tensor<2048xf32>
    %8492 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x2048x512xf32>
    %8493 = stablehlo.multiply %8492, %8011 : tensor<1x1x2048x512xf32>
    %8494 = stablehlo.add %7277, %8493 : tensor<1x1x2048x512xf32>
    %8495 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<3x3x512x512xf32>
    %8496 = stablehlo.multiply %8495, %8014 : tensor<3x3x512x512xf32>
    %8497 = stablehlo.add %7279, %8496 : tensor<3x3x512x512xf32>
    %8498 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x512x2048xf32>
    %8499 = stablehlo.multiply %8498, %8017 : tensor<1x1x512x2048xf32>
    %8500 = stablehlo.add %7281, %8499 : tensor<1x1x512x2048xf32>
    %8501 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8502 = stablehlo.multiply %8501, %8020 : tensor<512xf32>
    %8503 = stablehlo.add %7283, %8502 : tensor<512xf32>
    %8504 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8505 = stablehlo.multiply %8504, %8023 : tensor<512xf32>
    %8506 = stablehlo.add %7285, %8505 : tensor<512xf32>
    %8507 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8508 = stablehlo.multiply %8507, %8026 : tensor<512xf32>
    %8509 = stablehlo.add %7287, %8508 : tensor<512xf32>
    %8510 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8511 = stablehlo.multiply %8510, %8029 : tensor<512xf32>
    %8512 = stablehlo.add %7289, %8511 : tensor<512xf32>
    %8513 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %8514 = stablehlo.multiply %8513, %8032 : tensor<2048xf32>
    %8515 = stablehlo.add %7291, %8514 : tensor<2048xf32>
    %8516 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %8517 = stablehlo.multiply %8516, %8035 : tensor<2048xf32>
    %8518 = stablehlo.add %7293, %8517 : tensor<2048xf32>
    %8519 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x2048x512xf32>
    %8520 = stablehlo.multiply %8519, %8038 : tensor<1x1x2048x512xf32>
    %8521 = stablehlo.add %7295, %8520 : tensor<1x1x2048x512xf32>
    %8522 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<3x3x512x512xf32>
    %8523 = stablehlo.multiply %8522, %8041 : tensor<3x3x512x512xf32>
    %8524 = stablehlo.add %7297, %8523 : tensor<3x3x512x512xf32>
    %8525 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x512x2048xf32>
    %8526 = stablehlo.multiply %8525, %8044 : tensor<1x1x512x2048xf32>
    %8527 = stablehlo.add %7299, %8526 : tensor<1x1x512x2048xf32>
    %8528 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %8529 = stablehlo.multiply %8528, %8047 : tensor<64xf32>
    %8530 = stablehlo.add %7301, %8529 : tensor<64xf32>
    %8531 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %8532 = stablehlo.multiply %8531, %8050 : tensor<64xf32>
    %8533 = stablehlo.add %7303, %8532 : tensor<64xf32>
    %8534 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %8535 = stablehlo.multiply %8534, %8053 : tensor<64xf32>
    %8536 = stablehlo.add %7305, %8535 : tensor<64xf32>
    %8537 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %8538 = stablehlo.multiply %8537, %8056 : tensor<64xf32>
    %8539 = stablehlo.add %7307, %8538 : tensor<64xf32>
    %8540 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8541 = stablehlo.multiply %8540, %8059 : tensor<256xf32>
    %8542 = stablehlo.add %7309, %8541 : tensor<256xf32>
    %8543 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8544 = stablehlo.multiply %8543, %8062 : tensor<256xf32>
    %8545 = stablehlo.add %7311, %8544 : tensor<256xf32>
    %8546 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x256x64xf32>
    %8547 = stablehlo.multiply %8546, %8065 : tensor<1x1x256x64xf32>
    %8548 = stablehlo.add %7313, %8547 : tensor<1x1x256x64xf32>
    %8549 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<3x3x64x64xf32>
    %8550 = stablehlo.multiply %8549, %8068 : tensor<3x3x64x64xf32>
    %8551 = stablehlo.add %7315, %8550 : tensor<3x3x64x64xf32>
    %8552 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x64x256xf32>
    %8553 = stablehlo.multiply %8552, %8071 : tensor<1x1x64x256xf32>
    %8554 = stablehlo.add %7317, %8553 : tensor<1x1x64x256xf32>
    %8555 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %8556 = stablehlo.multiply %8555, %8074 : tensor<128xf32>
    %8557 = stablehlo.add %7319, %8556 : tensor<128xf32>
    %8558 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %8559 = stablehlo.multiply %8558, %8077 : tensor<128xf32>
    %8560 = stablehlo.add %7321, %8559 : tensor<128xf32>
    %8561 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %8562 = stablehlo.multiply %8561, %8080 : tensor<128xf32>
    %8563 = stablehlo.add %7323, %8562 : tensor<128xf32>
    %8564 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %8565 = stablehlo.multiply %8564, %8083 : tensor<128xf32>
    %8566 = stablehlo.add %7325, %8565 : tensor<128xf32>
    %8567 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8568 = stablehlo.multiply %8567, %8086 : tensor<512xf32>
    %8569 = stablehlo.add %7327, %8568 : tensor<512xf32>
    %8570 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8571 = stablehlo.multiply %8570, %8089 : tensor<512xf32>
    %8572 = stablehlo.add %7329, %8571 : tensor<512xf32>
    %8573 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x256x128xf32>
    %8574 = stablehlo.multiply %8573, %8092 : tensor<1x1x256x128xf32>
    %8575 = stablehlo.add %7331, %8574 : tensor<1x1x256x128xf32>
    %8576 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<3x3x128x128xf32>
    %8577 = stablehlo.multiply %8576, %8095 : tensor<3x3x128x128xf32>
    %8578 = stablehlo.add %7333, %8577 : tensor<3x3x128x128xf32>
    %8579 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x128x512xf32>
    %8580 = stablehlo.multiply %8579, %8098 : tensor<1x1x128x512xf32>
    %8581 = stablehlo.add %7335, %8580 : tensor<1x1x128x512xf32>
    %8582 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x256x512xf32>
    %8583 = stablehlo.multiply %8582, %8101 : tensor<1x1x256x512xf32>
    %8584 = stablehlo.add %7337, %8583 : tensor<1x1x256x512xf32>
    %8585 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8586 = stablehlo.multiply %8585, %8104 : tensor<512xf32>
    %8587 = stablehlo.add %7339, %8586 : tensor<512xf32>
    %8588 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8589 = stablehlo.multiply %8588, %8107 : tensor<512xf32>
    %8590 = stablehlo.add %7341, %8589 : tensor<512xf32>
    %8591 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %8592 = stablehlo.multiply %8591, %8110 : tensor<128xf32>
    %8593 = stablehlo.add %7343, %8592 : tensor<128xf32>
    %8594 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %8595 = stablehlo.multiply %8594, %8113 : tensor<128xf32>
    %8596 = stablehlo.add %7345, %8595 : tensor<128xf32>
    %8597 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %8598 = stablehlo.multiply %8597, %8116 : tensor<128xf32>
    %8599 = stablehlo.add %7347, %8598 : tensor<128xf32>
    %8600 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %8601 = stablehlo.multiply %8600, %8119 : tensor<128xf32>
    %8602 = stablehlo.add %7349, %8601 : tensor<128xf32>
    %8603 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8604 = stablehlo.multiply %8603, %8122 : tensor<512xf32>
    %8605 = stablehlo.add %7351, %8604 : tensor<512xf32>
    %8606 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8607 = stablehlo.multiply %8606, %8125 : tensor<512xf32>
    %8608 = stablehlo.add %7353, %8607 : tensor<512xf32>
    %8609 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x512x128xf32>
    %8610 = stablehlo.multiply %8609, %8128 : tensor<1x1x512x128xf32>
    %8611 = stablehlo.add %7355, %8610 : tensor<1x1x512x128xf32>
    %8612 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<3x3x128x128xf32>
    %8613 = stablehlo.multiply %8612, %8131 : tensor<3x3x128x128xf32>
    %8614 = stablehlo.add %7357, %8613 : tensor<3x3x128x128xf32>
    %8615 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x128x512xf32>
    %8616 = stablehlo.multiply %8615, %8134 : tensor<1x1x128x512xf32>
    %8617 = stablehlo.add %7359, %8616 : tensor<1x1x128x512xf32>
    %8618 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %8619 = stablehlo.multiply %8618, %8137 : tensor<128xf32>
    %8620 = stablehlo.add %7361, %8619 : tensor<128xf32>
    %8621 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %8622 = stablehlo.multiply %8621, %8140 : tensor<128xf32>
    %8623 = stablehlo.add %7363, %8622 : tensor<128xf32>
    %8624 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %8625 = stablehlo.multiply %8624, %8143 : tensor<128xf32>
    %8626 = stablehlo.add %7365, %8625 : tensor<128xf32>
    %8627 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %8628 = stablehlo.multiply %8627, %8146 : tensor<128xf32>
    %8629 = stablehlo.add %7367, %8628 : tensor<128xf32>
    %8630 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8631 = stablehlo.multiply %8630, %8149 : tensor<512xf32>
    %8632 = stablehlo.add %7369, %8631 : tensor<512xf32>
    %8633 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8634 = stablehlo.multiply %8633, %8152 : tensor<512xf32>
    %8635 = stablehlo.add %7371, %8634 : tensor<512xf32>
    %8636 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x512x128xf32>
    %8637 = stablehlo.multiply %8636, %8155 : tensor<1x1x512x128xf32>
    %8638 = stablehlo.add %7373, %8637 : tensor<1x1x512x128xf32>
    %8639 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<3x3x128x128xf32>
    %8640 = stablehlo.multiply %8639, %8158 : tensor<3x3x128x128xf32>
    %8641 = stablehlo.add %7375, %8640 : tensor<3x3x128x128xf32>
    %8642 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x128x512xf32>
    %8643 = stablehlo.multiply %8642, %8161 : tensor<1x1x128x512xf32>
    %8644 = stablehlo.add %7377, %8643 : tensor<1x1x128x512xf32>
    %8645 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %8646 = stablehlo.multiply %8645, %8164 : tensor<128xf32>
    %8647 = stablehlo.add %7379, %8646 : tensor<128xf32>
    %8648 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %8649 = stablehlo.multiply %8648, %8167 : tensor<128xf32>
    %8650 = stablehlo.add %7381, %8649 : tensor<128xf32>
    %8651 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %8652 = stablehlo.multiply %8651, %8170 : tensor<128xf32>
    %8653 = stablehlo.add %7383, %8652 : tensor<128xf32>
    %8654 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %8655 = stablehlo.multiply %8654, %8173 : tensor<128xf32>
    %8656 = stablehlo.add %7385, %8655 : tensor<128xf32>
    %8657 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8658 = stablehlo.multiply %8657, %8176 : tensor<512xf32>
    %8659 = stablehlo.add %7387, %8658 : tensor<512xf32>
    %8660 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8661 = stablehlo.multiply %8660, %8179 : tensor<512xf32>
    %8662 = stablehlo.add %7389, %8661 : tensor<512xf32>
    %8663 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x512x128xf32>
    %8664 = stablehlo.multiply %8663, %8182 : tensor<1x1x512x128xf32>
    %8665 = stablehlo.add %7391, %8664 : tensor<1x1x512x128xf32>
    %8666 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<3x3x128x128xf32>
    %8667 = stablehlo.multiply %8666, %8185 : tensor<3x3x128x128xf32>
    %8668 = stablehlo.add %7393, %8667 : tensor<3x3x128x128xf32>
    %8669 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x128x512xf32>
    %8670 = stablehlo.multiply %8669, %8188 : tensor<1x1x128x512xf32>
    %8671 = stablehlo.add %7395, %8670 : tensor<1x1x128x512xf32>
    %8672 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8673 = stablehlo.multiply %8672, %8191 : tensor<256xf32>
    %8674 = stablehlo.add %7397, %8673 : tensor<256xf32>
    %8675 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8676 = stablehlo.multiply %8675, %8194 : tensor<256xf32>
    %8677 = stablehlo.add %7399, %8676 : tensor<256xf32>
    %8678 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8679 = stablehlo.multiply %8678, %8197 : tensor<256xf32>
    %8680 = stablehlo.add %7401, %8679 : tensor<256xf32>
    %8681 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8682 = stablehlo.multiply %8681, %8200 : tensor<256xf32>
    %8683 = stablehlo.add %7403, %8682 : tensor<256xf32>
    %8684 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %8685 = stablehlo.multiply %8684, %8203 : tensor<1024xf32>
    %8686 = stablehlo.add %7405, %8685 : tensor<1024xf32>
    %8687 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %8688 = stablehlo.multiply %8687, %8206 : tensor<1024xf32>
    %8689 = stablehlo.add %7407, %8688 : tensor<1024xf32>
    %8690 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x512x256xf32>
    %8691 = stablehlo.multiply %8690, %8209 : tensor<1x1x512x256xf32>
    %8692 = stablehlo.add %7409, %8691 : tensor<1x1x512x256xf32>
    %8693 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %8694 = stablehlo.multiply %8693, %8212 : tensor<3x3x256x256xf32>
    %8695 = stablehlo.add %7411, %8694 : tensor<3x3x256x256xf32>
    %8696 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %8697 = stablehlo.multiply %8696, %8215 : tensor<1x1x256x1024xf32>
    %8698 = stablehlo.add %7413, %8697 : tensor<1x1x256x1024xf32>
    %8699 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x512x1024xf32>
    %8700 = stablehlo.multiply %8699, %8218 : tensor<1x1x512x1024xf32>
    %8701 = stablehlo.add %7415, %8700 : tensor<1x1x512x1024xf32>
    %8702 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %8703 = stablehlo.multiply %8702, %8221 : tensor<1024xf32>
    %8704 = stablehlo.add %7417, %8703 : tensor<1024xf32>
    %8705 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %8706 = stablehlo.multiply %8705, %8224 : tensor<1024xf32>
    %8707 = stablehlo.add %7419, %8706 : tensor<1024xf32>
    %8708 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8709 = stablehlo.multiply %8708, %8227 : tensor<256xf32>
    %8710 = stablehlo.add %7421, %8709 : tensor<256xf32>
    %8711 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8712 = stablehlo.multiply %8711, %8230 : tensor<256xf32>
    %8713 = stablehlo.add %7423, %8712 : tensor<256xf32>
    %8714 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8715 = stablehlo.multiply %8714, %8233 : tensor<256xf32>
    %8716 = stablehlo.add %7425, %8715 : tensor<256xf32>
    %8717 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8718 = stablehlo.multiply %8717, %8236 : tensor<256xf32>
    %8719 = stablehlo.add %7427, %8718 : tensor<256xf32>
    %8720 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %8721 = stablehlo.multiply %8720, %8239 : tensor<1024xf32>
    %8722 = stablehlo.add %7429, %8721 : tensor<1024xf32>
    %8723 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %8724 = stablehlo.multiply %8723, %8242 : tensor<1024xf32>
    %8725 = stablehlo.add %7431, %8724 : tensor<1024xf32>
    %8726 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x1024x256xf32>
    %8727 = stablehlo.multiply %8726, %8245 : tensor<1x1x1024x256xf32>
    %8728 = stablehlo.add %7433, %8727 : tensor<1x1x1024x256xf32>
    %8729 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %8730 = stablehlo.multiply %8729, %8248 : tensor<3x3x256x256xf32>
    %8731 = stablehlo.add %7435, %8730 : tensor<3x3x256x256xf32>
    %8732 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %8733 = stablehlo.multiply %8732, %8251 : tensor<1x1x256x1024xf32>
    %8734 = stablehlo.add %7437, %8733 : tensor<1x1x256x1024xf32>
    %8735 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8736 = stablehlo.multiply %8735, %8254 : tensor<256xf32>
    %8737 = stablehlo.add %7439, %8736 : tensor<256xf32>
    %8738 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8739 = stablehlo.multiply %8738, %8257 : tensor<256xf32>
    %8740 = stablehlo.add %7441, %8739 : tensor<256xf32>
    %8741 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8742 = stablehlo.multiply %8741, %8260 : tensor<256xf32>
    %8743 = stablehlo.add %7443, %8742 : tensor<256xf32>
    %8744 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8745 = stablehlo.multiply %8744, %8263 : tensor<256xf32>
    %8746 = stablehlo.add %7445, %8745 : tensor<256xf32>
    %8747 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %8748 = stablehlo.multiply %8747, %8266 : tensor<1024xf32>
    %8749 = stablehlo.add %7447, %8748 : tensor<1024xf32>
    %8750 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %8751 = stablehlo.multiply %8750, %8269 : tensor<1024xf32>
    %8752 = stablehlo.add %7449, %8751 : tensor<1024xf32>
    %8753 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x1024x256xf32>
    %8754 = stablehlo.multiply %8753, %8272 : tensor<1x1x1024x256xf32>
    %8755 = stablehlo.add %7451, %8754 : tensor<1x1x1024x256xf32>
    %8756 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %8757 = stablehlo.multiply %8756, %8275 : tensor<3x3x256x256xf32>
    %8758 = stablehlo.add %7453, %8757 : tensor<3x3x256x256xf32>
    %8759 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %8760 = stablehlo.multiply %8759, %8278 : tensor<1x1x256x1024xf32>
    %8761 = stablehlo.add %7455, %8760 : tensor<1x1x256x1024xf32>
    %8762 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<1000xf32>
    %8763 = stablehlo.multiply %8762, %8281 : tensor<1000xf32>
    %8764 = stablehlo.add %7457, %8763 : tensor<1000xf32>
    %8765 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<2048x1000xf32>
    %8766 = stablehlo.multiply %8765, %8284 : tensor<2048x1000xf32>
    %8767 = stablehlo.add %7459, %8766 : tensor<2048x1000xf32>
    %8768 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %8769 = stablehlo.multiply %8768, %8287 : tensor<64xf32>
    %8770 = stablehlo.add %7461, %8769 : tensor<64xf32>
    %8771 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %8772 = stablehlo.multiply %8771, %8290 : tensor<64xf32>
    %8773 = stablehlo.add %7463, %8772 : tensor<64xf32>
    %8774 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<7x7x3x64xf32>
    %8775 = stablehlo.multiply %8774, %8293 : tensor<7x7x3x64xf32>
    %8776 = stablehlo.add %7465, %8775 : tensor<7x7x3x64xf32>
    %c_565 = stablehlo.constant dense<0> : tensor<i32>
    %8777 = stablehlo.subtract %arg323, %c_565 : tensor<i32>
    %8778 = call @clip_13(%8777, %c, %cst) : (tensor<i32>, tensor<i32>, tensor<f32>) -> tensor<f32>
    %8779 = stablehlo.divide %8778, %cst : tensor<f32>
    %8780 = stablehlo.subtract %cst_0, %8779 : tensor<f32>
    %8781 = stablehlo.multiply %cst_1, %8780 : tensor<f32>
    %8782 = stablehlo.add %8781, %cst_2 : tensor<f32>
    %8783 = stablehlo.convert %arg323 : (tensor<i32>) -> tensor<f32>
    %8784 = stablehlo.compare  LT, %8783, %cst,  FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
    %8785 = stablehlo.convert %arg323 : (tensor<i32>) -> tensor<f32>
    %8786 = stablehlo.subtract %8785, %cst : tensor<f32>
    %8787 = stablehlo.minimum %8786, %cst_3 : tensor<f32>
    %8788 = stablehlo.multiply %cst_4, %8787 : tensor<f32>
    %8789 = stablehlo.divide %8788, %cst_3 : tensor<f32>
    %8790 = stablehlo.cosine %8789 : tensor<f32>
    %8791 = stablehlo.add %cst_0, %8790 : tensor<f32>
    %8792 = stablehlo.multiply %cst_5, %8791 : tensor<f32>
    %8793 = stablehlo.power %8792, %cst_0 : tensor<f32>
    %8794 = stablehlo.multiply %cst_0, %8793 : tensor<f32>
    %8795 = stablehlo.add %8794, %cst_6 : tensor<f32>
    %8796 = stablehlo.multiply %cst_2, %8795 : tensor<f32>
    %8797 = call @_where(%8784, %8782, %8796) : (tensor<i1>, tensor<f32>, tensor<f32>) -> tensor<f32>
    %cst_566 = stablehlo.constant dense<-1.000000e+00> : tensor<f32>
    %8798 = stablehlo.multiply %cst_566, %8797 : tensor<f32>
    %8799 = stablehlo.convert %8798 : tensor<f32>
    %8800 = stablehlo.broadcast_in_dim %8799, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %8801 = stablehlo.multiply %8800, %8296 : tensor<64xf32>
    %8802 = stablehlo.convert %8798 : tensor<f32>
    %8803 = stablehlo.broadcast_in_dim %8802, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %8804 = stablehlo.multiply %8803, %8299 : tensor<64xf32>
    %8805 = stablehlo.convert %8798 : tensor<f32>
    %8806 = stablehlo.broadcast_in_dim %8805, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %8807 = stablehlo.multiply %8806, %8302 : tensor<64xf32>
    %8808 = stablehlo.convert %8798 : tensor<f32>
    %8809 = stablehlo.broadcast_in_dim %8808, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %8810 = stablehlo.multiply %8809, %8305 : tensor<64xf32>
    %8811 = stablehlo.convert %8798 : tensor<f32>
    %8812 = stablehlo.broadcast_in_dim %8811, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8813 = stablehlo.multiply %8812, %8308 : tensor<256xf32>
    %8814 = stablehlo.convert %8798 : tensor<f32>
    %8815 = stablehlo.broadcast_in_dim %8814, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8816 = stablehlo.multiply %8815, %8311 : tensor<256xf32>
    %8817 = stablehlo.convert %8798 : tensor<f32>
    %8818 = stablehlo.broadcast_in_dim %8817, dims = [] : (tensor<f32>) -> tensor<1x1x64x64xf32>
    %8819 = stablehlo.multiply %8818, %8314 : tensor<1x1x64x64xf32>
    %8820 = stablehlo.convert %8798 : tensor<f32>
    %8821 = stablehlo.broadcast_in_dim %8820, dims = [] : (tensor<f32>) -> tensor<3x3x64x64xf32>
    %8822 = stablehlo.multiply %8821, %8317 : tensor<3x3x64x64xf32>
    %8823 = stablehlo.convert %8798 : tensor<f32>
    %8824 = stablehlo.broadcast_in_dim %8823, dims = [] : (tensor<f32>) -> tensor<1x1x64x256xf32>
    %8825 = stablehlo.multiply %8824, %8320 : tensor<1x1x64x256xf32>
    %8826 = stablehlo.convert %8798 : tensor<f32>
    %8827 = stablehlo.broadcast_in_dim %8826, dims = [] : (tensor<f32>) -> tensor<1x1x64x256xf32>
    %8828 = stablehlo.multiply %8827, %8323 : tensor<1x1x64x256xf32>
    %8829 = stablehlo.convert %8798 : tensor<f32>
    %8830 = stablehlo.broadcast_in_dim %8829, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8831 = stablehlo.multiply %8830, %8326 : tensor<256xf32>
    %8832 = stablehlo.convert %8798 : tensor<f32>
    %8833 = stablehlo.broadcast_in_dim %8832, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8834 = stablehlo.multiply %8833, %8329 : tensor<256xf32>
    %8835 = stablehlo.convert %8798 : tensor<f32>
    %8836 = stablehlo.broadcast_in_dim %8835, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %8837 = stablehlo.multiply %8836, %8332 : tensor<64xf32>
    %8838 = stablehlo.convert %8798 : tensor<f32>
    %8839 = stablehlo.broadcast_in_dim %8838, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %8840 = stablehlo.multiply %8839, %8335 : tensor<64xf32>
    %8841 = stablehlo.convert %8798 : tensor<f32>
    %8842 = stablehlo.broadcast_in_dim %8841, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %8843 = stablehlo.multiply %8842, %8338 : tensor<64xf32>
    %8844 = stablehlo.convert %8798 : tensor<f32>
    %8845 = stablehlo.broadcast_in_dim %8844, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %8846 = stablehlo.multiply %8845, %8341 : tensor<64xf32>
    %8847 = stablehlo.convert %8798 : tensor<f32>
    %8848 = stablehlo.broadcast_in_dim %8847, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8849 = stablehlo.multiply %8848, %8344 : tensor<256xf32>
    %8850 = stablehlo.convert %8798 : tensor<f32>
    %8851 = stablehlo.broadcast_in_dim %8850, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8852 = stablehlo.multiply %8851, %8347 : tensor<256xf32>
    %8853 = stablehlo.convert %8798 : tensor<f32>
    %8854 = stablehlo.broadcast_in_dim %8853, dims = [] : (tensor<f32>) -> tensor<1x1x256x64xf32>
    %8855 = stablehlo.multiply %8854, %8350 : tensor<1x1x256x64xf32>
    %8856 = stablehlo.convert %8798 : tensor<f32>
    %8857 = stablehlo.broadcast_in_dim %8856, dims = [] : (tensor<f32>) -> tensor<3x3x64x64xf32>
    %8858 = stablehlo.multiply %8857, %8353 : tensor<3x3x64x64xf32>
    %8859 = stablehlo.convert %8798 : tensor<f32>
    %8860 = stablehlo.broadcast_in_dim %8859, dims = [] : (tensor<f32>) -> tensor<1x1x64x256xf32>
    %8861 = stablehlo.multiply %8860, %8356 : tensor<1x1x64x256xf32>
    %8862 = stablehlo.convert %8798 : tensor<f32>
    %8863 = stablehlo.broadcast_in_dim %8862, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8864 = stablehlo.multiply %8863, %8359 : tensor<256xf32>
    %8865 = stablehlo.convert %8798 : tensor<f32>
    %8866 = stablehlo.broadcast_in_dim %8865, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8867 = stablehlo.multiply %8866, %8362 : tensor<256xf32>
    %8868 = stablehlo.convert %8798 : tensor<f32>
    %8869 = stablehlo.broadcast_in_dim %8868, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8870 = stablehlo.multiply %8869, %8365 : tensor<256xf32>
    %8871 = stablehlo.convert %8798 : tensor<f32>
    %8872 = stablehlo.broadcast_in_dim %8871, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8873 = stablehlo.multiply %8872, %8368 : tensor<256xf32>
    %8874 = stablehlo.convert %8798 : tensor<f32>
    %8875 = stablehlo.broadcast_in_dim %8874, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %8876 = stablehlo.multiply %8875, %8371 : tensor<1024xf32>
    %8877 = stablehlo.convert %8798 : tensor<f32>
    %8878 = stablehlo.broadcast_in_dim %8877, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %8879 = stablehlo.multiply %8878, %8374 : tensor<1024xf32>
    %8880 = stablehlo.convert %8798 : tensor<f32>
    %8881 = stablehlo.broadcast_in_dim %8880, dims = [] : (tensor<f32>) -> tensor<1x1x1024x256xf32>
    %8882 = stablehlo.multiply %8881, %8377 : tensor<1x1x1024x256xf32>
    %8883 = stablehlo.convert %8798 : tensor<f32>
    %8884 = stablehlo.broadcast_in_dim %8883, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %8885 = stablehlo.multiply %8884, %8380 : tensor<3x3x256x256xf32>
    %8886 = stablehlo.convert %8798 : tensor<f32>
    %8887 = stablehlo.broadcast_in_dim %8886, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %8888 = stablehlo.multiply %8887, %8383 : tensor<1x1x256x1024xf32>
    %8889 = stablehlo.convert %8798 : tensor<f32>
    %8890 = stablehlo.broadcast_in_dim %8889, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8891 = stablehlo.multiply %8890, %8386 : tensor<256xf32>
    %8892 = stablehlo.convert %8798 : tensor<f32>
    %8893 = stablehlo.broadcast_in_dim %8892, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8894 = stablehlo.multiply %8893, %8389 : tensor<256xf32>
    %8895 = stablehlo.convert %8798 : tensor<f32>
    %8896 = stablehlo.broadcast_in_dim %8895, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8897 = stablehlo.multiply %8896, %8392 : tensor<256xf32>
    %8898 = stablehlo.convert %8798 : tensor<f32>
    %8899 = stablehlo.broadcast_in_dim %8898, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8900 = stablehlo.multiply %8899, %8395 : tensor<256xf32>
    %8901 = stablehlo.convert %8798 : tensor<f32>
    %8902 = stablehlo.broadcast_in_dim %8901, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %8903 = stablehlo.multiply %8902, %8398 : tensor<1024xf32>
    %8904 = stablehlo.convert %8798 : tensor<f32>
    %8905 = stablehlo.broadcast_in_dim %8904, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %8906 = stablehlo.multiply %8905, %8401 : tensor<1024xf32>
    %8907 = stablehlo.convert %8798 : tensor<f32>
    %8908 = stablehlo.broadcast_in_dim %8907, dims = [] : (tensor<f32>) -> tensor<1x1x1024x256xf32>
    %8909 = stablehlo.multiply %8908, %8404 : tensor<1x1x1024x256xf32>
    %8910 = stablehlo.convert %8798 : tensor<f32>
    %8911 = stablehlo.broadcast_in_dim %8910, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %8912 = stablehlo.multiply %8911, %8407 : tensor<3x3x256x256xf32>
    %8913 = stablehlo.convert %8798 : tensor<f32>
    %8914 = stablehlo.broadcast_in_dim %8913, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %8915 = stablehlo.multiply %8914, %8410 : tensor<1x1x256x1024xf32>
    %8916 = stablehlo.convert %8798 : tensor<f32>
    %8917 = stablehlo.broadcast_in_dim %8916, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8918 = stablehlo.multiply %8917, %8413 : tensor<256xf32>
    %8919 = stablehlo.convert %8798 : tensor<f32>
    %8920 = stablehlo.broadcast_in_dim %8919, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8921 = stablehlo.multiply %8920, %8416 : tensor<256xf32>
    %8922 = stablehlo.convert %8798 : tensor<f32>
    %8923 = stablehlo.broadcast_in_dim %8922, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8924 = stablehlo.multiply %8923, %8419 : tensor<256xf32>
    %8925 = stablehlo.convert %8798 : tensor<f32>
    %8926 = stablehlo.broadcast_in_dim %8925, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %8927 = stablehlo.multiply %8926, %8422 : tensor<256xf32>
    %8928 = stablehlo.convert %8798 : tensor<f32>
    %8929 = stablehlo.broadcast_in_dim %8928, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %8930 = stablehlo.multiply %8929, %8425 : tensor<1024xf32>
    %8931 = stablehlo.convert %8798 : tensor<f32>
    %8932 = stablehlo.broadcast_in_dim %8931, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %8933 = stablehlo.multiply %8932, %8428 : tensor<1024xf32>
    %8934 = stablehlo.convert %8798 : tensor<f32>
    %8935 = stablehlo.broadcast_in_dim %8934, dims = [] : (tensor<f32>) -> tensor<1x1x1024x256xf32>
    %8936 = stablehlo.multiply %8935, %8431 : tensor<1x1x1024x256xf32>
    %8937 = stablehlo.convert %8798 : tensor<f32>
    %8938 = stablehlo.broadcast_in_dim %8937, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %8939 = stablehlo.multiply %8938, %8434 : tensor<3x3x256x256xf32>
    %8940 = stablehlo.convert %8798 : tensor<f32>
    %8941 = stablehlo.broadcast_in_dim %8940, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %8942 = stablehlo.multiply %8941, %8437 : tensor<1x1x256x1024xf32>
    %8943 = stablehlo.convert %8798 : tensor<f32>
    %8944 = stablehlo.broadcast_in_dim %8943, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8945 = stablehlo.multiply %8944, %8440 : tensor<512xf32>
    %8946 = stablehlo.convert %8798 : tensor<f32>
    %8947 = stablehlo.broadcast_in_dim %8946, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8948 = stablehlo.multiply %8947, %8443 : tensor<512xf32>
    %8949 = stablehlo.convert %8798 : tensor<f32>
    %8950 = stablehlo.broadcast_in_dim %8949, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8951 = stablehlo.multiply %8950, %8446 : tensor<512xf32>
    %8952 = stablehlo.convert %8798 : tensor<f32>
    %8953 = stablehlo.broadcast_in_dim %8952, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8954 = stablehlo.multiply %8953, %8449 : tensor<512xf32>
    %8955 = stablehlo.convert %8798 : tensor<f32>
    %8956 = stablehlo.broadcast_in_dim %8955, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %8957 = stablehlo.multiply %8956, %8452 : tensor<2048xf32>
    %8958 = stablehlo.convert %8798 : tensor<f32>
    %8959 = stablehlo.broadcast_in_dim %8958, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %8960 = stablehlo.multiply %8959, %8455 : tensor<2048xf32>
    %8961 = stablehlo.convert %8798 : tensor<f32>
    %8962 = stablehlo.broadcast_in_dim %8961, dims = [] : (tensor<f32>) -> tensor<1x1x1024x512xf32>
    %8963 = stablehlo.multiply %8962, %8458 : tensor<1x1x1024x512xf32>
    %8964 = stablehlo.convert %8798 : tensor<f32>
    %8965 = stablehlo.broadcast_in_dim %8964, dims = [] : (tensor<f32>) -> tensor<3x3x512x512xf32>
    %8966 = stablehlo.multiply %8965, %8461 : tensor<3x3x512x512xf32>
    %8967 = stablehlo.convert %8798 : tensor<f32>
    %8968 = stablehlo.broadcast_in_dim %8967, dims = [] : (tensor<f32>) -> tensor<1x1x512x2048xf32>
    %8969 = stablehlo.multiply %8968, %8464 : tensor<1x1x512x2048xf32>
    %8970 = stablehlo.convert %8798 : tensor<f32>
    %8971 = stablehlo.broadcast_in_dim %8970, dims = [] : (tensor<f32>) -> tensor<1x1x1024x2048xf32>
    %8972 = stablehlo.multiply %8971, %8467 : tensor<1x1x1024x2048xf32>
    %8973 = stablehlo.convert %8798 : tensor<f32>
    %8974 = stablehlo.broadcast_in_dim %8973, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %8975 = stablehlo.multiply %8974, %8470 : tensor<2048xf32>
    %8976 = stablehlo.convert %8798 : tensor<f32>
    %8977 = stablehlo.broadcast_in_dim %8976, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %8978 = stablehlo.multiply %8977, %8473 : tensor<2048xf32>
    %8979 = stablehlo.convert %8798 : tensor<f32>
    %8980 = stablehlo.broadcast_in_dim %8979, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8981 = stablehlo.multiply %8980, %8476 : tensor<512xf32>
    %8982 = stablehlo.convert %8798 : tensor<f32>
    %8983 = stablehlo.broadcast_in_dim %8982, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8984 = stablehlo.multiply %8983, %8479 : tensor<512xf32>
    %8985 = stablehlo.convert %8798 : tensor<f32>
    %8986 = stablehlo.broadcast_in_dim %8985, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8987 = stablehlo.multiply %8986, %8482 : tensor<512xf32>
    %8988 = stablehlo.convert %8798 : tensor<f32>
    %8989 = stablehlo.broadcast_in_dim %8988, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %8990 = stablehlo.multiply %8989, %8485 : tensor<512xf32>
    %8991 = stablehlo.convert %8798 : tensor<f32>
    %8992 = stablehlo.broadcast_in_dim %8991, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %8993 = stablehlo.multiply %8992, %8488 : tensor<2048xf32>
    %8994 = stablehlo.convert %8798 : tensor<f32>
    %8995 = stablehlo.broadcast_in_dim %8994, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %8996 = stablehlo.multiply %8995, %8491 : tensor<2048xf32>
    %8997 = stablehlo.convert %8798 : tensor<f32>
    %8998 = stablehlo.broadcast_in_dim %8997, dims = [] : (tensor<f32>) -> tensor<1x1x2048x512xf32>
    %8999 = stablehlo.multiply %8998, %8494 : tensor<1x1x2048x512xf32>
    %9000 = stablehlo.convert %8798 : tensor<f32>
    %9001 = stablehlo.broadcast_in_dim %9000, dims = [] : (tensor<f32>) -> tensor<3x3x512x512xf32>
    %9002 = stablehlo.multiply %9001, %8497 : tensor<3x3x512x512xf32>
    %9003 = stablehlo.convert %8798 : tensor<f32>
    %9004 = stablehlo.broadcast_in_dim %9003, dims = [] : (tensor<f32>) -> tensor<1x1x512x2048xf32>
    %9005 = stablehlo.multiply %9004, %8500 : tensor<1x1x512x2048xf32>
    %9006 = stablehlo.convert %8798 : tensor<f32>
    %9007 = stablehlo.broadcast_in_dim %9006, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %9008 = stablehlo.multiply %9007, %8503 : tensor<512xf32>
    %9009 = stablehlo.convert %8798 : tensor<f32>
    %9010 = stablehlo.broadcast_in_dim %9009, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %9011 = stablehlo.multiply %9010, %8506 : tensor<512xf32>
    %9012 = stablehlo.convert %8798 : tensor<f32>
    %9013 = stablehlo.broadcast_in_dim %9012, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %9014 = stablehlo.multiply %9013, %8509 : tensor<512xf32>
    %9015 = stablehlo.convert %8798 : tensor<f32>
    %9016 = stablehlo.broadcast_in_dim %9015, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %9017 = stablehlo.multiply %9016, %8512 : tensor<512xf32>
    %9018 = stablehlo.convert %8798 : tensor<f32>
    %9019 = stablehlo.broadcast_in_dim %9018, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %9020 = stablehlo.multiply %9019, %8515 : tensor<2048xf32>
    %9021 = stablehlo.convert %8798 : tensor<f32>
    %9022 = stablehlo.broadcast_in_dim %9021, dims = [] : (tensor<f32>) -> tensor<2048xf32>
    %9023 = stablehlo.multiply %9022, %8518 : tensor<2048xf32>
    %9024 = stablehlo.convert %8798 : tensor<f32>
    %9025 = stablehlo.broadcast_in_dim %9024, dims = [] : (tensor<f32>) -> tensor<1x1x2048x512xf32>
    %9026 = stablehlo.multiply %9025, %8521 : tensor<1x1x2048x512xf32>
    %9027 = stablehlo.convert %8798 : tensor<f32>
    %9028 = stablehlo.broadcast_in_dim %9027, dims = [] : (tensor<f32>) -> tensor<3x3x512x512xf32>
    %9029 = stablehlo.multiply %9028, %8524 : tensor<3x3x512x512xf32>
    %9030 = stablehlo.convert %8798 : tensor<f32>
    %9031 = stablehlo.broadcast_in_dim %9030, dims = [] : (tensor<f32>) -> tensor<1x1x512x2048xf32>
    %9032 = stablehlo.multiply %9031, %8527 : tensor<1x1x512x2048xf32>
    %9033 = stablehlo.convert %8798 : tensor<f32>
    %9034 = stablehlo.broadcast_in_dim %9033, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %9035 = stablehlo.multiply %9034, %8530 : tensor<64xf32>
    %9036 = stablehlo.convert %8798 : tensor<f32>
    %9037 = stablehlo.broadcast_in_dim %9036, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %9038 = stablehlo.multiply %9037, %8533 : tensor<64xf32>
    %9039 = stablehlo.convert %8798 : tensor<f32>
    %9040 = stablehlo.broadcast_in_dim %9039, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %9041 = stablehlo.multiply %9040, %8536 : tensor<64xf32>
    %9042 = stablehlo.convert %8798 : tensor<f32>
    %9043 = stablehlo.broadcast_in_dim %9042, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %9044 = stablehlo.multiply %9043, %8539 : tensor<64xf32>
    %9045 = stablehlo.convert %8798 : tensor<f32>
    %9046 = stablehlo.broadcast_in_dim %9045, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %9047 = stablehlo.multiply %9046, %8542 : tensor<256xf32>
    %9048 = stablehlo.convert %8798 : tensor<f32>
    %9049 = stablehlo.broadcast_in_dim %9048, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %9050 = stablehlo.multiply %9049, %8545 : tensor<256xf32>
    %9051 = stablehlo.convert %8798 : tensor<f32>
    %9052 = stablehlo.broadcast_in_dim %9051, dims = [] : (tensor<f32>) -> tensor<1x1x256x64xf32>
    %9053 = stablehlo.multiply %9052, %8548 : tensor<1x1x256x64xf32>
    %9054 = stablehlo.convert %8798 : tensor<f32>
    %9055 = stablehlo.broadcast_in_dim %9054, dims = [] : (tensor<f32>) -> tensor<3x3x64x64xf32>
    %9056 = stablehlo.multiply %9055, %8551 : tensor<3x3x64x64xf32>
    %9057 = stablehlo.convert %8798 : tensor<f32>
    %9058 = stablehlo.broadcast_in_dim %9057, dims = [] : (tensor<f32>) -> tensor<1x1x64x256xf32>
    %9059 = stablehlo.multiply %9058, %8554 : tensor<1x1x64x256xf32>
    %9060 = stablehlo.convert %8798 : tensor<f32>
    %9061 = stablehlo.broadcast_in_dim %9060, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %9062 = stablehlo.multiply %9061, %8557 : tensor<128xf32>
    %9063 = stablehlo.convert %8798 : tensor<f32>
    %9064 = stablehlo.broadcast_in_dim %9063, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %9065 = stablehlo.multiply %9064, %8560 : tensor<128xf32>
    %9066 = stablehlo.convert %8798 : tensor<f32>
    %9067 = stablehlo.broadcast_in_dim %9066, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %9068 = stablehlo.multiply %9067, %8563 : tensor<128xf32>
    %9069 = stablehlo.convert %8798 : tensor<f32>
    %9070 = stablehlo.broadcast_in_dim %9069, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %9071 = stablehlo.multiply %9070, %8566 : tensor<128xf32>
    %9072 = stablehlo.convert %8798 : tensor<f32>
    %9073 = stablehlo.broadcast_in_dim %9072, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %9074 = stablehlo.multiply %9073, %8569 : tensor<512xf32>
    %9075 = stablehlo.convert %8798 : tensor<f32>
    %9076 = stablehlo.broadcast_in_dim %9075, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %9077 = stablehlo.multiply %9076, %8572 : tensor<512xf32>
    %9078 = stablehlo.convert %8798 : tensor<f32>
    %9079 = stablehlo.broadcast_in_dim %9078, dims = [] : (tensor<f32>) -> tensor<1x1x256x128xf32>
    %9080 = stablehlo.multiply %9079, %8575 : tensor<1x1x256x128xf32>
    %9081 = stablehlo.convert %8798 : tensor<f32>
    %9082 = stablehlo.broadcast_in_dim %9081, dims = [] : (tensor<f32>) -> tensor<3x3x128x128xf32>
    %9083 = stablehlo.multiply %9082, %8578 : tensor<3x3x128x128xf32>
    %9084 = stablehlo.convert %8798 : tensor<f32>
    %9085 = stablehlo.broadcast_in_dim %9084, dims = [] : (tensor<f32>) -> tensor<1x1x128x512xf32>
    %9086 = stablehlo.multiply %9085, %8581 : tensor<1x1x128x512xf32>
    %9087 = stablehlo.convert %8798 : tensor<f32>
    %9088 = stablehlo.broadcast_in_dim %9087, dims = [] : (tensor<f32>) -> tensor<1x1x256x512xf32>
    %9089 = stablehlo.multiply %9088, %8584 : tensor<1x1x256x512xf32>
    %9090 = stablehlo.convert %8798 : tensor<f32>
    %9091 = stablehlo.broadcast_in_dim %9090, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %9092 = stablehlo.multiply %9091, %8587 : tensor<512xf32>
    %9093 = stablehlo.convert %8798 : tensor<f32>
    %9094 = stablehlo.broadcast_in_dim %9093, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %9095 = stablehlo.multiply %9094, %8590 : tensor<512xf32>
    %9096 = stablehlo.convert %8798 : tensor<f32>
    %9097 = stablehlo.broadcast_in_dim %9096, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %9098 = stablehlo.multiply %9097, %8593 : tensor<128xf32>
    %9099 = stablehlo.convert %8798 : tensor<f32>
    %9100 = stablehlo.broadcast_in_dim %9099, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %9101 = stablehlo.multiply %9100, %8596 : tensor<128xf32>
    %9102 = stablehlo.convert %8798 : tensor<f32>
    %9103 = stablehlo.broadcast_in_dim %9102, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %9104 = stablehlo.multiply %9103, %8599 : tensor<128xf32>
    %9105 = stablehlo.convert %8798 : tensor<f32>
    %9106 = stablehlo.broadcast_in_dim %9105, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %9107 = stablehlo.multiply %9106, %8602 : tensor<128xf32>
    %9108 = stablehlo.convert %8798 : tensor<f32>
    %9109 = stablehlo.broadcast_in_dim %9108, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %9110 = stablehlo.multiply %9109, %8605 : tensor<512xf32>
    %9111 = stablehlo.convert %8798 : tensor<f32>
    %9112 = stablehlo.broadcast_in_dim %9111, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %9113 = stablehlo.multiply %9112, %8608 : tensor<512xf32>
    %9114 = stablehlo.convert %8798 : tensor<f32>
    %9115 = stablehlo.broadcast_in_dim %9114, dims = [] : (tensor<f32>) -> tensor<1x1x512x128xf32>
    %9116 = stablehlo.multiply %9115, %8611 : tensor<1x1x512x128xf32>
    %9117 = stablehlo.convert %8798 : tensor<f32>
    %9118 = stablehlo.broadcast_in_dim %9117, dims = [] : (tensor<f32>) -> tensor<3x3x128x128xf32>
    %9119 = stablehlo.multiply %9118, %8614 : tensor<3x3x128x128xf32>
    %9120 = stablehlo.convert %8798 : tensor<f32>
    %9121 = stablehlo.broadcast_in_dim %9120, dims = [] : (tensor<f32>) -> tensor<1x1x128x512xf32>
    %9122 = stablehlo.multiply %9121, %8617 : tensor<1x1x128x512xf32>
    %9123 = stablehlo.convert %8798 : tensor<f32>
    %9124 = stablehlo.broadcast_in_dim %9123, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %9125 = stablehlo.multiply %9124, %8620 : tensor<128xf32>
    %9126 = stablehlo.convert %8798 : tensor<f32>
    %9127 = stablehlo.broadcast_in_dim %9126, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %9128 = stablehlo.multiply %9127, %8623 : tensor<128xf32>
    %9129 = stablehlo.convert %8798 : tensor<f32>
    %9130 = stablehlo.broadcast_in_dim %9129, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %9131 = stablehlo.multiply %9130, %8626 : tensor<128xf32>
    %9132 = stablehlo.convert %8798 : tensor<f32>
    %9133 = stablehlo.broadcast_in_dim %9132, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %9134 = stablehlo.multiply %9133, %8629 : tensor<128xf32>
    %9135 = stablehlo.convert %8798 : tensor<f32>
    %9136 = stablehlo.broadcast_in_dim %9135, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %9137 = stablehlo.multiply %9136, %8632 : tensor<512xf32>
    %9138 = stablehlo.convert %8798 : tensor<f32>
    %9139 = stablehlo.broadcast_in_dim %9138, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %9140 = stablehlo.multiply %9139, %8635 : tensor<512xf32>
    %9141 = stablehlo.convert %8798 : tensor<f32>
    %9142 = stablehlo.broadcast_in_dim %9141, dims = [] : (tensor<f32>) -> tensor<1x1x512x128xf32>
    %9143 = stablehlo.multiply %9142, %8638 : tensor<1x1x512x128xf32>
    %9144 = stablehlo.convert %8798 : tensor<f32>
    %9145 = stablehlo.broadcast_in_dim %9144, dims = [] : (tensor<f32>) -> tensor<3x3x128x128xf32>
    %9146 = stablehlo.multiply %9145, %8641 : tensor<3x3x128x128xf32>
    %9147 = stablehlo.convert %8798 : tensor<f32>
    %9148 = stablehlo.broadcast_in_dim %9147, dims = [] : (tensor<f32>) -> tensor<1x1x128x512xf32>
    %9149 = stablehlo.multiply %9148, %8644 : tensor<1x1x128x512xf32>
    %9150 = stablehlo.convert %8798 : tensor<f32>
    %9151 = stablehlo.broadcast_in_dim %9150, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %9152 = stablehlo.multiply %9151, %8647 : tensor<128xf32>
    %9153 = stablehlo.convert %8798 : tensor<f32>
    %9154 = stablehlo.broadcast_in_dim %9153, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %9155 = stablehlo.multiply %9154, %8650 : tensor<128xf32>
    %9156 = stablehlo.convert %8798 : tensor<f32>
    %9157 = stablehlo.broadcast_in_dim %9156, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %9158 = stablehlo.multiply %9157, %8653 : tensor<128xf32>
    %9159 = stablehlo.convert %8798 : tensor<f32>
    %9160 = stablehlo.broadcast_in_dim %9159, dims = [] : (tensor<f32>) -> tensor<128xf32>
    %9161 = stablehlo.multiply %9160, %8656 : tensor<128xf32>
    %9162 = stablehlo.convert %8798 : tensor<f32>
    %9163 = stablehlo.broadcast_in_dim %9162, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %9164 = stablehlo.multiply %9163, %8659 : tensor<512xf32>
    %9165 = stablehlo.convert %8798 : tensor<f32>
    %9166 = stablehlo.broadcast_in_dim %9165, dims = [] : (tensor<f32>) -> tensor<512xf32>
    %9167 = stablehlo.multiply %9166, %8662 : tensor<512xf32>
    %9168 = stablehlo.convert %8798 : tensor<f32>
    %9169 = stablehlo.broadcast_in_dim %9168, dims = [] : (tensor<f32>) -> tensor<1x1x512x128xf32>
    %9170 = stablehlo.multiply %9169, %8665 : tensor<1x1x512x128xf32>
    %9171 = stablehlo.convert %8798 : tensor<f32>
    %9172 = stablehlo.broadcast_in_dim %9171, dims = [] : (tensor<f32>) -> tensor<3x3x128x128xf32>
    %9173 = stablehlo.multiply %9172, %8668 : tensor<3x3x128x128xf32>
    %9174 = stablehlo.convert %8798 : tensor<f32>
    %9175 = stablehlo.broadcast_in_dim %9174, dims = [] : (tensor<f32>) -> tensor<1x1x128x512xf32>
    %9176 = stablehlo.multiply %9175, %8671 : tensor<1x1x128x512xf32>
    %9177 = stablehlo.convert %8798 : tensor<f32>
    %9178 = stablehlo.broadcast_in_dim %9177, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %9179 = stablehlo.multiply %9178, %8674 : tensor<256xf32>
    %9180 = stablehlo.convert %8798 : tensor<f32>
    %9181 = stablehlo.broadcast_in_dim %9180, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %9182 = stablehlo.multiply %9181, %8677 : tensor<256xf32>
    %9183 = stablehlo.convert %8798 : tensor<f32>
    %9184 = stablehlo.broadcast_in_dim %9183, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %9185 = stablehlo.multiply %9184, %8680 : tensor<256xf32>
    %9186 = stablehlo.convert %8798 : tensor<f32>
    %9187 = stablehlo.broadcast_in_dim %9186, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %9188 = stablehlo.multiply %9187, %8683 : tensor<256xf32>
    %9189 = stablehlo.convert %8798 : tensor<f32>
    %9190 = stablehlo.broadcast_in_dim %9189, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %9191 = stablehlo.multiply %9190, %8686 : tensor<1024xf32>
    %9192 = stablehlo.convert %8798 : tensor<f32>
    %9193 = stablehlo.broadcast_in_dim %9192, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %9194 = stablehlo.multiply %9193, %8689 : tensor<1024xf32>
    %9195 = stablehlo.convert %8798 : tensor<f32>
    %9196 = stablehlo.broadcast_in_dim %9195, dims = [] : (tensor<f32>) -> tensor<1x1x512x256xf32>
    %9197 = stablehlo.multiply %9196, %8692 : tensor<1x1x512x256xf32>
    %9198 = stablehlo.convert %8798 : tensor<f32>
    %9199 = stablehlo.broadcast_in_dim %9198, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %9200 = stablehlo.multiply %9199, %8695 : tensor<3x3x256x256xf32>
    %9201 = stablehlo.convert %8798 : tensor<f32>
    %9202 = stablehlo.broadcast_in_dim %9201, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %9203 = stablehlo.multiply %9202, %8698 : tensor<1x1x256x1024xf32>
    %9204 = stablehlo.convert %8798 : tensor<f32>
    %9205 = stablehlo.broadcast_in_dim %9204, dims = [] : (tensor<f32>) -> tensor<1x1x512x1024xf32>
    %9206 = stablehlo.multiply %9205, %8701 : tensor<1x1x512x1024xf32>
    %9207 = stablehlo.convert %8798 : tensor<f32>
    %9208 = stablehlo.broadcast_in_dim %9207, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %9209 = stablehlo.multiply %9208, %8704 : tensor<1024xf32>
    %9210 = stablehlo.convert %8798 : tensor<f32>
    %9211 = stablehlo.broadcast_in_dim %9210, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %9212 = stablehlo.multiply %9211, %8707 : tensor<1024xf32>
    %9213 = stablehlo.convert %8798 : tensor<f32>
    %9214 = stablehlo.broadcast_in_dim %9213, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %9215 = stablehlo.multiply %9214, %8710 : tensor<256xf32>
    %9216 = stablehlo.convert %8798 : tensor<f32>
    %9217 = stablehlo.broadcast_in_dim %9216, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %9218 = stablehlo.multiply %9217, %8713 : tensor<256xf32>
    %9219 = stablehlo.convert %8798 : tensor<f32>
    %9220 = stablehlo.broadcast_in_dim %9219, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %9221 = stablehlo.multiply %9220, %8716 : tensor<256xf32>
    %9222 = stablehlo.convert %8798 : tensor<f32>
    %9223 = stablehlo.broadcast_in_dim %9222, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %9224 = stablehlo.multiply %9223, %8719 : tensor<256xf32>
    %9225 = stablehlo.convert %8798 : tensor<f32>
    %9226 = stablehlo.broadcast_in_dim %9225, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %9227 = stablehlo.multiply %9226, %8722 : tensor<1024xf32>
    %9228 = stablehlo.convert %8798 : tensor<f32>
    %9229 = stablehlo.broadcast_in_dim %9228, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %9230 = stablehlo.multiply %9229, %8725 : tensor<1024xf32>
    %9231 = stablehlo.convert %8798 : tensor<f32>
    %9232 = stablehlo.broadcast_in_dim %9231, dims = [] : (tensor<f32>) -> tensor<1x1x1024x256xf32>
    %9233 = stablehlo.multiply %9232, %8728 : tensor<1x1x1024x256xf32>
    %9234 = stablehlo.convert %8798 : tensor<f32>
    %9235 = stablehlo.broadcast_in_dim %9234, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %9236 = stablehlo.multiply %9235, %8731 : tensor<3x3x256x256xf32>
    %9237 = stablehlo.convert %8798 : tensor<f32>
    %9238 = stablehlo.broadcast_in_dim %9237, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %9239 = stablehlo.multiply %9238, %8734 : tensor<1x1x256x1024xf32>
    %9240 = stablehlo.convert %8798 : tensor<f32>
    %9241 = stablehlo.broadcast_in_dim %9240, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %9242 = stablehlo.multiply %9241, %8737 : tensor<256xf32>
    %9243 = stablehlo.convert %8798 : tensor<f32>
    %9244 = stablehlo.broadcast_in_dim %9243, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %9245 = stablehlo.multiply %9244, %8740 : tensor<256xf32>
    %9246 = stablehlo.convert %8798 : tensor<f32>
    %9247 = stablehlo.broadcast_in_dim %9246, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %9248 = stablehlo.multiply %9247, %8743 : tensor<256xf32>
    %9249 = stablehlo.convert %8798 : tensor<f32>
    %9250 = stablehlo.broadcast_in_dim %9249, dims = [] : (tensor<f32>) -> tensor<256xf32>
    %9251 = stablehlo.multiply %9250, %8746 : tensor<256xf32>
    %9252 = stablehlo.convert %8798 : tensor<f32>
    %9253 = stablehlo.broadcast_in_dim %9252, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %9254 = stablehlo.multiply %9253, %8749 : tensor<1024xf32>
    %9255 = stablehlo.convert %8798 : tensor<f32>
    %9256 = stablehlo.broadcast_in_dim %9255, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %9257 = stablehlo.multiply %9256, %8752 : tensor<1024xf32>
    %9258 = stablehlo.convert %8798 : tensor<f32>
    %9259 = stablehlo.broadcast_in_dim %9258, dims = [] : (tensor<f32>) -> tensor<1x1x1024x256xf32>
    %9260 = stablehlo.multiply %9259, %8755 : tensor<1x1x1024x256xf32>
    %9261 = stablehlo.convert %8798 : tensor<f32>
    %9262 = stablehlo.broadcast_in_dim %9261, dims = [] : (tensor<f32>) -> tensor<3x3x256x256xf32>
    %9263 = stablehlo.multiply %9262, %8758 : tensor<3x3x256x256xf32>
    %9264 = stablehlo.convert %8798 : tensor<f32>
    %9265 = stablehlo.broadcast_in_dim %9264, dims = [] : (tensor<f32>) -> tensor<1x1x256x1024xf32>
    %9266 = stablehlo.multiply %9265, %8761 : tensor<1x1x256x1024xf32>
    %9267 = stablehlo.convert %8798 : tensor<f32>
    %9268 = stablehlo.broadcast_in_dim %9267, dims = [] : (tensor<f32>) -> tensor<1000xf32>
    %9269 = stablehlo.multiply %9268, %8764 : tensor<1000xf32>
    %9270 = stablehlo.convert %8798 : tensor<f32>
    %9271 = stablehlo.broadcast_in_dim %9270, dims = [] : (tensor<f32>) -> tensor<2048x1000xf32>
    %9272 = stablehlo.multiply %9271, %8767 : tensor<2048x1000xf32>
    %9273 = stablehlo.convert %8798 : tensor<f32>
    %9274 = stablehlo.broadcast_in_dim %9273, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %9275 = stablehlo.multiply %9274, %8770 : tensor<64xf32>
    %9276 = stablehlo.convert %8798 : tensor<f32>
    %9277 = stablehlo.broadcast_in_dim %9276, dims = [] : (tensor<f32>) -> tensor<64xf32>
    %9278 = stablehlo.multiply %9277, %8773 : tensor<64xf32>
    %9279 = stablehlo.convert %8798 : tensor<f32>
    %9280 = stablehlo.broadcast_in_dim %9279, dims = [] : (tensor<f32>) -> tensor<7x7x3x64xf32>
    %9281 = stablehlo.multiply %9280, %8776 : tensor<7x7x3x64xf32>
    %c_567 = stablehlo.constant dense<2147483647> : tensor<i32>
    %9282 = stablehlo.compare  LT, %arg323, %c_567,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
    %c_568 = stablehlo.constant dense<1> : tensor<i32>
    %9283 = stablehlo.add %arg323, %c_568 : tensor<i32>
    %9284 = call @_where_14(%9282, %9283, %c_567) : (tensor<i1>, tensor<i32>, tensor<i32>) -> tensor<i32>
    %9285 = stablehlo.add %arg1, %8801 : tensor<64xf32>
    %9286 = stablehlo.add %arg2, %8804 : tensor<64xf32>
    %9287 = stablehlo.add %arg3, %8807 : tensor<64xf32>
    %9288 = stablehlo.add %arg4, %8810 : tensor<64xf32>
    %9289 = stablehlo.add %arg5, %8813 : tensor<256xf32>
    %9290 = stablehlo.add %arg6, %8816 : tensor<256xf32>
    %9291 = stablehlo.add %arg7, %8819 : tensor<1x1x64x64xf32>
    %9292 = stablehlo.add %arg8, %8822 : tensor<3x3x64x64xf32>
    %9293 = stablehlo.add %arg9, %8825 : tensor<1x1x64x256xf32>
    %9294 = stablehlo.add %arg10, %8828 : tensor<1x1x64x256xf32>
    %9295 = stablehlo.add %arg11, %8831 : tensor<256xf32>
    %9296 = stablehlo.add %arg12, %8834 : tensor<256xf32>
    %9297 = stablehlo.add %arg13, %8837 : tensor<64xf32>
    %9298 = stablehlo.add %arg14, %8840 : tensor<64xf32>
    %9299 = stablehlo.add %arg15, %8843 : tensor<64xf32>
    %9300 = stablehlo.add %arg16, %8846 : tensor<64xf32>
    %9301 = stablehlo.add %arg17, %8849 : tensor<256xf32>
    %9302 = stablehlo.add %arg18, %8852 : tensor<256xf32>
    %9303 = stablehlo.add %arg19, %8855 : tensor<1x1x256x64xf32>
    %9304 = stablehlo.add %arg20, %8858 : tensor<3x3x64x64xf32>
    %9305 = stablehlo.add %arg21, %8861 : tensor<1x1x64x256xf32>
    %9306 = stablehlo.add %arg22, %8864 : tensor<256xf32>
    %9307 = stablehlo.add %arg23, %8867 : tensor<256xf32>
    %9308 = stablehlo.add %arg24, %8870 : tensor<256xf32>
    %9309 = stablehlo.add %arg25, %8873 : tensor<256xf32>
    %9310 = stablehlo.add %arg26, %8876 : tensor<1024xf32>
    %9311 = stablehlo.add %arg27, %8879 : tensor<1024xf32>
    %9312 = stablehlo.add %arg28, %8882 : tensor<1x1x1024x256xf32>
    %9313 = stablehlo.add %arg29, %8885 : tensor<3x3x256x256xf32>
    %9314 = stablehlo.add %arg30, %8888 : tensor<1x1x256x1024xf32>
    %9315 = stablehlo.add %arg31, %8891 : tensor<256xf32>
    %9316 = stablehlo.add %arg32, %8894 : tensor<256xf32>
    %9317 = stablehlo.add %arg33, %8897 : tensor<256xf32>
    %9318 = stablehlo.add %arg34, %8900 : tensor<256xf32>
    %9319 = stablehlo.add %arg35, %8903 : tensor<1024xf32>
    %9320 = stablehlo.add %arg36, %8906 : tensor<1024xf32>
    %9321 = stablehlo.add %arg37, %8909 : tensor<1x1x1024x256xf32>
    %9322 = stablehlo.add %arg38, %8912 : tensor<3x3x256x256xf32>
    %9323 = stablehlo.add %arg39, %8915 : tensor<1x1x256x1024xf32>
    %9324 = stablehlo.add %arg40, %8918 : tensor<256xf32>
    %9325 = stablehlo.add %arg41, %8921 : tensor<256xf32>
    %9326 = stablehlo.add %arg42, %8924 : tensor<256xf32>
    %9327 = stablehlo.add %arg43, %8927 : tensor<256xf32>
    %9328 = stablehlo.add %arg44, %8930 : tensor<1024xf32>
    %9329 = stablehlo.add %arg45, %8933 : tensor<1024xf32>
    %9330 = stablehlo.add %arg46, %8936 : tensor<1x1x1024x256xf32>
    %9331 = stablehlo.add %arg47, %8939 : tensor<3x3x256x256xf32>
    %9332 = stablehlo.add %arg48, %8942 : tensor<1x1x256x1024xf32>
    %9333 = stablehlo.add %arg49, %8945 : tensor<512xf32>
    %9334 = stablehlo.add %arg50, %8948 : tensor<512xf32>
    %9335 = stablehlo.add %arg51, %8951 : tensor<512xf32>
    %9336 = stablehlo.add %arg52, %8954 : tensor<512xf32>
    %9337 = stablehlo.add %arg53, %8957 : tensor<2048xf32>
    %9338 = stablehlo.add %arg54, %8960 : tensor<2048xf32>
    %9339 = stablehlo.add %arg55, %8963 : tensor<1x1x1024x512xf32>
    %9340 = stablehlo.add %arg56, %8966 : tensor<3x3x512x512xf32>
    %9341 = stablehlo.add %arg57, %8969 : tensor<1x1x512x2048xf32>
    %9342 = stablehlo.add %arg58, %8972 : tensor<1x1x1024x2048xf32>
    %9343 = stablehlo.add %arg59, %8975 : tensor<2048xf32>
    %9344 = stablehlo.add %arg60, %8978 : tensor<2048xf32>
    %9345 = stablehlo.add %arg61, %8981 : tensor<512xf32>
    %9346 = stablehlo.add %arg62, %8984 : tensor<512xf32>
    %9347 = stablehlo.add %arg63, %8987 : tensor<512xf32>
    %9348 = stablehlo.add %arg64, %8990 : tensor<512xf32>
    %9349 = stablehlo.add %arg65, %8993 : tensor<2048xf32>
    %9350 = stablehlo.add %arg66, %8996 : tensor<2048xf32>
    %9351 = stablehlo.add %arg67, %8999 : tensor<1x1x2048x512xf32>
    %9352 = stablehlo.add %arg68, %9002 : tensor<3x3x512x512xf32>
    %9353 = stablehlo.add %arg69, %9005 : tensor<1x1x512x2048xf32>
    %9354 = stablehlo.add %arg70, %9008 : tensor<512xf32>
    %9355 = stablehlo.add %arg71, %9011 : tensor<512xf32>
    %9356 = stablehlo.add %arg72, %9014 : tensor<512xf32>
    %9357 = stablehlo.add %arg73, %9017 : tensor<512xf32>
    %9358 = stablehlo.add %arg74, %9020 : tensor<2048xf32>
    %9359 = stablehlo.add %arg75, %9023 : tensor<2048xf32>
    %9360 = stablehlo.add %arg76, %9026 : tensor<1x1x2048x512xf32>
    %9361 = stablehlo.add %arg77, %9029 : tensor<3x3x512x512xf32>
    %9362 = stablehlo.add %arg78, %9032 : tensor<1x1x512x2048xf32>
    %9363 = stablehlo.add %arg79, %9035 : tensor<64xf32>
    %9364 = stablehlo.add %arg80, %9038 : tensor<64xf32>
    %9365 = stablehlo.add %arg81, %9041 : tensor<64xf32>
    %9366 = stablehlo.add %arg82, %9044 : tensor<64xf32>
    %9367 = stablehlo.add %arg83, %9047 : tensor<256xf32>
    %9368 = stablehlo.add %arg84, %9050 : tensor<256xf32>
    %9369 = stablehlo.add %arg85, %9053 : tensor<1x1x256x64xf32>
    %9370 = stablehlo.add %arg86, %9056 : tensor<3x3x64x64xf32>
    %9371 = stablehlo.add %arg87, %9059 : tensor<1x1x64x256xf32>
    %9372 = stablehlo.add %arg88, %9062 : tensor<128xf32>
    %9373 = stablehlo.add %arg89, %9065 : tensor<128xf32>
    %9374 = stablehlo.add %arg90, %9068 : tensor<128xf32>
    %9375 = stablehlo.add %arg91, %9071 : tensor<128xf32>
    %9376 = stablehlo.add %arg92, %9074 : tensor<512xf32>
    %9377 = stablehlo.add %arg93, %9077 : tensor<512xf32>
    %9378 = stablehlo.add %arg94, %9080 : tensor<1x1x256x128xf32>
    %9379 = stablehlo.add %arg95, %9083 : tensor<3x3x128x128xf32>
    %9380 = stablehlo.add %arg96, %9086 : tensor<1x1x128x512xf32>
    %9381 = stablehlo.add %arg97, %9089 : tensor<1x1x256x512xf32>
    %9382 = stablehlo.add %arg98, %9092 : tensor<512xf32>
    %9383 = stablehlo.add %arg99, %9095 : tensor<512xf32>
    %9384 = stablehlo.add %arg100, %9098 : tensor<128xf32>
    %9385 = stablehlo.add %arg101, %9101 : tensor<128xf32>
    %9386 = stablehlo.add %arg102, %9104 : tensor<128xf32>
    %9387 = stablehlo.add %arg103, %9107 : tensor<128xf32>
    %9388 = stablehlo.add %arg104, %9110 : tensor<512xf32>
    %9389 = stablehlo.add %arg105, %9113 : tensor<512xf32>
    %9390 = stablehlo.add %arg106, %9116 : tensor<1x1x512x128xf32>
    %9391 = stablehlo.add %arg107, %9119 : tensor<3x3x128x128xf32>
    %9392 = stablehlo.add %arg108, %9122 : tensor<1x1x128x512xf32>
    %9393 = stablehlo.add %arg109, %9125 : tensor<128xf32>
    %9394 = stablehlo.add %arg110, %9128 : tensor<128xf32>
    %9395 = stablehlo.add %arg111, %9131 : tensor<128xf32>
    %9396 = stablehlo.add %arg112, %9134 : tensor<128xf32>
    %9397 = stablehlo.add %arg113, %9137 : tensor<512xf32>
    %9398 = stablehlo.add %arg114, %9140 : tensor<512xf32>
    %9399 = stablehlo.add %arg115, %9143 : tensor<1x1x512x128xf32>
    %9400 = stablehlo.add %arg116, %9146 : tensor<3x3x128x128xf32>
    %9401 = stablehlo.add %arg117, %9149 : tensor<1x1x128x512xf32>
    %9402 = stablehlo.add %arg118, %9152 : tensor<128xf32>
    %9403 = stablehlo.add %arg119, %9155 : tensor<128xf32>
    %9404 = stablehlo.add %arg120, %9158 : tensor<128xf32>
    %9405 = stablehlo.add %arg121, %9161 : tensor<128xf32>
    %9406 = stablehlo.add %arg122, %9164 : tensor<512xf32>
    %9407 = stablehlo.add %arg123, %9167 : tensor<512xf32>
    %9408 = stablehlo.add %arg124, %9170 : tensor<1x1x512x128xf32>
    %9409 = stablehlo.add %arg125, %9173 : tensor<3x3x128x128xf32>
    %9410 = stablehlo.add %arg126, %9176 : tensor<1x1x128x512xf32>
    %9411 = stablehlo.add %arg127, %9179 : tensor<256xf32>
    %9412 = stablehlo.add %arg128, %9182 : tensor<256xf32>
    %9413 = stablehlo.add %arg129, %9185 : tensor<256xf32>
    %9414 = stablehlo.add %arg130, %9188 : tensor<256xf32>
    %9415 = stablehlo.add %arg131, %9191 : tensor<1024xf32>
    %9416 = stablehlo.add %arg132, %9194 : tensor<1024xf32>
    %9417 = stablehlo.add %arg133, %9197 : tensor<1x1x512x256xf32>
    %9418 = stablehlo.add %arg134, %9200 : tensor<3x3x256x256xf32>
    %9419 = stablehlo.add %arg135, %9203 : tensor<1x1x256x1024xf32>
    %9420 = stablehlo.add %arg136, %9206 : tensor<1x1x512x1024xf32>
    %9421 = stablehlo.add %arg137, %9209 : tensor<1024xf32>
    %9422 = stablehlo.add %arg138, %9212 : tensor<1024xf32>
    %9423 = stablehlo.add %arg139, %9215 : tensor<256xf32>
    %9424 = stablehlo.add %arg140, %9218 : tensor<256xf32>
    %9425 = stablehlo.add %arg141, %9221 : tensor<256xf32>
    %9426 = stablehlo.add %arg142, %9224 : tensor<256xf32>
    %9427 = stablehlo.add %arg143, %9227 : tensor<1024xf32>
    %9428 = stablehlo.add %arg144, %9230 : tensor<1024xf32>
    %9429 = stablehlo.add %arg145, %9233 : tensor<1x1x1024x256xf32>
    %9430 = stablehlo.add %arg146, %9236 : tensor<3x3x256x256xf32>
    %9431 = stablehlo.add %arg147, %9239 : tensor<1x1x256x1024xf32>
    %9432 = stablehlo.add %arg148, %9242 : tensor<256xf32>
    %9433 = stablehlo.add %arg149, %9245 : tensor<256xf32>
    %9434 = stablehlo.add %arg150, %9248 : tensor<256xf32>
    %9435 = stablehlo.add %arg151, %9251 : tensor<256xf32>
    %9436 = stablehlo.add %arg152, %9254 : tensor<1024xf32>
    %9437 = stablehlo.add %arg153, %9257 : tensor<1024xf32>
    %9438 = stablehlo.add %arg154, %9260 : tensor<1x1x1024x256xf32>
    %9439 = stablehlo.add %arg155, %9263 : tensor<3x3x256x256xf32>
    %9440 = stablehlo.add %arg156, %9266 : tensor<1x1x256x1024xf32>
    %9441 = stablehlo.add %arg157, %9269 : tensor<1000xf32>
    %9442 = stablehlo.add %arg158, %9272 : tensor<2048x1000xf32>
    %9443 = stablehlo.add %arg159, %9275 : tensor<64xf32>
    %9444 = stablehlo.add %arg160, %9278 : tensor<64xf32>
    %9445 = stablehlo.add %arg161, %9281 : tensor<7x7x3x64xf32>
    %c_569 = stablehlo.constant dense<1> : tensor<i32>
    %9446 = stablehlo.add %arg0, %c_569 : tensor<i32>
    %9447 = stablehlo.broadcast_in_dim %7491, dims = [] : (tensor<f32>) -> tensor<1xf32>
    %9448 = stablehlo.broadcast_in_dim %22, dims = [] : (tensor<f32>) -> tensor<1xf32>
    %9449 = stablehlo.broadcast_in_dim %7492, dims = [] : (tensor<f32>) -> tensor<1xf32>
    return %9446, %9285, %9286, %9287, %9288, %9289, %9290, %9291, %9292, %9293, %9294, %9295, %9296, %9297, %9298, %9299, %9300, %9301, %9302, %9303, %9304, %9305, %9306, %9307, %9308, %9309, %9310, %9311, %9312, %9313, %9314, %9315, %9316, %9317, %9318, %9319, %9320, %9321, %9322, %9323, %9324, %9325, %9326, %9327, %9328, %9329, %9330, %9331, %9332, %9333, %9334, %9335, %9336, %9337, %9338, %9339, %9340, %9341, %9342, %9343, %9344, %9345, %9346, %9347, %9348, %9349, %9350, %9351, %9352, %9353, %9354, %9355, %9356, %9357, %9358, %9359, %9360, %9361, %9362, %9363, %9364, %9365, %9366, %9367, %9368, %9369, %9370, %9371, %9372, %9373, %9374, %9375, %9376, %9377, %9378, %9379, %9380, %9381, %9382, %9383, %9384, %9385, %9386, %9387, %9388, %9389, %9390, %9391, %9392, %9393, %9394, %9395, %9396, %9397, %9398, %9399, %9400, %9401, %9402, %9403, %9404, %9405, %9406, %9407, %9408, %9409, %9410, %9411, %9412, %9413, %9414, %9415, %9416, %9417, %9418, %9419, %9420, %9421, %9422, %9423, %9424, %9425, %9426, %9427, %9428, %9429, %9430, %9431, %9432, %9433, %9434, %9435, %9436, %9437, %9438, %9439, %9440, %9441, %9442, %9443, %9444, %9445, %7813, %7816, %7819, %7822, %7825, %7828, %7831, %7834, %7837, %7840, %7843, %7846, %7849, %7852, %7855, %7858, %7861, %7864, %7867, %7870, %7873, %7876, %7879, %7882, %7885, %7888, %7891, %7894, %7897, %7900, %7903, %7906, %7909, %7912, %7915, %7918, %7921, %7924, %7927, %7930, %7933, %7936, %7939, %7942, %7945, %7948, %7951, %7954, %7957, %7960, %7963, %7966, %7969, %7972, %7975, %7978, %7981, %7984, %7987, %7990, %7993, %7996, %7999, %8002, %8005, %8008, %8011, %8014, %8017, %8020, %8023, %8026, %8029, %8032, %8035, %8038, %8041, %8044, %8047, %8050, %8053, %8056, %8059, %8062, %8065, %8068, %8071, %8074, %8077, %8080, %8083, %8086, %8089, %8092, %8095, %8098, %8101, %8104, %8107, %8110, %8113, %8116, %8119, %8122, %8125, %8128, %8131, %8134, %8137, %8140, %8143, %8146, %8149, %8152, %8155, %8158, %8161, %8164, %8167, %8170, %8173, %8176, %8179, %8182, %8185, %8188, %8191, %8194, %8197, %8200, %8203, %8206, %8209, %8212, %8215, %8218, %8221, %8224, %8227, %8230, %8233, %8236, %8239, %8242, %8245, %8248, %8251, %8254, %8257, %8260, %8263, %8266, %8269, %8272, %8275, %8278, %8281, %8284, %8287, %8290, %8293, %9284, %7600, %7602, %7604, %7606, %7608, %7610, %7612, %7614, %7616, %7618, %7620, %7622, %7624, %7626, %7628, %7630, %7632, %7634, %7636, %7638, %7640, %7642, %7644, %7646, %7648, %7650, %7652, %7654, %7656, %7658, %7660, %7662, %7664, %7666, %7668, %7670, %7672, %7674, %7676, %7678, %7680, %7682, %7684, %7686, %7688, %7690, %7692, %7694, %7696, %7698, %7700, %7702, %7704, %7706, %7708, %7710, %7712, %7714, %7716, %7718, %7720, %7722, %7724, %7726, %7728, %7730, %7732, %7734, %7736, %7738, %7740, %7742, %7744, %7746, %7748, %7750, %7752, %7754, %7756, %7758, %7760, %7762, %7764, %7766, %7768, %7770, %7772, %7774, %7776, %7778, %7780, %7782, %7784, %7786, %7788, %7790, %7792, %7794, %7796, %7798, %7800, %7802, %7804, %7806, %7808, %7810, %9447, %9448, %9449 : tensor<i32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<256xf32>, tensor<256xf32>, tensor<1x1x64x64xf32>, tensor<3x3x64x64xf32>, tensor<1x1x64x256xf32>, tensor<1x1x64x256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<256xf32>, tensor<256xf32>, tensor<1x1x256x64xf32>, tensor<3x3x64x64xf32>, tensor<1x1x64x256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<1x1x1024x256xf32>, tensor<3x3x256x256xf32>, tensor<1x1x256x1024xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<1x1x1024x256xf32>, tensor<3x3x256x256xf32>, tensor<1x1x256x1024xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<1x1x1024x256xf32>, tensor<3x3x256x256xf32>, tensor<1x1x256x1024xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<2048xf32>, tensor<2048xf32>, tensor<1x1x1024x512xf32>, tensor<3x3x512x512xf32>, tensor<1x1x512x2048xf32>, tensor<1x1x1024x2048xf32>, tensor<2048xf32>, tensor<2048xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<2048xf32>, tensor<2048xf32>, tensor<1x1x2048x512xf32>, tensor<3x3x512x512xf32>, tensor<1x1x512x2048xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<2048xf32>, tensor<2048xf32>, tensor<1x1x2048x512xf32>, tensor<3x3x512x512xf32>, tensor<1x1x512x2048xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<256xf32>, tensor<256xf32>, tensor<1x1x256x64xf32>, tensor<3x3x64x64xf32>, tensor<1x1x64x256xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<512xf32>, tensor<512xf32>, tensor<1x1x256x128xf32>, tensor<3x3x128x128xf32>, tensor<1x1x128x512xf32>, tensor<1x1x256x512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<512xf32>, tensor<512xf32>, tensor<1x1x512x128xf32>, tensor<3x3x128x128xf32>, tensor<1x1x128x512xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<512xf32>, tensor<512xf32>, tensor<1x1x512x128xf32>, tensor<3x3x128x128xf32>, tensor<1x1x128x512xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<512xf32>, tensor<512xf32>, tensor<1x1x512x128xf32>, tensor<3x3x128x128xf32>, tensor<1x1x128x512xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<1x1x512x256xf32>, tensor<3x3x256x256xf32>, tensor<1x1x256x1024xf32>, tensor<1x1x512x1024xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<1x1x1024x256xf32>, tensor<3x3x256x256xf32>, tensor<1x1x256x1024xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<1x1x1024x256xf32>, tensor<3x3x256x256xf32>, tensor<1x1x256x1024xf32>, tensor<1000xf32>, tensor<2048x1000xf32>, tensor<64xf32>, tensor<64xf32>, tensor<7x7x3x64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<256xf32>, tensor<256xf32>, tensor<1x1x64x64xf32>, tensor<3x3x64x64xf32>, tensor<1x1x64x256xf32>, tensor<1x1x64x256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<256xf32>, tensor<256xf32>, tensor<1x1x256x64xf32>, tensor<3x3x64x64xf32>, tensor<1x1x64x256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<1x1x1024x256xf32>, tensor<3x3x256x256xf32>, tensor<1x1x256x1024xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<1x1x1024x256xf32>, tensor<3x3x256x256xf32>, tensor<1x1x256x1024xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<1x1x1024x256xf32>, tensor<3x3x256x256xf32>, tensor<1x1x256x1024xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<2048xf32>, tensor<2048xf32>, tensor<1x1x1024x512xf32>, tensor<3x3x512x512xf32>, tensor<1x1x512x2048xf32>, tensor<1x1x1024x2048xf32>, tensor<2048xf32>, tensor<2048xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<2048xf32>, tensor<2048xf32>, tensor<1x1x2048x512xf32>, tensor<3x3x512x512xf32>, tensor<1x1x512x2048xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<2048xf32>, tensor<2048xf32>, tensor<1x1x2048x512xf32>, tensor<3x3x512x512xf32>, tensor<1x1x512x2048xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<256xf32>, tensor<256xf32>, tensor<1x1x256x64xf32>, tensor<3x3x64x64xf32>, tensor<1x1x64x256xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<512xf32>, tensor<512xf32>, tensor<1x1x256x128xf32>, tensor<3x3x128x128xf32>, tensor<1x1x128x512xf32>, tensor<1x1x256x512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<512xf32>, tensor<512xf32>, tensor<1x1x512x128xf32>, tensor<3x3x128x128xf32>, tensor<1x1x128x512xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<512xf32>, tensor<512xf32>, tensor<1x1x512x128xf32>, tensor<3x3x128x128xf32>, tensor<1x1x128x512xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<512xf32>, tensor<512xf32>, tensor<1x1x512x128xf32>, tensor<3x3x128x128xf32>, tensor<1x1x128x512xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<1x1x512x256xf32>, tensor<3x3x256x256xf32>, tensor<1x1x256x1024xf32>, tensor<1x1x512x1024xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<1x1x1024x256xf32>, tensor<3x3x256x256xf32>, tensor<1x1x256x1024xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<1x1x1024x256xf32>, tensor<3x3x256x256xf32>, tensor<1x1x256x1024xf32>, tensor<1000xf32>, tensor<2048x1000xf32>, tensor<64xf32>, tensor<64xf32>, tensor<7x7x3x64xf32>, tensor<i32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<2048xf32>, tensor<2048xf32>, tensor<2048xf32>, tensor<2048xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<2048xf32>, tensor<2048xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<2048xf32>, tensor<2048xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<256xf32>, tensor<256xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<512xf32>, tensor<512xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<512xf32>, tensor<512xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<512xf32>, tensor<512xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<64xf32>, tensor<64xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>
  }
  func.func private @clip(%arg0: tensor<i32>, %arg1: tensor<i32>, %arg2: tensor<f32>) -> tensor<f32> {
    %0 = stablehlo.maximum %arg1, %arg0 : tensor<i32>
    %1 = stablehlo.convert %0 : (tensor<i32>) -> tensor<f32>
    %2 = stablehlo.minimum %arg2, %1 : tensor<f32>
    return %2 : tensor<f32>
  }
  func.func private @_where(%arg0: tensor<i1>, %arg1: tensor<f32>, %arg2: tensor<f32>) -> tensor<f32> {
    %0 = stablehlo.select %arg0, %arg1, %arg2 : tensor<i1>, tensor<f32>
    return %0 : tensor<f32>
  }
  func.func private @relu(%arg0: tensor<256x112x112x64xf16>) -> tensor<256x112x112x64xf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f16>) -> tensor<256x112x112x64xf16>
    %1 = stablehlo.maximum %arg0, %0 : tensor<256x112x112x64xf16>
    return %1 : tensor<256x112x112x64xf16>
  }
  func.func private @relu_0(%arg0: tensor<256x56x56x64xf16>) -> tensor<256x56x56x64xf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f16>) -> tensor<256x56x56x64xf16>
    %1 = stablehlo.maximum %arg0, %0 : tensor<256x56x56x64xf16>
    return %1 : tensor<256x56x56x64xf16>
  }
  func.func private @relu_1(%arg0: tensor<256x56x56x256xf16>) -> tensor<256x56x56x256xf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f16>) -> tensor<256x56x56x256xf16>
    %1 = stablehlo.maximum %arg0, %0 : tensor<256x56x56x256xf16>
    return %1 : tensor<256x56x56x256xf16>
  }
  func.func private @relu_2(%arg0: tensor<256x56x56x128xf16>) -> tensor<256x56x56x128xf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f16>) -> tensor<256x56x56x128xf16>
    %1 = stablehlo.maximum %arg0, %0 : tensor<256x56x56x128xf16>
    return %1 : tensor<256x56x56x128xf16>
  }
  func.func private @relu_3(%arg0: tensor<256x28x28x128xf16>) -> tensor<256x28x28x128xf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f16>) -> tensor<256x28x28x128xf16>
    %1 = stablehlo.maximum %arg0, %0 : tensor<256x28x28x128xf16>
    return %1 : tensor<256x28x28x128xf16>
  }
  func.func private @relu_4(%arg0: tensor<256x28x28x512xf16>) -> tensor<256x28x28x512xf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f16>) -> tensor<256x28x28x512xf16>
    %1 = stablehlo.maximum %arg0, %0 : tensor<256x28x28x512xf16>
    return %1 : tensor<256x28x28x512xf16>
  }
  func.func private @relu_5(%arg0: tensor<256x28x28x256xf16>) -> tensor<256x28x28x256xf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f16>) -> tensor<256x28x28x256xf16>
    %1 = stablehlo.maximum %arg0, %0 : tensor<256x28x28x256xf16>
    return %1 : tensor<256x28x28x256xf16>
  }
  func.func private @relu_6(%arg0: tensor<256x14x14x256xf16>) -> tensor<256x14x14x256xf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f16>) -> tensor<256x14x14x256xf16>
    %1 = stablehlo.maximum %arg0, %0 : tensor<256x14x14x256xf16>
    return %1 : tensor<256x14x14x256xf16>
  }
  func.func private @relu_7(%arg0: tensor<256x14x14x1024xf16>) -> tensor<256x14x14x1024xf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f16>) -> tensor<256x14x14x1024xf16>
    %1 = stablehlo.maximum %arg0, %0 : tensor<256x14x14x1024xf16>
    return %1 : tensor<256x14x14x1024xf16>
  }
  func.func private @relu_8(%arg0: tensor<256x14x14x512xf16>) -> tensor<256x14x14x512xf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f16>) -> tensor<256x14x14x512xf16>
    %1 = stablehlo.maximum %arg0, %0 : tensor<256x14x14x512xf16>
    return %1 : tensor<256x14x14x512xf16>
  }
  func.func private @relu_9(%arg0: tensor<256x7x7x512xf16>) -> tensor<256x7x7x512xf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f16>) -> tensor<256x7x7x512xf16>
    %1 = stablehlo.maximum %arg0, %0 : tensor<256x7x7x512xf16>
    return %1 : tensor<256x7x7x512xf16>
  }
  func.func private @relu_10(%arg0: tensor<256x7x7x2048xf16>) -> tensor<256x7x7x2048xf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f16>) -> tensor<256x7x7x2048xf16>
    %1 = stablehlo.maximum %arg0, %0 : tensor<256x7x7x2048xf16>
    return %1 : tensor<256x7x7x2048xf16>
  }
  func.func private @log_softmax(%arg0: tensor<256x1000xf16>) -> (tensor<256x1000xf16>, tensor<256x1000xf16>, tensor<256x1xf16>) {
    %cst = stablehlo.constant dense<0xFC00> : tensor<f16>
    %0 = stablehlo.reduce(%arg0 init: %cst) applies stablehlo.maximum across dimensions = [1] : (tensor<256x1000xf16>, tensor<f16>) -> tensor<256xf16>
    %1 = stablehlo.reshape %0 : (tensor<256xf16>) -> tensor<256x1xf16>
    %2 = stablehlo.broadcast_in_dim %1, dims = [0, 1] : (tensor<256x1xf16>) -> tensor<256x1000xf16>
    %3 = stablehlo.compare  EQ, %arg0, %2,  FLOAT : (tensor<256x1000xf16>, tensor<256x1000xf16>) -> tensor<256x1000xi1>
    %4 = stablehlo.convert %3 : (tensor<256x1000xi1>) -> tensor<256x1000xf16>
    %cst_0 = stablehlo.constant dense<0.000000e+00> : tensor<f16>
    %5 = stablehlo.reduce(%4 init: %cst_0) applies stablehlo.add across dimensions = [1] : (tensor<256x1000xf16>, tensor<f16>) -> tensor<256xf16>
    %cst_1 = stablehlo.constant dense<0xFC00> : tensor<f16>
    %6 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f16>) -> tensor<256xf16>
    %7 = stablehlo.maximum %6, %0 : tensor<256xf16>
    %8 = stablehlo.compare  EQ, %0, %7,  FLOAT : (tensor<256xf16>, tensor<256xf16>) -> tensor<256xi1>
    %cst_2 = stablehlo.constant dense<1.000000e+00> : tensor<f16>
    %9 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f16>) -> tensor<256xf16>
    %cst_3 = stablehlo.constant dense<0.000000e+00> : tensor<f16>
    %10 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f16>) -> tensor<256xf16>
    %11 = stablehlo.select %8, %9, %10 : tensor<256xi1>, tensor<256xf16>
    %12 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f16>) -> tensor<256xf16>
    %13 = stablehlo.compare  EQ, %12, %7,  FLOAT : (tensor<256xf16>, tensor<256xf16>) -> tensor<256xi1>
    %cst_4 = stablehlo.constant dense<2.000000e+00> : tensor<f16>
    %14 = stablehlo.broadcast_in_dim %cst_4, dims = [] : (tensor<f16>) -> tensor<256xf16>
    %15 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f16>) -> tensor<256xf16>
    %16 = stablehlo.select %13, %14, %15 : tensor<256xi1>, tensor<256xf16>
    %17 = stablehlo.divide %11, %16 : tensor<256xf16>
    %18 = stablehlo.broadcast_in_dim %7, dims = [0] : (tensor<256xf16>) -> tensor<256x1xf16>
    %19 = stablehlo.broadcast_in_dim %18, dims = [0, 1] : (tensor<256x1xf16>) -> tensor<256x1000xf16>
    %20 = stablehlo.subtract %arg0, %19 : tensor<256x1000xf16>
    %21 = stablehlo.exponential %20 : tensor<256x1000xf16>
    %22 = stablehlo.convert %21 : (tensor<256x1000xf16>) -> tensor<256x1000xf32>
    %cst_5 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %23 = stablehlo.reduce(%22 init: %cst_5) applies stablehlo.add across dimensions = [1] : (tensor<256x1000xf32>, tensor<f32>) -> tensor<256xf32>
    %24 = stablehlo.broadcast_in_dim %23, dims = [0] : (tensor<256xf32>) -> tensor<256x1xf32>
    %25 = stablehlo.convert %24 : (tensor<256x1xf32>) -> tensor<256x1xf16>
    %26 = stablehlo.log %25 : tensor<256x1xf16>
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] : (tensor<256x1xf16>) -> tensor<256x1000xf16>
    %28 = stablehlo.subtract %20, %27 : tensor<256x1000xf16>
    return %28, %21, %25 : tensor<256x1000xf16>, tensor<256x1000xf16>, tensor<256x1xf16>
  }
  func.func private @log_softmax_11(%arg0: tensor<256x1000xf16>, %arg1: tensor<256x1xf16>, %arg2: tensor<256x1000xf16>) -> tensor<256x1000xf16> {
    %0 = stablehlo.negate %arg2 : tensor<256x1000xf16>
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f16>
    %1 = stablehlo.reduce(%0 init: %cst) applies stablehlo.add across dimensions = [1] : (tensor<256x1000xf16>, tensor<f16>) -> tensor<256xf16>
    %2 = stablehlo.reshape %1 : (tensor<256xf16>) -> tensor<256x1xf16>
    %3 = stablehlo.divide %2, %arg1 : tensor<256x1xf16>
    %4 = stablehlo.convert %3 : (tensor<256x1xf16>) -> tensor<256x1xf32>
    %cst_0 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %5 = stablehlo.reduce(%4 init: %cst_0) applies stablehlo.add across dimensions = [1] : (tensor<256x1xf32>, tensor<f32>) -> tensor<256xf32>
    %6 = stablehlo.broadcast_in_dim %5, dims = [0] : (tensor<256xf32>) -> tensor<256x1000xf32>
    %7 = stablehlo.convert %6 : (tensor<256x1000xf32>) -> tensor<256x1000xf16>
    %8 = stablehlo.multiply %7, %arg0 : tensor<256x1000xf16>
    %9 = stablehlo.add %arg2, %8 : tensor<256x1000xf16>
    return %9 : tensor<256x1000xf16>
  }
  func.func private @log_softmax_12(%arg0: tensor<256x1000xf16>) -> tensor<256x1000xf16> {
    %cst = stablehlo.constant dense<0xFC00> : tensor<f16>
    %0 = stablehlo.reduce(%arg0 init: %cst) applies stablehlo.maximum across dimensions = [1] : (tensor<256x1000xf16>, tensor<f16>) -> tensor<256xf16>
    %cst_0 = stablehlo.constant dense<0xFC00> : tensor<f16>
    %1 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f16>) -> tensor<256xf16>
    %2 = stablehlo.maximum %1, %0 : tensor<256xf16>
    %3 = stablehlo.broadcast_in_dim %2, dims = [0] : (tensor<256xf16>) -> tensor<256x1xf16>
    %4 = stablehlo.broadcast_in_dim %3, dims = [0, 1] : (tensor<256x1xf16>) -> tensor<256x1000xf16>
    %5 = stablehlo.subtract %arg0, %4 : tensor<256x1000xf16>
    %6 = stablehlo.exponential %5 : tensor<256x1000xf16>
    %7 = stablehlo.convert %6 : (tensor<256x1000xf16>) -> tensor<256x1000xf32>
    %cst_1 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %8 = stablehlo.reduce(%7 init: %cst_1) applies stablehlo.add across dimensions = [1] : (tensor<256x1000xf32>, tensor<f32>) -> tensor<256xf32>
    %9 = stablehlo.broadcast_in_dim %8, dims = [0] : (tensor<256xf32>) -> tensor<256x1xf32>
    %10 = stablehlo.convert %9 : (tensor<256x1xf32>) -> tensor<256x1xf16>
    %11 = stablehlo.log %10 : tensor<256x1xf16>
    %12 = stablehlo.broadcast_in_dim %11, dims = [0, 1] : (tensor<256x1xf16>) -> tensor<256x1000xf16>
    %13 = stablehlo.subtract %5, %12 : tensor<256x1000xf16>
    return %13 : tensor<256x1000xf16>
  }
  func.func private @argmax(%arg0: tensor<256x1000xf16>) -> tensor<256xi32> {
    %0 = stablehlo.iota dim = 1 : tensor<256x1000xi32>
    %cst = stablehlo.constant dense<0xFC00> : tensor<f16>
    %c = stablehlo.constant dense<0> : tensor<i32>
    %1:2 = stablehlo.reduce(%arg0 init: %cst), (%0 init: %c) across dimensions = [1] : (tensor<256x1000xf16>, tensor<256x1000xi32>, tensor<f16>, tensor<i32>) -> (tensor<256xf16>, tensor<256xi32>)
     reducer(%arg1: tensor<f16>, %arg3: tensor<f16>) (%arg2: tensor<i32>, %arg4: tensor<i32>)  {
      %2 = stablehlo.compare  GT, %arg1, %arg3,  FLOAT : (tensor<f16>, tensor<f16>) -> tensor<i1>
      %3 = stablehlo.compare  NE, %arg1, %arg1,  FLOAT : (tensor<f16>, tensor<f16>) -> tensor<i1>
      %4 = stablehlo.or %2, %3 : tensor<i1>
      %5 = stablehlo.compare  EQ, %arg1, %arg3,  FLOAT : (tensor<f16>, tensor<f16>) -> tensor<i1>
      %6 = stablehlo.compare  LT, %arg2, %arg4,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
      %7 = stablehlo.and %5, %6 : tensor<i1>
      %8 = stablehlo.or %4, %7 : tensor<i1>
      %9 = stablehlo.select %4, %arg1, %arg3 : tensor<i1>, tensor<f16>
      %10 = stablehlo.select %8, %arg2, %arg4 : tensor<i1>, tensor<i32>
      stablehlo.return %9, %10 : tensor<f16>, tensor<i32>
    }
    return %1#1 : tensor<256xi32>
  }
  func.func private @clip_13(%arg0: tensor<i32>, %arg1: tensor<i32>, %arg2: tensor<f32>) -> tensor<f32> {
    %0 = stablehlo.convert %arg1 : tensor<i32>
    %1 = stablehlo.maximum %0, %arg0 : tensor<i32>
    %2 = stablehlo.convert %1 : (tensor<i32>) -> tensor<f32>
    %3 = stablehlo.minimum %arg2, %2 : tensor<f32>
    return %3 : tensor<f32>
  }
  func.func private @_where_14(%arg0: tensor<i1>, %arg1: tensor<i32>, %arg2: tensor<i32>) -> tensor<i32> {
    %0 = stablehlo.select %arg0, %arg1, %arg2 : tensor<i1>, tensor<i32>
    return %0 : tensor<i32>
  }
}
